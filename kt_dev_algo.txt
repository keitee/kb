*kt_dev_algo*                                                           tw=100, utf-8

/^[#=]{
Use #{ for a group and ={ for a item

*kt_dev_algo_0000* dev-algo-code-sites

*kt_dev_algo_0000* algo-two-player-card-game
*kt_dev_algo_0000* algo-swap swap without a temporary
*kt_dev_algo_0000* algo-grade
*kt_dev_algo_0000* algo-intersect find intersect between rectangles
*kt_dev_algo_0000* algo-roman roman converter
*kt_dev_algo_0000* dev-algo-problem algo-recursion
*kt_dev_algo_0000* dev-algo-problem algo-recursion-tail-recursion
*kt_dev_algo_0000* dev-algo-problem algo-recursion algo-maze
*kt_dev_algo_0000* algo-count-bit count same bits between two integers
*kt_dev_algo_0000* algo-reverse-bit
*kt_dev_algo_0000* algo-partition algo-remove algo-unique
*kt_dev_algo_0000* algo-rotate
*kt_dev_algo_0000* dev-algo-problem algo-game-of-life

*kt_dev_algo_0000* dev-algo-problem code-review
|kt_dev_quiz_015| sorting and searching questions from {ref-004}
*kt_dev_algo_0000* dev-algo-quiz estimation using power of two *ex-interview*
|kt_dev_quiz_018| linked list questions from {ref-004} {runner-technique} {tortoise-and-hare}
|kt_dev_quiz_019| array and string questions from {ref-004}
|kt_dev_quiz_020| coding task
*kt_dev_quiz_021* q-technical
|kt_dev_quiz_021| q-logic

|kt_dev_algo_0000| algo-equi equilibrium index of a sequence
*kt_dev_algo_0000* algo-equi-tape
|kt_dev_algo_0000| algo-water
|kt_dev_algo_0000| algo-frog-jump
|kt_dev_algo_0000| dev-algo-problem algo-find-missing-element
|kt_dev_algo_0000| dev-algo-problem algo-find-perm
|kt_dev_algo_0000| dev-algo-problem algo-frog-river
*kt_dev_algo_0000* dev-algo-problem algo-find-missing-integer
*kt_dev_algo_0000* dev-algo-problem algo-max-counters
*kt_dev_algo_0000* algo-minmax
*kt_dev_algo_0000* algo-prefix-sum algo-mushroom
*kt_dev_algo_0000* algo-max-sum-sub-array
*kt_dev_algo_0000* algo-max-profit
*kt_dev_algo_0000* dev-algo-problem algo-passing-car
*kt_dev_algo_0000* dev-algo-problem algo-count-div
*kt_dev_algo_0000* dev-algo-problem algo-count-identical-pairs
*kt_dev_algo_0000* dev-algo-problem algo-lesson-time-complexity
*kt_dev_algo_0000* dev-algo-problem algo-lesson-conunting-element
*kt_dev_algo_0000* dev-algo-problem algo-repairman

*kt_dev_quiz_300* q-code-rally

#{ algorithm
|kt_dev_algo_000| sentinel
*kt_dev_algo_0000* dev-algo-adt
*kt_dev_algo_0000* dev-algo-stack
*kt_dev_algo_0000* dev-algo-stack-problem
*kt_dev_algo_0000* dev-algo-list
*kt_dev_algo_0000* dev-algo-list-general
*kt_dev_algo_0000* dev-algo-list-problem algo-cycle-detection
*kt_dev_algo_0000* dev-algo-queue
|kt_dev_algo_005| array: index shift
*kt_dev_algo_008* algo-bigo-notation
*kt_dev_algo_0000* algo-search
*kt_dev_algo_0000* algo-binary-search
*kt_dev_algo_008* algo-ordered-list
*kt_dev_algo_0000* algo-sort
|kt_dev_algo_010| table and hash {radixsort}
*kt_dev_algo_0000* dev-algo-binary-tree
|kt_dev_algo_011| binary tree {binary-search-tree} {treesort}
|kt_dev_algo_012| avl tree
|kt_dev_algo_013| multiway tree {b-tree} {red-black-tree}
|kt_dev_algo_050| comparison of methods

#{ CASES
|kt_dev_algo_100| dobble linked list 

#{ DISCUSSION
|kt_dev_algo_300| C++ map insertion and lookup performance and storage overhead

|kt_dev_glib_000| glib sites
*kt_dev_algo_0000* algo-atoi algo-itoa dev-algo-htoi
|kt_dev_glib_002| atof 
*kt_dev_algo_0000* dev-algo-itoa
|kt_dev_glib_004| printf
|kt_dev_glib_005| qsort
|kt_dev_glib_006| glib-tail
|kt_dev_glib_007| fopen
|kt_dev_glib_008| isdigit
|kt_dev_glib_010| abs
|kt_dev_glib_101| general tips

|kt_dev_glib_200| strcpy and strncpy
*kt_dev_algo_0000* lib-strlen
|kt_dev_glib_202| strcat
|kt_dev_glib_203| strstr, strindex
|kt_dev_glib_204| strcmp
|kt_dev_glib_205| strpbrk, strtok
|kt_dev_glib_206| strdup
|kt_dev_glib_207| strchr and basename

|kt_dev_glib_300| malloc


# ============================================================================
#{ dev questions
={============================================================================
*kt_dev_algo_0000* dev-algo-code-sites

https://leetcode.com
https://www.hackerrank.com
https://codility.com/
http://codility-lessons.blogspot.com/2014/07/lesson-2maxcounters.html
https://interviewing.io/
http://rosettacode.org/wiki/Rosetta_Code


={============================================================================
*kt_dev_algo_0000* algo-two-player-card-game


={============================================================================
*kt_dev_algo_0000* algo-swap swap without a temporary
  
How to swap two vars without using a temp?

  It's the standard a=a+b, b=a-b, a=a-b problem. We hired the guy who said,
  well, "if they're integers, then I'd do it by a=a|b, b=a^b, a=a^b. But I don't
  know how to do it if they're strings."


From Cracking the coding interview, p430,

| -- | ------ | ----
     a        b 


namespace algo_swap
{
  void swap_1(int &a, int &b)
  {
    a = a + b;
    b = a - b;      // b = a
    a = a - b;      // a = b
  }

  // X XOR  X  = 0
  // X XOR  0  = X
  // X XOR  1  = ~X    // X XOR (~0) = ~X
  // X XOR ~X  = 1     
  // 
  // 00000000000000000000111111000000 // x
  // 00000000000000000000111111000000 // x^0
  // 11111111111111111111000000111111 // x^(~0) but not x^1
  // 
  // x =  1010; y = 0011;          // before
  // x =  1001 =  1010  ^ 0011     // x = x^y
  // y =  1010 = [1001] ^ 0011     // y = x^y, y = (x^y)^y = (x^0) = x
  // x = [0011] =  1001 ^ [1010]   // x = x^y, x = (x^y)^x = (y^0) = y
  // x = 0011; y = 1010;           // after

  void swap_2(int &a, int &b)
  {
    a = a ^ b;
    b = a ^ b;      // b = a^b = (a^b)^b = a^0 = a
    a = a ^ b;      // a = a^b = (a^b)^a = b^0 = b
  }
} // namespace

TEST(AlgoSwap, Swap)
{
  using namespace algo_swap;

  {
    int a = 9, b = 4;

    swap_1(a, b);

    EXPECT_THAT(a, Eq(4));
    EXPECT_THAT(b, Eq(9));
  }
  {
    int a = 9, b = 4;

    swap_2(a, b);

    EXPECT_THAT(a, Eq(4));
    EXPECT_THAT(b, Eq(9));
  }
}  


={===========================================================================
*kt_dev_algo_0000* algo-roman roman converter

// Convert Arabic number to Roman number
//
// 1. the roman number has fixed mappings:
//
//  1       : I
//  5       : V
//  10      : X
//  50      : L
//  100     : C
//  500     : D
//  1000    : M
//
// 2. As itoa(), use loop, %, and / to get a digit to convert:
//  
//      tens    2   1   0
//              X   X   X
//      digit   D   D   D
//
// 3. Divide 0-9 into sub-groups to get:
//
//  * 0 < digit < 4:
//
//      tens = 0:
//          1       (1, 10**0)      I
//          2       (2, 10**0)      II
//          3       (3, 10**0)      III
//
//      tens = 1:
//          10      (1, 10**1)      X
//          20      (2, 10**1)      XX
//          30      (3, 10**1)      XXX
//
//      tens = 2:
//          100     (1, 10**2)      C
//          200     (2, 10**2)      CC
//          300     (3, 10**2)      CCC
//      ...
//
//      To use the same function as 5 < digit < 9 case:
//
//      tens = 0:
//                          (base, repeat, roman to repeat)
//          1, 0+1          (0*10**0, 1, 10**0)     I
//          2, 0+1          (0*10**0, 2, 10**0)     II
//          3, 0+1          (0*10**0, 3, 10**0)     III
//
//  * 5 < digit < 9:
//
//      tens = 0:
//                          (base, repeat, roman to repeat)
//          6, 5+1          (5*10**0, 1, 10**0)     VI
//          7, 5+2          (5*10**0, 2, 10**0)     VII
//          8, 5+3          (5*10**0, 3, 10**0)     VIII
//
//      tens = 1:
//          60, 50+10       (5*10**1, 1, 10**1)     LX
//          70, 50+20       (5*10**1, 2, 10**1)     LXX
//          89, 50+30       (5*10**1, 3, 10**1)     LXXX
//
//      tens = 2:
//          600, 500+100    (5*10**1, 1, 10**1)     DC
//          700, 500+200    (5*10**1, 2, 10**1)     DCC
//          890, 500+300    (5*10**1, 3, 10**1)     DCCC
//      ...
//
//  * 4 or 9
//
//      tens = 0:
//          4, 5-1          (10**0 + (4+1)*10**0)   IV
//          9, 10-1         (10**0 + (9+1)*10**0)   IX
//
//      tens = 1:
//          40, 50-10       (10**1 + (4+1)*10**1)   XL
//          90, 100-10      (10**1 + (9+1)*10**1)   XC
//      ...
//
//  * 5
//
//      tens = 0:
//          5,              (10**0*5)
//
//      tens = 1:
//          50              (10**1*5)
//
//      tens = 2:
//          500             (10**2*5)

namespace algo_roman
{
  class RomanConvert
  {
    public:

      // 1. tried to use input/output string arg like 
      //
      //      void convert(uint32_t, std::string &)
      //
      // and use public string member in the fixture class.
      // However, since there are many asserts in a test, have to reset
      // this string member before using the next assert. dropped.
      //
      // 2. uses one single string and add at the front whenever converted a
      // letter. By this, no need to reverse the result as itoa() does but
      // there will be a downside; relocation and performance. Howerver, since
      // it is not a long string, do not think they matter here. 

      std::string convert(uint32_t number) const 
      {
        std::string converted;
        uint32_t tens{0}, digit{0};

        // for fixed roman letters
        // the code works without this to cover fixed romans since the loop
        // below will find it eventually. However, it uses a map already and
        // may save some time.

        auto it = roman_table.find(number);
        if (it != roman_table.cend())
          return it->second;

        for (; number;)
        {
          digit = number % 10;

          if (digit < 4)
          {
            padWithFoundRoman(digit, tens, 0, converted);
          }
          else if (digit > 5 && digit < 9)
          {
            padWithFoundRoman(digit, tens, 5, converted);
          }
          else if (!(digit % 5))
          {
            findFiveBaseRoman(digit, tens, converted);
          }
          else if (digit == 4 || digit == 9)
          {
            findSubstractRoman(digit, tens, converted);
          }

          ++tens;

          number /= 10;
        }

        return converted;
      }

    private:
      const std::map<uint32_t, std::string> roman_table{
        {0, ""},
          {1, "I"}, {5, "V"},
          {10, "X"}, {50, "L"},
          {100, "C"}, {500, "D"},
          {1000, "M"}
      };

      void padWithFoundRoman(uint32_t number, uint32_t tens, uint32_t fixed, std::string &padded) const
      {
        std::string result;

        // find the letter to pad
        auto it = roman_table.find( pow(10, tens) );
        if ( it == roman_table.cend() )
          std::cout << "roman_table(" << pow(10, tens) << ") not found" << std::endl;

        std::string letter = it->second;

        // find the base
        it = roman_table.find( fixed*pow(10, tens) );
        if ( it == roman_table.cend() )
          std::cout << "roman_table(" << fixed*pow( 10, tens ) << ") not found" << std::endl;

        std::string base = it->second;

        // add the base once
        result += base;

        // add the pad
        for (uint32_t count = number - fixed; count; --count)
          result += letter;

        padded.insert(0, result);
      }

      void findSubstractRoman(uint32_t number, uint32_t tens, std::string &converted) const
      {
        std::string padded;

        // find the letter in substract form
        auto it = roman_table.find( pow(10, tens) );
        if ( it == roman_table.cend() )
          std::cout << "roman_table(" << pow(10, tens) << ") not found" << std::endl;

        std::string letter = it->second;

        // find the base
        it = roman_table.find( (number+1)*pow(10, tens) );
        if ( it == roman_table.cend() )
          std::cout << "roman_table(" << (number+1)*pow( 10, tens ) << ") not found" << std::endl;

        std::string base = it->second;

        converted.insert( 0, letter + base );
      }

      void findFiveBaseRoman(uint32_t number, uint32_t tens, std::string &converted) const
      {
        // find the letter in substract form
        auto it = roman_table.find( number * pow(10, tens) );
        if ( it == roman_table.cend() )
          std::cout << "roman_table(" << pow(10, tens) << ") not found" << std::endl;

        converted.insert( 0, it->second );
      }
  };

} // namespace

TEST(AlgoRoman, ToRomans_1) 
{
  using namespace algo_roman;

  RomanConvert converter;

  EXPECT_THAT(converter.convert(1), Eq("I"));
  EXPECT_THAT(converter.convert(2), Eq("II"));
  EXPECT_THAT(converter.convert(3), Eq("III"));
  EXPECT_THAT(converter.convert(4), Eq("IV"));
  EXPECT_THAT(converter.convert(5), Eq("V"));
  EXPECT_THAT(converter.convert(6), Eq("VI"));
  EXPECT_THAT(converter.convert(7), Eq("VII"));
  EXPECT_THAT(converter.convert(8), Eq("VIII"));
  EXPECT_THAT(converter.convert(9), Eq("IX"));
  EXPECT_THAT(converter.convert(10), Eq("X"));
  EXPECT_THAT(converter.convert(11), Eq("XI"));
  EXPECT_THAT(converter.convert(12), Eq("XII"));
  EXPECT_THAT(converter.convert(13), Eq("XIII"));
  EXPECT_THAT(converter.convert(16), Eq("XVI"));
  EXPECT_THAT(converter.convert(17), Eq("XVII"));
  EXPECT_THAT(converter.convert(18), Eq("XVIII"));
  EXPECT_THAT(converter.convert(20), Eq("XX"));
  EXPECT_THAT(converter.convert(23), Eq("XXIII"));
  EXPECT_THAT(converter.convert(41), Eq("XLI"));
  EXPECT_THAT(converter.convert(45), Eq("XLV"));
  EXPECT_THAT(converter.convert(50), Eq("L"));
  EXPECT_THAT(converter.convert(80), Eq("LXXX"));
  EXPECT_THAT(converter.convert(91), Eq("XCI"));
  EXPECT_THAT(converter.convert(95), Eq("XCV"));
  EXPECT_THAT(converter.convert(100), Eq("C"));
  EXPECT_THAT(converter.convert(122), Eq("CXXII"));
  EXPECT_THAT(converter.convert(152), Eq("CLII"));
  EXPECT_THAT(converter.convert(196), Eq("CXCVI"));
  EXPECT_THAT(converter.convert(247), Eq("CCXLVII"));
  EXPECT_THAT(converter.convert(288), Eq("CCLXXXVIII"));
  EXPECT_THAT(converter.convert(298), Eq("CCXCVIII"));
  EXPECT_THAT(converter.convert(500), Eq("D"));
  EXPECT_THAT(converter.convert(1000), Eq("M"));
  EXPECT_THAT(converter.convert(1513), Eq("MDXIII"));
  EXPECT_THAT(converter.convert(2999), Eq("MMCMXCIX"));
  EXPECT_THAT(converter.convert(3447), Eq("MMMCDXLVII"));
}


namespace algo_roman
{
  string to_roman_2(unsigned int arabic) 
  {
    string convert{};

    // note:
    // 1. the order of element in the map matters
    // 2. do not need 6?? in the map since it follows the same addition rule
    // 3. to fix a warning on signed int and unsigned int comparion, use "u"
    // suffix.

    const auto lookup_table = {
      make_pair(1000u, "M"),
      make_pair(900u, "CM"),
      // make_pair(600, "DC"),
      make_pair(500u, "D"),
      make_pair(400u, "CD"),
      make_pair(100u, "C"),
      //
      make_pair(90u, "XC"),
      // make_pair(60, "LX"),
      make_pair(50u, "L"),
      make_pair(40u, "XL"),
      make_pair(10u, "X"),
      //
      make_pair(9u, "IX"),
      // make_pair(6, "VI"),
      make_pair(5u, "V"),
      make_pair(4u, "IV"),
      make_pair(1u, "I")
    };

    for (const auto e : lookup_table)
    {
      while (e.first <= arabic)
      {
        arabic -= e.first;
        convert += e.second;
      }
    }

    // cout << "converted: " << convert << endl;

    return convert;
  }

} // namespace


// from TDD book

TEST(AlgoRoman, ToRomans_2) 
{
  using namespace algo_roman;

  EXPECT_THAT(to_roman_2(1), Eq("I"));
  EXPECT_THAT(to_roman_2(2), Eq("II"));
  EXPECT_THAT(to_roman_2(3), Eq("III"));
  EXPECT_THAT(to_roman_2(4), Eq("IV"));
  EXPECT_THAT(to_roman_2(5), Eq("V"));
  EXPECT_THAT(to_roman_2(6), Eq("VI"));
  EXPECT_THAT(to_roman_2(7), Eq("VII"));
  EXPECT_THAT(to_roman_2(8), Eq("VIII"));
  EXPECT_THAT(to_roman_2(9), Eq("IX"));
  EXPECT_THAT(to_roman_2(10), Eq("X"));
  EXPECT_THAT(to_roman_2(11), Eq("XI"));
  EXPECT_THAT(to_roman_2(12), Eq("XII"));
  EXPECT_THAT(to_roman_2(13), Eq("XIII"));
  EXPECT_THAT(to_roman_2(16), Eq("XVI"));
  EXPECT_THAT(to_roman_2(17), Eq("XVII"));
  EXPECT_THAT(to_roman_2(18), Eq("XVIII"));
  EXPECT_THAT(to_roman_2(20), Eq("XX"));
  EXPECT_THAT(to_roman_2(23), Eq("XXIII"));
  EXPECT_THAT(to_roman_2(41), Eq("XLI"));
  EXPECT_THAT(to_roman_2(45), Eq("XLV"));
  EXPECT_THAT(to_roman_2(50), Eq("L"));
  EXPECT_THAT(to_roman_2(80), Eq("LXXX"));
  EXPECT_THAT(to_roman_2(91), Eq("XCI"));
  EXPECT_THAT(to_roman_2(95), Eq("XCV"));
  EXPECT_THAT(to_roman_2(100), Eq("C"));
  EXPECT_THAT(to_roman_2(122), Eq("CXXII"));
  EXPECT_THAT(to_roman_2(152), Eq("CLII"));
  EXPECT_THAT(to_roman_2(196), Eq("CXCVI"));
  EXPECT_THAT(to_roman_2(247), Eq("CCXLVII"));
  EXPECT_THAT(to_roman_2(288), Eq("CCLXXXVIII"));
  EXPECT_THAT(to_roman_2(298), Eq("CCXCVIII"));
  EXPECT_THAT(to_roman_2(500), Eq("D"));
  EXPECT_THAT(to_roman_2(1000), Eq("M"));
  EXPECT_THAT(to_roman_2(1513), Eq("MDXIII"));
  EXPECT_THAT(to_roman_2(2999), Eq("MMCMXCIX"));
  EXPECT_THAT(to_roman_2(3447), Eq("MMMCDXLVII"));
}

namespace algo_roman
{
  const string to_roman_3(unsigned int value)
  {
    const auto roman_table{
      make_pair(1000u, "M"),
        make_pair(900u, "CM"),
        make_pair(500u, "D"),
        make_pair(400u, "CD"),
        make_pair(100u, "C"),
        make_pair(90u, "XC"),
        make_pair(50u, "L"),
        make_pair(40u, "XL"),
        make_pair(10u, "X"),
        make_pair(9u, "IX"),
        make_pair(5u, "V"),
        make_pair(4u, "IV"),
        make_pair(1u, "I")
    };

    string result{};

    for (const auto &e : roman_table)
    {
      // note: must be "<=" but not "<"

      while (e.first <= value)
      {
        value -= e.first;
        result += e.second;
      }
    }

    return result;
  }

  // 2018
  const string to_roman_4(unsigned int value)
  {
    const initializer_list<pair<unsigned int, string>> roman_table{
      {1000u, "M"},
        {900u, "CM"},
        {500u, "D"},
        {400u, "CD"},
        {100u, "C"},
        {90u, "XC"},
        {50u, "L"},
        {40u, "XL"},
        {10u, "X"},
        {9u, "IX"},
        {5u, "V"},
        {4u, "IV"},
        {1u, "I"}
    };

    string result{};

    for (const auto &e : roman_table)
    {
      // note: must be "<=" but not "<"

      while (e.first <= value)
      {
        value -= e.first;
        result += e.second;
      }
    }

    return result;
  }

} // namespace

TEST(AlgoRoman, ToRomans_3) 
{
  using namespace algo_roman;

  EXPECT_THAT(to_roman_4(1), Eq("I"));
  EXPECT_THAT(to_roman_4(2), Eq("II"));
  EXPECT_THAT(to_roman_4(3), Eq("III"));
  EXPECT_THAT(to_roman_4(4), Eq("IV"));
  EXPECT_THAT(to_roman_4(5), Eq("V"));
  EXPECT_THAT(to_roman_4(6), Eq("VI"));
  EXPECT_THAT(to_roman_4(7), Eq("VII"));
  EXPECT_THAT(to_roman_4(8), Eq("VIII"));
  EXPECT_THAT(to_roman_4(9), Eq("IX"));
  EXPECT_THAT(to_roman_4(10), Eq("X"));
  EXPECT_THAT(to_roman_4(11), Eq("XI"));
  EXPECT_THAT(to_roman_4(12), Eq("XII"));
  EXPECT_THAT(to_roman_4(13), Eq("XIII"));
  EXPECT_THAT(to_roman_4(16), Eq("XVI"));
  EXPECT_THAT(to_roman_4(17), Eq("XVII"));
  EXPECT_THAT(to_roman_4(18), Eq("XVIII"));
  EXPECT_THAT(to_roman_4(20), Eq("XX"));
  EXPECT_THAT(to_roman_4(23), Eq("XXIII"));
  EXPECT_THAT(to_roman_4(41), Eq("XLI"));
  EXPECT_THAT(to_roman_4(45), Eq("XLV"));
  EXPECT_THAT(to_roman_4(50), Eq("L"));
  EXPECT_THAT(to_roman_4(80), Eq("LXXX"));
  EXPECT_THAT(to_roman_4(91), Eq("XCI"));
  EXPECT_THAT(to_roman_4(95), Eq("XCV"));
  EXPECT_THAT(to_roman_4(100), Eq("C"));
  EXPECT_THAT(to_roman_4(122), Eq("CXXII"));
  EXPECT_THAT(to_roman_4(152), Eq("CLII"));
  EXPECT_THAT(to_roman_4(196), Eq("CXCVI"));
  EXPECT_THAT(to_roman_4(247), Eq("CCXLVII"));
  EXPECT_THAT(to_roman_4(288), Eq("CCLXXXVIII"));
  EXPECT_THAT(to_roman_4(298), Eq("CCXCVIII"));
  EXPECT_THAT(to_roman_4(500), Eq("D"));
  EXPECT_THAT(to_roman_4(1000), Eq("M"));
  EXPECT_THAT(to_roman_4(1513), Eq("MDXIII"));
  EXPECT_THAT(to_roman_4(2999), Eq("MMCMXCIX"));
  EXPECT_THAT(to_roman_4(3447), Eq("MMMCDXLVII"));
}

// algo-leetcode-4
/*
13. Roman to Integer, Easy

Roman numerals are represented by seven different symbols: I, V, X, L, C, D and M.

Symbol       Value
I             1
V             5
X             10
L             50
C             100
D             500
M             1000

For example, two is written as II in Roman numeral, just two one's added
together. Twelve is written as, XII, which is simply X + II. The number twenty
seven is written as XXVII, which is XX + V + II.

Roman numerals are usually written largest to smallest from left to right.
However, the numeral for four is not IIII. Instead, the number four is written
as IV. Because the one is before the five we subtract it making four. The same
principle applies to the number nine, which is written as IX. There are six
instances where subtraction is used:

I can be placed before V (5) and X (10) to make 4 and 9. 
X can be placed before L (50) and C (100) to make 40 and 90. 
C can be placed before D (500) and M (1000) to make 400 and 900.

Given a roman numeral, convert it to an integer. Input is guaranteed to be
within the range from 1 to 3999.

see algo-roman for integer to roman conversion which is rated as:

12. Integer to Roman, Medium

*/

namespace algo_roman
{
  // Runtime: 52 ms, faster than 97.00% of C++ online submissions for Roman to
  // Integer.
  //
  // Memory Usage: 30.7 MB, less than 96.08% of C++ online submissions for Roman
  // to Integer.

  int to_integer_1(std::string input)
  {
    // do not use this from since "M" is deduced to "const char*" but want to
    // use it as string so that cah use size() on it. Or can add size member in
    // the table.
    //
    // const auto table = {
    //   make_pair("M", 1000),
    //   make_pair("CM", 900)
    // };

    // for each char of the table, see if there is matched substr using running
    // start position and string size. contine doing so until there is no match
    // and if there is no match, move on to the next char.

    const initializer_list<pair<std::string, int>> table = {
      {"M", 1000},
      {"CM", 900},
      {"D", 500},
      {"CD", 400},
      {"C", 100},
      {"XC", 90},
      {"L", 50},
      {"XL", 40},
      {"X", 10},
      {"IX", 9},
      {"V", 5},
      {"IV", 4},
      {"I", 1}
    };

    size_t run{};
    int result{};

    for (const auto& e : table)
    {
      while ((run < input.size()) && (input.substr(run, e.first.size()) == e.first))
      {
        // cout << "first: " << e.first << endl;
        result += e.second;
        run += e.first.size();
      }
    }
    // cout << "result: " << result << endl;

    return result;
  }

  int to_integer_2(std::string input)
  {
    const auto table{
      make_pair(string("M"), 1000),
      make_pair(string("CM"), 900),
      make_pair(string("D"), 500),
      make_pair(string("CD"), 400),
      make_pair(string("C"), 100),
      make_pair(string("XC"), 90),
      make_pair(string("L"), 50),
      make_pair(string("XL"), 40),
      make_pair(string("X"), 10),
      make_pair(string("IX"), 9),
      make_pair(string("V"), 5),
      make_pair(string("IV"), 4),
      make_pair(string("I"), 1)
    };

    int result{};
    size_t start{};

    for (auto const &e : table)
    {
      while (input.find(e.first, start) == start)
      {
        start += e.first.size();
        result += e.second;
      }
    }

    return result;
  }
} // namespace


TEST(AlgoRoman, ToInteger)
{
  using namespace algo_roman;

  {
    const auto func = to_integer_1;

    EXPECT_THAT(func("I"), 1);
    EXPECT_THAT(func("II"), 2);
    EXPECT_THAT(func("III"), 3);
    EXPECT_THAT(func("IV"), 4);
    EXPECT_THAT(func("V"), 5);
    EXPECT_THAT(func("VI"), 6);
    EXPECT_THAT(func("VII"), 7);
    EXPECT_THAT(func("VIII"), 8);
    EXPECT_THAT(func("IX"), 9);
    EXPECT_THAT(func("X"), 10);
    EXPECT_THAT(func("XI"), 11);
    EXPECT_THAT(func("XII"), 12);
    EXPECT_THAT(func("XIII"), 13);
    EXPECT_THAT(func("XVI"), 16);
    EXPECT_THAT(func("XVII"), 17);
    EXPECT_THAT(func("XVIII"), 18);
    EXPECT_THAT(func("XX"), 20);
    EXPECT_THAT(func("XXIII"), 23);
    EXPECT_THAT(func("XLI"), 41);
    EXPECT_THAT(func("XLV"), 45);
    EXPECT_THAT(func("L"), 50);
    EXPECT_THAT(func("LXXX"), 80);
    EXPECT_THAT(func("XCI"), 91);
    EXPECT_THAT(func("XCV"), 95);
    EXPECT_THAT(func("C"), 100);
    EXPECT_THAT(func("CXXII"), 122);
    EXPECT_THAT(func("CLII"), 152);
    EXPECT_THAT(func("CXCVI"), 196);
    EXPECT_THAT(func("CCXLVII"), 247);
    EXPECT_THAT(func("CCLXXXVIII"), 288);
    EXPECT_THAT(func("CCXCVIII"), 298);
    EXPECT_THAT(func("D"), 500);
    EXPECT_THAT(func("M"), 1000);
    EXPECT_THAT(func("MDXIII"), 1513);
    EXPECT_THAT(func("MMCMXCIX"), 2999);
    EXPECT_THAT(func("MMMCDXLVII"), 3447);
  }

  {
    const auto func = to_integer_2;

    EXPECT_THAT(func("I"), 1);
    EXPECT_THAT(func("II"), 2);
    EXPECT_THAT(func("III"), 3);
    EXPECT_THAT(func("IV"), 4);
    EXPECT_THAT(func("V"), 5);
    EXPECT_THAT(func("VI"), 6);
    EXPECT_THAT(func("VII"), 7);
    EXPECT_THAT(func("VIII"), 8);
    EXPECT_THAT(func("IX"), 9);
    EXPECT_THAT(func("X"), 10);
    EXPECT_THAT(func("XI"), 11);
    EXPECT_THAT(func("XII"), 12);
    EXPECT_THAT(func("XIII"), 13);
    EXPECT_THAT(func("XVI"), 16);
    EXPECT_THAT(func("XVII"), 17);
    EXPECT_THAT(func("XVIII"), 18);
    EXPECT_THAT(func("XX"), 20);
    EXPECT_THAT(func("XXIII"), 23);
    EXPECT_THAT(func("XLI"), 41);
    EXPECT_THAT(func("XLV"), 45);
    EXPECT_THAT(func("L"), 50);
    EXPECT_THAT(func("LXXX"), 80);
    EXPECT_THAT(func("XCI"), 91);
    EXPECT_THAT(func("XCV"), 95);
    EXPECT_THAT(func("C"), 100);
    EXPECT_THAT(func("CXXII"), 122);
    EXPECT_THAT(func("CLII"), 152);
    EXPECT_THAT(func("CXCVI"), 196);
    EXPECT_THAT(func("CCXLVII"), 247);
    EXPECT_THAT(func("CCLXXXVIII"), 288);
    EXPECT_THAT(func("CCXCVIII"), 298);
    EXPECT_THAT(func("D"), 500);
    EXPECT_THAT(func("M"), 1000);
    EXPECT_THAT(func("MDXIII"), 1513);
    EXPECT_THAT(func("MMCMXCIX"), 2999);
    EXPECT_THAT(func("MMMCDXLVII"), 3447);
  }
}


={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-recursion

The recursion is `divide-and-conquer` as it reduce the large problem to one or
more problems of a similar nature but a smaller size. 

Must determine the `stopping-rule`, the smallest case because there must be
some way that the recursion stops.

<ex> algo-recursion-hanoi

the-tower-of-hanoi

The idea is to concentrate not on the first step, but rather on the hardest
step: moving the bottom disk because condition is that only one disk can be
moved at a time and the bottom, largest, one can never be on top of any other.

Assume that there are 64 disks:

Move(disk, start, finish, temp);

Move(64, 1, 3, 2)
{
  // moves 63th from 1 to 2
  Move(63, 1, 2, 3);

  // moves 64th from 1 to 3 since there is no 63th on top of it
  printf("move disk 64 from tower 1 to 3.\n");

  // moves 63th from 2 to 3
  Move(63, 2, 3, 1);
}

The stopping rule is when there is no disk to be moved, there is nothing to do.

namespace algo_recursion_hanoi
{
  unsigned int recursion_depth;

  void print_depth(bool dash, unsigned int depth)
  {
    for( unsigned int i=0; i <= depth; ++i)
    {
      if(dash)
        cout << "--";
      else
        cout << "  ";
    }

    if(dash)
      cout << "(" << depth << ") ";
    else
      cout << "      ";
  }

  void move_disk(int count, int start, int finish, int temp)
  {
    // ++calls;
    ++recursion_depth;
    print_depth(true, recursion_depth);

    cout << "Move(" << count << "," << start << "," << finish << "," << temp << ")" << endl;

    if (count > 0)
    {
      move_disk(count-1, start, temp, finish);

      print_depth(false, recursion_depth);
      cout << "move " << count << " disk, " << start << " -> " << finish << endl;

      move_disk(count-1, temp, finish, start);
    }
    else
    {
      print_depth(false, recursion_depth);
      cout << "move " << count << " disk, " << start << " -> " << finish << endl;
    }

    --recursion_depth;
  }

} // namespace


The number of non-leafs, that is the number of moves for 64 is 2^64-1. This
is about 5x10^11 years where 2x10^10 is 20 billion years


<recursion-tree>

This is a tool to visualize recursive call in which node represents recursion
call. The time requirement is the total number of nodes, vertices, in a
recursion tree since traverse all nodes and the space(stack space) is the
depth of tree, not the number of nodes.

                                                          Move(3, 1,3,2) ()

                             Move(2, 1,2,3) ()                             ...

         Move(1, 1,3,2) ()                      Move(1, 3,2,1) ()          

Move(0, 1,2,3) ()  Move(0, 2,3,1) ()   Move(0, 3,1,2) ()  Move(0, 1,2,3) ()


// disks are 0, 1, 2, 3
//
// [ RUN      ] AlgoRecursion.Hanoi
// ----(1) Move(3,1,3,2)
// ------(2) Move(2,1,2,3)                {
// --------(3) Move(1,1,3,2)
// ----------(4) Move(0,1,2,3)
//                 move 0 disk, 1 -> 2
//               move 1 disk, 1 -> 3
// ----------(4) Move(0,2,3,1)
//                 move 0 disk, 2 -> 3
//
//             move 2 disk, 1 -> 2
//
// --------(3) Move(1,3,2,1)
// ----------(4) Move(0,3,1,2)
//                 move 0 disk, 3 -> 1
//               move 1 disk, 3 -> 2
// ----------(4) Move(0,1,2,3)
//                 move 0 disk, 1 -> 2    }
//
//           move 3 disk, 1 -> 3
//
// ------(2) Move(2,2,3,1)
// --------(3) Move(1,2,1,3)
// ----------(4) Move(0,2,3,1)
//                 move 0 disk, 2 -> 3
//               move 1 disk, 2 -> 1
// ----------(4) Move(0,3,1,2)
//                 move 0 disk, 3 -> 1
//             move 2 disk, 2 -> 3
// --------(3) Move(1,1,3,2)
// ----------(4) Move(0,1,2,3)
//                 move 0 disk, 1 -> 2
//               move 1 disk, 1 -> 3
// ----------(4) Move(0,2,3,1)
//                 move 0 disk, 2 -> 3
// [       OK ] AlgoRecursion.Hanoi (3 ms)

TEST(AlgoRecursion, Hanoi) 
{
  using namespace algo_recursion_hanoi;

  const int DISKS{3};

  move_disk(DISKS, 1, 3, 2);
}


<ex>
// algo-leetcode-12 algo-recursion
/*
38. Count and Say, Easy

The count-and-say sequence is the sequence of integers with the first five terms
as following:

1.     1
2.     11
3.     21
4.     1211
5.     111221

1 is read off as "one 1" or 11.

11 is read off as "two 1s" or 21.

21 is read off as "one 2, then one 1" or 1211.

Given an integer n where 1 ≤ n ≤ 30, generate the nth term of the count-and-say
sequence.

Note: Each term of the sequence of integers will be represented as a string.

Example 1:

Input: 1
Output: "1"

Example 2:
Input: 4
Output: "1211"

note:

the problem is to make string output which is done by counting numbers and what
the number is for the previous. That is "count and what"

starts new counting when see different char.

*/

namespace leetcode_easy_012
{
  string count_string_1(string const &input)
  {
    char current_char{};
    size_t count{};
    string result{};

    for (auto ch : input)
    {
      if (ch == current_char)
        ++count;
      else
      {
        // to handle the first read
        if (count != 0)
          result += to_string(count) + current_char;

        current_char = ch;
        count = 1;
      }
    }

    // to handle when input ends
    result += to_string(count) + current_char;

    // cout << "result: " << result << endl;

    return result;
  }

  // to remove handling of the first char read

  string count_string_2(string const &input)
  {
    char current_char = input[0];
    size_t count{1};
    string result{};

    for (size_t i = 1; i < input.size(); ++i)
    {
      if (input[i] == current_char)
        ++count;
      else
      {
        result += to_string(count) + current_char;
        current_char = input[i];
        count = 1;
      }
    }

    // to handle then input ends
    result += to_string(count) + current_char;

    return result;
  }

  // Given an integer n where 1 ≤ n ≤ 30,

  string count_and_say_1(int n)
  {
    if (n == 1)
      return "1";

    auto result = count_and_say_1(n-1);
    return count_string_1(result);
  }

  string count_and_say_2(int n)
  {
    if (n == 1)
      return "1";

    auto result = count_and_say_2(n-1);
    return count_string_2(result);
  }

  // to make a single function
  //
  // Runtime: 4 ms, faster than 100.00% of C++ online submissions for Count and
  // Say.
  //
  // Memory Usage: 9.1 MB, less than 35.44% of C++ online submissions for Count
  // and Say.

  string count_and_say_3(int n)
  {
    if (n == 1)
      return "1";

    auto input = count_and_say_3(n-1);

    // return count_string_2(result);
    // string count_string_2(string const &input)
    {
      char current_char = input[0];
      size_t count{1};
      string result{};

      for (size_t i = 1; i < input.size(); ++i)
      {
        if (input[i] == current_char)
          ++count;
        else
        {
          result += to_string(count) + current_char;
          current_char = input[i];
          count = 1;
        }
      }

      // to handle then input ends
      result += to_string(count) + current_char;

      return result;
    }
  }
} // namespace 

TEST(LeetCode, Easy_012_CountAndSay_1)
{
  using namespace leetcode_easy_012;

  // 2th
  EXPECT_THAT(count_string_1("1"), "11");
  // 3th
  EXPECT_THAT(count_string_1("11"), "21");
  // 4th
  EXPECT_THAT(count_string_1("21"), "1211");
  // 5th 
  EXPECT_THAT(count_string_1("1211"), "111221");
  // 6th
  EXPECT_THAT(count_string_1("111221"), "312211");

  EXPECT_THAT(count_and_say_1(2), "11");
  EXPECT_THAT(count_and_say_1(3), "21");
  EXPECT_THAT(count_and_say_1(4), "1211");
  EXPECT_THAT(count_and_say_1(5), "111221");
  EXPECT_THAT(count_and_say_1(6), "312211");

  EXPECT_THAT(count_and_say_3(2), "11");
  EXPECT_THAT(count_and_say_3(3), "21");
  EXPECT_THAT(count_and_say_3(4), "1211");
  EXPECT_THAT(count_and_say_3(5), "111221");
  EXPECT_THAT(count_and_say_3(6), "312211");
}

// to see string sizes of results
// 1
// 2
// 2
// 4
// 6
// 6
// 8
// 10
// 14
// 20
// 26
// 34
// 46
// 62
// 78
// 102
// 134
// 176
// 226
// 302
// 408
// 528
// 678
// 904
// 1182
// 1540
// 2012
// 2606
// 3410
// 4462

TEST(LeetCode, Easy_012_CountAndSay_2)
{
  using namespace leetcode_easy_012;

  for (int i = 1; i <= 30; ++i)
  {
    count_and_say_1(i).size();
    // cout << count_and_say(i).size() << endl;
  }
}


<ex> algo-recursion-eight-queen

From {ref-001} and C version. The chess rules is that a queen can take another queen that is on the
same row, the same column, or the same diagonal.

<key-step>

This is formulating or outlining that use recursion to mean contiune to the next stage and repeat
the task.

This is naive approach when 8x8 board:

void AddQueen()
{
	 for( every unguarded position p on the board )
	 {
		  place a queen in position p;
		  queen++;

		  if( queen == 8 )
				print the configuration;
		  else
				AddQueen();

		  remove the queen from position p;
		  queen--;
	 }
}
 
4x4 eample

 dead end    dead end    solution    solution
  0 1 2 3     0 1 2 3     0 1 2 3     0 1 2 3 
0 Q ? ? ?   0 Q ? ? ?   0 X Q ? ?   0     Q   
1 X X Q ?   1 X X X Q   1 X X X Q   1 Q       
2 X X X X   2 X Q X X   2 Q X X X   2       Q 
3           3 X X X X   3 X X Q X   3   Q     

<backtrack> <postponing-the-work>

When reach a dead end, must backtrack by going back to the most recent choice we have made and
trying another possibility. Usally called [backtracking-algorithm] which attempt to complete a
search for a solution by constructing [partial-solution] and which proves useful in situation where
many possibilities may first appear such as scheduling problems and a compiler parsing to determine
the meaning of a statement. 

<data-structure>

To choose the data structure to represent data to solve a problem. In this case, array.

<observations>

observation-01: mark guarded and unguarded. 
If scan the board to see if a position is guarded whenever place a queen, would involve considerable
searching. As do on a paper, if can mark guarded posion when place a queen, can look for unguarded
position in the next stage. So reduced searching but a problem arise.

When remove a queen, should not necessrily change a position from false to true(unguarded) because
some other queen still guard that posiotion. So can use int array instead to count and position is
unguarded if and only if it has a count of 0. Better than the first approach but involves
considerable searching and calculation. How to improve? Need more observations.

observation-02: only one queen in each row

int queencol[ rows ] gives the column containing a queen and this covers vertical and horizental
positions.

observation-03: use [difference] for downwards and [sum] for upwards.

4x4
00 01 02 03 : down diff -3. 4th covers 1 pos. -> 0th
10 11 12 13 : down diff -2. 5th covers 2         1th
20 21 22 23 : down diff -1. 6th covers 3         2th
30 31 32 33 : down diff  0. 0th covers 4         3th
            : down diff  1. 1th covers 3         4th
				: down diff  2. 2th covers 2         5th
				: down diff  3. 3th covers 1         6th

The down and up diagonal examples are:

00 11 22 33 : down, 30 21 12 03 : up. where these are xy index in a array. 

The obseravtion here is that the main down diagonal has the same difference: 00 11 22 33 and otheres
are between -3..3. Since there is no minus index in array use offset to map 0..6 (shifted)

up diagonal are ones to upper-right. As down diagonal, cannot use difference because cannot uniquely
identify up diagonals. For example, 00 and 33 have 0 in difference. Therefore, use sum instead.

Try one example

  0 1 2 3
0 Q ? ? ?
1 X X Q ?
2 X X X X
3        

pos 00:Q: queencol[0] = 0. down diff 0 and 0th. up 0th.
pos 12:Q: queencol[1] = 2. down diff -1 and 6th. up sum 3.
    dead: backtrack. unset down 6th and up 3th. there is no duplicates in set/unset up and down diagonal
because pos on the same diagonal will not tried.

Therefore, no need to have int array for marking guarded and unguarded cells for a whole board.
Hence reduced calaulations and searching.

<analysis>

The navie approach which place 8 queens and reject illegal configutation every time when place a
queen. This is C(64, 8) = 64!/8!(64-8)! = 4,426,165,368. This is [combination] notation in math.

The [observation-02] cuts this to 8^8 = 16,777,216
The [observation-03] cuts this to 8! = 40,320

This shows the effectiveness of [backtrack] as reduce a recursion tree to manageable step. The
actual number of cases the program consider will be much less than this.

<code-program>

#include <iostream>

using namespace std;

#define BOARDSIZE 	4						// 4x4 space
#define DIAGONAL		(2*BOARDSIZE-1)	// up or down diagonal size
#define DOWNOFFSET	(BOARDSIZE-1)		// down diagonal offset. BOARDSIZE-1

// to set a column where queen is for a each row. For example,
//
//   0 1 2
// 0 Q
// 1 X X Q
//
// queencol has {0, 2, .. } means that row 0 has 0, row 1 has 2. this is the answer when finish.
//
int queencol[ BOARDSIZE ];					

// row where queen is and also means the number of queens has been put. recursion depth and
// horizental
int queenrow = -1;							

// bitset to mark guarded(occupied) or upguarded position for column, up and down diagonal
// for [backtrack]
bool colfree[ BOARDSIZE ];		// cloumn is guarded? vertical.
bool upfree[ DIAGONAL ];
bool downfree[ DIAGONAL ];

void PrintDepth( bool dash, unsigned int depth )
{
	for( unsigned int i=0; i <= depth; ++i)
	{
		if(dash)
			cout << "-";
		else
			cout << " ";
	}

	if(dash)
		cout << "(" << depth << ") ";
	else
		cout << "    ";
}

void WriteBoard()
{
	cout << "solution {";

	for( int i=0; i < BOARDSIZE; ++i)
		cout << queencol[i] << ",";

	cout << "}" << endl;
}

void AddQueen()
{
	 int col=0;

	 queenrow++;
	 PrintDepth(true, queenrow);
	 cout << "AddQueen(" << queenrow << ", " << col << ")" << endl;

	 for( col = 0; col < BOARDSIZE; col++ )
	 {
		  // check if colfree, upfree and downfree are unguarded
		  //
		  if( colfree[ col ] && upfree[ queenrow + col ] && downfree[ queenrow - col + DOWNOFFSET ] )
		  {
				// put a queen in position( queenrow, col )
				//
				PrintDepth(false, queenrow);
				cout << "added a queen(" << queenrow << ", " << col << ")" << endl;

				queencol[ queenrow ] = col;

				colfree[ col ] = false;
				upfree[ queenrow + col ] = false;
				downfree[ queenrow - col + DOWNOFFSET ] = false;

				if( queenrow == BOARDSIZE-1 ) // termination condition
					 WriteBoard();					// print out and should not terminate program to see all
					                           // solutions
				else 									// proceed recursively
					 AddQueen();

				PrintDepth(false, queenrow);
				cout << "removed a queen(" << queenrow << ", " << col << ")" << endl;

				// backtrack by removing the queen
				colfree[ col ] = true;
				upfree[ queenrow + col ] = true;
				downfree[ queenrow - col + DOWNOFFSET ] = true;
		  }
	 } // for end

	 queenrow--;
}

int main()
{
	 int i;
	 
	 // init bitsets
	 for(i = 0; i < BOARDSIZE; i++)
		  colfree[i] = true;	// unguarded

	 for(i = 0; i < DIAGONAL; i++)
	 {
		  upfree[i] = downfree[i] = true;
	 }

	 AddQueen();
	 return 0;
}

The output when run 4x4:

-(0) AddQueen(0, 0)
     added a queen(0, 0)
--(1) AddQueen(1, 0)
      added a queen(1, 2)
---(2) AddQueen(2, 0)
      removed a queen(1, 2)
      added a queen(1, 3)
---(2) AddQueen(2, 0)
       added a queen(2, 1)
----(3) AddQueen(3, 0)
       removed a queen(2, 1)
      removed a queen(1, 3)
     removed a queen(0, 0)
     added a queen(0, 1)
--(1) AddQueen(1, 0)
      added a queen(1, 3)
---(2) AddQueen(2, 0)
       added a queen(2, 0)
----(3) AddQueen(3, 0)
        added a queen(3, 2)
solution {1,3,0,2,}
        removed a queen(3, 2)
       removed a queen(2, 0)
      removed a queen(1, 3)
     removed a queen(0, 1)
     added a queen(0, 2)
--(1) AddQueen(1, 0)
      added a queen(1, 0)
---(2) AddQueen(2, 0)
       added a queen(2, 3)
----(3) AddQueen(3, 0)
        added a queen(3, 1)
solution {2,0,3,1,}
        removed a queen(3, 1)
       removed a queen(2, 3)
      removed a queen(1, 0)
     removed a queen(0, 2)
     added a queen(0, 3)
--(1) AddQueen(1, 0)
      added a queen(1, 0)
---(2) AddQueen(2, 0)
       added a queen(2, 2)
----(3) AddQueen(3, 0)
       removed a queen(2, 2)
      removed a queen(1, 0)
      added a queen(1, 1)
---(2) AddQueen(2, 0)
      removed a queen(1, 1)
     removed a queen(0, 3)


{designing-recursive}

o find the key step to divide a problem into parts
o find a stopping rule
o outline your algorithm
o check it with a small case
o draw a recursion tree.


<make-a-decision>

The good starting point is to study a recursion tree.

o if it has a simple form like a chain, the iterative may be better. Such as factorial and can do by
reading the recursion tree from bottom to top instead of top to bottom.

o if it has duplicate tasks, use other data structure other than stack. fibonacci iterative version.

So use recursion when the tree appears quite bushy, with little duplication of tasks.


={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-recursion-tail-recursion

The tail recursion when the last-executed statment is a recursive call waste
space as do unnecessary recusive call. Because when return, restore stack but
terminates immediately. For this case, can change it to iterative one. 

<example-one>

void Move(int count, int start, int finish, int temp)
{
	 if( count > 0 )
	 {
		  Move( count-1, start, temp, finish );
		  printf("move a disk %d from tower %d to %d.\n", count, start, finish );
		  Move( count-1, temp, finish, start );
	}
}


void Move(int count, int start, int finish, int temp)
{
	 int swap;

	 if( count > 0 )
	 {
		  Move( count-1, start, temp, finish );
		  printf("move a disk %d from tower %d to %d.\n", count, start, finish );
		  count--;
		  swap = start;   // swap(start, temp) how does it work???
		  start = temp;
		  temp = swap; 
	}
}


<ex> algo-recursion-factorial

The factorial function says to multiply all whole numbers from our chosen
number down to 1.

Examples:

4! = 4 × 3 × 2 × 1 = 24
7! = 7 × 6 × 5 × 4 × 3 × 2 × 1 = 5040

namespace algo_recursion_factorial
{
  // CPR 227
  int factorial_1(int value)
  {
    // CodeComplete 440, #19
    if (value > 1)
      return factorial_1(value-1)*value;

    return 1;
  }

  // CodeComplete 397, #17.2,
  // Don’t use recursion for factorials or Fibonacci numbers

  int factorial_2(int value)
  {
    int result{1};

    // for (int i = 1; i <= value; ++i)

    for (int i = 2; i <= value; ++i)
    {
      result *= i;
    }

    return result;
  }

  int factorial_3(int value)
  {
    int result{1};

    for (; 0 < value; --value)
    {
      result *= value;
    }

    return result;
  }
} // namespace


// not good idea to use factorial to see performance difference due to tail
// recursion since number gets bigger quickly

TEST(AlgoRecursion, Factorial) 
{
  using namespace algo_recursion_factorial;

  EXPECT_THAT(factorial_1(5), 120);
  EXPECT_THAT(factorial_1(10), 3628800);

  EXPECT_THAT(factorial_2(5), 120);
  EXPECT_THAT(factorial_2(10), 3628800);

  EXPECT_THAT(factorial_3(5), 120);
}


<ex> algo-recursion-fibonacci

The Fibonacci Sequence is the series of numbers:

0, 1, 1, 2, 3, 5, 8, 13, 21, 34, ...

The definition is:

F0 = 0.
F1 = 1.
Fn = Fn-1 + Fn-2 for n >= 2

int fibonacci(int n)
{
  if( n <= 0 )
    return 0;
  else if( n==1 )
    return 1;
  else
    return fibonacci(n-1) + fibonacci(n-2);
}

Far more wasteful example than factorial example, the calculation of f7, when
use recursive because when see recursion tree, figure 3.18, DSAPD, after f5 is
calculated on the way to f6 in the left side of tre, it will be lost and
unavailable when it is later needed to get f7 in the right side of tree. Have
to calculate it again. O(2^n) tree

The interative version is:

current   one back(fn-1)   two back(fn-2)
2       = 1              + 0
3       = 2              + 1
4       = 3              + 2
5       = 4              + 3
6       = 5              + 4
...

namespace algo_recursion_fibonacci
{
  // n is nth fibonacci term

  int fibonacci_1(int n)
  {
    if (n <= 0)
      return 0;
    else if (n == 1)
      return 1;
    else
      return fibonacci_1(n-1) + fibonacci_1(n-2);
  }

  int fibonacci_2(int n)
  {
    int twoback{};  // f(n-2)
    int oneback{};  // f(n-1)
    int current{};

    if (n <= 0)
      return 0;
    else if (n == 1)
      return 1;
    else
    {
      // back from current
      twoback = 0;
      oneback = 1;

      for (int i = 2; i <= n; ++i)
      {
        current = twoback + oneback;

        // for next f
        twoback = oneback;
        oneback = current;
      }
    }

    return current;
  }

} // namespace

TEST(AlgoRecursion, Fibonacci) 
{
  using namespace algo_recursion_fibonacci;

  EXPECT_THAT(fibonacci_1(4), 3);
  EXPECT_THAT(fibonacci_1(5), 5);
  EXPECT_THAT(fibonacci_1(6), 8);
  EXPECT_THAT(fibonacci_1(7), 13);

  EXPECT_THAT(fibonacci_2(4), 3);
  EXPECT_THAT(fibonacci_2(5), 5);
  EXPECT_THAT(fibonacci_2(6), 8);
  EXPECT_THAT(fibonacci_2(7), 13);
}

<ex>
// algo-leetcode-18
/*
70. Climbing Stairs, Easy

You are climbing a stair case. It takes n steps to reach to the top.

Each time you can either climb 1 or 2 steps. In how many distinct ways can you
climb to the top?

Note: Given n will be a positive integer.

Example 1:
Input: 2
Output: 2
Explanation: There are two ways to climb to the top.
1. 1 step + 1 step
2. 2 steps

Example 2:
Input: 3
Output: 3
Explanation: There are three ways to climb to the top.
1. 1 step + 1 step + 1 step
2. 1 step + 2 steps
3. 2 steps + 1 step
 
*/

/*

Approach 1: Brute Force

In this brute force approach we take all possible step combinations i.e. 1 and
2, at every step. At every step we are calling the function
climbStairsclimbStairs for step 1 and 2, and return the sum of returned values
of both functions.

climbStairs(i,n)=(i+1,n)+climbStairs(i+2,n)

where i defines the current step and n defines the destination step.

Time complexity : O(2^n)

since the size of recursion tree will be 2^n

N = 2
          (0,2)

    (1,2)       (2,2)
                ret 1
(2,2)   (3,2) 
ret 1   ret 0

return 1 means found and return 0 means not found.

Space complexity : O(n) The depth of the recursion tree can go upto n.

*/ 

namespace leetcode_easy_018
{
  int climb_stairs(int start, int end)
  {
    if (start == end)
      return 1;
    else if (start > end)
      return 0;

    return climb_stairs(start + 1, end) + climb_stairs(start + 2, end);
  }

  int climbStairs_1(int n) 
  {
    return climb_stairs(0, n);
  }
} // namespace

TEST(AlgoRecusrion, LeetCode_Easy_018_ClimbStairs_1)
{
  using namespace leetcode_easy_018;
  auto func = climbStairs_1;

  EXPECT_THAT(func(2), 2);
  EXPECT_THAT(func(3), 3);
  EXPECT_THAT(func(4), 5);
  EXPECT_THAT(func(30), 1346269);
}


/*
Approach 2: Recursion with memoization

In the previous approach we are redundantly calculating the result for every
step. Instead, we can store the result at each step in memomemo array and
directly returning the result from the memo array whenever that function is
called again.

In this way we are *pruning* recursion tree with the help of memo array and
reducing the size of recursion tree upto n.

(Like fibonacci problem, the right part of recursion tree uses the same
calculation which are calculated already but calculate them again since they are
lost. So can keep them and use it then better performance)

Time complexity : O(n). Size of recursion tree can go upto nn.
Space complexity : O(n). The depth of recursion tree can go upto nn. 

see time difference between recursion and iterative version

[ RUN      ] LeetCode.Easy_018_ClimbStairs_1
[       OK ] LeetCode.Easy_018_ClimbStairs_1 (52 ms)
[ RUN      ] LeetCode.Easy_018_ClimbStairs_2
[       OK ] LeetCode.Easy_018_ClimbStairs_2 (0 ms)
[ RUN      ] LeetCode.Easy_018_ClimbStairs_3
[       OK ] LeetCode.Easy_018_ClimbStairs_3 (0 ms)
 
*/

namespace leetcode_easy_018
{
  int climb_stairs(int start, int end, vector<int> &memo)
  {
    if (start == end)
      return 1;
    else if (start > end)
      return 0;
    else if(memo[start])
      return memo[start];

    memo[start] = climb_stairs(start + 1, end, memo) + climb_stairs(start + 2, end, memo);
    return memo[start];
  }

  int climbStairs_2(int n) 
  {
    vector<int> memo(n + 1, 0);
    return climb_stairs(0, n, memo);
  }
} // namespace

TEST(AlgoRecusrion, LeetCode_Easy_018_ClimbStairs_2)
{
  using namespace leetcode_easy_018;
  auto func = climbStairs_2;

  EXPECT_THAT(func(2), 2);
  EXPECT_THAT(func(3), 3);
  EXPECT_THAT(func(4), 5);
  EXPECT_THAT(func(30), 1346269);
}


/*
Approach 3: Dynamic Programming

As we can see this problem can be broken into subproblems, and it contains the
optimal substructure property i.e. its optimal solution can be constructed
efficiently from optimal solutions of its subproblems, we can use dynamic
programming to solve this problem.

One can reach ith step in one of the two ways:

Taking a single step from (i-1) th step.

Taking two step from (i−2) th step.

(since it is about way to reach to n but not number of steps)

So, the total number of ways to reach i th is equal to sum of ways of reaching
(i−1)th step and ways of reaching (i-2)th step.  

Let dp[i] denotes the number of ways to reach on i th step:

dp[i]=dp[i-1]+dp[i-2]


Approach 4: Fibonacci Number

In the above approach we have used dpdp array where dp[i]=dp[i-1]+dp[i-2]. It
can be easily analysed that dp[i] is nothing but ith fibonacci number.

means the dp value sequence. this is fibonacci sequence:

0, 1, 1, 2, 3, 5, 8, 13, 21, 34, ...

dp value sequence:

0, 1, 2, 3, 5, 8, 13, 21, 34, ...

Now we just have to find n th number of the fibonacci series having 1 and 2
their first and second term respectively, i.e. Fib(1)=1 and Fib(2)=2.


  int fibonacci_2(int n)
  {
    int twoback{};  // f(n-2)
    int oneback{};  // f(n-1)
    int current{};

    if (n <= 0)
      return 0;
    else if (n == 1)
      return 1;
    else
    {
      // back from current
      twoback = 0;
      oneback = 1;

      for (int i = 2; i <= n; ++i)
      {
        current = twoback + oneback;

        // for next f
        twoback = oneback;
        oneback = current;
      }
    }

    return current;
  }
*/

namespace leetcode_easy_018
{
  int climbStairs_3(int n) 
  {
    // base cases
    if(n <= 0) return 0;
    if(n == 1) return 1;
    if(n == 2) return 2;

    int one_step_before = 2;    // when n == 2
    int two_steps_before = 1;   // when n == 1
    int all_ways = 0;

    // starts from n == 3
    for(int i=3; i <= n; i++)
    {
      all_ways = one_step_before + two_steps_before;
      two_steps_before = one_step_before;
      one_step_before = all_ways;
    }

    return all_ways;
  };
} // namespace

TEST(AlgoRecusrion, LeetCode_Easy_018_ClimbStairs_3)
{
  using namespace leetcode_easy_018;
  auto func = climbStairs_3;

  EXPECT_THAT(func(2), 2);
  EXPECT_THAT(func(3), 3);
  EXPECT_THAT(func(4), 5);
  EXPECT_THAT(func(30), 1346269);
}


={============================================================================
*kt_dev_algo_0000* dev-algo-problem algo-recursion algo-maze

From SS.

You are given an N*N matrix with white, black, or gray cells. You have to find
a `white path` from (1, 1) to (N, N). 

Here (1, 1) means the top-leftmost cell and (N, N) means th bottom-rightmost
cell. You can move from one cell to an 

o horizontally, vertically, or diagonally adjacent cells.

o You cannot visit a cell more than once.

o one gray cell is given and your path must visit the gray cell in the path. 

The cells (1, 1) and (N, N) cannot be the gray cell. Your path does not have
to be the shortest path. 

Given an N*N matrix with white cells, black cells, and a gray cell. Generate a
program that finds a white-cell path from (1, 1) to (N, N) which visits the
gray cell in the middle of the path.

// A black cell is represented by 1, a white cell by 0, and the gray cell by 2. 
// so black cell represents a wall

// o should visit green cell first. ???

This problem can be difficult for some special cases. To ease the problem,
there are not more than four white cells adjacent to the grey one. For partial
  points, a considerable part of the test cases will be rather easy. 

In three of the test cases, just finding a path from (1, 1) to the gray cell
and then finding a path from the gray cell to (N, N) will always find a
successful path. 

And in other three of the test cases, only ** two white cells will be adjacent
to the gray cell. It will be guaranteed that all of the test cases will have a
solution. That is, it will be always possible to find a valid path.

  
[Constraints]
5 <= N <= 100

[Input]
10 test cases are given. In each case, the first line has N, the dimension of
  the matrix, and the next N lines show the shape of the matrix. 
  
[Output]
Write the 10 answers in 10 lines. Each line starts with '#x' where x means the
  index of a case, puts a space, and then prints a path. A path is represented
  by the coordinates of cells visited in order.  A coordinate is represented
  by 'row column'. For example, in the matrix below, the only successful path
  is (1, 1)->(2, 1)->(3, 2)->(3, 3); it is represented in the output as '1 1 2
  1 3 2 3 3'.


<code-frame>

#include<iostream>

using namespace std;

int A[101][101], N;
int Answer1[10001], Answer2[10001], AnswerN;

int main(int argc, char** argv)
{
  int test_case;
  /*
     freopen function below opens input.txt file in read only mode, and
     afterward, the program will read from input.txt file instead of
     standard(keyboard) input.  To test your program, you may save input data
     in input.txt file, and use freopen function to read from the file when
     using scanf function.  You may remove the comment symbols(//) in the
     below statement and use it.  But before submission, you must remove the
     freopen function or rewrite comment symbols(//).
   */
  // freopen("input.txt", "r", stdin);


  /*
     Your program should handle 10 test cases given.
   */
  for(test_case = 1; test_case <= 10; ++test_case)
  {
    int i, j;

    /*
       Read each test case from standard input.
       The dimension of the matrix will be stored in variable N,
       and the matrix will be stored in an array A[1..N][1..N].
     */
    cin >> N;
    for(i = 1; i <= N; i++)
    {
      for (j = 1; j <= N; j++)
      {
        cin >> A[i][j];
      }
    }


    /*
       Implement your algorithm here.
       The length of the path will be stored in variable AnswerN, and the
       coordinates will be stored in arrays (Answer1[1..AnswerN],
       Answer2[1..AnswerN]).
     */

    AnswerN = 1;
    Answer1[1] = Answer2[1] = 0;


    // Print the answer to standard output(screen).
    cout << "#" << test_case;
    for(i = 1; i <= AnswerN; i++) cout << " " << Answer1[i] << " " << Answer2[i];
    cout << endl;
  }

  return 0; //Your program should return 0 on normal termination.
}


<test-cases>

5
0 0 0 0 0
1 1 1 1 0
0 0 0 0 0
0 1 1 1 1
2 0 0 0 0

10, when do not support diagonal move

0 1 0 1 0 1 0 0 0 1
0 1 0 1 0 1 1 1 0 1
0 0 0 0 0 1 0 0 0 1
0 1 0 1 1 1 0 1 1 1
0 1 2 1 0 0 0 0 0 1
1 1 0 1 0 1 1 1 1 1
0 1 0 0 0 0 0 1 0 1
0 1 1 1 0 1 1 1 0 1
0 0 0 0 0 0 0 0 0 1
1 1 1 1 1 1 1 1 0 0

10, when supports diagonal move

0 1 0 1 0 1 0 0 0 1
0 1 0 1 0 1 1 1 0 1
0 0 0 0 0 1 0 0 0 1
0 1 0 1 1 1 0 1 1 1
0 1 2 1 0 0 0 0 0 1
1 1 0 1 0 1 1 1 1 1
0 1 0 0 0 0 0 1 0 1
0 1 1 1 0 1 1 1 0 1
0 0 0 0 0 0 0 0 0 1
1 1 1 1 1 1 1 1 1 0

15
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 0 1 0 0 0 1 0 1 0 1 0 1 0
0 1 0 0 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 0 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1
2 0 0 0 0 0 0 0 0 0 0 0 0 0 0
20
0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 1
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1
0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1
0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1
0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1
0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1
0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1
0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1
0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1
0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1
0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1
0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1
0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
29
0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0
0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0
0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0
0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0
0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0
0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0
0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0
0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0
0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0
0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0
0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0
0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1
0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0
0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0
0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0
1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1
0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0
1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0
0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0
0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0
0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0
1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1
0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0

There are more up to 99.

<code>

template <typename T>
void PRINT_MAZE_ELEMENTS( T& coll, const string optstr="" )
{
    size_t count{};
    cout << optstr;

    for( const auto &elem : coll )
    {
        cout << "(" << elem.first << ", " << elem.second << ") ";
        ++count;
    }

    cout << "(" << count << ")" << endl;
}

using Point = std::pair<int, int>;

// 1. input and point(row, col) which is the same as point(y, x) but 
// not point(x, y). This has to do with array access.
//
// 2. If it's valid point which are not checked against to traveled points, call
// find_path for every possible move from a point and then this move is cheked
// against to the traveled points. So supporting diagonal move needs more
// recursive calls. Therefore, it use the traveled path to exit the call for
// points that it already traveled; to move forward, to move back when see the
// dead end, and naturally to prevent circular path.
//
// See again that calls find_path() for every possible move.
//
// 3. To support range from (1,1) to (N,N), used padding to the input data:
//
// {2,2,2,2,2,2},
// {2,0,0,0,0,0}, 
// {2,1,1,1,1,0},
// {2,0,0,0,0,0},
// {2,0,1,1,1,1},
// {2,2,0,0,0,0}
//
// the result of run:
//
// (1, 2) (1, 3) (1, 4) (1, 5) (2, 5) (3, 5) (3, 4) (3, 3) (3, 2) (3, 1) (4, 1) (5, 1) (5, 2) (5, 3) (5, 4) (5, 5) (16)
//
//             [ 10578] | find_path(1, 1) {
//             [ 10578] |   find_path(1, 2) {
//             [ 10578] |     find_path(1, 1) {
//   12.428 us [ 10578] |     } /* find_path */
//             [ 10578] |     find_path(1, 3) {
//             [ 10578] |       find_path(1, 2) {
//   10.787 us [ 10578] |       } /* find_path */
//             [ 10578] |       find_path(1, 4) {
//             [ 10578] |         find_path(1, 3) {
//   13.404 us [ 10578] |         } /* find_path */
//             [ 10578] |         find_path(1, 5) {
//             [ 10578] |           find_path(1, 4) {
//   12.767 us [ 10578] |           } /* find_path */
//             [ 10578] |           find_path(2, 5) {
//             [ 10578] |             find_path(1, 5) {
//   85.506 us [ 10578] |             } /* find_path */
//             [ 10578] |             find_path(3, 5) {
//             [ 10578] |               find_path(3, 4) {
//             [ 10578] |                 find_path(3, 3) {
//             [ 10578] |                   find_path(3, 2) {
//             [ 10578] |                     find_path(3, 1) {
//             [ 10578] |                       find_path(3, 2) {
//   28.249 us [ 10578] |                       } /* find_path */
//             [ 10578] |                       find_path(4, 1) {
//             [ 10578] |                         find_path(3, 1) {
//  182.678 us [ 10578] |                         } /* find_path */
//             [ 10578] |                         find_path(5, 1) {
//             [ 10578] |                           find_path(5, 2) {
//             [ 10578] |                             find_path(5, 1) {
//   82.954 us [ 10578] |                             } /* find_path */
//             [ 10578] |                             find_path(5, 3) {
//             [ 10578] |                               find_path(5, 2) {
//   17.163 us [ 10578] |                               } /* find_path */
//             [ 10578] |                               find_path(5, 4) {
//             [ 10578] |                                 find_path(5, 3) {
//   19.277 us [ 10578] |                                 } /* find_path */
//             [ 10578] |                                 find_path(5, 5) {
//   19.241 us [ 10578] |                                 } /* find_path */
//  116.223 us [ 10578] |                               } /* find_path */
//  213.627 us [ 10578] |                             } /* find_path */
//  391.920 us [ 10578] |                           } /* find_path */
//  967.572 us [ 10578] |                         } /* find_path */
//    2.857 ms [ 10578] |                       } /* find_path */
//    3.996 ms [ 10578] |                     } /* find_path */
//    4.060 ms [ 10578] |                   } /* find_path */
//    4.126 ms [ 10578] |                 } /* find_path */
//    4.220 ms [ 10578] |               } /* find_path */
//    4.287 ms [ 10578] |             } /* find_path */
//    5.416 ms [ 10578] |           } /* find_path */
//    6.411 ms [ 10578] |         } /* find_path */
//    6.485 ms [ 10578] |       } /* find_path */
//    6.559 ms [ 10578] |     } /* find_path */
//    6.708 ms [ 10578] |   } /* find_path */
//    7.233 ms [ 10578] | } /* find_path */


struct Maze
{
  std::vector<std::vector<int>> input;

  // std::array<std::array<int, 11>, 11> input;
  // std::array<std::array<int, 6>, 6> input;

  // set of visited points
  std::set<Point> visited_points{};

  // array of path points
  std::vector<Point> path_points{};

  Maze(int row, int col)
    : row_(row), col_(col) {}

  bool AlreadyTried(Point position)
  {
    return visited_points.find(position) == visited_points.end() ? false : true;
  }

  bool FoundTheExit(Point position)
  {
    return position == Point(row_-1, col_-1) ? true : false;
  }

  void RememberPosition(Point position)
  {
    auto result = visited_points.insert(position);
    if (!result.second)
    {
      cout << "RememberPosition: founds duplicates" << endl;
      cout << "RememberPosition: (" << position.first << ", " << position.second << ")" << endl;
      PRINT_MAZE_ELEMENTS(visited_points);
    }
  }

  // if cannot move, return the input position
  Point GetPositionToMoveLeft(Point position)
  {
    Point point_to_move{position.first, position.second-1};

    if (ValidPoint(point_to_move))
    {
      return point_to_move;
    }
    else 
    {
      return position;
    }
  }

  Point GetPositionToMoveRight(Point position)
  {
    Point point_to_move{position.first, position.second+1};

    if (ValidPoint(point_to_move))
    {
      return point_to_move;
    }
    else 
    {
      return position;
    }
  }

  Point GetPositionToMoveUp(Point position)
  {
    Point point_to_move{position.first-1, position.second};

    if (ValidPoint(point_to_move))
    {
      return point_to_move;
    }
    else 
    {
      return position;
    }
  }

  Point GetPositionToMoveDown(Point position)
  {
    Point point_to_move{position.first+1, position.second};

    if (ValidPoint(point_to_move))
    {
      return point_to_move;
    }
    else 
    {
      return position;
    }
  }

  Point GetPositionToDiagRightUp(Point position)
  {
    Point point_to_move{position.first-1, position.second+1};

    if (ValidPoint(point_to_move))
    {
      return point_to_move;
    }
    else 
    {
      return position;
    }
  }

  Point GetPositionToDiagRightDown(Point position)
  {
    Point point_to_move{position.first+1, position.second+1};

    if (ValidPoint(point_to_move))
    {
      return point_to_move;
    }
    else 
    {
      return position;
    }
  }

  Point GetPositionToDiagLeftUp(Point position)
  {
    Point point_to_move{position.first-1, position.second-1};

    if (ValidPoint(point_to_move))
    {
      return point_to_move;
    }
    else 
    {
      return position;
    }
  }

  Point GetPositionToDiagLeftDown(Point position)
  {
    Point point_to_move{position.first+1, position.second-1};

    if (ValidPoint(point_to_move))
    {
      return point_to_move;
    }
    else 
    {
      return position;
    }
  }

  private:

  bool ValidPoint(Point position)
  {
    if ((0 <= position.first && position.first < row_) &&
        (0 <= position.second && position.second < col_) &&
        input[position.first][position.second] != 1
       )
    {
      return true;
    }
    else
    {
      return false;
    }
  }

  int row_{};
  int col_{};
};


// To use uftrace log, changed it from 
// bool find_path(Maze &maze, Point position)

bool find_path(Maze &maze, int row, int col)
{
  Point position{row, col};

  // to prevent circular path and going backwards and this make it search
  // forward. 
  if (maze.AlreadyTried(position))
  {
    return false;
  }

  // found a path which is stop condition
  if (maze.FoundTheExit(position))
  {
    return true;
  }

  // remember a position tried
  maze.RememberPosition(position);

  Point new_position{};

  // left
  if ((new_position = maze.GetPositionToMoveLeft(position)) != position)
  {
    cout << "l:(" << new_position.first << ", " << new_position.second << ")" << endl;

    if (find_path(maze, new_position.first, new_position.second))
    {
      // cout << "left:insert(" << new_position.first << ", " << new_position.second << ")" << endl;
      maze.path_points.insert(maze.path_points.begin(), new_position);
      return true;
    }
  }

  // right
  if ((new_position = maze.GetPositionToMoveRight(position)) != position)
  {
    cout << "r:(" << new_position.first << ", " << new_position.second << ")" << endl;

    if (find_path(maze, new_position.first, new_position.second))
    {
      cout << "right:insert(" << new_position.first << ", " << new_position.second << ")" << endl;
      maze.path_points.insert(maze.path_points.begin(), new_position);
      return true;
    }
  }

  // up
  if ((new_position = maze.GetPositionToMoveUp(position)) != position)
  {
    cout << "u:(" << new_position.first << ", " << new_position.second << ")" << endl;

    if (find_path(maze, new_position.first, new_position.second))
    {
      // cout << "up:insert(" << new_position.first << ", " << new_position.second << ")" << endl;
      maze.path_points.insert(maze.path_points.begin(), new_position);
      return true;
    }
  }

  // down
  if ((new_position = maze.GetPositionToMoveDown(position)) != position)
  {
    cout << "d:(" << new_position.first << ", " << new_position.second << ")" << endl;

    if (find_path(maze, new_position.first, new_position.second))
    {
      // cout << "down:insert(" << new_position.first << ", " << new_position.second << ")" << endl;
      maze.path_points.insert(maze.path_points.begin(), new_position);
      return true;
    }
  }

  // diag right up 
  if ((new_position = maze.GetPositionToDiagRightUp(position)) != position)
  {
    cout << "dru:(" << new_position.first << ", " << new_position.second << ")" << endl;

    if (find_path(maze, new_position.first, new_position.second))
    {
      // cout << "diag:rup:insert(" << new_position.first << ", " << new_position.second << ")" << endl;
      maze.path_points.insert(maze.path_points.begin(), new_position);
      return true;
    }
  }

  // diag right down 
  if ((new_position = maze.GetPositionToDiagRightDown(position)) != position)
  {
    cout << "drd:(" << new_position.first << ", " << new_position.second << ")" << endl;

    if (find_path(maze, new_position.first, new_position.second))
    {
      // cout << "diag:rdown:insert(" << new_position.first << ", " << new_position.second << ")" << endl;
      maze.path_points.insert(maze.path_points.begin(), new_position);
      return true;
    }
  }

  // diag left up 
  if ((new_position = maze.GetPositionToDiagLeftUp(position)) != position)
  {
    cout << "dlu:(" << new_position.first << ", " << new_position.second << ")" << endl;

    if (find_path(maze, new_position.first, new_position.second))
    {
      // cout << "diag:lup:insert(" << new_position.first << ", " << new_position.second << ")" << endl;
      maze.path_points.insert(maze.path_points.begin(), new_position);
      return true;
    }
  }

  // diag left down 
  if ((new_position = maze.GetPositionToDiagLeftDown(position)) != position)
  {
    cout << "dld:(" << new_position.first << ", " << new_position.second << ")" << endl;

    if (find_path(maze, new_position.first, new_position.second))
    {
      // cout << "diag:ldown:insert(" << new_position.first << ", " << new_position.second << ")" << endl;
      maze.path_points.insert(maze.path_points.begin(), new_position);
      return true;
    }
  }

  return false;
}

TEST(Maze, ExerciseInterfaces)
{
  Maze maze(5, 5);
  maze.input = {
    {0,0,0,0,0},
    {1,1,1,1,0},
    {0,0,0,0,0},
    {0,1,1,1,1},
    {2,0,0,0,0}
  };

  maze.RememberPosition(Point(1, 1));
  maze.RememberPosition(Point(1, 2));

  EXPECT_THAT(maze.AlreadyTried(Point(1, 1)), true);
  EXPECT_THAT(maze.AlreadyTried(Point(1, 3)), false);

  EXPECT_THAT(maze.FoundTheExit(Point(4, 5)), false);
  EXPECT_THAT(maze.FoundTheExit(Point(5, 5)), false);

  // not able to move
  EXPECT_THAT(maze.GetPositionToMoveLeft(Point(0, 0)), Eq(Point(0, 0)));

  // able to move
  EXPECT_THAT(maze.GetPositionToMoveLeft(Point(0, 1)), Eq(Point(0, 0)));
}

TEST(DISABLED_Maze, Array5x5)
{
  Maze maze(5, 5);
  maze.input = {
    {0,0,0,0,0},
    {1,1,1,1,0},
    {0,0,0,0,0},
    {0,1,1,1,1},
    {2,0,0,0,0}
  };

  // use start point (0, 0) rather then (1, 1).
  find_path(maze, 0, 0);
  PRINT_MAZE_ELEMENTS(maze.path_points);
}

// TEST(DISABLED_Maze, Array10x10)
TEST(Maze, Array10x10)
{
  // when not support diagonal move
  // Maze maze(10, 10);
  // maze.input = {
  //   {0,1,0,1,0,1,0,0,0,1},
  //   {0,1,0,1,0,1,1,1,0,1},
  //   {0,0,0,0,0,1,0,0,0,1},
  //   {0,1,0,1,1,1,0,1,1,1},
  //   {0,1,2,1,0,0,0,0,0,1},
  //   {1,1,0,1,0,1,1,1,1,1},
  //   {0,1,0,0,0,0,0,1,0,1},
  //   {0,1,1,1,0,1,1,1,0,1},
  //   {0,0,0,0,0,0,0,0,0,1},
  //   {1,1,1,1,1,1,1,1,0,0}
  // };

  Maze maze(10, 10);
  maze.input = {
    {0,1,0,1,0,1,0,0,0,1},
    {0,1,0,1,0,1,1,1,0,1},
    {0,0,0,0,0,1,0,0,0,1},
    {0,1,0,1,1,1,0,1,1,1},
    {0,1,2,1,0,0,0,0,0,1},
    {1,1,0,1,0,1,1,1,1,1},
    {0,1,0,0,0,0,0,1,0,1},
    {0,1,1,1,0,1,1,1,0,1},
    {0,0,0,0,0,0,0,0,0,1},
    {1,1,1,1,1,1,1,1,1,0}
  };
 
  find_path(maze, 0, 0);
  PRINT_MAZE_ELEMENTS(maze.path_points);
}

TEST(DISABLED_Maze, Array15x15)
{
  Maze maze(15, 15);
  maze.input = {
    {0,0,0,0,0,0,0,0,0,0,0,0,0,0,0},  
    {0,1,0,1,0,0,0,1,0,1,0,1,0,1,0},
    {0,1,0,0,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,1,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,1,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,1,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,1,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,0,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,1,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,1,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,1,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,1,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,0,1,0,1,0,1,0,1,0,1,0,1,0},
    {0,1,1,1,1,1,1,1,1,1,1,1,1,1,1},
    {2,0,0,0,0,0,0,0,0,0,0,0,0,0,0}
  };
 
  find_path(maze, 0, 0);
  PRINT_MAZE_ELEMENTS(maze.path_points);
}

// This input select the path which do have have "2" in. How to support this
// requirement?
//
// * change the traveled path to have the value and to keep only traveled points
// so far. So need to remove point when find_path() returns false so that
// traveled path only have points up to where it runs into
//
// * changed the end condition to see if the traveled path has the "2". if not
// return false so that can try other paths.


TEST(DISABLED_Maze, Array20x20)
{
  Maze maze(20, 20);
  maze.input = {

    {0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1}, 
    {0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1},
    {0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,1},
    {0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1},
    {0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1},
    {0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1},
    {0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1},
    {0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1},
    {0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,1},
    {0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1},
    {0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1},
    {0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1},
    {0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1},
    {0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1},
    {0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1},
    {0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1},
    {0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1},
    {0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1},
    {0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1},
    {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0}
  };
 
  find_path(maze, 0, 0);
  PRINT_MAZE_ELEMENTS(maze.path_points);
}


={============================================================================
*kt_dev_algo_0000* algo-count-bit count same bits between two integers

From SS. The problem to get how many bits are the same `between-two-integers`.

// A = 35 = 10 0011
// B =  9 =    1001
//
// Ans = 2 because only counts bit positions which are valid position in both
// integers.
//
// From ansic, p50. 
// The function counts the number of 1 bits in its integer argument. 
//
// 1. The key is not to use sizeof operator
// 2. unsigned int
//
// *cxx-shift* Must use `unsigned` to do  `right-shift` in order to have
// guaranteed 0 values. 
//
// 3. use independent of type.


/* 191. Number of 1 Bits, Easy

Write a function that takes an unsigned integer and return the number of '1'
bits it has (also known as the Hamming weight).

Example 1:

Input: 00000000000000000000000000001011
Output: 3

Explanation: 
The input binary string 00000000000000000000000000001011 has a total of three
'1' bits.

Example 2:

Input: 00000000000000000000000010000000
Output: 1

Explanation: 
The input binary string 00000000000000000000000010000000 has a total of one '1'
bit.

Example 3:

Input: 11111111111111111111111111111101
Output: 31

Explanation: 
The input binary string 11111111111111111111111111111101 has a total of thirty
one '1' bits.
 
Note:

Note that in some languages such as Java, there is no unsigned integer type. In
this case, the input will be given as signed integer type and should not affect
your implementation, as the internal binary representation of the integer is the
same whether it is signed or unsigned. 

In Java, the compiler represents the signed integers using 2's complement
notation. Therefore, in Example 3 above the input represents the signed integer
-3.

*/

// namespace leetcode_easy_191
namespace algo_bit
{
  // as with itoa
  //
  // Runtime: 4 ms, faster than 100.00% of C++ online submissions for Number of
  // 1 Bits.
  //
  // Memory Usage: 8.1 MB, less than 70.42% of C++ online submissions for Number
  // of 1 Bits.

  int hammingWeight_1(uint32_t n)
  {
    int count{};

    while (n)
    {
      if (n % 2)
        count++;

      n /= 2;
    }

    return count;
  }

  // since input is unsigned int, can use >> shift

  int hammingWeight_2(uint32_t n)
  {
    int count{};

    while (n)
    {
      if (n & 0x01)
        count++;

      n >>= 1;
    }

    return count;
  }

  // page 51. exercise 2-9. In a two's complement number system, x &= (x-1)
  // deletes the rightmost 1-bit in x. Explain why. Use this observation to write
  // a 'faster' version of bitcount.
  //
  // Answer:
  // 
  // If x is odd, then (x-1) has the same bit representation as x except that the
  // rightmost 1-bit becomes a 0. In this case, (x & (x-1)) == (x-1).
  // 
  // x = 5: 5(101) & 4(100) = 100  // 101 -> 100 by having rightmost 1 to 0
  // 
  // If x is even, the end result of anding(&) x and x-1 has the rightmost 1 of x to 0.
  // 
  // x = 4: 4(100) & 3(11)  = 0    // 100 -> 0   by having rightmost 1 to 0
  //          ^ rightmost 1
  //
  // x = 6: 6(110) & 5(101) = 100  // 110 -> 100 by having rightmost 1 to 0
  //           ^ rightmost 1
  //
  // x = 8: 8(1000) & 7(111) = 0   // 1000 -> 0  by having rightmost 1 to 0
  // 
  // 000   0     All even numbers has tailing 0s and it becomes 1 when minus 1
  // 001   1
  // 010   2
  // 011   3
  // 100   4
  // 101   5
  // 110   6
  // 111   7
  // ...
  // 
  // note: This is about careful observation but not a mechanism of borrowing a
  // carry for example. For both odd and even case, has the effect of having
  // rightmost 1 to 0. So clear 1 from x one by one and no need to check on if
  // to count bits.
  // 
  // note: And(&) is faster than shift operation? Yes and also there is no `if`
  // in the loop.

  int count_bit(uint32_t n)
  {
    int count{};

    for (; n; n &= (n-1))
      count++;

    return count;
  }

} // namespace

TEST(AlgoBit, CountBits)
{
  using namespace algo_bit;

  {
    auto func = hammingWeight_1;

    // Input: 00000000000000000000000000001011, 11
    EXPECT_THAT(func(11), 3); 

    // Input: 00000000000000000000000010000000, 128
    EXPECT_THAT(func(128), 1); 

    // Input: 11111111111111111111111111111101, 4294967293
    EXPECT_THAT(func(4294967293), 31); 
  }
  {
    auto func = hammingWeight_2;

    // Input: 00000000000000000000000000001011, 11
    EXPECT_THAT(func(11), 3); 

    // Input: 00000000000000000000000010000000, 128
    EXPECT_THAT(func(128), 1); 

    // Input: 11111111111111111111111111111101, 4294967293
    EXPECT_THAT(func(4294967293), 31); 
  }
  {
    auto func = count_bit;

    // Input: 00000000000000000000000000001011, 11
    EXPECT_THAT(func(11), 3); 

    // Input: 00000000000000000000000010000000, 128
    EXPECT_THAT(func(128), 1); 

    // Input: 11111111111111111111111111111101, 4294967293
    EXPECT_THAT(func(4294967293), 31); 
  }
}


namespace algo_bit
{
  // note:
  // used to loop count running on two inputs to get common bit coutns for early
  // attempts. However, turns out it's not necessary.
  //
  // returns MSB position which starts from 1 since input >> is evalueated after
  // ++count but not 0th.

  uint32_t get_msb_pos_1(const uint32_t value)
  {
    uint32_t count{};
    uint32_t input = value;

    // do not need to check like: if (input &1) to increase count for every
    // interation since when runs out 1, input becomes 0 and the loop ends. 
    for (; input != 0; input >>= 1)
      ++count;

    return count;
  }

} // namespace


TEST(AlgoBit, GetMSBPosition)
{
  using namespace algo_bit;

  // A = 35 = 10 0011
  // B =  9 =    1001
  EXPECT_THAT(get_msb_pos_1(35), Eq(6));
  EXPECT_THAT(get_msb_pos_1(9), Eq(4));

  // count_bit() is different since has high MSB and has 0s in the lower bits.

  EXPECT_THAT(count_bit(35), 3);
  EXPECT_THAT(count_bit(9), 2);
}


namespace algo_bit
{
  // 2018.0619
  // 1. unsigned int
  int count_bits_18_0619(const unsigned int a, const unsigned int b)
  {
    // get min and max
    auto input = minmax(a, b);

    // take min value
    unsigned int min = input.first;
    unsigned int max = input.second;

    // get position of the pivot
    unsigned int num_of_bits = sizeof(min)*8;
    unsigned int pos_of_msb{};
    unsigned int pivot = min;

    for (unsigned int i = 0; i < num_of_bits; ++i)
    {
      if (pivot & 0x1)
        pos_of_msb = i;

      pivot >>= 1;
    }

    // // get mask value, mask max, and get xor'ed value
    // unsigned int mask_value{}, calculated_input{};

    // for (unsigned int i = 0; i <= pos_of_msb; ++i)
    //   mask_value |= (1 << i);

    // max = max & mask_value;

    unsigned int calculated_input = max^min;

    // get num of common bits
    unsigned int num_of_common_bits{};

    for (unsigned int i = 0; i <= pos_of_msb; ++i)
    {
      if (!(calculated_input & 0x1))
        ++num_of_common_bits;

      calculated_input >>= 1;
    }

    return num_of_common_bits;
  }

  // 2018.07
  int count_bits_18_0717(const unsigned int a, const unsigned int b)
  {
    // get min and max
    auto input = minmax(a, b);

    // take min value
    unsigned int min = input.first;
    unsigned int max = input.second;

    unsigned int num_of_common_bits{};

    // no differetn when use for (; min && min >>= 1;)
    for (; min; min >>= 1, max >>= 1)
    {
      // same bit, 0 or 1 between two numbers
      if ((min & 0x1) == (max &0x1u))
        ++num_of_common_bits;
    }

    return num_of_common_bits;
  }

  // 2019.03
  int count_common_bits(uint32_t a, uint32_t b)
  {
    uint32_t count{};

    for (; a && b; a >>= 1, b >>= 1)
    {
      if ((a & 0x1) == (b & 0x01))
        count++;
    }

    return count;
  }

} // namespce

TEST(AlgoBit, CommonBits)
{
  using namespace algo_bit;

  {
    //   9,   1001
    //  35, 100011,   mask, 15 (1111),  max, 3(0011)
    //                                    9,   1001
    //                                  xor,   1010
    //                                  ans, 2
    EXPECT_THAT(count_bits_18_0717(35, 9), 2);

    // 55 = 100111,  mask, 7 (0111),   max, 7(0111)
    //                                    5,    101
    //                                  xor, 2( 010)
    //                                  ans, 2 
    EXPECT_THAT(count_bits_18_0717(55, 5), 2);
  }
  {
    auto func = count_common_bits;
    EXPECT_THAT(func(35, 9), 2);
    EXPECT_THAT(func(55, 5), 2);
  }
}


={============================================================================
*kt_dev_algo_0000* algo-reverse-bit

/* 190. Reverse Bits, Easy

Reverse bits of a given 32 bits unsigned integer.

Example 1:

Input: 00000010100101000001111010011100
Output: 00111001011110000010100101000000

Explanation: 
The input binary string 00000010100101000001111010011100 represents the unsigned
integer 43261596, so return 964176192 which its binary representation is
00111001011110000010100101000000.

Example 2:

Input: 11111111111111111111111111111101
Output: 10111111111111111111111111111111

Explanation: 
The input binary string 11111111111111111111111111111101 represents the unsigned
integer 4294967293, so return 3221225471 which its binary representation is
10101111110010110010011101101001.
 
*/

namespace algo_bit
{
  // initial thought was to use mix of atoi and itoa

  // from discussion:
  //
  // O(1) bit operation C++ solution (8ms), tworuler
  //
  // for 8 bit binary number abcdefgh, the process is as follow:
  // abcdefgh -> efghabcd -> ghefcdab -> hgfedcba

  // Runtime: 4 ms, faster than 100.00% of C++ online submissions for Reverse
  // Bits.
  //
  // Memory Usage: 8 MB, less than 79.46% of C++ online submissions for Reverse
  // Bits.

  uint32_t reverseBits(uint32_t n) 
  {
    // abcdefgh -> efghabcd 
    n = (n >> 16) | (n << 16);

    // efghabcd -> ghefcdab
    // ef00ab00 >> 00ef00ab, 00gh00cd << gh00cd00
    n = ((n & 0xff00ff00) >> 8) | ((n & 0x00ff00ff) << 8);

    // ghefcdab -> hgfedcba
    n = ((n & 0xf0f0f0f0) >> 4) | ((n & 0x0f0f0f0f) << 4);

    n = ((n & 0xcccccccc) >> 2) | ((n & 0x33333333) << 2);
    n = ((n & 0xaaaaaaaa) >> 1) | ((n & 0x55555555) << 1);

    return n;
  }

} // namespace

TEST(AlgoBit, ReverseBits)
{
  using namespace algo_bit;

  EXPECT_THAT(reverseBits(43261596), 964176192);
  EXPECT_THAT(reverseBits(4294967293), 3221225471);
}


={============================================================================
*kt_dev_algo_0000* algo-partition algo-gather algo-remove algo-unique

// algo-partition which uses the same grouping trick as algo-sort-insert

namespace algo_partition
{
  // Re-arrange the portfolio between (begin, end)  in such a way that all the
  // stocks with quantity <= maxQuantity precede all those with quantity >
  // maxQuantity Return the iterator to the first element with quantity >
  // maxQuantity

  using PortfolioIterator = vector<unsigned int>::iterator;

  // replace Stock to simple int 
  // std::vector<Stock> PortfolioGreater, PortfolioLesser;

  // 2N space and 2N time(2 pass)

  PortfolioIterator rearrangeByQuantity_1(PortfolioIterator begin,
      PortfolioIterator end,
      unsigned int maxQuantity)
  {
    // implement me
    std::vector<unsigned int> PortfolioGreater, PortfolioLesser;
    PortfolioIterator run = begin;

    for( ; run != end; ++run)
    {
      // greater
      // if( run->quantity > maxQuantity )
      if( *run > maxQuantity )
        PortfolioGreater.push_back(*run);
      else
        PortfolioLesser.push_back(*run);
    }

    run = begin;
    for(const auto& elem : PortfolioLesser) {
      *run++ = elem;
    }
    begin = run;

    for(const auto& elem : PortfolioGreater) {
      *run++ = elem;
    }

    return begin;
  }

  // less space but still 2 pass

  PortfolioIterator rearrangeByQuantity_2(PortfolioIterator begin,
      PortfolioIterator end, unsigned int max_quanity)
  {
    // how to get T of coll such as algo-remove? here, assumes that we know T
    vector<unsigned int> coll;

    PortfolioIterator start = begin;
    PortfolioIterator current{};

    // one pass to filter <=

    for (; start != end; ++start)
    {
      // not use push_back() since void push_back()
      if (*start <= max_quanity)
        current = coll.insert(coll.end(), *start);
    }

    start = begin;

    // second pass to filter >

    for (; start != end; ++start)
    {
      if (*start > max_quanity)
        coll.push_back(*start);
    }

    // copy it back
    copy(coll.begin(), coll.end(), begin);

    // *cxx-vector-reallocation* *cxx-iter-invalidated*
    // *cxx-iter-singular* means invalidated iterator since there is no guarantee
    // that current is valid after second pass push_back due to relocation
    //
    // /usr/include/c++/6/debug/safe_iterator.h:298:
    // Error: attempt to increment a singular iterator.
    // 
    // Objects involved in the operation:
    //     iterator "this" @ 0x0x7ffdeb5ea9a0 {
    //       type = __gnu_debug::_Safe_iterator<__gnu_cxx::__normal_iterator<unsigned int*, std::__cxx1998::vector<unsigned int, std::allocator<unsigned int> > >, 
    //          std::__debug::vector<unsigned int, std::allocator<unsigned int> > > (mutable iterator);
    //       state = singular;
    //       references sequence with type 'std::__debug::vector<unsigned int, std::allocator<unsigned int> >' @ 0x0x7ffdeb5eaa00
    //     }
    // Aborted
    //
    // return ++current;

    return current;
  }

  namespace algo_code
  {
    // /usr/include/c++/4.9.2/bits/stl_algo.h

    /**
     *  @brief Move elements for which a predicate is true to the beginning
     *         of a sequence.
     *  @ingroup mutating_algorithms
     *  @param  __first   A forward iterator.
     *  @param  __last    A forward iterator.
     *  @param  __pred    A predicate functor.
     *  @return  An iterator @p middle such that @p __pred(i) is true for each
     *  iterator @p i in the range @p [__first,middle) and false for each @p i
     *  in the range @p [middle,__last).
     *
     *  @p __pred must not modify its operand. @p partition() does not preserve
     *  the relative ordering of elements in each group, use
     *  @p stable_partition() if this is needed.
     */
    template<typename _ForwardIterator, typename _Predicate>
      inline _ForwardIterator
      partition(_ForwardIterator __first, _ForwardIterator __last,
          _Predicate   __pred)
      {
        return std::__partition(__first, __last, __pred,
            std::__iterator_category(__first));
      }

    /// This is a helper function...
    template<typename _ForwardIterator, typename _Predicate>
      _ForwardIterator
      __partition(_ForwardIterator __first, _ForwardIterator __last,
          _Predicate __pred, forward_iterator_tag)
      {
        if (__first == __last)
          return __first;

        while (__pred(*__first))
          if (++__first == __last)
            return __first;

        _ForwardIterator __next = __first;

        while (++__next != __last)
          if (__pred(*__next))
          {
            std::iter_swap(__first, __next);
            ++__first;
          }

        return __first;
      }
  } // namespace


  // same as algo-partition in /usr/include/c++/4.9.2/bits/stl_algo.h
  //
  // o is to find the first unmatched

  template <typename _Iterator, typename _Compare>
    _Iterator partition_1(_Iterator begin, _Iterator end, _Compare comp)
    {
      if (begin == end)
        return begin;

      // skip matched elements and begin becomes the first unmatched item.
      // begin is "start of the unmatched"
      // note that begin is increased in "if"
 
      while (comp(*begin))
        if (++begin == end)
          return begin;

      // do the same
      // _Iterator first = begin;
      // for (; first != end; ++first)
      //   if (!comp(*first))
      //     break;

      _Iterator run = begin;

      // increase first since knows *run is already unmatched.
      while (++run != end)
      {
        // see matched and move it to matched group
        if (comp(*run))
        {
          // cannot use "=" since it's not algo-remove
          std::iter_swap(run, begin);
          ++begin;
        }
      }

      return begin;
    }

} // namespace


TEST(AlgoPartition, Partition)
{
  using namespace algo_partition;

  // | matched | unmatched |
  //
  // algo-partition returns an iterator to the first element where the
  // predicate is not true, or the end of the range if all elements satisfy
  // the predicate. so first odd element:

  {
    vector<int> coll1;
    vector<int> coll2;

    // INSERT_ELEMENTS(coll1, 1, 9);
    coll1 = {1,2,3,4,5,6,7,8,9};
    EXPECT_THAT(coll1, ElementsAre(1, 2, 3, 4, 5, 6, 7, 8, 9));

    auto pos1 = partition(coll1.begin(), coll1.end(),    // range
        [](int elem)
        {
        return elem %2 == 0;
        });

    EXPECT_THAT(coll1, ElementsAre(8, 2, 6, 4, 5, 3, 7, 1, 9));

    EXPECT_EQ(*pos1, 5);

    // INSERT_ELEMENTS(coll2, 1, 9);
    coll2 = {1,2,3,4,5,6,7,8,9};
    EXPECT_THAT(coll2, ElementsAre(1, 2, 3, 4, 5, 6, 7, 8, 9));

    auto pos2 = stable_partition(coll2.begin(), coll2.end(),
        [](int elem)
        {
        return elem %2 == 0;
        });
    EXPECT_THAT(coll2, ElementsAre(2, 4, 6, 8, 1, 3, 5, 7, 9));

    // first odd element:
    EXPECT_EQ(*pos2, 1);
  }

  // works like algo-partition-stable_partition
  {
    vector<unsigned int> coll{43,6,11,42,29,23,21,19,34,37,48,24,15,20,13,26,41,30,6,23};

    const auto func = rearrangeByQuantity_1;

    auto it = func(coll.begin(), coll.end(), 25);

    // 43,6,11,42,29,23,21,19,34,37,48,24,15,20,13,26,41,30,6,23,
    // 6,11,23,21,19,24,15,20,13,6,23,43,42,29,34,37,48,26,41,30,
    //                                ^^

    EXPECT_THAT(coll, 
        ElementsAreArray({6,11,23,21,19,24,15,20,13,6,23,43,42,29,34,37,48,26,41,30}));

    EXPECT_THAT(*it, 43);
  }

  {
    vector<unsigned int> coll{43,6,11,42,29,23,21,19,34,37,48,24,15,20,13,26,41,30,6,23};

    const auto func = rearrangeByQuantity_2;

    auto it = func(coll.begin(), coll.end(), 25);

    // 43,6,11,42,29,23,21,19,34,37,48,24,15,20,13,26,41,30,6,23,
    // 6,11,23,21,19,24,15,20,13,6,23,43,42,29,34,37,48,26,41,30,
    //                                ^^

    EXPECT_THAT(coll, 
        ElementsAreArray({6,11,23,21,19,24,15,20,13,6,23,43,42,29,34,37,48,26,41,30}));

    // this now fails since `current` is iterator of internal coll but not input
    // coll. Have to work out one.
    // EXPECT_THAT(*it, 43);
  }

  {
    vector<unsigned int> coll{43,6,11,42,29,23,21,19,34,37,48,24,15,20,13,26,41,30,6,23};

    // this prevents cxx-template-deduction
    // const auto func = partition_1;

    auto it = partition_1(coll.begin(), coll.end(), 
        [](unsigned int value)
        { return value <= 25; }
        );

    EXPECT_THAT(coll, 
        ElementsAreArray({6,11,23,21,19,24,15,20,13,6,23,43,42,29,34,26,41,30,37,48}));
    EXPECT_THAT(distance(coll.begin(), it), 11);
    EXPECT_THAT(*it, 43);
  }


  // Q: why partiton_xxx() make different order from partition() when use the
  // same logic? but distance is the same.

  {
    vector<unsigned int> coll{43,6,11,42,29,23,21,19,34,37,48,24,15,20,13,26,41,30,6,23};

    auto it = partition(coll.begin(), coll.end(), 
        [](unsigned int value)
        { return value <= 25; }
        );

    // EXPECT_THAT(coll, 
    //     ElementsAreArray({6,11,23,21,19,24,15,20,13,6,23,43,42,29,34,26,41,30,37,48}));

    EXPECT_THAT(coll, 
        ElementsAreArray({23,6,11,6,13,23,21,19,20,15,24,48,37,34,29,26,41,30,42,43}));

    EXPECT_THAT(distance(coll.begin(), it), 11);

    // EXPECT_THAT(*it, 43);
    EXPECT_THAT(*it, 48);
  }
}


// algo-sort-insert algo-remove 

namespace algo_remove
{
  namespace algo_code 
  {
    // /usr/include/c++/4.9/bits/predefined_ops.h

    // check if when predicate is called, what arg iter refers to equals to the
    // value.

    template<typename _Value>
      struct _Iter_equals_val
      {
        _Value& _M_value;

        _Iter_equals_val(_Value& __value)
          : _M_value(__value)
        { }

        template<typename _Iterator>
          bool
          operator()(_Iterator __it)
          { return *__it == _M_value; }
      };

    template<typename _Value>
      inline _Iter_equals_val<_Value>
      __iter_equals_val(_Value& __val)
      { return _Iter_equals_val<_Value>(__val); }

    // /usr/include/c++/4.9/bits/stl_algo.h

    /**
     *  @brief Remove elements from a sequence.
     *  @ingroup mutating_algorithms
     *  @param  __first  An input iterator.
     *  @param  __last   An input iterator.
     *  @param  __value  The value to be removed.
     *  @return   An iterator designating the end of the resulting sequence.
     *
     *  All elements equal to @p __value are removed from the range
     *  @p [__first,__last).
     *
     *  remove() is stable, so the relative order of elements that are
     *  not removed is unchanged.
     *
     *  Elements between the end of the resulting sequence and @p __last
     *  are still present, but their value is unspecified.
     */
    template<typename _ForwardIterator, typename _Tp>
      inline _ForwardIterator
      remove(_ForwardIterator __first, _ForwardIterator __last,
          const _Tp& __value)
      {
        return std::__remove_if(__first, __last,
            __gnu_cxx::__ops::__iter_equals_val(__value));
      }

    template<typename _ForwardIterator, typename _Predicate>
      _ForwardIterator
      __remove_if(_ForwardIterator __first, _ForwardIterator __last,
          _Predicate __pred)
      {
        __first = std::__find_if(__first, __last, __pred);
        if (__first == __last)
          return __first;

        _ForwardIterator __result = __first;
        ++__first;
        for (; __first != __last; ++__first)
          if (!__pred(__first))
          {
            // note
            // this is `assign` but not `swap` which make a difference to own
            // remove does.

            *__result = _GLIBCXX_MOVE(*__first);
            ++__result;
          }
        return __result;
      }

    // /usr/include/c++/4.9/bits/predefined_ops.h
    template<typename _Predicate>
      struct _Iter_pred
      {
        _Predicate _M_pred;

        _Iter_pred(_Predicate __pred)
          : _M_pred(__pred)
        { }

        template<typename _Iterator>
          bool
          operator()(_Iterator __it)
          { return bool(_M_pred(*__it)); }
      };

    template<typename _Predicate>
      inline _Iter_pred<_Predicate>
      __pred_iter(_Predicate __pred)
      { return _Iter_pred<_Predicate>(__pred); }

    template<typename _ForwardIterator, typename _Predicate>
      inline _ForwardIterator
      remove_if(_ForwardIterator __first, _ForwardIterator __last,
          _Predicate __pred)
      {
        return std::__remove_if(__first, __last,
            __gnu_cxx::__ops::__pred_iter(__pred));
      }
  } // namespace


  // *algo-remove* 
  // same as partition_1() but | unmatched | matched |

  template <typename _Iterator, typename _T>
    _Iterator remove_1(_Iterator begin, _Iterator end, _T value)
    {
      if (begin == end)
        return begin;

      // skip `unmatched` elements and begin becomes the first matched item.
      // note that begin is increased in "if"
 
      while (*begin != value)
        if (++begin == end)
          return begin;

      _Iterator run = begin;

      // increase first since knows *run is already matched.
      while (++run != end)
      {
        // see matched and move it to matched group
        if (*run != value)
        {
          // cannot use "=" since it's not algo-remove
          // std::iter_swap(run, begin);
          *begin = *run;
          ++begin;
        }
      }

      return begin;
    }

  // 1. do the same as algo-partition but from the end. 
  // 2. therefore, do not care about the order of unmatched group.

  template <typename _Iterator, typename _T>
    _Iterator remove_2(_Iterator __begin, _Iterator __end, _T __value)
    {
      _Iterator run = __end - 1;
      _Iterator start_of_remove = __end;

      for (; run > __begin; --run)
      {
        // swap only when element has the same value and swap is necessary
        if ((*run == __value) && (run != start_of_remove-1))
          swap(*run, *(--start_of_remove));
      }

      // swap only when element has the same value and swap is necessary
      if ((*run == __value) && (run != start_of_remove-1))
        swap(*run, *(--start_of_remove));

      return start_of_remove;
    }

} // namespace


TEST(AlgoRemove, Remove)
{
  using namespace algo_remove;

  // algo-remove which is opposite from algo-partition
  // | unmatched | matched |
  
  // coll.erase() delete elements but algo-remove do not.
  {
    std::vector<int> coll{1,2,3,4,5,6,2,7,2,8,2,9};

    for (auto it = coll.begin(); it != coll.end(); ++it)
    {
      if (*it == 2)
        it = coll.erase(it);
    }

    EXPECT_THAT(coll, ElementsAre(1,3,4,5,6,7,8,9));
  }

  {
    std::vector<int> coll{1,2,3,4,5,6,2,7,2,8,2,9};

    auto end = remove(coll.begin(), coll.end(), 2);

    EXPECT_THAT(distance(end, coll.end()), 4);
    EXPECT_THAT(coll, 
        ElementsAreArray({1,3,4,5,6,7,8,9,2,8,2,9}));

    coll.erase(end, coll.end());
    EXPECT_THAT(coll, ElementsAre(1,3,4,5,6,7,8,9));
  }

  // show that algo-remove() do not remove elements
  {
    std::vector<int> coll{1,2,3,4,5,6,2,7,2,8,2,9};

    remove(coll.begin(), coll.end(), 2);

    // std::vector<int> coll{1,3,4,5,6,7,8,9,2,8,2,9};
    //                                       ^^^^^^^ 

    EXPECT_THAT(coll, ElementsAreArray({1,3,4,5,6,7,8,9,2,8,2,9}));
  }

  // show that remove_if() returns end if not found
  {
    std::vector<int> coll{1,2,3,4,5,6,2,7,2,8,2,9};

    auto it = remove_if(coll.begin(), coll.end(), 
        [](int value)
        { return value == 10; }
        );

    EXPECT_THAT(it, coll.end());
  }

  // own remove
  {
    std::vector<int> coll{1,2,3,4,5,6,2,7,2,8,2,9};

    auto end = remove_1(coll.begin(), coll.end(), 2);

    EXPECT_THAT(distance(end, coll.end()), 4);
    EXPECT_THAT(coll, 
        ElementsAreArray({1,3,4,5,6,7,8,9,2,8,2,9}));

    coll.erase(end, coll.end());
    EXPECT_THAT(coll, ElementsAre(1,3,4,5,6,7,8,9));
  }
}


// algo-leetcode-9
/*
27. Remove Element, Easy

Given an array nums and a value val, remove all instances of that value in-place
and return the new length.

Do not allocate extra space for another array, you must do this by modifying the
input array in-place with O(1) extra memory.

The order of elements can be changed. It doesn't matter what you leave beyond
the new length.

Example 1:

Given nums = [3,2,2,3], val = 3,

Your function should return length = 2, with the first two elements of nums
being 2.

It doesn't matter what you leave beyond the returned length.

Example 2:

Given nums = [0,1,2,2,3,0,4,2], val = 2,

Your function should return length = 5, with the first five elements of nums
containing 0, 1, 3, 0, and 4.

Note that the order of those five elements can be arbitrary.

It doesn't matter what values are set beyond the returned length.

Clarification:

Confused why the returned value is an integer but your answer is an array?

Note that the input array is passed in by reference, which means modification to
the input array will be known to the caller as well.

Internally you can think of this:

// nums is passed in by reference. (i.e., without making a copy)
int len = removeElement(nums, val);

// any modification to nums in your function would be known by the caller.
// using the length returned by your function, it prints the first len elements.
for (int i = 0; i < len; i++) {
    print(nums[i]);
}

*/

namespace leetcode_easy_009
{
  // o Unlike RemoveDuplicates_02, end is not index but index+1

  // Runtime: 4 ms, faster than 100.00% of C++ online submissions for Remove
  // Element.
  //
  // Memory Usage: 9.3 MB, less than 56.68% of C++ online submissions for Remove
  // Element.

  int RemoveIf_01(vector<int> &nums, int val)
  {
    if (nums.empty())
      return 0;

    size_t end{};

    for (size_t i = 0; i < nums.size(); ++i)
    {
      if (nums[i] != val)
      {
        if (end != i)
          swap(nums[end], nums[i]);

        ++end;
      }
    }

    return end;
  }

} // namespace

TEST(AlgoRemove, LeetCode_Easy_009_RemoveIf)
{
  using namespace leetcode_easy_009;

  {
    const auto func = RemoveIf_01;

    vector<int> coll{3,2,2,3};
    auto len = func(coll, 3);

    EXPECT_THAT(len, 2);

    vector<int> result{};

    for (int i = 0; i < len; ++i)
      result.push_back(coll[i]);

    EXPECT_THAT(result, ElementsAre(2,2));
  }

  {
    const auto func = RemoveIf_01;

    vector<int> coll{0,1,2,2,3,0,4,2};
    auto len = func(coll, 2);

    EXPECT_THAT(len, 5);

    vector<int> result{};

    for (int i = 0; i < len; ++i)
      result.push_back(coll[i]);

    EXPECT_THAT(result, ElementsAre(0,1,3,0,4));
  }
}

algo-sort-insertion is similar to *algo-remove* *algo-partition* *algo-rotate*
in that it uses two partitions; one that is sorted or meets condition and the
other that is not.


// cxx-algo-unique

namespace algo_unique 
{
  using ITERATOR = vector<int>::iterator;

  // when see two consequtive equal items, return a iterator to the first.
  ITERATOR adjacent_find(ITERATOR first, ITERATOR last)
  {
    if (first == last)
      return last;

    ITERATOR next = first;
    while (++next != last)
    {
      if (*first == *next)
        return first;
      first = next;
    }

    return last;
  }

  // /usr/include/c++/4.9/bits/stl_algo.h

  ITERATOR unique_1(ITERATOR first, ITERATOR last)
  {
    first = adjacent_find(first, last);
    if (first == last)
      return last;

    ITERATOR dest = first;
    ++first;
    while (++first != last)
    {
      // not equal and assign(overwrite). so if equals, keep increase first.
      if (*dest != *first)
        *++dest = *first;
    }

    // one after from the last unique
    return ++dest;
  }

  template <typename _Iterator>
    _Iterator unique_2(_Iterator first, _Iterator last)
    {
      // first = adjacent_find(first, last);
      // if (first == last)
      //   return last;

      _Iterator dest = first;
      // ++first;
      while (++first != last)
      {
        // not equal and assign(overwrite). so if equals, keep increase first.
        if (*dest != *first)
          *++dest = *first;
      }

      // one after from the last unique
      return ++dest;
    }
} // namespace

TEST(AlgoUnique, Unique)
{
  using namespace algo_unique;
  
  // o Both forms collapse `consecutive equal elements` by removing the
  // following duplicates.
  {
    vector<int> coll{1, 4, 4, 6};
    auto pos = unique(coll.begin(), coll.end());
    coll.erase(pos, coll.end());
    EXPECT_THAT(coll, ElementsAreArray({1, 4, 6}));
  }
  {
    vector<int> coll{1, 4, 4, 4, 6};
    auto pos = unique(coll.begin(), coll.end());
    coll.erase(pos, coll.end());
    EXPECT_THAT(coll, ElementsAreArray({1, 4, 6}));
  }

  // o algo-unique() is not perferct
  // The first form removes from the range [beg,end) all elements that are equal
  // to `the previous elements.` Thus, only when 
  //
  // the elements in the sequence are sorted, or at least when all elements of
  // the same value are adjacent, 
  //
  // does it remove all duplicates.
  //
  // o sorted input is not assumed

  {
    list<int> coll{1,2,3,1,2,3,4,4,6,1,2,2,3,1,6,6,6,4,4};

    auto pos = unique(coll.begin(), coll.end());
    EXPECT_THAT(coll, 
        ElementsAreArray(
          {1,2,3,1,2,3,4,6,1,2,3,1,6,4,6,6,6,4,4}));

    coll.erase(pos, coll.end());
    EXPECT_THAT(coll, 
        ElementsAreArray(
          {1,2,3,1,2,3,4,6,1,2,3,1,6,4}));
  }

  {
    list<int> coll{1,2,3,1,2,3,4,4,6,1,2,2,3,1,6,6,6,4,4};

    auto pos = unique_2(coll.begin(), coll.end());
    EXPECT_THAT(coll, 
        ElementsAreArray(
          {1,2,3,1,2,3,4,6,1,2,3,1,6,4,6,6,6,4,4}));

    coll.erase(pos, coll.end());
    EXPECT_THAT(coll, 
        ElementsAreArray(
          {1,2,3,1,2,3,4,6,1,2,3,1,6,4}));
  }

  // o The second form removes all elements that follow an element e and for
  // which the binary predicate op(e,elem) yields true. In other words, the
  // predicate is not used to compare an element with its predecessor; the
  // element is compared with the previous element that was not removed (see the
  // following examples).

  // For example, the first 6 is greater than the following 1, 2, 2, 3, and 1,
  // so all these elements are removed. In other words, the predicate is not
  // used to compare an element with its predecessor; the element is compared
  // with the previous element that was not removed 
  {
    list<int> coll{1, 4, 4, 6, 1, 2, 2, 3, 1, 6, 6, 6, 5, 7, 5, 4, 4};

    auto pos = unique(coll.begin(), coll.end(), greater<int>());
    coll.erase(pos, coll.end());
    EXPECT_THAT(coll, ElementsAreArray({1, 4, 4, 6, 6, 6, 6, 7}));
  }

  {
    string input{"1   2  3            4           "};
    EXPECT_THAT(input, "1   2  3            4           ");

    auto new_end = unique(input.begin(), input.end(), [](const char &x, const char &y) {
      return x == y and x == ' ';
    });

    input.erase(new_end, input.end());
    EXPECT_THAT(input, "1 2 3 4 ");
  }


  // o Both forms collapse `consecutive equal elements` by removing the
  // following duplicates.
  {
    vector<int> coll{1, 4, 4, 6};
    auto pos = unique_1(coll.begin(), coll.end());
    coll.erase(pos, coll.end());
    EXPECT_THAT(coll, ElementsAreArray({1, 4, 6}));
  }
  {
    vector<int> coll{1, 4, 4, 4, 6};
    auto pos = unique_1(coll.begin(), coll.end());
    coll.erase(pos, coll.end());
    EXPECT_THAT(coll, ElementsAreArray({1, 4, 6}));
  }

  // o sorted input is not assumed
  {
    vector<int> coll{1, 4, 4, 6, 1, 2, 2, 3, 1, 6, 6, 6, 5, 7, 5, 4, 4};

    auto pos = unique_1(coll.begin(), coll.end());
    EXPECT_THAT(coll, 
        ElementsAreArray({1, 4, 6, 1, 2, 3, 1, 6, 5, 7, 5, 4, 5, 7, 5, 4, 4}));

    coll.erase(pos, coll.end());
    EXPECT_THAT(coll, 
        ElementsAreArray({1, 4, 6, 1, 2, 3, 1, 6, 5, 7, 5, 4}));
  }
}


// algo-leetcode-8
/*
26. Remove Duplicates from Sorted Array, Easy

Given a sorted array nums, remove the duplicates in-place such that each element
appear only once and return *the new length.*

Do not allocate extra space for another array, you must do this by modifying the
input array in-place with O(1) extra memory.

Example 1:

Given nums = [1,1,2],

Your function should return length = 2, with the first two elements of nums
being 1 and 2 respectively.

It doesn't matter what you leave beyond the returned length.

Example 2:

Given nums = [0,0,1,1,1,2,2,3,3,4],

Your function should return length = 5, with the first five elements of nums
being modified to 0, 1, 2, 3, and 4 respectively.

It doesn't matter what values are set beyond the returned length.

Clarification:

Confused why the returned value is an integer but your answer is an array?

Note that the input array is passed in by reference, which means modification to
the input array will be known to the caller as well.

Internally you can think of this:

// nums is passed in by reference. (i.e., without making a copy)
int len = removeDuplicates(nums);

// any modification to nums in your function would be known by the caller.
// using the length returned by your function, it prints the first len elements.

for (int i = 0; i < len; i++) {
    print(nums[i]);
}

*/

namespace leetcode_easy_008
{
  // num is sorted (ascending)
  // the key idea is to swap to the right
  int RemoveDuplicates_01(vector<int> &nums)
  {
    if (nums.empty())
      return 0;

    int value = nums[0];
    size_t i{};

    for (i = 1; i < nums.size(); ++i)
    {
      int run = nums[i];

      // cout << "for i: " << i << ", run: " << run 
      //   << ", value: " << value << endl;

      // update current max when current value is bigger
      if (run > value)
        value = run;
      // ends when see smaller and means reaches the the new end
      else if(run < value)
      {
        // cout << "break i: " << i << endl;
        break;
      }
      // when run == value, swap it to tne end.
      else
      {
        for (size_t s = i; s < nums.size()-1; ++s)
          swap(nums[s], nums[s+1]);

        if (nums[i] > value)
          value = nums[i];
      }
    }

    // cout << "return i: " << i << endl;

    return i;
  }

  // o the key idea is to swap to the left
  // o no repeated swap until see the new end. single swap is enough 
  // o swap() should be done after updating current_max
  // o end is index but shold return len so +1

  // Runtime: 24 ms, faster than 100.00% of C++ online submissions for Remove
  // Duplicates from Sorted Array.
  //
  // Memory Usage: 11 MB, less than 24.81% of C++ online submissions for Remove
  // Duplicates from Sorted Array.

  int RemoveDuplicates_02(vector<int> &nums)
  {
    if (nums.empty())
      return 0;

    int current_max = nums[0];
    size_t end{};

    for (size_t i = 1; i < nums.size(); ++i)
    {
      if (nums[i] > current_max)
      {
        current_max = nums[i];
        ++end;
        swap(nums[end], nums[i]);
      }
    }

    return end+1;
  }

  // algo-unique, same as unique_1(), works on not-sorted input.
  // `first` is end of the interested group

  int RemoveDuplicates_03(vector<int> &nums)
  {
    auto first = nums.begin();
    auto last = nums.end();

    auto end = adjacent_find(first, last);

    // means empty or no duplicates
    if (end == last)
      return 0;

    auto run = end;

    while (++run != last)
    {
      // see different item
      if (*end != *run)
        *++end = *run;
    }

    return distance(first, end) + 1;
  }

} // namespace

TEST(AlgoUnique, LeetCode_Easy_008_RemoveDuplicates)
{
  using namespace leetcode_easy_008;

  // okay
  {
    const auto func = RemoveDuplicates_01;

    vector<int> coll{1,1,2};
    auto len = func(coll);

    EXPECT_THAT(len, 2);

    vector<int> result{};

    for (int i = 0; i < len; ++i)
      result.push_back(coll[i]);

    EXPECT_THAT(result, ElementsAre(1,2));
  }

  // fails
  {
    const auto func = RemoveDuplicates_01;

    vector<int> coll{0,0,1,1,1,2,2,3,3,4};
    auto len = func(coll);

    EXPECT_THAT(len, Not(5));

    vector<int> result{};

    for (int i = 0; i < len; ++i)
      result.push_back(coll[i]);

    EXPECT_THAT(result, Not(ElementsAre(0,1,2,3,4)));
  }

  // okay
  {
    const auto func = RemoveDuplicates_02;

    vector<int> coll{1,1,2};
    auto len = func(coll);

    EXPECT_THAT(len, 2);

    vector<int> result{};

    for (int i = 0; i < len; ++i)
      result.push_back(coll[i]);

    EXPECT_THAT(result, ElementsAre(1,2));
  }

  // fails
  {
    const auto func = RemoveDuplicates_02;

    vector<int> coll{0,0,1,1,1,2,2,3,3,4};
    auto len = func(coll);

    EXPECT_THAT(len, 5);

    vector<int> result{};

    for (int i = 0; i < len; ++i)
      result.push_back(coll[i]);

    EXPECT_THAT(result, ElementsAre(0,1,2,3,4));
  }
}


={============================================================================
*kt_dev_algo_0000* algo-rotate

// algo-rotate, algo-slide, algo-reverse

TEST(AlgoRotate, Rotate)
{
  vector<int> coll{1,2,3,4,5,6,7,8};

  // rotate one to the left
  // before *cxx-11* void rotate() so comment out 
  // auto pos = rotate(

  rotate(
    coll.begin(),     // begin  
    coll.begin()+1,   // new begin
    coll.end()        // end
  );
  EXPECT_THAT(coll, ElementsAre(2,3,4,5,6,7,8,1));

  // return the new position of the (pervious) first element.
  // EXPECT_THAT(*pos, 1);

  // pos = rotate(

  rotate(
    coll.begin(),
    coll.end()-2,
    coll.end()
  );
  EXPECT_THAT(coll, ElementsAre(8,1,2,3,4,5,6,7));
  // EXPECT_THAT(*pos, 2);

  // rotate so that 4 is the beginning
  // pos = rotate(

  rotate(
    coll.begin(),
    find(coll.begin(), coll.end(), 4),
    coll.end()
  );
  EXPECT_THAT(coll, ElementsAre(4,5,6,7,8,1,2,3));
  // EXPECT_THAT(*pos, 8);
}


// 1. do not use additional space
// 2. slide down sub group, [ne, e}
// 3. use of for loop count
//
// /usr/include/c++/4.9.2/bits/stl_algo.h
//
// /// This is a helper function for the rotate algorithm.
// template<typename _ForwardIterator>
//   _ForwardIterator
//   __rotate(_ForwardIterator __first,
//      _ForwardIterator __middle,
//      _ForwardIterator __last,
//      forward_iterator_tag)
// {}

//         ne           e
// 1  2  3 [4  5  6  7]
//       4  3
//          5  3
//             6  3
//       ne       7  3
//    ne[4  5  6  7] 3
// ne[4  5  6  7] 2  3
// 4  5  6  7] 1  2  3
// 
// use reverse:
//
// 1  2  3 [4  5  6  7]
// 3  2  1 [7  6  5  4]
// 4  5  6  7  1  2  3

namespace algo_remove 
{
  template <typename _Iterator>
    void rotate_1(_Iterator __begin, _Iterator __new_end, _Iterator __end)
    {
      if ((__begin == __new_end) || (__end == __new_end))
        return;

      auto num_swap = std::distance(__new_end, __end);

      for (;__new_end != __begin; --__new_end)
      {
        _Iterator start = __new_end;

        for (int i = 0; i < num_swap; ++i)
        {
          swap(*start, *(start-1));
          ++start;
        }
      }
    }

  // algo-rotate that use algo-reverse()
  // void
  // reverse (BidirectionalIterator beg, BidirectionalIterator end)

  template <typename _Iterator>
    void rotate_2(_Iterator begin, _Iterator new_begin, _Iterator end)
    {
      std::reverse(begin, new_begin);
      std::reverse(new_begin, end);
      std::reverse(begin, end);
    }
} // namespace

TEST(AlgoRotate, Rotate_1)
{
  using namespace algo_remove; 

  {
    vector<int> coll{1,2,3,4,5,6,7,8};

    // cannot use this since it's template
    // auto func = rotate_1;

    // rotate one to the left
    rotate_1(
        coll.begin(),     // begin  
        coll.begin()+1,   // new begin
        coll.end()        // end
        );
    EXPECT_THAT(coll, ElementsAre(2,3,4,5,6,7,8,1));

    rotate_1(
        coll.begin(),
        coll.end()-2,
        coll.end()
        );
    EXPECT_THAT(coll, ElementsAre(8,1,2,3,4,5,6,7));

    rotate_1(
        coll.begin(),
        find(coll.begin(), coll.end(), 4),
        coll.end()
        );
    EXPECT_THAT(coll, ElementsAre(4,5,6,7,8,1,2,3));
  }

  {
    vector<int> coll{1,2,3,4,5,6,7,8};
    // auto func = rotate_2;

    // rotate one to the left
    rotate_2(
        coll.begin(),     // begin  
        coll.begin()+1,   // new begin
        coll.end()        // end
        );
    EXPECT_THAT(coll, ElementsAre(2,3,4,5,6,7,8,1));

    rotate_2(
        coll.begin(),
        coll.end()-2,
        coll.end()
        );
    EXPECT_THAT(coll, ElementsAre(8,1,2,3,4,5,6,7));

    rotate_2(
        coll.begin(),
        find(coll.begin(), coll.end(), 4),
        coll.end()
        );
    EXPECT_THAT(coll, ElementsAre(4,5,6,7,8,1,2,3));
  }
}


={============================================================================
*kt_dev_algo_0000* dev-algo-problem algo-game-of-life

From {ref-001}. In short, the rule as to the neighbour count is:

o if 3 and the dead cell, gets live in the next run.
o if > 4 and the live cell, gets dead in the next run.
o if 2, makes no change.
o if 0, 1, gets dead. makes no change.

{first-version}

Grid map, newmap; // [MAXROW+2][MAXCOL+2]

do 
{
	 for( row = 1; row <= MAXROW; row++ )	// why starts from 1? see {hedge-or-sentinel}
		  for( col = 1; col <= MAXCOL; col++ )
				switch( NeighborCount( map, row, col )) 
				{
					 case 0: case 1:
					 newmap[row][col] = DEAD; break;

					 case 2:
					 newmap[row][col] = map[row][col]; break;

					 case 3:
					 newmap[row][col] = ALIVE; break;

					 case 4: case 5: case 6: case 7: case 8:
					 newmap[row][col] = DEAD; break;
				}

		CopyMap(map, newmap);
		WriteMap(map);

} while( UserSaysYes());

This approach is:

 map (current gen) -> cal and updated newmap(next gen) -> copy newmap to map
 ... repeats
	
MAXROW x MAXCOL = 20 x 60 = 1200. This amounts to about 18,000 statements.


{second-version}

Question is that is it necessary to calculate the number of neighbors of every cell at every
generation? No and improvements are:

o no copy from newmap to map.
o no cal for a whole map but for neighboring cells.

Grid map, numbernbrs;	// [MAXROW+2][MAXCOL+2]
List newlive, newdie;
List maylive, maydie;

while(UserSaysYes())
{
	 // current generation
	 // Vivify it in [map] and add it from [maylive] to [newlive] when it is dead and 3
	 TraverseList( &maylive, Vivify );
	 TraverseList( &maydie, Kill );
	 ClearList( &maylive );
	 ClearList( &maydie );

	 WriteMap( map );		// print to user

	 // next generation
	 // while traversing [newlive], cal neighbor count and update [numbernbrs]. Add it to [maylive]
	 // or [maydie]
	 TraverseList( &newlive, AddNeighbors );
	 TraverseList( &newdie, SubstractNeighbors );
	 ClearList( &newlive );
	 ClearList( &newdie );
}

{postpone-difficulty}

The subtle problem is that maylive/maydie can have multiple same entry and spurious entry and some
should be changed later because [numbernbrs] is not fully updated while traversing lists. This
difficluty is handled later when running vivify call because we have now completed neighbor counts,
that is [numbernbrs]. 

{loop-invariant}

The {loop-invariant} is a statement that is true at the beginning of every iteration of the loop. In
this example, that is:

At the beginning of the main loop, list maylive contains only dead cells, and list maydie contains
only living cells, but the list may contain duplicates or spurious entries whose counts are wrong.
The list newlive and newdie are empty.

The purpose of loop invariant is to capture the essence of the dynamic process. It is not always
easy to find.

{performance}

The amount of computation is no longer proportional to the size of the grid but to the number of
changes being made. Has about 2900 statements which is 6 times faster than the first. Is it
worthwhile although it is more complicated and costly to maintain? Usually there is
{space-and-time-trade-offs}. Depends on.




={{===========================================================================
*kt_dev_algo_0000* dev-algo-problem code-review
  
*ex-interview*

Code Review Task

systematic examination (often as peer review) of computer source code intended
to find and fix mistakes overlooked in the initial development phase, improving
both the overall quality of software and the developers' skills.

The aim of this task is to examine a piece of code that your colleague has
written. You must critically analyse and report on the quality of the code and
review it for any mistakes, bugs or issues that you feel are present. You can
make any comments, improvements or suggestions that you feel are appropriate
about style, design and logic.

Please write any review comments inline in the code below in bold red text.

There is no time or word limit but try to not spend too long completing the
task. Treat it as if it were a real review in your day as a developer.

This example is massively contrived and intentionally badly coded; don't expect
code like this in your day to day life.


General Comments On Code:

#include <cstdio>
#include <cstring>
#include <map>
#include <iostream>
#include <string>

/*
// Read file in
// Stock, TimeInterval, Volume Traded, High, Low.

VOD.L 1 100 184.0 183.7
BT.L 1 14 449.4 448.2 
VOD.L 2 434 184.1 182.4
BT.L 2 234 449.8 449.5
..

// Find the total volume traded for each stock
// Find the high and low for each stock.

// Write file a to stdout
// Per stock per interval output the %volume traded in that interval as a
// percentage of the whole day 
// Stock, Interval, %Vol for day.

VOD.L,1,2.0
BT.L,1,1.1
VOD.L,2,8.2
BT.L,2,19.0

// Write file b to stdout
// Stock, day high, day low

VOD.L,186.7,182.4
BT.L,445.3,450.9
*/

using namespace std;
typedef basic_string<char> string;

class CHighLow
{
  public:
    CHighLow() : nCurLow(0), nCurHigh(0) {};

    void add(int nHigh, int nLow)
    {
      if (nHigh > nCurHigh)
        nCurHigh = nHigh;

      if (nLow < nCurLow)
        nCurLow = nLow;
    }

    int nCurLow;
    int nCurHigh;
};

int main(int argc, char* argv[])
{
  if (!strcmp("version", argv[1]))
  {
    cerr << "Using version 1.0 VWAPer" << endl;
    return 0;
  }

  FILE* file = fopen(argv[2], "r");

  cerr << "Reading file" << argv[2] << endl;

  char line[256];
  char Stocks[1000][10];
  int Intervals[1000];
  int Volumes[1000];
  float Highs[1000];
  float Lows[1000];

  int i = 0;
  int sum = 0;

  // read input file
  while (fgets(line, 256, file))
  {
    sscanf(line, "%s %d %d %f %f", 
        Stocks[i], &Intervals[i], &Volumes[i], &Highs[i], &Lows[i++]);
  }

  cerr << "Calculating total volumes" << endl;

  // for each stock, loop through all inputs and add volumes to get the total.
  // Given map used, the same stock lines in the input will be merged into the
  // one stock. i is total # of lines

  map<std::string, int> TotalVolumes;

  for (int s = 0; s <= i; ++s)
  {
    std::string stockname = Stocks[s];

    for (int j =0; j <= i; ++j)
    {
      if (!strcmp(Stocks[j], stockname.c_str()))
      {
        TotalVolumes[stockname] += Volumes[j];
      }
    }
  }

  cerr << "Calculating high lows" << endl;

  map<std::string, CHighLow> HighLows;

  for (int s = 0; s <= i; ++s)
  {
    HighLows[Stocks[s]].add(Highs[s], Lows[s]);
  }

  cerr << "Writing files" << endl;

  // write file a
  for (int s = 0; s <= i; ++s)
  {
    cout << Stocks[s] << "," << Intervals[s] << "," 
      << TotalVolumes[Stocks[s]] / Volumes[s] * 100 << endl;
  }

  // write file b
  map<std::string, CHighLow>::iterator itr = HighLows.begin();
  while (itr != HighLows.end())
  {
    cout << (*itr).first << "," << (*itr).second.nCurLow << 
      "," << (*itr).second.nCurHigh << endl;
    ++itr;
  }

  return 1;
}


{review-by-ian}
General Comments On Code:

// `file-header` is missing. If it is a real situation, I would strongly
// complaining like "no comment on each classes and functions at all"

#include <cstdio>
#include <cstring>
#include <map>
#include <iostream>
#include <string>


using namespace std;

// I would prefer not to use std namespace. Consider using standard library
// with 'std::' prefix.

typedef basic_string<char> string;

// In most of case this type definition is not necessary.

class CHighLow
{
  public:
    CHighLow() : nCurLow(0), nCurHigh(0) {};

    // note: minor. about invalid value.
    // Setting the initial value of nCurLow to zero is wrong. Define a constant
    // variable like 'MAX_PRICE' with large integer value and set it to nCurLow.
    // Otherwise, you need to add another comparison in add() function. For a
    // case when there is an input with value 0.

    // note: major. about type. cause truncation.
    // As the high and low input values are float value, change the type of
    // parameters to float

    void add(int nHigh, int nLow)
    {
      // note: minor. agree about assumption on High > Low.
      // Need to check if nHigh is lower than nLow and handle the case properly

      if (nHigh > nCurHigh)
        nCurHigh = nHigh;

      // note: that is why suggest to set nCurLow(MAX) when nLow is 0.
      // If you set nCurLow to zero, this would not be working at all. You need
      // to assign nLow to nCurLow if nCurLow is zero for it. However I would
      // prefer setting initial value with maximum value.  

      if (nLow < nCurLow)
        nCurLow = nLow;
    }

    // As the input has floating point, define those variables as float.
    // Prefer a prefix m_ for the names of member variables. Member variables
    // should be under the private keyword 

    int nCurLow;
    int nCurHigh;
};

int main(int argc, char* argv[])
{
  // This comparison is ambiguous. Please put comments explaining why the first
  // argument should not be 'version'

  if (!strcmp("version", argv[1]))
  {
    cerr << "Using version 1.0 VWAPer" << endl;
    return 0;
  }

  // Consider using ifstream. You did not check if there is the second argument.
  // Otherwise you will see a segmentation fault when argv[2] is null.

  FILE* file = fopen(argv[2], "r");

  // Add a white space after the log message otherwise file and argv[2] will be
  // put together so file name will be looking weird.

  cerr << "Reading file" << argv[2] << endl;

  // If you are sure a line is not longer than 256 bytes this is ok, however
  // please define a constant variable like MAX_LINE_LENGTH rather than just
  // using the number.

  char line[256];

  // Like above comment, you should define MAX_STOCK_NAME_LENGTH instead of
  // putting 10. You assume the input file has 1000 lines at most. This is
  // limitation. I will suggest better design later.  Anyway define
  // MAX_INPUT_LINE_COUNT as above.

  char Stocks[1000][10]; 
  int Intervals[1000]; 
  int Volumes[1000]; 
  float Highs[1000]; 
  float Lows[1000];

  int i = 0;
  // sum is not used at all. Delete this.
  int sum = 0;

    // Replace 256 to MAX_LINE_LENGTH. If you use ifstream, getLine function can
    // replace this. If you use ifstream, cin can replace sscanf
    // note: std::getline(). How to use cin with ifstream?

    while (fgets(line, 256, file))
    {
      // note: major. agree.
      // You made big mistake here. Increasing i in the parameter is very
      // dangerous. The evaluation order of function parameter is undefined in
      // spec and usually they are evaluated in reverse order in most of
      // compilers. Therefore i will be increased firstly and the data for
      // Stocks,Intervals,Volumes and Highs will be stored in the next row. The
      // data will be totally mangled. Increase i in the separated line.

      sscanf(line, "%s %d %d %f %f", Stocks[i], &Intervals[i], 
          &Volumes[i], &Highs[i], &Lows[i++]);
    }

  cerr << "Calculating total volumes" << endl;

  map<std::string, int> TotalVolumes;

  // note: major. no need to have double loop and must be re-written
  // This double looping is really bad idea especially when the input file is
  // huge. Exponential complexity is expected and we can avoid this problem by
  // adopting a new design. I will describe later. change 's <=i' to 's < i'

  for (int s = 0; s <= i; ++s)
  {
    // No reason to create string object. Please avoid unnecessary object
    // creation and memory copy

    std::string stockname = Stocks[s];

    // Change 'j <=i' to 'j < i'
    for (int j =0; j <= i; ++j)
    {
      // So this just can be comparing Stocks[j] and Stocks[s]
      if (!strcmp(Stocks[j], stockname.c_str()))
      {
        // Map can work with char* even though it's key is string type. Just use
        // Stocks[s] here. 
        // note: may disagree since will cause creating a temp string objects.

        TotalVolumes[stockname] += Volumes[j];
      }
    }
  }

  cerr << "Calculating high lows" << endl;

  // You use this type of map later again. Set a typedef for the readability.
  map<std::string, CHighLow> HighLows;

  // note: major. good spot.
  // Calculating high and low value could be done while reading file. Running
  // another loop is not necessary. 
  
  // note: major. good spot. Change 's <=i' to 's < i'

  for (int s = 0; s <= i; ++s)
  {
    HighLows[Stocks[s]].add(Highs[s], Lows[s]);
  }

  cerr << "Writing files" << endl;

  // Change s <=i to s < i
  for (int s = 0; s <= i; ++s)
  {
    // note: major. good spot.
    // You don't want to devide by zero when Volume[s] is zero. Check the volume
    // in advance and handle the case properly.

    cout << Stocks[s] << "," << Intervals[s] << "," << 
      TotalVolumes[Stocks[s]] / Volumes[s] * 100 << endl; 
  }

  // Writing the whole definition of map is stressful always. Prefer using
  // typedef as I mentioned before.

  map<std::string, CHighLow>::iterator itr = HighLows.begin();

  // note: minor. agree. 
  // For this simple iteration, for( ; itr != HighLows.end() ; ++itr) is useful.
  // You would never need to worry about not increasing the iterator with it.

  while (itr != HighLows.end())
  {
    cout << (*itr).first << "," << (*itr).second.nCurLow << "," << 
      (*itr).second.nCurHigh << endl;

    ++itr;
  }

  return 1;
}


<design-suggestion>
You can slightly improve collecting and writing logic by adopting a wrapper
class. So you can call add() function to collect, and can do 'cout <<
highLowMapper' for printing out.

class CHighLowMapper
{
  public:
    CHighLowMapper() {};
    void add(const char* stock, int nHigh, int nLow) {
      m_HighLows[stock].add(nHigh, nLow);
    }

    friend ostream& operator<<(ostream& os, const CHighLowMapper& hlm) {
      HLMap::const_iterator itr = hlm.m_HighLows.begin();
      while (itr != hlm.m_HighLows.end())
      {
        cout << (*itr).first << "," << (*itr).second.nCurLow << "," 
          << (*itr).second.nCurHigh << endl;
        ++itr;
      }
      return os;
    }

  private:
    typedef map<std::string, CHighLow> HLMap;
    HLMap    m_HighLows;
};


The double looping to calculate the total volume must be replaced with better
logic. Here is a class to collect volume information and accumulate the total
volume for each stock. Therefore the required information can be collected in
the file reading loop. This class overrides operator >> therefore users are able
to printout the result using cout. CVolumeCollector takes maxSize for the vector
reservation. If flexibility and scalability are more important than performance,
  you can omit it.

class CVolumeCollector
{
  public:
    struct VolumeInfo{
      string stock;
      int interval;
      int volume;
    };

    // good to have since it is vector

    CVolumeCollector(int maxSize = 0) {
      if(maxSize > 0) {
        m_volumeInfoList.reserve(maxSize);
      }
    };

    void add(const char* stock, int interval, int volume) {
      VolumeInfo vi;
      vi.stock = stock;
      vi.interval = interval;
      vi.volume = volume;

      m_volumeInfoList.push_back(vi);
      m_volumes[stock] += volume;
    }

    const int getVolumeForStock(const string& stock) const {
      int totalVolume = 0;
      VolMap::const_iterator itr = m_volumes.find(stock);
      if(itr != m_volumes.end()) {
        totalVolume = itr->second;
      }
      return totalVolume;
    }

    // note: 
    // 1. calculation is wrong to get %. should be (value*100)/total. 
    // 2. % volume seems float type from the input description.
    // 3. divide-by-zero check? 

    friend ostream& operator<<(ostream& os, const CVolumeCollector& vc) {
      VolInfoVec::const_iterator itr = vc.m_volumeInfoList.begin();
      while(itr != vc.m_volumeInfoList.end()) {
        cout << (*itr).stock << "," << (*itr).interval << "," 
          << vc.getVolumeForStock((*itr).stock) / (*itr).volume * 100 
          << endl;
        ++itr;
      }
      return os;
    }

  private:
    typedef map<string, int> VolMap;
    VolMap  m_volumes;

    typedef vector<VolumeInfo> VolInfoVec;
    VolInfoVec m_volumeInfoList;
};

Using CVolumeCollector and CHighLowMapper described above, the main function is
much simpler and well structured.

int main(int argc, char* argv[])
{
  // omitted
  char line[MAX_LINE_LENGTH];

  CHighLowMapper hlm;
  CVolumeCollector vc(MAX_INPUT_FILE);

  // note: can use C++ way using ifstrem and stringstream or use freopen(
  // argv[1], "r", stdin ) to use cin.

  while (fgets(line, MAX_LINE_LENGTH, file))
  {
    char stock[MAX_STOCK_NAME_LENGTH];
    int interval;
    int volume;
    float high;
    float low;
    sscanf(line, "%s %d %d %f %f", stock, &interval, &volume, &high, &low);
    hlm.add(stock, high, low);
    vc.add(stock, interval, volume);
  }

  cout  << "Writing files"  << endl;
  // write file a
  cout << vc;
  // write file b
  cout << hlm;
  return 1;
}


note: How about having a single class and a single map rather than two classes
and three containers?

struct Record;
{
  int interval;
  float volume;
  float totalvolume;
  float high;
  float low;
};

map<stock, Record>

No since input stocks can have duplicates and the total volume, high and low are
for each unique stock.

input stock (duplicates)  -> total volume for each stock -> get % volume
                          -> high and low for each stock -> get high and low

How about one vector for input and one map for totoal volume, high and low?
Okay.


={============================================================================
*kt_dev_quiz_015* sorting and searching questions from {ref-004}

1. You are given two sorted arrays, A and B, where A has a large enough buffer at the end to hold B.
Write a method to merge B into A in sorted order.

Our logic should invlove simply comparing elements of A and B and inserting them in order, until we
have exhausted all elements in A and in B. The issue is that if insert an element into the front of
A, then we will have to shift the existing elements backwards. Better to insert elements into the
back where there is empty space. In short, combine in mergesort but from back.

void merge( int* a, int* b, int lastA, int lastB )
{
	int indexA = lastA-1, indexB = lastB-1;
	int indexMerged = lastB+lastA-1;

	while( indexA >= 0 && indexB >= 0 )
	{
		if( a[indexA] > b[indexB] )
		{
			a[indexMerged] = a[indexA];
			indexMerged--;
			indexA--;
		}
		else
		{
			a[indexMerged] = a[indexB];
			indexMerged--;
			indexB--;
		}
	}
	
	while( indexB >= 0 )
			a[indexMerged] = a[indexB];
			indexMerged--;
			indexB--;
}


2. Write a method to sort an array of strings so that all the anagrams are next to each other.

Ask us to group the strings in an array that the anagrams appear next to each other. Note that no
specific ordering of the words is required.

One way to do this is to use any standard sorting and modify the comparator. What's the easiest way
of checking if two words are anagrams? Could count occurrences of chars or could sort the string.


But do not actually need to fully sort the array. Only need to group the strings in the array by
anagram. Can do this by using a hash table which maps from the sorted version of a word to a list of
its anagrams. So, for example, 'acre' will map to the list {acre, race, care}. Once we've grouped
all the words into these list by anagram, can then put them back into the array.

public void sort( String[] array )
{
	Hashtable< String, LinkedList< String >> hash = new Hashtable< String, LinkedList< String >>();

	// group words by anagram
	for( String s : array ) {
		String key = sortChars(s);
		if( !hash.containsKey(key))
			hash.put( key, new LinkedList<String>());

		LInkedList< String > anagrams = hash.get(key);
		anagrams.push(s);
	}

	// convert hash table to array
	int index = 0;
	for( String key : hash.keySet())
	{
		LinkedList< String > list = hash.get(key);
		for( String t : list ) {
			array[index] = t;
			index++;
		}
	}
}

If use STL, then can code:

bool isAnagram( string a, sting b )
{
	if( a.size() != b.size() ) return false;

	sort( a.begin(), a.end() );
	sort( b.begin(), b.end() );

	return a == b;
}

func( vector< string > &svec )
{
	sort( svec.begin(), svec.end(), isAnagram );
}

However, question is how the final vector looks like?


3. Given a sorted array of n integers that has been rotated an unknown unmber of times, wrtie code
to find an element in the array. You may assume that the array was originally sorted in increasing
order.

EXAMPLE
input: find 5 in {15, 16, 19, 20, 25, 1, 3, 4, 5, 7, 10, 14}
output: 8 (the index of 5 in the array)

The complication is that the array is rotated and may have an inflection point and consider
following examples:

A1{10, 15, 20,  0,  5}
A2{50,  5, 20, 30, 40}

See that 5 appears on different side so comparing x with the midpoint is insufficient. However, if
you look a bit DEEPER, one half of the array must be ordered (regardless of how much it is rotated.) 
This is key observation which allows us to determine whether should search the left or right half.

 [KT] The rotation breaks sorted array but there is still one half ordered.

For example of searching 5 in A1, look at the left element, 10, and middle, 20. Since 10 < 20, the
left half must be ordered and since 5 is not in left half, must search the right half.

So determine the ordered half and see if a key is in the the ordered half. If so, do binary search
or sequential if n is small. If not, do sequential on the opposite half.

The tricky is if the left and the middle are identical, as in the example array

{2, 2, 2, 3, 4, 2}
       m

    m
2 2 2 2 3 4 (left)
4 2 2 2 2 3
3 4 2 2 2 2
2 3 4 2 2 2 
2 2 3 4 2 2 
2 2 2 3 4 2 (right)
2 2 2 2 3 4 (left)

In this case, check if the rightmost element is different. If it is, can search just the right side.
Otherwise, we have no choice but to search both halves.

public int search( int a[], int left, int right, int x ) {
	int mid = ( left + right )/2;

	// check mid first
	if( x == a[mid] )
		return mid;

	if( right < left )
		return -1;

	// left is ordered
	if( a[left] < a[mid] )
	{
		if( x >= a[left] && x <= a[mid] ) 		// is in the left and search it
			return search( a, left, mid-1, x );
		else
			return search( a, mid+1, right,x );	// is not in the left and search the right
	}
	// right is ordered
	else if( a[mid] < a[left] )
	{
		if( x >= a[mid] && x <= a[right] )		// search right
			return search(a, mid+1, right, x );
		elser
			return search(a, left, mid-1, x );	// search left
	}
	// left is all repeats
	else if( a[left] == a[mid] )
	{
		if( a[mid] != a[right])
			return search(a, mid+1, right, x);			// search right
		else
		{
			int result = search(a, left, mid-1, x );	// search left
			if( result == -1 )
				return search(a, mid+1, right, x );		// search right
			else
				return result;
		}
	}

	return -1;
}

This will run in O(logn) if all the elements are unique. However, with many duplicates is actually
O(n). This is because with many duplicates, will often have to search both.

 [KT] If n is large, can use iterative binary1 search on ordered half.


4. Imagine you have a 20GB file with one string per line. Explain how you would sort the file.

In this case, it suggests that they don't want you to bring all the data into memory. We'll divide
the fine into chunks which are x MB each where x is the amount of memory we have available. Each
chunk is sorted separately and then saved back to the file system.

Once all the chunks are sorted, we then merge the chunks, one by one. At the end, we have a fully
sorted file. This is known as external sort.

 [KT] For sorting chunks, load it to a memeory and use quicksort as it is good for contig memory and
 can use mergesort for merging sorted chunks which are in file system. 


<5> Given a sorted array of string which is interspersed with empty string, write a method to find
the location of a given string.

EXAMPLE
input: find 'ball' in { "at", "", "", "", "ball", "", "", "cor", "", "", "dad", "", "" }
output: 4 (the index of 4 in the array)


{A} Can implement simple modification of binary search. All we need to do is fix the comparison
against mid, in case mid is an empty string. Simply move mid to the closest non-empty string. 

public int searchR( String[] strings, String str, int first, int last )
{
	int mid = (last+first)/2;

	// if mid is empty, find closest non-empty string in both direction.
	if( strings[mid].isEmpty())
	{
		int left = mid-1;
		int right = mid+1;

		while(true)
		{
			if(left < first && right > last)
				return -1;
			else if( right <= last && !strings[right].isEmpty())
			{
				mid = right; break;
			}
			else if( left >= first && !strings[left].isEmpty())
			{
				mid = left; break;
			}

			right++; left--;
		}
	}

	// check for string, and recurse if necessary
	if( str.equals( strings[mid] ))		// found
		return mid;
	else if( strings[mid].compareTo(str) < 0)
		return searchR( strings, str, mid+1, last );		// search right
	else
		return searchR( strings, str, first, mid-1 );	// search left
}

public int search( String[] strings, String str )
{
	if( strings == null || str == null || str == "" )
		return -1;

	return searchR( strings, str, 0, strings.length-1 );
}


Careful consideration should be given to the situation when someone searches for the empty string.
Should we find the location( which is an O(n) operation)? Or should we handle this as an error?
There is no correct answer here. This is an issue you should raise with your interviewer. Simply
asking this question will demonstrate that you are a careful coder.

 [KT] Is it possible since do not know how to identify a empty string between them?



<6> Given MxN matrix in which each row and column is sorted, write a method to find an element.

{A} If do binary search on every row, then O(M logN). This is a good approach to mention to your
interviewer before you proceed with a better algorithm.

[approach-one] use first and last element.

Use these observations:
- if the start of col is greater than x, x is to the left of the col. exclude col.
- if the end of col is less than x, x is to the right of the col.

- if the start of row is greater than x, x is above that row.
- if the end of row is less than x, x is below that row.

15 20 40  85
20 35 80  95
30 55 95  105
40 80 100 120

Use 1 and 4 condition and repeatedly apply these to search for 55. Eleminate row and col from
top-right of array and so EQ check on the first at each iteration which is top-right. See that
top-right is both the start of col and the end of row.

bool findElement( int [][] matrix, int elem )
{
	int row = 0;
	int col = matrix[0].length -1;

	while( row < matrix.length && col >= 0 )
	{
		if( matrix[row][col] == elem )
			return true;
		else if( matrix[row][col] > elem )	// start of col
			col--;
		else 											// end of row
			row++;
	}
	return false;
}


[approach-two]
This more directly looks like binary search. More complicated but it applies many of the same
learnings.

The observation is that when see 95, all elements in sub rectangle are less than 95 and this is true
along the diagonal. So do binary search on the diagonal.

15 20 70 |85
20 35 80 |95
30 55 95 |105
----------
40 80 100 120

In search for 85, it cannot be in top-left and bot-right sub rectangle and continue for other sub
rectangles.

 15  20  * [70]  85
 20  35  *  80  [95]
***************
[30] 55  * [95] 105
 40 [80] * 100  120

static Coordinate findElement( int matrix[][], int x )
{
	Coordinate origin = new Coordinate(0, 0);
	Coordinate dest = new Coordinate( matrix.length-1, matrix[0].length-1 );

	return findElement(matrix, origin, dest, x );
}

// origin is top-left and dest is bot-right
public Coordinate findElement( int [][] matrix, Coordinate origin, Coordinate dest, int x )
{
	if( !origin.inbounds( matrix ) || !dest.inbounds(matrix) )
		return null;

	// EQ on origin
	if( matrix[origin.row][origin.col] == x )
		return origin;

	else if( !origin.isBefore(dest))
		return null;

	// get start and end of diagonal since the grid may not be square, the end of the diagonal may
	// not equal dest.
	Coordinate start = (Coordinate) origin.clone();
	int diagDist = Math.min( dest.row - origin.row, dest.col - origin.col );
	Coordinate end = new Coordinate( start.row + diagDist, start.col + diagDist );

	// do binary search on the diagonal, looking for the first element greater than x
	// but seems wrong. think of searcing 25.
	Coordinate p = new Coordinate(0,0);

	while( start.isBefore(end))
	{
		p.setToAverage( start, end );

		if( x > matrix[p.row][p.col] )
		{
			start.row = p.row+1; start.col = p.col+1;
		}
		else
		{
			end.row = p.row-1; end.col = p.col-1;
		}
	}

	return partitionAndSearch( matrix, origin, dest, start, x );
}

public Coordinate partitionAndSearch( int [][] matrix, Coordinate origin, Coordinate dest,
		Coordinate pivot, int elem )
{
	// origin and dest for low-left sub rectangle
	Coordinate lowerLeftOrigin	 =  new Coordinate( pivot.row, origin.col );
	Coordinate lowerLeftDest	 =  new Coordinate( dest.row, pivot.col-1 );

	// origin and dest for up-right sub rectangle
	Coordinate upperRightOrigin =  new Coordinate( origin.row, pivot.col );
	Coordinate upperRightDest 	=  new Coordinate( pivot.row-1, dest.col );

	Coordinate lowerLeft = findElement( matrix, lowerLeftOrigin, lowerLeftDest, elem );
	if( lowerLeft == null )
		return findElement(matrix, upperrightorigin, upperRightDest, elem );

	return lowerLeft;
}



<7> A circus is designing a tower routine consisting of people standing atop one another's shoulder.
For practical and aesthetic reasons, each person must be both shorter and lighter than the person
below him or her. Given the heights and weights of each person in the circus, write a method to
compute the largest possible number of people in such a tower.

We have a list of pairs of items. Find the longest sequence such that both the first and second
items are in increasing order. Apply the simple-and-generalize approach and can relate this problem
to finding the-longest-increasing-sequence in an array.

If the elements do not need to stay in the same(relative) order, then we would simply sort the
array. This makes the problem too trivial, so let's assume that the elements need to stay in the
same order.

The first recursive approach:

Array: 13, 14, 10, 11, 12
Longest(0 through 0) : 13
Longest(0 through 1) : 13, 14
Longest(0 through 2) : 13, 14
Longest(0 through 3) : 13, 14 or 10, 11
Longest(0 through 4) : 10, 11, 12

The different approach: Rather then trying to find the longest increasing subsequence across
elements 0 through i, can find the longest subsequence which [ends] with element i. 

Array: 13, 14, 10, 11, 12
Longest(ending with A[0]) : 13
Longest(ending with A[1]) : 13, 14
Longest(ending with A[2]) : 10
Longest(ending with A[3]) : 10, 11
Longest(ending with A[4]) : 10, 11, 12

For the real problem, sort the list of people by their hights and then apply the second approach on
their weights. The solution is the exact implementation of the second and to build a array of list
where a list is sequence. This scans from 0 for every element.

 [KT] The approach in *kt_dev_quiz_013* looks better than this.


<8> sorting and searching questions from {ref-004}, p122
Imagine you are reading a stream of integers. Periodically, you wish to be able to look up the rank
of a number x (the number of values less than or equal to x).

Implement the data structures and algorithms to support these operations.

That is, implement the method track(int x), which is called when each number is generated, and the
method getRankOfNumber(int x), which returns the number of values less than or equal to x (not
including x itself).


{A} A easy way would be to use an array. As with contiguous list, not efficient whenever element
arrives, insert, sort, do binary search, and return the found index. Return -1 when not found. This is what BST
solves. To find the rank of a number, we could do an inorder traversal and this is exactly
{treesort}. The key is that the rank of the node is the number of nodes in the left subtree.

Two solutions?

1) build BST when element comes in and do inorder traversal when getRankOfNumber() is called. Count
the number of visits until found a match and -1 if not found. However, this approach requires full
traversal. 

2) In the book, it have left count per each node and increase it whenever inserting on left happens
since it means that element which is less is inserted. That is, build a BST with left count as add
new elements to the left subtree. When getting the rank, traverse a tree by adding left count and
and 1 when move right since it need to add node itself before move to right. By doing this, can save
some time of traversal to left subtree so better than the full traversal.

                  20[4] ()

         15[3] ()                25[2] ()

   10[1] ()                   23[0] ()          // notice it has 0

5[0] () 13[0] ()                 24[0] ()

where [x] means left count and as an example, take 24 which returns 6.

// outline. recursive version
//
in getRank( Node node, int x )
{
  if x is node.data
    return node.leftSize();

  // when move to left, do not get the rank since the rank of the left is already calculated. this
  // book said that "not passing over any samller nodes". 
  if x is on left of node
    return getRank( node.left, x );

  // when move to right, add +1 since should include the current node, and get the right.
  if x is on right of node
    return node.leftSize() +1 + getRank( node.right, x );
}

// reference java code
public class Question {
  private static RankNode root = null;

  public static void track(int number) {
    if( root == null )
      root = new RankNode(number);
    else
      root.insert(number);
  }

  public static int getRankOfNumber(int number) {
    return root.getRank(number);
  }
}

class RankNode {
  int left_size = 0;
  RankNode left, right;
  int data = 0;

  public void insert(int d) {
    if ( d <= data )                // suggest that 'equal' items on its left.
    {
      if( left != null ) left.insert(d);
      else left = new RankNode(d);
      left_size++;                  // increase counts
    }
    else 
    {
      if( right != null ) right.insert(d);
      else right = new RankNode(d);
    }
  }

  public int getRank(int d) {
    if( d == data )
    { return left_size; }
    else if( d < data )
    {
      if( left == null ) return -1;
      else return left.getRank(d);
    }
    else    // move to right
    {
      int right_rank = right == null ? -1 : right.getRank(d);

      if( right_rank == -1 ) return -1;         
      // this is necessary. otherwise, will return left_size even if it is not found in the right tree.
      else return left_size + 1 + right_rank;
    }
  }
};

Handled the case in which d is not found in the tree and return -1 up the tree. It is important that
you handle cases like that.


={{===========================================================================
*kt_dev_algo_0000* dev-algo-quiz estimation using power of two *ex-interview*

From google phone interview, quick calculation of 2^24.

2^10 = 10^3 = 1K  (about)
2^20 = 10^6 = 1000K = 1M = million
2^24 = 2^4 * 2^20 = 16M


={============================================================================
*kt_dev_quiz_018* q-code-list linked list questions from {ref-004}

single-or-double

When you are dicussing a linked list in an interview, must understand whether it
is a singly linked list or a doubly linked list.

delete-a-node-in-a-list

Given a node n, find the previous node prev and set prev.next equal to n.next. If the list is doubly
linked, must also update n.next to set n.next.prev equal to n.prev. Also important to check for the
null pointer, to update the head or tail as necessary, or to do memory management.


<2-1> Write code to remove duplicates from an unsorted linked list. Follow up. How would you solve
this problem if a temporary buffer is not allowed?

A simple hash table will work well here. Simply iterate through the linked list, adding each element
to a hash table. When discover a duplicate element, remove the element and continue iterating. Can
do this all in one pass since we are using a linked list.

public static void deleteDups( LinkedListNode n )
{
	Hashtable table = new Hashtable();

	LinkedListNode prev = null;

	while( n != null )
	{
		if( table.containsKey(n.data))
		{
			prev.next = n.next;
		}
		else
		{
			table.put(n.data, true );
			prev = n;
		}

		n = n.next;
	}
}

This takes O(n) time. [KT] Can use stl::set and should delete duplicate node. 

If do not have a buffer, can iterate with two pointers; current which iterates through the linked
list, and runner which checks all subsequent nodes for duplicates.

public static void deleteDups( LinkedListNode head )
{
	if( head == null ) return;

	LinkedListNode current = head;

	while( current != null )
	{
		LinkedListNode runner = current;
		while( runner.next != null )
		{
			if( runner.next.data == current.data )
				runner.next = runner.next.next;
			else
				runner = runner.next;
		}

		current = current.next;
	}
}

This runs in O(1) space and O(n2) time. This is called [runner-technique] which is the second
pointer used in many linked list problems.


<2-2> Implement an algorithm to find the kth to last element of a singly linked list.

If the size of the linked list is known, the kth to last is the (length-k) th element. Just iterate
through the list to find this element. Because this solution is so trivial, we can almost be sure
that this is not what the interviewer intended. [KT] The solutions in this book looks odd and don't
get why since iterating through from the head is better and ture when do not know the size as when
know the size.


<2-3> Implement an algorithm to delete a node in the middle of a singly linked list, given only access
to that node.

You are not given the head of the list and only have access to that node. The solution is to copy
the data from the next node over to the current and delete the next node.

public static boolean deleteNode( LinkedListNode n ) {
	if( n == null || n.next == null )
		return false;

	LinkedListNode next = n.next;
	n.data = next.data;
	n.next = next.next;

	// must delete next;
	return true;
}

This connot solve if the node to be deleted is the last node since it do not have next. That is okay
as long as you can point that out. Can add a dummy node.


<2-4> Write a code to partition a linked list around a value x, such that all nodes less than x come
before all nodes greater than or equal to x.

If this were an array, be careful about how we shifted elements since array shift are very
expensive. However in a linked list the situation is much easier and can create two different linked
lists; before and after list. Once completed splitting and reached the end, merge the two list.

ListNode* partition( List* list, int x )
{
	ListNode* beforeStart = null;
	ListNode* beforeEnd = null;
	ListNode* afterStart = null;
	ListNode* afterEnd = null;

	ListNode* node = list->header;

	while(node != null)
	{
		// save next node
		ListNode* next = node->next;
		
		// break a link but not needed
		node->next = null;

		if( node->data < x )
		{
			// insert node into the before list
			if( beforeStart == null )
			{ beforeStart = node; beforeEnd = beforeStart; }
			else
			{ beforeEnd->next = node; beforeEnd = node; }
		}
		else
		{
			// insert node into the after list
			if( afterStart == null )
			{ afterStart = node; afterEnd = afterStart; }
			else
			{ afterEnd->next = node; afterEnd = node; }
		}

		node = next;
	}

	if( beforeStart == null )
		return afterStart;

	// merge before and after list
	beforeEnd->next = afterStart;
	return beforeStart;
}

If it bugs you to keep four different variables, can get rid of some with a minor hit to the
efficiency. This drop comes because have to traverse the list an extra time. The big-O time will
remain the same though and we get shorter and cleaner code. Instead of inserting nodes into the end
of list, inserts node into the front of them.

ListNode* partition( List* list, int x )
{
	ListNode* beforeStart = null;
	ListNode* afterStart = null;

	ListNode* node = list->header;

	while(node != null)
	{
		// save next node
		ListNode* next = node->next;
		
		if( node->data < x )
		{
			node->next = beforeStart;
			beforeStart = node;
		}
		else
		{
			node->next = afterStart;
			afterStart = node;
		}

		node = next;
	}

	if( beforeStart == null )
		return afterStart;

	// find end of before list and merge them
	ListNode* head = beforeStart;		// node = beforeStart; to use node variable.
	while( beforeStart->next != null )
		beforeStart = beforeStart.next;

	beforeStart->next = afterStart;
	return head;
}

[KT] Thought about modification of BST since it has the left which is less and the right which is
greater than node entry. For example, use fixed entry value of root and node either left or right.
Not recursive since need only the right and the left. After all, this has two pointers and is the
same as above. Also think {mergesort}


<2-5> You have two numbers represented by a linked list, where each node contains a single digit.
The digits are stored in reverse order, such that the 1's digit is at the head of the list. Write a
function that adds the two numbers and returns the sum as a linked list.

The book's approach is to use how addition works and can do this process recursively by adding node
by node, carrying over any excess to the next node.

 7 -> 1 -> 6 -> X
+5 -> 9 -> 2 -> X
------------
 2 -> 1 -> 9
 ----------> pass carry forward

Be careful to handle the condition when one list is shorter than another.

LinkedListNode addLists( LinkedListNode lone, LinkedListNode ltwo, int carry )
{
	// done if both lists are null and the carry is 0, no need to check on carry
	if( lone == null && ltwo == null && carry == 0 )
		return null;

	LinkdedListNode result = new LinkedListNode( carry, null, null );

	int value = carry;

	if( lone != null )
		value += lone.data;

	if( ltwo != null )
		value += ltwo.data;

	result.data = value % 10;
	
	if( lone != null || ltwo != null || value >= 10 )
	{
		LinkedListNode more = addLists( lone == null ? null : lone.next,
				ltwo == null ? null : ltwo.next,
				value >= 10 ? 1 : 0 );

		result.setNext(more);
	}

	return result;
}

<code-example>

#include <iostream>
#include <cstdlib>

typedef int ListEntry;

typedef struct node
{
	ListEntry 	entry;
	node*			pnext;
} ListNode;

typedef struct {
   int   count;
	ListNode*	header;
} List;

ListNode* MakeListNode( ListEntry entry )
{
	ListNode* pnode = NULL;

	if( (pnode = (ListNode*) malloc( sizeof(ListNode))) == NULL )
	{
		std::cout << "no more memory" << std::endl;
		return NULL;
	}

	pnode->entry = entry;
	pnode->pnext = NULL;

	return pnode;
}

void CreatList( List* list )
{ 
   list->count = 0;
   list->header = NULL; 
}	

bool ListEmpty( List* list )
{ return ( list->header == NULL ); }

// add only at the end
bool ListAdd( List* list, ListEntry entry )
{
	ListNode* pnode, *pend;

	if( (pnode = MakeListNode(entry)) == NULL )
	{
		std::cout << "add: mem is full" << std::endl;
		return false;
	}

   if( ListEmpty( list ) )
   {
      list->header = pnode;
   }
   else
   {
      for( pend = list->header; pend->pnext; pend = pend->pnext )
         ;

      pend->pnext = pnode;
   }

   list->count++;

   std::cout << "add: added " << entry << ", count " << list->count << std::endl;

	return true;
}

typedef void(*TRAVERSEFUNC)(ListEntry);	

void ListTraverse( List* list, TRAVERSEFUNC func)
{
	ListNode* pnode;

	if( ListEmpty(list) )
	{
		std::cout << "list is empty" << std::endl;
		return;
	}
	
	pnode = list->header;

	while(pnode)
	{
		func(pnode->entry);
		pnode = pnode->pnext;
	}
}

void EntryPrint(ListEntry item)
{
   std::cout << "item is: " << item << std::endl;
}

ListNode* sumLists( ListNode *one, ListNode *two, ListEntry carry )
{
	if( one == NULL && two == NULL )
		return NULL;

	ListNode* pnode = MakeListNode( carry );
	if(!pnode)
	{
		std::cout << "sumLists: mem is full" << std::endl;
		return NULL;
	}

	if( one != NULL )
		carry += one->entry;

	if( two != NULL )
		carry += two->entry;

	pnode->entry = carry % 10;

// This was an attempt to reduce one recursive call because the book's approach make a one last call
// when both input node is null. For example
//
// 1->2->X
// 3->4->5->X // here a call made to X on this list
//
// However, this cause a crash because when one of both is null, cannot use one->pnext or
// two->pnext.
//
// {LL} When use recursive, must careful about NULL and accessing data from NULL.
//
//	if( one->pnext != NULL || two->pnext != NULL )
//		pnode->pnext = sumLists( one->pnext, two->pnext, carry >= 10 ? 1 : 0 );
//

	if( one != NULL || two != NULL )
		pnode->pnext = sumLists( one == NULL ? NULL : one->pnext, two == NULL ? NULL : two->pnext, 
				carry >= 10 ? 1 : 0 );

	return pnode;
}

int main()
{
	int item = 0;

	// first
	List first;
	CreatList(&first);

	std::cout << "type in 2 numbers." << std::endl;

	for(int i=0; i < 2; i++)
	{
		std::cin >> item;
		ListAdd(&first, item );
	}		

	// second
	List second;
	CreatList(&second);

	std::cout << "type in 3 numbers." << std::endl;

	for(int i=0; i < 3; i++)
	{
		std::cin >> item;
		ListAdd(&second, item );
	}		

	std::cout << "first:" << std::endl;
	ListTraverse(&first, EntryPrint);

	std::cout << "=======" << std::endl;
	std::cout << "second:" << std::endl;
	ListTraverse(&second, EntryPrint);

	// sum
	List sum;
	CreatList(&sum);

	sum.header = sumLists( first.header, second.header, 0 );

	ListTraverse(&sum, EntryPrint);
}


[KT] If there is no need to build a list for a result, simply follow a list and build number and do
integer addition.

1's			10's			100's
10^0			10^1			10^2
node*10^0	node*10^1	node*10^2


<follow-up> Suppose the digits are stored in forward order. Repeat the above problem.

Two complications:

- One list may be shorter then the other. For example, 1->2->3->4 and 5->6->7. Need to know that the
5 should be matched with the 2, not the 1. How? Compare the length of the lists and pad the shorter
list with zeros.

- In the previous, the successive results were added to the tail, ie., passed carry forward. In this
case results are added to the head, ie., passed backward. This time recursive call must return the
carry as well. Can solve this by creating a wrapper class, PartialSum.


1 -> 2 -> 3 -> X
4 -> 5 -> 6 -> X
h
               sum
          sum+val+carry
     sum+val+carry
sum+val+carry

So PartialSums is one to pass backward sum and carry.


public class PartialSum {
	public LinkedListNode sum = null;
	public int carry = 0;
}

LinkedListNode padList( LinkedListNode l, int padding )
{
	LinkedListNode head = l;

	for( int i = 0; i < padding; i++ )
	{
		LinkedListNode n = new LinkedListNode( 0, null, null );
		// if it is single linked list 
		// head.prev = n;
		n.next = head;
		head = n;
	}
}

LinkedListNode insertBefore( LinkedListNode list, int data )
{
	LinkedListNode node = new LinkedListNode( data, null, null );

	if( list != null )
	{
		// list.prev = node;
		node.next = list;
	}

	return node;
}

// See how the recursive is used to start from the end node.
PartialSum addListsHelper( LinkedListNode l1, LinkedListNode l2 )
{
	if( l1 == null && l2 == null )
	{
		PartialSum sum = new PartialSum();
		return sum;
	}

	// add smaller digit recursively up to null
	PartialSum sum = addListsHelper( l1.next, l2.next );

	// add carry to current data
	int val = sum.carry + l1.data + l2.data;

	// insert sum of current digit. Initially, sum.sum is null.
	LinkedListNode full_result = insertBefore( sum.sum, val%10 );

	// return sum so far and the carry value
	sum.sum = full_result;
	sum.carry = val / 10;

	return sum;
}

// see that there is no carry arg
LinkedListNode addLists( LinkedListNode l1, LinkedListNode l2 )
{
	int len1 = length(l1); int len2 = length(l2);

	// pad the shorter list with zeros
	if( len1 < len2 )
		l1 = padList( l1, len2-len1);
	else
		l2 = padList( l2, len1-len2);

	PartialSum sum = addListsHelper( l1, l2 );

	if( sum.carry == 0 )
		return sum.sum;
	else
	{
		LinkedListNode result = insertBefore( sum.sum, sum.carry );
		return result;
	}
}

See have pulled insertBefore(), padList() into their own methods. This makes the code cleaner and
easier to read. Wise thing to do in your interview.


<2-6> Given a circular linked list, implement an algorithm which returns the node at the beginning
of the loop.

This is a modification of a classic interview problem: detect if a linked list has a loop. Let's
apply the pattern matching approach. See {tortoise-and-hare}. 


==============================================================================
*kt_dev_quiz_019*	array and string questions from {ref-004}

{1-4} Write a method to replace all spaces in a string with '%20'. You may assume that the string
has sufficient space at the end of the string to hold the additional characters, and that you are
given the 'true' length of the string.

EXAMPLE
input:   "Mr John Smith    "
output:  "Mr%20John%20Smith"

A common approach is to edit the string straight from the end and work backwards because we have
extra buffer at the end.

o If cannot use extra space and have to use input to edit, then use two pass approach like
reference. One pass to find out how many spaces are needed; this is new length. Two pass to replace
chars.

o If can use extra space then use one pass approach to copy and replace chars.

<ref-code>
public void replaceSpaces( char[] str, int length ) {

  int spaceCount = 0, newLength, i = 0;
  for( i = 0; i < length; i++ ) {
    if( str[i] == ' ' )
      spaceCount++;
  }

  newLength = length + spaceCount*2;

  str[newLength] = '\0';

  for( i = length-1; i >= 0; i-- )
  {
    if( str[i] == ' ' )
    {
      str[newLength-1] = '0'; 
      str[newLength-2] = '2'; 
      str[newLength-3] = '%'; 
      newLength = newLength-3;
    }
    else
    {
      str[newLength-1] = str[i];
      newLength = newLength-1;
    }
  }
}

{1-5} Implement a method to perform basic string compression using counts of repeated characters.
For example, the string aabcccccaaa would becomre a2b1c5a3. If the compressed string would not
become smaller than the original string, your method should return the original string.

<ref-code> poor
public String compressBad( String str )
{
  String mystr = "";
  char last = str.charAt(0);
  int count = 1;

  for( int i = 1; i < str.length(); i++ )
  {
    if( str.charAt(i) == last )
      count++;
    else
    {
      mystr += last + "" + count;   // why need ""?
      last = str.charAt(i);
      count = 1;
    }
  }

  // since the last sequence wouldn't be set in the compressed string yet.
  return mystr + last + count;
}

This does not handle the case when the compressed string is longer than the original string but it
otherwise works. Efficient? This is O(n + k^2) where k is the number of sequence because string
concatenation happens whenever there is a sequence and string + operates in O(n^2). See
{inefficient-concatnation}

<ref-code> better
String compressBetter(String str)
{
  // check if compression would create a longer string.
  int size = countCompression(str);
  if( size >= str.length())
    return str;

  StringBuffer mystr = new StringBuffer();
  char last = str.charAt(0);
  int count = 1;
  for( int i = 1; i < str.length(); i++ )
  {
    if( str.charAt(i) == last )
      count++;
    else
    {
      mystr.append(last);
      mystr.append(count);
      // mystr += last + "" + count;   // why need ""?
      last = str.charAt(i);
      count = 1;
    }
  }

  mystr.append(last);
  mystr.append(count);
  return mystr.toString();
}

int countCompression(String str)
{
  char last = str.charAt(0);
  int size = 0;
  int count = 1;

  for( int i = 1; i < str.length(); i++ )
  {
    if( str.charAt(i) == last )
      count++;
    else
    {
      last = str.charAt(i);
      size += 1 + String.valueOf(count).length();
      count = 1;
    }
  }
  
  // valueOf returns string representation of count since count could be big and needs more spaces
  // in character representation.
  //
  size += 1 + String.valueOf(count).length();
  return size;
}

This runs on O(n) space and time. If cannot use StringBuffer then create a char array.


={============================================================================
*kt_dev_quiz_020* coding task

For Kantar media, second phase after phone call and used via email.

The test is as follow. Please send the code and results to me within 24 hours if you can.

A sample daily viewing file called sample.SWD, which contains the following fields (start position,
character length).

·         Home ID (0,7)
·         Individual ID (7,2)
·         Channel ID (9,4) {the corresponding channel description is in StnDesc.txt}
·         Start time - hhmmss (13,6)
·         End time - hhmmss (19,6)
·         TV set ID (25,1)

- Please extract the viewing distribution (number of viewing statements) by minute and identify any
unusual patterns.

- Please find out the percentage of unmatched tuning (i.e. Channel ID 49) to the total tuning across
the whole day.

- Please find out the top 10 channels based on the volume of viewing.

<sample.swd>
10001340100491938001945591
10001340100491951002049591
10001340100492055002108591
10001340100492124002135591
10001340100492145002156591
10001340100492204002205591
10001340100492211002222591
10001340100492230002236591
10001340200491938001945591
10001340200491951002049591
10001340200492055002108591
10001340200492124002135591
10001340200492145002156591
...

<stndesc.txt>
1;BBC1 London
2;BBC2 London
3;ITV London
4;Pick TV
5;Dave
6;ITV2
7;ITV3
8;ITV4
9;Challenge TV
10;ITV2+1
11;E4
12;E4+1
...

<code-submitted>

#include <iostream>
#include <fstream>
#include <string>
#include <vector>
#include <map>

class viewEntry
{
  public:
    viewEntry(): viewCount(0), viewVolume(0), cid(0) {}
    unsigned int viewCount;
    unsigned long long viewVolume;
    unsigned int cid;
};

class Viewing
{
  private:
    const int MINUTES_A_DAY;
    unsigned int viewTotal;

    std::vector<int> minutes; 

    typedef std::map<unsigned int, viewEntry> VIEWS;
    VIEWS views;

    unsigned int _getMinutes(std::string time);
    void _countViews( unsigned int line, unsigned int start, unsigned int end );
    unsigned int _getPercent(unsigned int minute, unsigned int max);

  public:
    Viewing( std::ifstream &ifs );

    void getTop10();

    void getPercent(int channel);

    void getDistribution(unsigned int percent, unsigned int max);
};

// Note: Used 25 hours since the data have entries such as 25:59:59
Viewing::Viewing( std::ifstream &ifs ) : viewTotal(0), MINUTES_A_DAY(1560)
{
  unsigned int lineno = 0;
  std::string line, chname, cid, stime, etime;
  unsigned int icid = 0, istime = 0, ietime = 0;

  for(int i = 0; i <= MINUTES_A_DAY; i++)
    minutes.push_back(0);

  // build data
  while(std::getline( ifs, line))
  {
    cid = line.substr(9,4);
    stime = line.substr(13,6);
    etime = line.substr(19,6);

    icid = std::stoi(cid);
    istime = _getMinutes(stime);
    ietime = _getMinutes(etime);

    // handle invalid entries
    if( icid == 950 )
      continue;

    // build views map
    auto& entry = views[icid];
    entry.viewCount++; 
    entry.viewVolume += (ietime-istime);
    entry.cid = icid;

    // build distribution vector
    _countViews( lineno, _getMinutes(stime), _getMinutes(etime));

    lineno++;
  }
}

unsigned int Viewing::_getMinutes(std::string time)
{
  return std::stoi(time.substr(0,2))*60 + std::stoi(time.substr(2,2));
}

void Viewing::_countViews(unsigned int line, unsigned int start, unsigned int end)
{
  if(start > MINUTES_A_DAY || end > MINUTES_A_DAY)
  {
    std::cout << "countViews: error: time is out of a day limit. line: " << line << std::endl;
    return;
  }

  for(int idx = start+1; idx <= end; idx++)
  {
    minutes[idx] += 1;
  }
  
  viewTotal++;
}

unsigned int Viewing::_getPercent(unsigned int minute, unsigned int max)
{
  return (minutes[minute]*100 / max);
}

// Please find out the top 10 channels based on the volume of viewing
// Note: here assumes that this is rarely used and if not, need to consider having a running
// structure rather than a temporay.
void Viewing::getTop10()
{
  VIEWS::iterator views_it = views.begin();
  typedef std::map<int, int> VOLUMES;
  VOLUMES volumes;

  for(views_it; views_it != views.end(); ++views_it)
  {
    volumes[views_it->second.viewVolume] = views_it->second.cid;
  }

  int i = 0;
  VOLUMES::iterator volumes_it = volumes.end();
  for(--volumes_it, i; i < 10; i++)
  {
    std::cout << i+1 << "th channel is " << (*volumes_it).second << std::endl;
    --volumes_it;
  }
}

// Please find out the percentage of unmatched tuning (i.e. Channel ID 49) to the total tuning across the whole day.
void Viewing::getPercent(int channel)
{
  auto& entry = views[channel];
  double result = (entry.viewCount*100/viewTotal);
  std::cout << "The channel " << channel << " has " << result << " % in total" << std::endl;
}


// Please extract the viewing distribution (number of viewing statements) by minute and identify any unusual patterns.
// Note: Assumes that viewing distribution means that the number of viewes in a specific minute and
// that it is unusal when it is over the specified percentage in the scaled down space. Here used
// 50% and 4000 as a max.
void Viewing::getDistribution(unsigned int percent, unsigned int max)
{
  for(unsigned int i = 1; i <= MINUTES_A_DAY; i++)
  {
    unsigned int scaled_percent = 0;

    if( (scaled_percent = _getPercent(i, max)) > percent )
      std::cout << i << " minutes has " << scaled_percent << " % viewers in the scaled-down space."  << std::endl;
  }
}

// Note: Generally no error handling, design, and space/time cosideration since no requirement was given. Aim
// to get the answer and to run in a rather quick fashion since was told it's about 30 minute task. 
int main()
{
  std::string line;
  int lnum = 0;
  std::ifstream ifs("sample.SWD", std::ifstream::in );

  if( ifs.is_open() )
  {
    Viewing view(ifs);

    std:: cout << "==================================================" << std::endl;
    std:: cout << "Q 01" << std::endl;
    std:: cout << "==================================================" << std::endl;
    view.getTop10();
    std:: cout << "==================================================" << std::endl;
    std:: cout << "Q 02" << std::endl;
    std:: cout << "==================================================" << std::endl;
    view.getPercent(49);
    std:: cout << "==================================================" << std::endl;
    std:: cout << "Q 03" << std::endl;
    std:: cout << "==================================================" << std::endl;
    view.getDistribution(50, 4000);

    ifs.close();
  }
  else
    std:: cout << "file is not opened" << std::endl;
}

// <The output from a run>
// ==================================================
// Q 01
// ==================================================
// 1th channel is 49
// 2th channel is 52
// 3th channel is 45
// 4th channel is 3
// 5th channel is 1
// 6th channel is 2
// 7th channel is 96
// 8th channel is 69
// 9th channel is 73
// 10th channel is 67
// ==================================================
// Q 02
// ==================================================
// The channel 49 has 35 % in total
// ==================================================
// Q 03
// ==================================================
// 1211 minutes has 51 % viewers in the scaled-down space.
// 1213 minutes has 51 % viewers in the scaled-down space.
// 1214 minutes has 51 % viewers in the scaled-down space.
// 1216 minutes has 51 % viewers in the scaled-down space.
// 1217 minutes has 51 % viewers in the scaled-down space.
// 1218 minutes has 51 % viewers in the scaled-down space.
// 1219 minutes has 52 % viewers in the scaled-down space.
// 1220 minutes has 51 % viewers in the scaled-down space.
// 1221 minutes has 51 % viewers in the scaled-down space.
// 1222 minutes has 52 % viewers in the scaled-down space.
// 1223 minutes has 51 % viewers in the scaled-down space.
// 1224 minutes has 52 % viewers in the scaled-down space.
// 1225 minutes has 51 % viewers in the scaled-down space.
// 1226 minutes has 51 % viewers in the scaled-down space.
// 1227 minutes has 51 % viewers in the scaled-down space.
// 1231 minutes has 51 % viewers in the scaled-down space.
// 1232 minutes has 52 % viewers in the scaled-down space.
// 1233 minutes has 52 % viewers in the scaled-down space.
// 1234 minutes has 53 % viewers in the scaled-down space.
// 1235 minutes has 53 % viewers in the scaled-down space.
// 1236 minutes has 52 % viewers in the scaled-down space.
// 1237 minutes has 52 % viewers in the scaled-down space.
// 1238 minutes has 52 % viewers in the scaled-down space.
// 1239 minutes has 53 % viewers in the scaled-down space.
// 1240 minutes has 52 % viewers in the scaled-down space.
// 1241 minutes has 53 % viewers in the scaled-down space.
// 1242 minutes has 53 % viewers in the scaled-down space.
// 1243 minutes has 53 % viewers in the scaled-down space.
// 1244 minutes has 53 % viewers in the scaled-down space.
// 1245 minutes has 53 % viewers in the scaled-down space.
// 1246 minutes has 53 % viewers in the scaled-down space.
// 1247 minutes has 53 % viewers in the scaled-down space.
// 1248 minutes has 53 % viewers in the scaled-down space.
// 1249 minutes has 53 % viewers in the scaled-down space.
// 1250 minutes has 54 % viewers in the scaled-down space.
// 1251 minutes has 53 % viewers in the scaled-down space.
// 1252 minutes has 53 % viewers in the scaled-down space.
// 1253 minutes has 53 % viewers in the scaled-down space.
// 1254 minutes has 54 % viewers in the scaled-down space.
// 1255 minutes has 52 % viewers in the scaled-down space.
// 1257 minutes has 52 % viewers in the scaled-down space.
// 1258 minutes has 52 % viewers in the scaled-down space.
// 1262 minutes has 51 % viewers in the scaled-down space.
// 1263 minutes has 51 % viewers in the scaled-down space.
// 1264 minutes has 53 % viewers in the scaled-down space.
// 1265 minutes has 52 % viewers in the scaled-down space.
// 1266 minutes has 53 % viewers in the scaled-down space.
// 1267 minutes has 53 % viewers in the scaled-down space.
// 1268 minutes has 53 % viewers in the scaled-down space.
// 1269 minutes has 54 % viewers in the scaled-down space.
// 1270 minutes has 54 % viewers in the scaled-down space.
// 1271 minutes has 54 % viewers in the scaled-down space.
// 1272 minutes has 54 % viewers in the scaled-down space.
// 1273 minutes has 54 % viewers in the scaled-down space.
// 1274 minutes has 54 % viewers in the scaled-down space.
// 1275 minutes has 55 % viewers in the scaled-down space.
// 1276 minutes has 54 % viewers in the scaled-down space.
// 1277 minutes has 54 % viewers in the scaled-down space.
// 1278 minutes has 54 % viewers in the scaled-down space.
// 1279 minutes has 54 % viewers in the scaled-down space.
// 1280 minutes has 54 % viewers in the scaled-down space.
// 1281 minutes has 54 % viewers in the scaled-down space.
// 1282 minutes has 55 % viewers in the scaled-down space.
// 1283 minutes has 55 % viewers in the scaled-down space.
// 1284 minutes has 54 % viewers in the scaled-down space.
// 1285 minutes has 54 % viewers in the scaled-down space.
// 1286 minutes has 54 % viewers in the scaled-down space.
// 1287 minutes has 54 % viewers in the scaled-down space.
// 1288 minutes has 55 % viewers in the scaled-down space.
// 1289 minutes has 54 % viewers in the scaled-down space.
// 1290 minutes has 54 % viewers in the scaled-down space.
// 1291 minutes has 53 % viewers in the scaled-down space.
// 1292 minutes has 53 % viewers in the scaled-down space.
// 1293 minutes has 54 % viewers in the scaled-down space.
// 1294 minutes has 54 % viewers in the scaled-down space.
// 1295 minutes has 54 % viewers in the scaled-down space.
// 1296 minutes has 54 % viewers in the scaled-down space.
// 1297 minutes has 54 % viewers in the scaled-down space.
// 1298 minutes has 52 % viewers in the scaled-down space.
// 1299 minutes has 53 % viewers in the scaled-down space.
// 1300 minutes has 53 % viewers in the scaled-down space.
// 1301 minutes has 53 % viewers in the scaled-down space.
// 1302 minutes has 53 % viewers in the scaled-down space.
// 1303 minutes has 53 % viewers in the scaled-down space.
// 1304 minutes has 53 % viewers in the scaled-down space.
// 1305 minutes has 53 % viewers in the scaled-down space.
// 1306 minutes has 53 % viewers in the scaled-down space.
// 1307 minutes has 53 % viewers in the scaled-down space.
// 1308 minutes has 53 % viewers in the scaled-down space.
// 1309 minutes has 52 % viewers in the scaled-down space.
// 1310 minutes has 53 % viewers in the scaled-down space.
// 1311 minutes has 52 % viewers in the scaled-down space.
// 1312 minutes has 52 % viewers in the scaled-down space.
// 1313 minutes has 52 % viewers in the scaled-down space.
// 1314 minutes has 53 % viewers in the scaled-down space.
// 1315 minutes has 52 % viewers in the scaled-down space.
// 1316 minutes has 52 % viewers in the scaled-down space.
// 1317 minutes has 52 % viewers in the scaled-down space.



={============================================================================
*kt_dev_quiz_021* q-logical

From TEKSystem for BB.

About yourself

1. Tell about your work experience
2. Why you left the company?
3. What do you anticipate in Bloomberg?
- what is your background / experience ?
- why would you find another job?
- why Bloomberg?
- what do you know about Bloomberg ?
- what do you expect from a job at Bloomberg ?


Technical:

- What is polymorphism?
- Give an example of usage of virtual functions.
- How are virtual functions implemented?
- How many vTables are there?
- What is a deadlock?
- How would you prevent a deadlock?
- Can you give an example for a deadlock that isn't due to mutual locks?
- What Versions of C++ did you use?
- Do you know what's changed in C++11?
- What types of STL containers do you know?
- What is the insertion complexity for a vector?
- What types of iterators are there?
- What's the difference between a forward and random access iterator?
- Do you know what static polymorphism is?
- (After explaining) How would you implement it?
- What are C++ Traits?
- Any experience with JavaScript?
- Any experience with Boost? 

1. What is a virtual function?
2. How does it work (inner mechanism)?
3. Compare sorted vector and sorted list
4. Complexity of inserting of an element in a vector and in a list
5. What is RAII (Resource Acquisition Is Initialization) technique?
6. Which patterns of programming do you know?
7. How the singleton pattern can be implemented?
8. Why it can be wrong to use it?
9. What is deadlock and how it can be prevented?

- what is a pointer  ?
- what is it useful for ?
- what are the differents types of memory ? 
note: assume it's not about hardware.

- what is dynamic allocation ?
- what are the differences of dynamic allocation between C and C++ ?

C malloc() and free() do not call constructors or destructors. C++ new and
delete operators are "class aware" and will call class constructors when a class
is allocated with new and a destructor when delete is called.

Mixing malloc with delete or new with free is undefined. In addition, C++ new
and delete operators were introduced with the C++ practice of allocating memory
in constructors and deallocating the same memory with a destructor.

new/delete advantages:

new/delete invokes constructor/destructor. Malloc/free will not.  new does not
need typcasting. Malloc requires typcasting the returned pointer.  new/delete
operators can be overloaded, malloc/free can not.  new does not require you to
explicitly calculate the quantity of memory required. (Unlike malloc)

- what is the risk of dynamic allocation ?
- how memory leaks can occur?
- if an object is allocated by a new at the beginning of a function, and freed by a delete at the
end of it, is it possible to have memory leaks, and why ?

- how this could be avoided?
- why it is no safe to throw exceptions in a destructor ?
- what happen if an exception is thrown by a destructor while another exception is being processed
(stack unwinding) ?

- how can be implemented a smart pointer with a reference counter?
- do you use STL ?
- what is the complexity of a search in a map container ?
- what is the complexity of a search in a hash table ?
- what is a collision in a hash table?
- is it better to handle collisions in hash tables using lists or vectors?
- what are the differences between multi-threads and multi-processes ?
- what is virtual memory?


={============================================================================
*kt_dev_quiz_021* q-logical

{1}
Q: You have 3 baskets, one with apples, one with oranges and one with both
apples and oranges mixed.  Each basket is closed and is labeled with 'Apples',
       'Oranges' and 'Apples and Oranges'. However, each of these labels is
       always placed incorrectly. How many fruits would you need to pick from
       the baskets in order to place the labels correctly on all the baskets?

A:
http://www.mytechinterviews.com/apples-and-oranges

These kinds of questions make for a good warm up in an interview. Frankly
speaking, this puzzle just needs a little thought. It really doesn't take any
algorithmic genius.

Say you pick a fruit from the basket labeled 'Apples and Oranges'. If this fruit
is an apple, then we know that since the label is incorrect, this basket only
contains apples. Now that we've determined that the basket marked as 'Apples and
Oranges' only contains apples, we can figure out what the other baskets contain. 

note:
Since the lable for this basket is incorrect, this either Apple or Orange.
Picked up apple and this basket is Apple.

If we look at the basket labeled as 'Oranges', we know that since the label is
incorrect, this basket either has only apple in it or has both apples and
oranges.  Since we've already established that the basket labeled 'Apples and
Oranges' contains only apples, we know that the basket labeled as 'Oranges'
contains both apples and oranges.

note:
Since the lable for this basket is incorrect, this (O)range was either (A)pple
or (O/A) but found (A) so this is (O/A).

Then by simple process of 'elimination', we know that the basket labeled as
'Apples' contains only oranges.

You can apply the same logic if you assume you picked an orange from the basket
labeled as 'Apples and Oranges'.

note: 
The key is "each of these labels is always placed incorrectly" and the answer 1.


{2}
There are 4 people who want to go across the bridge. Bridge is strength enough
to carry not more than 2 people at the time. People need a torch to cross the
bridge, the torch is only one. The first man goes across the bridge for 1
minute, the second for 2 minutes, the third for 5 minutes, the forth for 10
minutes. What is the fastest way for all people to get to another side of the
river?

note:
If use (1) to cross the bridge with others every time, takes 19. The trick here
is that cross the short one and cross the longest. Then use that short one to
finish.

Move                             Time
(1) & (2) Cross with Torch       2
(1) Returns with Torch           1
(5) & (10) Cross with Torch      10
(2) Returns with Torch           2
(1) & (2) Cross with Torch       2
                                 17

Out Of The Box Thinking

Eric Bowman E-Mailed me with a 10 minute solution. The solution is to have
Dave(10) carry the torch and begin to cross with any of the others lets say
Adam(1). Each continues at their own pace so in 1 minute Adam has reached the
other side and one of the others can begin to cross say Bob(2), when he reaches
the other side Clair(5) can begin to cross. Adam, Bob & Clair will be done in 8
minutes and Dave will be done in a further 2.

This solution satisfies the criteria that there are never more than 2 people on
the bridge and the torch is always on the bridge whilst someone is crossing. 

So in that sense it is a neat solution. I personally don't think that this is
the solution intended, not least because the question specifically asks you to
show it can be done in 17 minutes but also because I believe the torch or
flashlight is intended to bind the traveling pairs together. Always with these
puzzles it is a matter of extracting the logic of the puzzle from the more
verbose real world metaphor and that is my interpretation. However, if you
regard these questions as interview preparation then an understanding of the 10
minute argument can do you no harm at all. 


={============================================================================
*kt_dev_algo_0000* algo-equi equilibrium index of a sequence

// codility: equilibrium index of a sequence

The equilibrium index of a sequence is an index such that the sum of elements
at lower indexes is equal to the sum of elements at higher indexes. For
example, in a sequence A:

A[0]=-7 A[1]=1 A[2]=5 A[3]=2 A[4]=-4 A[5]=3 A[6]=0    [-7, 1, 5, 2, -4, 3, 0]

3 is an equilibrium index, because: A[0]+A[1]+A[2]=A[4]+A[5]+A[6]

6 is also an equilibrium index, because: A[0]+A[1]+A[2]+A[3]+A[4]+A[5]=0 (The
sum of zero elements is zero) 

7 is not an equilibrium index - because it is not a valid index of sequence A.

If you still have doubts, here is a precise definition: 

The integer k is an equilibrium index of a sequence A[0],A[1]..,A[n-1] if and
only if 0<= k and sum(A[0..(k-1)])=sum(A[(k+1)..(n-1)]). Assume the sum of
zero elements is equal to zero.

Write a function

int equi(int A[], int n);

that, given a sequence, returns its equilibrium index (any) or -1 if no
equilibrium index exists. `Assume that the sequence may be very long.` 

The problem can be solved by using various approaches, the most common being
simply to follow the equilibrium definition:

// while moving index, continues to sum right and left sum.

int equi ( int A[], int n ) {

  int k, m, lsum, rsum; 

  for(k = 0; k < n; ++k) { 
    lsum = 0; rsum = 0;
    for(m = 0; m < k; ++m) lsum += A[m]; 
    for(m = k + 1; m < n; ++m) rsum += A[m];  
    if (lsum == rsum) return k;
  } 
  return -1; 
} 

Unfortunately, this approach has two disadvantages:

o it fails on large input data sets, since the time complexity is O(n2)

o it fails on large input values (for example if the input array contains
    values like MIN/MAX_INT) due to the arithmetic overflows

We can fix the first problem with a better algorithm, and the second problem
with a better data-type (for example, using long long type instead of int for
    sum computations). 
  
The key observation for better running time is to update the left/right sums
in constant time instead of recomputing them from the scratch. O(n)

      [0] [ ] [ ] ... [ ]
   ->     <------------->
   lsum   rsum

      [0] [1] [ ] ... [ ]
   ----->     <------------->
   lsum   rsum

      [0] [1] [2] [3] ... [ ]
   --------->     <------------->
   lsum   rsum


<ex>

namespace algo_equi
{
  // brute force
  int equi_1(int A[], int n)
  {
    int start{}, index{};

    for (index = 0; index < n; ++index)
    {
      // have to reset them on every loop
      int left_sum{}, right_sum{};

      for (start = 0; start < index; ++start)
        left_sum += A[start];

      for (start = index+1; start < n; ++start)
        right_sum += A[start];

      if (left_sum == right_sum)
        return index;
    }

    return -1;
  }

  // use total sum

  int equi_2(int A[], int n)
  {
    int index{};

    long long total_sum{};
    for (index = 0; index < n; ++index)
      total_sum += A[index];

    long long right_sum{total_sum};
    long long left_sum{};

    for (index = 0; index < n; ++index)
    {
      if (index-1 >= 0)
        left_sum += A[index-1];

      right_sum = total_sum - left_sum - A[index];

      if (left_sum == right_sum)
        return index;
    }

    return -1;
  }

  // same as 2() but remove if by moving equal check

  int equi_3(int A[], int n)
  {
    int index{};

    long long total_sum{};
    for (index = 0; index < n; ++index)
      total_sum += A[index];

    long long right_sum{total_sum};
    long long left_sum{};

    for (index = 0; index < n; ++index)
    {
      // if (index-1 >= 0)
      //   left_sum += A[index-1];

      right_sum = total_sum - left_sum - A[index];

      if (left_sum == right_sum)
        return index;

      left_sum += A[index];
    }

    return -1;
  }

  // do not use total_sum variable since rsum is total 

  int equi_4( int A[], int n )
  {
    if( !n || !A )
      return -1;

    long long rsum = 0, lsum = 0;

    for(int i=0; i<n; i++)
      rsum += A[i];

    for(int i=0; i<n; i++)
    {
      rsum -= A[i];

      if( lsum == rsum )
        return i;

      lsum += A[i];
    }

    return -1;
  }

} // namespace

TEST(AlgoEquilbrium, Equi)
{
  using namespace algo_equi;

  int coll[] = {-7, 1, 5, 2, -4, 3, 0};

  {
    auto func = equi_1;
    EXPECT_THAT(func(coll, 7), 3);
  }
  {
    auto func = equi_2;
    EXPECT_THAT(func(coll, 7), 3);
  }
  {
    auto func = equi_3;
    EXPECT_THAT(func(coll, 7), 3);
  }
  {
    auto func = equi_4;
    EXPECT_THAT(func(coll, 7), 3);
  }
}


={============================================================================
*kt_dev_algo_0000* algo-equi-tape

https://codility.com/train/

When choose C++

A non-empty zero-indexed array A consisting of N integers is given. Array A
represents numbers on a tape.

Any integer P, such that 0 < P < N, splits this tape into two non-empty parts: 
A[0], A[1], ..., A[P - 1] and A[P], A[P + 1], ..., A[N - 1].

The difference between the two parts is the value of: 
|(A[0] + A[1] + ... + A[P - 1]) - (A[P] + A[P + 1] + ... + A[N - 1])|

In other words, it is the absolute difference between the sum of the first part
and the sum of the second part.

For example, consider array A such that:

  A[0] = 3    _ (split point)
  A[1] = 1    _
  A[2] = 2    _
  A[3] = 4    _
  A[4] = 3

We can split this tape in four places:

  P = 1, difference = |3 - 10| = 7
  P = 2, difference = |4 - 9 | = 5
  P = 3, difference = |6 - 7 | = 1
  P = 4, difference = |10 - 3| = 7

Write a function:

`int` solution(vector<int> &A);

that, given a non-empty zero-indexed array A of N integers, returns the
`minimal-difference`, but not index, that can be achieved.

For example, given:

  A[0] = 3
  A[1] = 1
  A[2] = 2
  A[3] = 4
  A[4] = 3

the function should return `minimal difference` 1 when P = 3, as explained above.

Assume that:

N is an integer within the range [2..100,000];
each element of array A is an integer within the range [-1,000..1,000].

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(N), beyond input storage (not counting
    the storage required for input arguments).

Elements of input arrays can be modified.

you can also use includes, for example:
#include <algorithm>


note:
If calculate first and second half sum every time when moves array index, time
complexity would be O(N*N).


<ex>

namespace algo_equi
{
  int equi_tape_1(vector<int> &A)
  {
    int abs_diff{};
    int saved_diff = numeric_limits<int>::max();
    long long right_sum{}, left_sum{};

    for (unsigned int i = 0; i < A.size(); ++i)
      right_sum += A[i]; 

    for (unsigned int i = 0; i < A.size()-1; ++i)
    {
      left_sum += A[i];
      right_sum -= A[i];

      abs_diff = abs(left_sum - right_sum);
      if (abs_diff < saved_diff)
      {
        saved_diff = abs_diff;
      }
    }

    return saved_diff;
  }


  int equi_tape_2(vector<int> &A)
  {
    if(!A.size())
      return -1;

    // note:
    long long tsum = 0;

    // size N, [0, N-1]
    for(unsigned int i=0; i < A.size(); i++)
      tsum += A[i];

    long long rsum = 0, lsum = 0;
    int runabs = INT_MAX, curabs = 0;

    for(unsigned int i=0; i < A.size()-1; i++)
    {
      lsum += A[i];
      rsum = tsum - lsum;

      curabs = abs(lsum-rsum);

      if(runabs > curabs)
        runabs = curabs;
    }

    return runabs;
  }

  int equi_tape_3(vector<int> &A)
  {
    if(!A.size())
      return -1;

    // note:
    long long rsum = 0;

    // size N, [0, N-1]
    for(unsigned int i=0; i < A.size(); i++)
      rsum += A[i];

    long long lsum = 0;
    int runabs = INT_MAX, curabs = 0;

    // [0, N-2] since no need to process the last element
    for(unsigned int i=0; i < A.size()-1; i++)
    {
      lsum += A[i];
      rsum -= A[i];

      curabs = abs(lsum-rsum);

      if(runabs > curabs)
        runabs = curabs;
    }

    return runabs;
  }

  // model answer

  int equi_tape_4(vector<int> &A) 
  {
    // write your code in C++98
    if( !A.size() )
      return -1;

    long long sum = 0, rsum = 0, lsum = 0;
    int cmin = INT_MAX;

    for(size_t i=0; i<A.size(); i++)
      sum += A[i];

    lsum = A[0];

    // note: 
    // it is okay to use (n-1)th to calc lsum since not used anyway. WHY?
    for(size_t i=1; i<A.size(); i++)
    {
      rsum = sum - lsum;

      // cmin = abs cause warning of possible loss since assign from long long to int.
      if( abs(lsum-rsum) < cmin )
        cmin = abs(lsum-rsum);

      lsum += A[i];
    }

    return cmin;
  }

} // namespace

TEST(AlgoEquilbrium, EquiTape)
{
  using namespace algo_equi;

  vector<int> coll{3, 2, 1, 4, 3};

  EXPECT_THAT(equi_tape_1(coll), 1);
  EXPECT_THAT(equi_tape_2(coll), 1);
  EXPECT_THAT(equi_tape_3(coll), 1);
  EXPECT_THAT(equi_tape_4(coll), 1);
}

={============================================================================
*kt_dev_algo_0000* algo-water

How much water between walls?
http://qandwhat.runkite.com/i-failed-a-twitter-interview/

Consider the following picture:
              _ _
7             7 7 _
6   _         # # 6
5   5         # # #
4   #       4 # # #
3 _ #     3 # # # #
2 2 #   2 # # # # #
1 # # 1 # # # # # #
  -----------------
  0 1 2 3 4 5 6 7 8

In this picture we have walls of different heights. This picture is
represented by an array of integers, where the value at each index is the
height of the wall. The picture above is represented with an array as
[2,5,1,2,3,4,7,7,6].

Now imagine it rains. How much water is going to be accumulated in puddles
between walls?

              _ _
7             7 7 _
6   _         # # 6
5   5 * * * * # # #
4   # * * * 4 # # #
3 _ # * * 3 # # # #
2 2 # * 2 # # # # #
1 # # 1 # # # # # #
  -----------------
  0 1 2 3 4 5 6 7 8

We count volume in square blocks of 1X1. So in the picture above, everything
to the left of index 1 spills out. Water to the right of index 7 also spills
out. We are left with a puddle between 1 and 6 and the volume is 10. 


<KT> 2014.04.12. Initial thought by drawings is that

* only have waters when there is down-and-up, i.e., 5-1-2. 
* there are as many as down-and-ups in a array. 
* when goes down including the start from 0 index, set the hightest.
* when goes up, check with the previous heightest to see which is less than, 
  then there is water up to the less on hight.

This has the same flaw as the author's initial try has since only get the part.

The first thing I tried to do was to figure out how much water we would have
at any given index. This stroke a resemblance with Calculus and integrals, so
I immediately remembered that looking for local maximums could be of use. And
indeed, in the picture above, the water above index 2 is bounded by the
smaller of the two surrounding maximums at index 1 and 6. 

I was thinking out loud: "What if we found all the local maximums, and filled
in water between them. Would that work?"

"Yeah, that should work" replied Justin.

So I went ahead and coded this solution. Then Justin asked me for a bunch of
test cases which I provided. All the test cases we talked about seemed to
work.

"Do you have questions for me?" Justin asked. "How did I do?" "Reasonably
well. Your solution does 2 passes, but there is a more interesting one that
does only 1"

The second I hung up I realized my solution was wrong. Think about this input:

[2, 5, 1, 3, 1, 2, 1, 7, 7, 6]

<flaw-when-use-local-max>
My solution solved between the local maximums and looked like this: 

7               # # _
6   _           # # #
5   #           # # #
4   #           # # #
3 _ # * #       # # #
2 # # * # * # * # # #
1 # # 1 # # # # # # #
  --------------- ---
  0 1 2 3 4 5 6 7 7 8

But the result should have been one puddle between the two taller towers: 

7               # # _
6   _           # # #
5   # * * * * * # # #
4   # * * * * * # # #
3 _ # * # * * * # # #
2 # # * # * # * # # #
1 # # 1 # # # # # # #
  --------------- ---
  0 1 2 3 4 5 6 7 7 8

Now I ask myself: what have I learned from this? Realistically - not much. I
am upset that the interviewer didn't ask me the right questions to guide me
towards the right train of thought. I don't know why Justin told me "this
should work," when my solution in fact didn't. I know that this should have
come up in the test cases he asked for, but since I missed the flaw when
coming up with the algorithm, I didn't think of testing for it. 


<two-pass>
The logic is as follows:

If we traverse the list from left to right, the amount of water at each index
is at most the largest value we have discovered so far. That means that 

`if we knew that there is something larger or equal to it somewhere on the right` 
we would know exactly how much water we can hold without spilling. 

Same goes for traversing in the opposite direction: if we know we have found
something larger on the left than the largest thing on the right, we can
safely fill up water.

With this in mind, one solution would be to first find the absolute maximum
value, traverse from the left to the maximum, and then traverse from the right
to the maximum. This solution does 2 passes: one to find the maximum, and the
other is split into two subtraversals.


Why two pass? For one pass, find the first high and see if there is larger or
equal to it. The calculate the water between two points. But if not find
larger or equal to it then? More than two pass? Need to loop in the first
pass? This could be difficult since if the first high do not have the larger
or equal to it in the list then need to try the second high and so on.

No. This approach is to find the max in the list and have two traversals to
the max. 

left ...              max ... right
sum towards to max -> *
                        <- sum towards to max

So one pass to find the max ine list and two pass to sum waters.


<one-pass>
The solution in one pass (shown in the gist) avoids finding the maximum value
by moving two pointers from the opposite ends of the array towards each other.
If the largest value found to the left of the left pointer is smaller than the
largest value found to the right of the right pointer, then move the left
pointer one index to the right. Otherwise move the right pointer one index to
the left. Repeat until the two pointers intersect. This is a wordy
explanation, but the code is really simple.

class Ideone
{
  public static void main (String[] args) throws java.lang.Exception
  {
    int[] myIntArray = {2, 5, 1, 2, 3, 4, 7, 7, 6};
    System.out.println(calculateVolume(myIntArray));
  }

  public static int calculateVolume(int[] land) {
    int leftMax = 0;
    int rightMax = 0;
    int left = 0;
    int right = land.length - 1;
    int volume = 0;

    while(left < right) {

      // update current max for left and right.
      if(land[left] > leftMax) {
        leftMax = land[left];
      }
      if(land[right] > rightMax) {
        rightMax = land[right];
      }

      // decide to which direction it start to sum. Should from the lesser. If
      // equals, from right but do not matter when start from left.


      if(leftMax >= rightMax) {
        volume += rightMax - land[right];
        right--;
      } else {
        volume += leftMax - land[left];
        left++;
      }
    }

    return volume;
  }
}


<code>

namespace algo_water_volume
{
  // two pass algo

  int water_volume_1(vector<int> const &A)
  {
    int max_value{};
    size_t max_index{};
    size_t volume{};

    // get the index of max
    for (size_t i = 0; i < A.size(); ++i)
    {
      if (max_value < A[i])
      {
        max_value = A[i];
        max_index = i;
      } 
    }

    // from left to the max
    int max_current{std::numeric_limits<int>::min()};

    for (size_t i = 0; i < max_index; ++i)
    {
      if (max_current <= A[i])
        max_current = A[i];
      else
        volume += max_current - A[i];
    }

    // from right to the max
    max_current = std::numeric_limits<int>::min();

    for (size_t i = A.size()-1; i > max_index; --i)
    {
      if (max_current <= A[i])
        max_current = A[i];
      else
        volume += max_current - A[i];
    }

    return volume;
  }

  // one pass

  int water_volume_2(vector<int> const &A)
  {
    int right_max{std::numeric_limits<int>::min()};
    int left_max{std::numeric_limits<int>::min()};

    size_t left_index{0};
    size_t right_index{A.size()-1};

    size_t volume{};

    while (left_index < right_index)
    {
      left_max = max(left_max, A[left_index]);
      right_max = max(right_max, A[right_index]);

      // cout << "li: " << left_index << ", ri: " << right_index
      //   << ", lm: " << left_max << ", rm: " << right_max << endl;

      // move left bar to right
      // note: should have "equal" case on either if. otherwise, loops goes
      // infinitive.

      if (left_max <= right_max)
      {
        if (A[left_index] < left_max)
        {
          volume += left_max - A[left_index];
          // cout << "vol += " << left_max << " - " 
          //   << A[left_index] << endl;
        }

        left_index++;
      }

      // move right bar to left
      if (left_max > right_max)
      {
        if (A[right_index] < right_max)
        {
          volume += right_max - A[right_index];
          // cout << "vol += " << right_max << " - " 
          //   << A[right_index] << endl;
        } 

        right_index--;
      }
    }

    return volume;
  }
} // namespace

TEST(AlgoWaterVolume, TwoPass)
{
  using namespace algo_water_volume;

  auto func = water_volume_1; 
  {
    vector<int> coll{2,5,1,2,3,4,7,7,6};
    EXPECT_THAT(func(coll), 10);
  }
  {
    vector<int> coll{2,5,1,3,1,2,1,7,7,6};
    EXPECT_THAT(func(coll), 17);
  }
  {
    vector<int> coll{2,5,4,3,4,7,6,5,4,5,7,9,5,4,3,4,5,6};
    EXPECT_THAT(func(coll), 21);
  }
}

TEST(AlgoWaterVolume, OnePass)
{
  using namespace algo_water_volume;

  auto func = water_volume_2; 
  {
    vector<int> coll{2,5,1,2,3,4,7,7,6};
    EXPECT_THAT(func(coll), 10);
  }
  {
    vector<int> coll{2,5,1,3,1,2,1,7,7,6};
    EXPECT_THAT(func(coll), 17);
  }
  {
    vector<int> coll{2,5,4,3,4,7,6,5,4,5,7,9,5,4,3,4,5,6};
    EXPECT_THAT(func(coll), 21);
  }
}


={============================================================================
*kt_dev_algo_0000* algo-frog-jump

codility, frog jump

A small frog wants to get to the other side of the road. The frog is currently
located at position X and wants to get to a position greater than or equal to
Y. The small frog always jumps a fixed distance, D.

Count the minimal number of jumps that the small frog must perform to reach
its target.

Write a function:

int solution(int X, int Y, int D); 

that, given three integers X, Y and D, returns the minimal number of jumps
from position X to a position equal to or greater than Y.

For example, given:

  X = 10
  Y = 85
  D = 30

the function should return 3, because the frog will be positioned as follows:

  after the first jump, at position 10 + 30 = 40
  after the second jump, at position 10 + 30 + 30 = 70
  after the third jump, at position 10 + 30 + 30 + 30 = 100

Assume that:

X, Y and D are integers within the range [1..1,000,000,000];
X <= Y.

Complexity:

expected worst-case time complexity is O(1);
expected worst-case space complexity is O(1).

note: key conditions are: X and Y is > 0. X <= Y.

<ex>

namespace algo_frog_jump
{
  // brute force but this is not O(1) since loop may be long if Y  is big
  // enough.

  int frog_jump_1(int X, int Y, int D)
  {
    int count{};

    for (long long i = X; i < Y; i += D)
      ++count;

    return count;
  }

  // model

  int frog_jump_2(int X, int Y, int D)
  {
    int quotient = (Y-X)/D;
    int remainder = (Y-X)%D;

    return remainder ? quotient+1 : quotient;
  }

  // score: 100 of 100. Detected time complexity:O(1)
  // 
  // X==Y : no jump
  // X<Y  : ----------------------
  //         X         Y   D         
  //         
  //    (Y-X)/D == 0. needs one jump.
  //    (Y-X)/D > 0. needs more jump.
  //       -----------------------
  //         X         Y
  //              D   D
  //       (Y-X)%D == 0. fall exactly on Y.
  //       (Y-X)%D != 0. +1 jump.
  // 
  // Lesson learned. Read the question carefully such as 'greater or equal', 'X <=
  // Y', and O(1).

  // There are three cases:
  // 
  //                   Y    Y   Y
  // -------------- | ----- | ----- | ---------------------- 
  //                       jumps == X + D*jump;

  // 2014.12
  int frog_jump_3( int X, int Y, int D )
  {
    if( X>Y || D==0 ) return -1;

    int diff = (Y-X);
    int jump = diff/D;

    if( (diff % D) == 0 )
      return jump;
    else
      return jump+1;
  }

} // namespace

TEST(AlgoFrogJump, FrogJump)
{
  using namespace algo_frog_jump;

  EXPECT_THAT(frog_jump_1(10, 85, 30), 3);
  EXPECT_THAT(frog_jump_1(10, 10, 30), 0);

  EXPECT_THAT(frog_jump_2(10, 85, 30), 3);
  EXPECT_THAT(frog_jump_2(10, 10, 30), 0);

  EXPECT_THAT(frog_jump_3(10, 85, 30), 3);
  EXPECT_THAT(frog_jump_3(10, 10, 30), 0);
}


={============================================================================
*kt_dev_algo_0000* algo-find-missing-element

codility, find missing element. PermMissingElem

A zero-indexed array A consisting of N different integers is given. The array
contains integers in the range [1..(N + 1)], which means that exactly one
element is missing.

Your goal is to find that missing element.

Write a function:

int solution(int A[], int N);

that, given a zero-indexed array A, returns the value of the missing element.

For example, given array A such that:

  A[0] = 2
  A[1] = 3
  A[2] = 1
  A[3] = 5

the function should return 4, as it is the missing element.

Assume that:

N is an integer within the range [0..100,000]; the elements of A are all
distinct; each element of array A is an integer within the range [1..(N + 1)].

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(1), beyond input storage (not
counting the storage required for input arguments).

Elements of input arrays can be modified.

<code>
int find_missing_0623(const vector<int> &A)
{
  int N = A.size();
  int total_sum{};
  for (int i = 1; i <= N+1; ++i)
    total_sum += i;

  int local_sum{};
  for (auto e : A)
    local_sum += e;

  // cout << "total: " << total_sum << ", local: " << local_sum << endl;
  return total_sum - local_sum;
}

TEST(AlgoFindMissing, 0623)
{
  EXPECT_THAT(find_missing_0623({2,3,1,5}), 4);
  EXPECT_THAT(find_missing_0623({1,2,3,4}), 5);
  EXPECT_THAT(find_missing_0623({2,3,4,5}), 1);
  EXPECT_THAT(find_missing_0623({1,3,4,5}), 2);
  EXPECT_THAT(find_missing_0623({}), 1);
}

// fails when N=0.
//
// score: 90 of 100
// Detected time complexity: O(N)
//
// empty list and single element 	0.020 s. 	WRONG ANSWER got 0 expected 1
//
// This is about permutation. For example, {1,2,3,4,5} can have
// 
// {1,2,3,4} is missing 5
// {2,3,4,5} is missing 1
// {1,3,4,5} is missing 2
// 
// Reversely, 
// if N==3 inputs are given, then it's one of permutation of 4. [1,4]
// if N==2 inputs are given, then it's one of permutation of 3. [1,3]
// if N==1 inputs are given, then it's one of permutation of 2. [1,2]
// if N==0 inputs are given, then it's one of permutation of 1. [1] so the
// missing is always 1.


int find_missing_old(const vector<int> &A) 
{
  // write your code in C++98
  if( !A.size() )
    return 0;

  long long isum = 0;

  for( unsigned int i = 0; i < A.size(); i++ )
    isum += A[i];

  long long csum = 0;

  for( unsigned int i = 1; i <= A.size()+1; i++ )
    csum += i;

  return csum - isum;
}

TEST(AlgoFindMissing, find_missing_old)
{
  EXPECT_THAT(find_missing_old({2,3,1,5}), 4);
  EXPECT_THAT(find_missing_old({1,2,3,4}), 5);
  EXPECT_THAT(find_missing_old({2,3,4,5}), 1);
  EXPECT_THAT(find_missing_old({1,3,4,5}), 2);
  // fails
  // EXPECT_THAT(find_missing_old({}), 1);
}

int find_missing_old_fix(const vector<int> &A) 
{
  // do not have a size check

  long long isum = 0;

  for( unsigned int i = 0; i < A.size(); i++ )
    isum += A[i];

  long long csum = 0;

  for( unsigned int i = 1; i <= A.size()+1; i++ )
    csum += i;

  return csum - isum;
}

TEST(AlgoFindMissing, find_missing_old_fix)
{
  EXPECT_THAT(find_missing_old_fix({2,3,1,5}), 4);
  EXPECT_THAT(find_missing_old_fix({1,2,3,4}), 5);
  EXPECT_THAT(find_missing_old_fix({2,3,4,5}), 1);
  EXPECT_THAT(find_missing_old_fix({1,3,4,5}), 2);
  EXPECT_THAT(find_missing_old_fix({}), 1);
}

int find_missing_old_two(const vector<int> &A) 
{
  // write your code in C++98
  long long isum = 0;

  for( unsigned int i = 0; i < A.size(); i++ )
    isum += A[i];

  // use the fact that sum{1..N} is N(N+1)/2 and take cauiton on integer
  // division. so not n*((n+1)/2)

  int n = A.size()+1;
  long long csum = (n*(n+1))/2;

  return csum - isum;
}

TEST(AlgoFindMissing, find_missing_old_two)
{
  EXPECT_THAT(find_missing_old_two({2,3,1,5}), 4);
  EXPECT_THAT(find_missing_old_two({1,2,3,4}), 5);
  EXPECT_THAT(find_missing_old_two({2,3,4,5}), 1);
  EXPECT_THAT(find_missing_old_two({1,3,4,5}), 2);
  EXPECT_THAT(find_missing_old_two({}), 1);
}


={============================================================================
*kt_dev_algo_0000* dev-algo-problem algo-find-perm

PermCheck https://codility.com/programmers/lessons/2

A non-empty zero-indexed array A consisting of N integers is given.

A permutation is a sequence containing 'each' element from 1 to N once, and
only once.

For example, array A such that:

    A[0] = 4
    A[1] = 1
    A[2] = 3
    A[3] = 2

is a permutation, but array A such that:

    A[0] = 4
    A[1] = 1
    A[2] = 3

is not a permutation.

The goal is to check whether array A is a permutation.

Write a function:

    int solution(int A[], int N); 

that, given a zero-indexed array A, returns 1 if array A is a permutation and
0 if it is not.

For example, given array A such that:

    A[0] = 4
    A[1] = 1
    A[2] = 3
    A[3] = 2

the function should return 1.

Given array A such that:

    A[0] = 4
    A[1] = 1
    A[2] = 3

the function should return 0.

Assume that:

N is an integer within the range [1..100,000]; each element of array A is an
integer within the range [1..1,000,000,000].

note: this suggest that A may have invalid value which are > N.

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(N), beyond input storage (not
counting the storage required for input arguments).

Elements of input arrays can be modified.

<code>
// 2018.06.25
int find_perm_0625(const vector<int> &A)
{
  //  int N = A.size();
  int total_sum{};
  int input_max{};

  for (auto e : A)
  {
    if (e > input_max)
      input_max = e;

    total_sum += e;
  }

  int perm_sum = (input_max*(input_max+1))/2;

  cout << "total: " << total_sum << ", perm: " << perm_sum << endl;

  return total_sum == perm_sum;
}

TEST(AlgoFindPerm, 0625)
{
  EXPECT_THAT(find_perm_0625({4,1,3,2,1}), 0);
  EXPECT_THAT(find_perm_0625({1,4,1}), 0);
  // fails
  // EXPECT_THAT(find_perm_0625({9,5,7,3,2,7,3,1,10,8}),0);
}

// based on old tries. N's permutation and it downs to algo-unique in the end so
// if don't need to be defensive about input value, can return false as soon as
// see duplicates. 
//
// fails on:
// extreme_min_max 
// single element with minimal/maximal value
// large_range 
// sequence 1, 2, ..., N, N = ~100,000

int find_perm_0625_02(const vector<int> &A)
{
  int count{};
  int input_max{};

  vector<bool> lookup(A.size()+1);

  for (auto e : A)
  {
    if (e > input_max)
      input_max = e;

    if (lookup[e] == true)
      return false;
    else
    {
      lookup[e] = true;
      ++count;
    } 
  }

  // size_t perm_sum = (input_max*(input_max+1))/2;

  cout << "input_max: " << input_max << ", perm: " << count << endl;

  return count == input_max;
}

// so keys:
// no duplicate
// N, input max is A.size()
// all values <= N, input max
//
// 100% pass
// Detected time complexity: O(N * log(N)) or O(N)

int find_perm_0625_03(const vector<int> &A)
{
  int count{};
  int input_max = A.size();

  vector<bool> lookup(input_max+1);

  for (auto e : A)
  {
    if (e > input_max || lookup[e] == true)
      return false;
    else
    {
      lookup[e] = true;
      ++count;
    } 
  }

  // size_t perm_sum = (input_max*(input_max+1))/2;

  cout << "input_max: " << input_max << ", perm: " << count << endl;

  return count == input_max;
}

TEST(AlgoFindPerm, 0625_02)
{
  EXPECT_THAT(find_perm_0625_03({4,1,3,2,1}), 0);
  EXPECT_THAT(find_perm_0625_03({1,4,1}), 0);
  EXPECT_THAT(find_perm_0625_03({9,5,7,3,2,7,3,1,10,8}),0);
}


// nov 2014. both are O(n)
// 1. To get N, find the max value in the input and the sum of input in a
// single loop 
// 2. If the sum is different from sum[1,N] then return false.  
// 3. If N is different from input size then return false.

// 80% pass
int find_perm_old_01( vector<int> &A )
{
  int max = 0;

  for( unsigned int i=0; i < A.size(); i++ )
  {
    if( max < A[i] )
      max = A[i];
  }

  return max == (int)A.size();
}


// <key> The problem is to understand question which is confusing. The question
// is that N is the size of array and also is the N for permutation. That is
// there shall be [1,N] elements in the input. If not, not a permutation. This
// becomes bit set problem to see if all elements are seen.

int find_perm_old_02( vector<int> &A )
{
  if( !A.size() )
    return 0;

  // default is false
  vector<bool> flag( A.size() );

  for( unsigned int i=0; i < A.size(); i++ )
  {
    // note: -1 since permutation starts from 1 but index starts from 0
    // note: 'unsigned' to handle possible negative input which will be caught
    // below if statement.

    unsigned int value = A[i]-1;

    // note: this covers values which are not in [1, N]
    if( value < A.size() )
      flag[value] = true;
    else
      return 0;
  }

  // note: if it is permutation then there is no flase in flag set
  return count( flag.cbegin(), flag.cend(), false ) == 0;
}

// The count() in the return which is a loop can be removed as below since can
// return 0 as soon as duplucates.

// 100% pass
// Detected time complexity: O(N * log(N)) or O(N)

int find_perm_old_03( vector<int> &A )
{
  if( !A.size() )
    return 0;

  // default is false
  vector<bool> flag( A.size() );

  for( unsigned int i=0; i < A.size(); i++ )
  {
    // note: -1 since permutation starts from 1 but index starts from 0
    // note: 'unsigned' to handle possible negative input which will be caught
    // below if statement.
    
    unsigned int value = A[i]-1;

    // note: this covers values which are not in [1, N]
    if( value < A.size() && !flag[value])
      flag[value] = true;
    else
      return 0;
  }

  return 1;
}


={============================================================================
*kt_dev_algo_0000* dev-algo-problem algo-frog-river

FrogRiverOne 

A small frog wants to get to the other side of a river. The frog is currently
located at position 0, and wants to get to position X. Leaves fall from a tree
onto the surface of the river.

You are given a non-empty zero-indexed array A consisting of N integers
representing the falling leaves. A[K] represents the position where one leaf
falls at time K, measured in minutes.

The goal is to find the earliest time when the frog can jump to the other side
of the river. The frog can cross only when leaves appear at every position
across the river from 1 to X.

For example, you are given integer X = 5 and array A such that:

  A[0] = 1
  A[1] = 3
  A[2] = 1
  A[3] = 4
  A[4] = 2
  A[5] = 3
  A[6] = 5
  A[7] = 4

In minute 6, a leaf falls into position 5. This is the earliest time when
leaves appear in every position across the river.

Write a function:

    int solution(int X, int A[], int N); 

that, given a non-empty zero-indexed array A consisting of N integers and
  integer X, returns the earliest time when the frog can jump to the other
  side of the river.

If the frog is never able to jump to the other side of the river, the function
should return -1.

For example, given X = 5 and array A such that:

  A[0] = 1
  A[1] = 3
  A[2] = 1
  A[3] = 4
  A[4] = 2
  A[5] = 3
  A[6] = 5
  A[7] = 4

the function should return 6, as explained above. Assume that:

N and X are integers within the range [1..100,000];
each element of array A is an integer within the range [1..X].

note: suggest that all input are < N


Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(X), beyond input storage (not
    counting the storage required for input arguments).

Elements of input arrays can be modified.

<code>
// 2018.06.26
int find_frog_river_0626(int X, const vector<int> &A)
{
  // input check
  if (A.empty())
    return -1;

  vector<bool> lookup(A.size());
  int target_sum = (X*(X+1))/2;
  int input_sum{};

  for (size_t i = 0; i < A.size(); ++i)
  {
    if (lookup[A[i]] == false)
    {
      lookup[A[i]] = true;
      input_sum += A[i];

      if (target_sum == input_sum)
        return i;
    }
  }

  return -1;
}

TEST(AlgoFrogRiver, 0626_01)
{
  EXPECT_THAT(find_frog_river_0626(5, {1,3,1,4,2,3,5,4}), 6);
  // fails
  // EXPECT_THAT(find_frog_river_0626(1, {2,3,4,5,1,3,5,4}), 4);
}

int find_frog_river_0626_02(int X, const vector<int> &A)
{
  // input check
  if (A.empty())
    return -1;

  vector<bool> lookup(A.size());
  int target_sum = (X*(X+1))/2;
  int input_sum{};

  for (size_t i = 0; i < A.size(); ++i)
  {
    if (A[i] <= X && lookup[A[i]] == false)
    {
      lookup[A[i]] = true;
      input_sum += A[i];

      if (target_sum == input_sum)
        return i;
    }
  }

  return -1;
}

// although this version passed, it's wrong in size of lookup table.
TEST(AlgoFrogRiver, 0626_02)
{
  EXPECT_THAT(find_frog_river_0626_02(5, {1,3,1,4,2,3,5,4}), 6);
  EXPECT_THAT(find_frog_river_0626_02(1, {2,3,4,5,1,3,5,4}), 4);
  EXPECT_THAT(find_frog_river_0626_02(5, {}), -1);

  // fails
  // /usr/include/c++/4.9/debug/vector:357:error: attempt to subscript container 
  //     with out-of-bounds index 1, but container only holds 1 elements.

  // Objects involved in the operation:
  // sequence "this" @ 0x0x7fff25cb8fd0 {
  //   type = NSt7__debug6vectorIbSaIbEEE;
  // }
  // Aborted
  //
  // EXPECT_THAT(find_frog_river_0626_02(5, {1}), -1);
}

int find_frog_river_0626_03(int X, const vector<int> &A)
{
  // input check
  if (A.empty())
    return -1;

  vector<bool> lookup(A.size()+1);
  int target_sum = (X*(X+1))/2;
  int input_sum{};

  for (size_t i = 0; i < A.size(); ++i)
  {
    if (A[i] <= X && lookup[A[i]] == false)
    {
      lookup[A[i]] = true;
      input_sum += A[i];

      if (target_sum == input_sum)
        return i;
    }
  }

  return -1;
}

TEST(AlgoFrogRiver, 0626_03)
{
  EXPECT_THAT(find_frog_river_0626_03(5, {1,3,1,4,2,3,5,4}), 6);
  EXPECT_THAT(find_frog_river_0626_03(1, {2,3,4,5,1,3,5,4}), 4);
  EXPECT_THAT(find_frog_river_0626_03(5, {}), -1);
  EXPECT_THAT(find_frog_river_0626_03(5, {1}), -1);
  EXPECT_THAT(find_frog_river_0626_03(1, {2}), -1);
  EXPECT_THAT(find_frog_river_0626_03(1, {1}), 0);
}


int find_frog_river_old_01( int X, std::vector<int> &A )
{
  if( A.empty() || X==1 )
    return -1;

  bool *pbitset = new bool(X);
 
  int idx;                        
  int count=0;

  // bitset{0, X-1}
  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < (int)A.size(); idx++)    // signed and unsigned warning.
  {
    // wasn't set before?
    if( pbitset[A[idx]-1] == false )
    {
      // set it and increase count
      pbitset[A[idx]-1] = true;
      count++;

      // are all position set?
      if( count == X )                 // signed and unsigned warning.
      {
        delete pbitset; return idx;
      }
    }
  }

  delete pbitset; return -1;
}

// Failed on 25%:
// 
// small_random1 3 random permutation, X = 50     0.020 s.     RUNTIME ERROR
// tested program terminated unexpectedly
//
// 1. signed and unsigned that complier warns mismatch between signed and
// unsigned.  No such error when run with GCC 4.6.3.
// 
// 2. this is wrong since it allocate a single bool but not array. Failed on
// other many test cases with the same error. But why no such error on GCC
// 4.6.3. This sites uses C++98 so may be new initialize way in C++11?


// Still failed with the same error.
int find_frog_river_old_02( int X, std::vector<int> &A )
{
  if( A.empty() || X==1 )
    return -1;

  bool *pbitset = new bool(X);
 
  int idx;                        
  int count=0;

  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < (int)A.size(); idx++)
  {
    if( pbitset[A[idx]-1] == false )
    {
      pbitset[A[idx]-1] = true;
      count++;

      if( count == X )
      {
        delete[] pbitset; return idx;  // diff
      }
    }
  }

  delete[] pbitset; return -1;         // diff
}


int find_frog_river_old_03( int X, std::vector<int> &A )
{
  if( A.empty() || X==1 )
    return -1;

  bool *pbitset = new bool[X];   // diff
 
  int idx;                        
  int count=0;

  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < (int)A.size(); idx++)
  {
    if( pbitset[A[idx]-1] == false )
    {
      pbitset[A[idx]-1] = true;
      count++;

      if( count == X )
      {
        delete[] pbitset; return idx;
      }
    }
  }

  delete[] pbitset; return -1;
}

// 90 out of 100 points. Detected time complexity: O(N). Failed on:
// 
// single single element     0.020 s.     WRONG ANSWER got -1 expected 0
// 
// note: think about when single element has big value(position)


int find_frog_river_old_04( int X, std::vector<int> &A )
{
  if( A.empty() || X==0 )           // diff
    return -1;

  bool *pbitset = new bool[X];
 
  int idx;                        
  int count=0;

  // bitset{0, X-1}
  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < (int)A.size(); idx++)
  {
    // wasn't set before?
    if( (A[idx]-1 < X) && pbitset[A[idx]-1] == false )   // diff
    {
      // set it and increase count
      pbitset[A[idx]-1] = true;
      count++;

      // are all position set?
      if( count == X )
      {
        delete [] pbitset; return idx;
      }
    }
  }

  delete [] pbitset; return -1;
}

// 100 out of 100 points. Detected time complexity: O(N) 


int find_frog_river_old_05( int X, std::vector<int> &A )
{
  if( A.empty() || X==0 )           // diff
    return -1;

  bool *pbitset = new bool[X];
 
  int idx;                        
  int count=0;

  // bitset{0, X-1}
  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < (int)A.size(); idx++)
  {
    int value = A[idx]-1;

    // wasn't set before?
    if( (value < X) && pbitset[value] == false )   // diff
    {
      // set it and increase count
      pbitset[value] = true;
      count++;

      // are all position set?
      if( count == X )
      {
        delete [] pbitset; return idx;
      }
    }
  }

  delete [] pbitset; return -1;
}

// The key idea is that it is about counting and to use counter to check if
// receives all inputs rather than using loops or function call like bitset.


int find_frog_river_old_06(int X, const vector<int> &A) {
  // write your code in C++11
  if( A.empty() || !X )
    return -1;

  vector<bool> flags(X);
  int count = 0;

  for(unsigned int i=0; i < A.size(); i++ )
  {
    int value = A[i]-1;

    if( value < X && flags[value] == false )
    {
      flags[value] = true;
      count++;
    }

    if( count == X )
      return i;
  }

  return -1;
}

// Detected time complexity: O(N)

TEST(AlgoFrogRiver, 0626_02_old)
{
  EXPECT_THAT(find_frog_river_old_06(5, {1,3,1,4,2,3,5,4}), 6);
  EXPECT_THAT(find_frog_river_old_06(1, {2,3,4,5,1,3,5,4}), 4);
  EXPECT_THAT(find_frog_river_old_06(5, {}), -1);
  EXPECT_THAT(find_frog_river_old_06(5, {1}), -1);
  EXPECT_THAT(find_frog_river_old_06(1, {2}), -1);
  EXPECT_THAT(find_frog_river_old_06(1, {1}), 0);
}

={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-find-missing-integer

Find the minimal positive integer not occurring in a given sequence.

Write a function:

int solution(int A[], int N); 

that, given a non-empty zero-indexed array A of N integers, returns the
  minimal positive integer that does not occur in A.

For example, given:

  A[0] = 1    
  A[1] = 3    
  A[2] = 6
  A[3] = 4    
  A[4] = 1    
  A[5] = 2

the function should return 5.

Assume that:

N is an integer within the range [1..100,000]; each element of array A is an
integer within the range [-2,147,483,648..2,147,483,647].

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(N), beyond input storage (not
    counting the storage required for input arguments).

Elements of input arrays can be modified.

<code>

// 2018.08.07
// These assumptions seems wrong:
//
// Since it's about `positive` minimal integer, inputs are 1..2,147,xxx,xxx.
// Since N size array could have the max input value which is N.
//
// So can reduce input value range to 1...N
//
// And what if input is {-2, -1, 0, 2, 3}?
//
// So not a good problem?


// 2018.06.27
// 1. do not say about return value for errors
//
// 2. Allocate lookup table for 2,147,xxx,xxx x 2? No and not meet O(n) space as
// well. 
//  
// Since it's about `positive` minimal integer, inputs are 1..2,147,xxx,xxx.
// Since N size array could have the max input value which is N.
//
// So can reduce input value range to 1...N
//
// What if input is not sequential such as "{100, 200, 300, 340}"? Not a valid
// input since we are looking for `missing`, `not occurring` element. If that's
// valid input then what are the missing element? So many and not a valid input.


int find_missing_integer(const vector<int> &A)
{
  // input check
  if (A.empty())
    return -1;

  vector<bool> lookup(A.size());

  for (size_t i = 0; i < A.size(); ++i)
  {
    if (A[i] > 0 && lookup[A[i]-1] == false)
      lookup[A[i]-1] = true;
  }

  for (size_t i = 0; i < lookup.size(); ++i)
    if (lookup[i] == false)
      return i+1;

  return -1;
}

TEST(AlgoFindMissingInteger, 0627_01)
{
  EXPECT_THAT(find_missing_integer({1,3,6,4,1,2}), 5);
}


// O(N), 100%
//
// Use bool vector approach? The input element can be negative so ignore
// negegative inputs.  However, the problem is input value can be too big to
// have bool vector. how to solve?
// 
// The key is whatever the input value is the aim to find the minimum positive
// value which is missed. So have bool vector(N) and only consider inputs in 0 <
// x <= N. Since even if there is no input in the specificed range then it
// simply means that it misses the whole value of the range and need to get the
// first false in the bool vector. 
//
// If bool vector has all set then return N+1. ????

int find_missing_integer_old(const vector<int> &A)
{
  vector<bool> flags(A.size());

  for(unsigned int i=0; i < A.size(); i++)
  {
    int value = A[i];

    if( value > 0 && value <= (int)A.size() )
      flags[value-1] = true;
  }

  for(unsigned int i=0; i < flags.size(); i++)
    if( flags[i] == false )
      return i+1;

  return A.size()+1;
}

TEST(AlgoFindMissingInteger, OldTries)
{
  EXPECT_THAT(find_missing_integer_old({1,3,6,4,1,2}), 5);
}


={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-max-counters

Calculate the values of counters after applying all alternating operations:
increase counter by 1; set value of all counters to current maximum.

You are given N counters, initially set to 0, and you have two possible
operations on them:

increase(X) − counter X is increased by 1,
max_counter − all counters are set to the maximum value of any counter.

A non-empty zero-indexed array A of M integers is given. This array represents
consecutive operations:

if A[K] = X, such that 1 ≤ X ≤ N, then operation K is increase(X),
if A[K] = N + 1 then operation K is max_counter.

For example, given integer N = 5 and array A such that:

    A[0] = 3
    A[1] = 4
    A[2] = 4
    A[3] = 6
    A[4] = 1
    A[5] = 4
    A[6] = 4

the values of the counters after each consecutive operation will be:

    (0, 0, 1, 0, 0)
    (0, 0, 1, 1, 0)
    (0, 0, 1, 2, 0)
    (2, 2, 2, 2, 2)
    (3, 2, 2, 2, 2)
    (3, 2, 2, 3, 2)
    (3, 2, 2, 4, 2)

The goal is to calculate the value of every counter after all operations.

Assume that the following declarations are given:

    struct Results {
      int * C;
      int L;
    }; 

Write a function:

struct Results solution(int N, int A[], int M); 

that, given an integer N and a non-empty zero-indexed array A consisting of M
  integers, returns a sequence of integers representing the values of the
  counters.

The sequence should be returned as:

a structure Results (in C), or
a vector of integers (in C++), or
a record Results (in Pascal), or
an array of integers (in any other programming language).

For example, given:

    A[0] = 3
    A[1] = 4
    A[2] = 4
    A[3] = 6
    A[4] = 1
    A[5] = 4
    A[6] = 4

the function should return [3, 2, 2, 4, 2], as explained above.

Assume that:

N and M are integers within the range [1..100,000];
each element of array A is an integer within the range [1..N + 1].

Complexity:

expected worst-case time complexity is O(N+M);
expected worst-case space complexity is O(N), beyond input storage (not counting
the storage required for input arguments).

Elements of input arrays can be modified.

<code>
// 2018.06.27
// 
// A[M] array, N counters
// A[k], 1 =< A[k] =< N+1, 
//  if A[k] =< N, increase(A[k]). if A[k] == N+1, max_counter
// 1 =< N, M =< 100,000

vector<int> find_max_counters_0627(int N, vector<int> A)
{
  vector<int> result(N, 0);
  int max{};

  for(size_t i = 0; i < A.size(); ++i)
  {
    if (A[i] == N+1)
    {
      // fill_n(result, N, max);
      for(auto &e : result)
        e = max;
    }
    else if (A[i] >= 1 && A[i] <= N)
    {
      if(++result[A[i]-1] > max)
        max = result[A[i]-1];
    }
  }

  return result;
}

TEST(AlgoMaxCounters, 0627_01)
{
  EXPECT_THAT(find_max_counters_0627(5, {3,4,4,6,1,4,4}), 
      ElementsAre(3,2,2,4,2));
}


// when simply follows descriptions:
//
// The result is that 100% correctness and 40% performance.
//
// Therefore, can see that the problem is the max-all operation and as a worst
// case, when there are N max-all operations this will be O(N*M) but target is
// O(M+N). So the key is to find a way to have max-all effect without doing a
// loop. How?

vector<int> find_max_counters_old_01(int N, const vector<int>& A)
{
  vector<int> counters(N, 0);

  int current_max = 0;

  for( size_t i=0; i < A.size(); i++ )
  {
    // set current max to all
    if( A[i] >= N+1 )
    {
      for( size_t j=0; j < counters.size(); j++ )
        if( counters[j] > current_max )
          current_max = counters[j];

      for( size_t j=0; j < counters.size(); j++ )
        counters[j] = current_max;
    }
    // increment a counter
    else
      counters[A[i]-1] += 1;
  }

  return counters;
}

TEST(AlgoMaxCounters, OldTries)
{
  EXPECT_THAT(find_max_counters_old_01(5, {3,4,4,6,1,4,4}), 
      ElementsAre(3,2,2,4,2));
}

// The above has time O(N*M) for worst cases such as when input has all 6, max
// operations. So key is not to loop on N counter array for a max operation.
//
// The observation shows that max-all op is performance bottleneck.
//
// How to solve?
//
// {3,4,4,6,1,4,4}
//
// 0   0 0 0 0
// 0   0 1 0 0
// 0   0 1 1 0
// 0   0 1 2 0
// -   - - - - take a snapshot of current max rather than run max op
// 2+1 0 1 2 0
// 3   0 1 3 0
// 3   0 1 4 0
// then do lopp and update elements that are less than snapshot value so that
// avoid run loop every max op.

vector<int> find_max_counters_0627_02(int N, vector<int> A)
{
  vector<int> result(N, 0);
  int current_max{}, operation_max{};

  for (size_t i = 0; i < A.size(); ++i)
  {
    if (A[i] == N+1)
    {
      operation_max = current_max;
    }
    else if (A[i] >= 1 && A[i] <= N)
    {
      if (result[A[i]-1] < operation_max)
        result[A[i]-1] = operation_max + 1;
      else 
        result[A[i]-1] += 1;

      if(result[A[i]-1] > current_max)
        current_max = result[A[i]-1];
    }
  }

  for (auto &e : result)
  {
    if (e < operation_max)
      e = operation_max;
  }

  return result;
}

TEST(AlgoMaxCounters, 0627_02)
{
  EXPECT_THAT(find_max_counters_0627_02(5, {3,4,4,6,1,4,4}), 
      ElementsAre(3,2,2,4,2));
  EXPECT_THAT(find_max_counters_0627_02(5, {3,4,4,6,1,4,6}), 
      ElementsAre(3,3,3,3,3));
  EXPECT_THAT(find_max_counters_0627_02(5, {3,6,6,6,6,6,6}), 
      ElementsAre(1,1,1,1,1));
}


// solution from online.
// http://codility-lessons.blogspot.co.uk/2014/07/lesson-2maxcounters.html
// 
//     (0, 0, 1, 0, 0)        (0, 0, 1, 0, 0)
//     (0, 0, 1, 1, 0)        (0, 0, 1, 1, 0)
//     (0, 0, 1, 2, 0)        (0, 0, 1, 2, 0)
//     (2, 2, 2, 2, 2)        (-, -, -, -, -)   max=2, maxLastMaxOp = 2
//     (3, 2, 2, 2, 2)        (3, 0, 1, 2, 0)
//     (3, 2, 2, 3, 2)        (3, 0, 1, 3, 0)
//     (3, 2, 2, 4, 2)        (3, 0, 1, 4, 0)
//                            (3, 2, 2, 4, 2)   set maxLastMaxOp to all which are not increased since
//                            last max-all operation.
// 
// This approach use flags to know which is increased since the last max-all
// operation and set maxLastMaxOp to all which are not increased since the last
// max-all.
// 
// The key 'observation' is that max-all sets the 'base' for following increase
// operations. 
//
// This approach still however didn't meet performance goal. 88%. WHY? since do
// memset on every max op.


struct Results find_max_counters_old_02(int N, int A[], int M) 
{
  struct Results result;
  result.C = calloc(sizeof(int), N);
  result.L = N;

  int* flg = alloca(sizeof(int) * N);
  memset(flg, 0x00, sizeof(int) * N);

  int max = 0;
  int maxAtTheLastMaxCntOp = 0;

  int i;
  for (i = 0; i < M; i++){
    int op = A[i];
    //if the op is max counter.
    if (op == N + 1){
      maxAtTheLastMaxCntOp = max;
      memset(flg, 0x00, sizeof(int) * N);    
    }
    //if the op is increase(x)
    else {
      //op is beweetn 1 to N, but the index for the array C 
      //is between 0 and (N-1). Decrease op to adjust it.
      op--; 
      if (flg[op] == 1){
        result.C[op]++;
      }
      else {
        result.C[op] = maxAtTheLastMaxCntOp + 1;
        flg[op] = 1;                
      }

      if (result.C[op] > max){
        max = result.C[op];
      }
    }
  }

  //apply the 'max counter' operation
  //to the slot(s) where it should be applied. 
  int j;  
  for (j = 0; j < N; j++){
    if (flg[j] == 0){
      result.C[j] = maxAtTheLastMaxCntOp;
    }
  }
  return result;
}

// the final solution from online.
// 
// This approach removes the use of flags. As with the above observation,
// max-all set the base that means any following increase should be based on
// 'hidden' base. So if result[op] < maxLastMaxOp then result[op] =
// maxLastMaxOp+1. Once done a loop, handle all which are not increased since
// the last max-all by checking less than maxLastMaxOp. 
//
// Verified 100% peformance mark.

vector<int> find_max_counters_old_03(int N, vector<int> &A) 
{
  // write your code in C++11
  vector<int> result(N,0);

  unsigned int maxLast =0, maxCurrent = 0;

  for(unsigned int i = 0; i < A.size(); i++ )
  {
    int op = A[i];

    if( op == N+1 )   // max-all op
      maxLast = maxCurrent;
    else              // inc op
    {
      op--;

      if( result[op] < maxLast )
        result[op] = maxLast+1;
      else
        result[op]++;

      if( result[op] > maxCurrent )
        maxCurrent = result[op];
    }
  }

  for( unsigned int i =0; i < N; i++ )
    if( result[i] < maxLast )
      result[i] = maxLast;

  return result;
}


={===========================================================================
*kt_dev_algo_0000* algo-minmax

// algo-minmax

namespace algo_min_max {

  bool AbsLess(int elem1, int elem2) {
    return abs(elem1) < abs(elem2);
  }

  using ITERATOR = std::deque<int>::iterator;

  pair<ITERATOR, ITERATOR> my_minmax(ITERATOR begin, ITERATOR end)
  {
    auto min = numeric_limits<int>::max();
    auto max = numeric_limits<int>::min();

    ITERATOR min_iter = begin;
    ITERATOR max_iter = begin;

    for(; begin != end; ++begin) {

      if (*begin < min) {
        min = *begin;
        min_iter = begin;
      }

      // add '=' to support the last max as minmax_element()
      if (max <= *begin) {
        max = *begin;
        max_iter = begin;
      }
    }

    return make_pair(min_iter, max_iter);
  }
}

TEST(AlgoMinMax, Stl)
{
  using namespace algo_min_max;

  deque<int> coll{2, 3, 4, 5, 6, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6};

  // If more than one minimum or maximum element exists, min_element() and
  // max_element() return `the first` found; minmax_element() returns the first
  // minimum but the last maximum element, so max_element() and minmax_element()
  // don’t yield the same maximum element.

  EXPECT_THAT(*min_element(coll.begin(), coll.end()), -3);

  EXPECT_THAT(*max_element(coll.begin(), coll.end()), 6);
  EXPECT_THAT(distance(coll.begin(),max_element(coll.begin(), coll.end())), 4);
 
  // return iterator pair
  // Note also that minmax_element() yields `the last maximum`, so the distance
  // 9.
  auto minmax = minmax_element(coll.begin(), coll.end());
  EXPECT_THAT(*(minmax.first), -3);   // first minimum
  EXPECT_THAT(*(minmax.second), 6);   // last maximum

  // last maximum is 6 which is the last element
  EXPECT_THAT(distance(coll.begin(), minmax.second), coll.size()-1);

  EXPECT_THAT(distance(minmax.first, minmax.second), 9);
  EXPECT_THAT(distance(
        min_element(coll.begin(), coll.end()),
        max_element(coll.begin(), coll.end()))
      , -1);

  // min/max of absolute values
  EXPECT_THAT(*min_element(coll.begin(), coll.end(), AbsLess), 0);
  EXPECT_THAT(*max_element(coll.begin(), coll.end(), AbsLess), 6);
}

namespace algo_min_max
{
  struct _Iter_less
  {
    template<typename _Iterator1, typename _Iterator2>
      bool operator()(_Iterator1 __it1, _Iterator2 __it2) const
      { return *__it1 < *__it2; }
  };

  template <typename _Iterator, typename _Compare>
    _Iterator my_max_element(_Iterator __first, _Iterator __last, 
        _Compare __comp)
    {
      // if thre is only one
      if (__first == __last)
        return __first;

      _Iterator __result = __first;

      // if *__result < *__first 
      while (++__first != __last)
        if (__comp(__result, __first))
          __result = __first;

      return __result;
    }

  // note: do by simply reversing comp()

  template <typename _Iterator, typename _Compare>
    _Iterator my_min_element(_Iterator __first, _Iterator __last,
        _Compare __comp)
    {
      if (__first == __last)
        return __first;

      _Iterator __result = __first;

      while (++__first != __last)
        // if (comp(__result, __first))
        if (__comp(__first, __result))
          __result = __first;

      return __result;
    }

} // namespace

TEST(AlgoMinMax, UseOwn)
{
  using namespace algo_min_max;

  {
    deque<int> coll{2, 3, 4, 5, 6, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6};

    // return iterator pair
    // Note also that minmax_element() yields `the last maximum`, so the distance
    // 9.
    auto minmax = my_minmax(coll.begin(), coll.end());
    EXPECT_THAT(*(minmax.first), -3);
    EXPECT_THAT(*(minmax.second), 6);
    EXPECT_THAT(distance(minmax.first, minmax.second), 9);
  }

  // on map
  {
    // sorted by key
    std::map<int, size_t> counts{
      {1, 2},
        {3, 2},
        {5, 3},
        {8, 3},
        {13, 1} 
    };

    auto e = max_element(counts.begin(), counts.end());
    EXPECT_THAT(*e, make_pair(13, 1));

    // ForwardIterator
    // max_element (ForwardIterator beg, ForwardIterator end, CompFunc op)
    // op is used to compare two elements:
    // op(elem1,elem2)
    // It should return true when the first element is less than the second
    // element.

    auto maxelem = std::max_element(
        std::begin(counts), std::end(counts),
        [](pair<int, size_t> const& e1, pair<int, size_t> const& e2)
        { return e1.second < e2.second; });

    EXPECT_THAT(*maxelem, make_pair(5, 3));
  }

  // multimap
  {
    // sorted by key and the order in the equal range are the order of input
    std::multimap<int, size_t> counts{
      {1, 2},
        {3, 9},
        {3, 8},
        {5, 3},
        {8, 3},
        {13, 2},
        {13, 4},
        {13, 12},
        {13, 1}
    };

    // for (auto &e : counts)
    //   cout << e.first << ", " << e.second << endl;

    // Q: how max_element() finds the max on the second?
    // see *cxx-pair-comparison*

    auto e = max_element(counts.begin(), counts.end());
    EXPECT_THAT(*e, make_pair(13, 12));
  }

  // max_element
  {
    // sorted by key
    std::map<int, size_t> counts{
      {1, 2},
        {3, 2},
        {5, 3},
        {8, 3},
        {13, 1} 
    };

    auto pos = my_max_element(counts.begin(), counts.end(),
        _Iter_less());

    EXPECT_THAT(*pos, make_pair(13, 1));
  }

  // min_element
  {
    // sorted by key
    std::map<int, size_t> counts{
      {1, 2},
        {3, 2},
        {5, 3},
        {8, 3},
        {13, 1} 
    };

    auto pos = my_min_element(counts.begin(), counts.end(),
        _Iter_less());

    EXPECT_THAT(*pos, make_pair(1, 2));
  }
}


={===========================================================================
*kt_dev_algo_0000* algo-prefix-sum algo-mushroom

Prefix sums

There is a simple yet powerful technique that allows for the fast calculation
of `sums of elements` in given slice (`contiguous` segments of array). Its
main idea uses prefix sums which are defined as the consecutive totals of the
first 0, 1, 2, . . . , n elements of an array.

        a0            a1              a2                ...   an−1
p0 = 0  p1 = a0       p2 = a0 + a1    p3 = a0 + a1 + a2 ...   pn = a0 + a1 + ... + an−1
p0 = 0  p1 = p0 + a0  p2 = p1 + a1    p3 = p2 + a2      ...   pn = pn-1 + an−1

or
        a0            a1              a2                ...   an−1
        p0 = a0       p1 = p0 + a1    p2 = p1 + a2      ...   pn-1 = a0 + a1 + ... + an−1

We can easily calculate the prefix sums in O(n) time complexity. Notice that
the total pk equals pk−1 + ak−1, so each consecutive value can be calculated
in a constant time.


5.1: Counting prefix sums — O(n).
1 def prefix_sums(A):
2 n = len(A)
3 P = [0] * (n + 1)
4 for k in xrange(1, n + 1):
5 P[k] = P[k - 1] + A[k - 1]
6 return P

Similarly, we can calculate suffix sums, which are the totals of the k last
values. 


<code>
// counting prefix sums, O(n)
vector<int> make_prefix_sums(const vector<int> &A)
{
  // +1 since prefix sum has one more
  size_t size = A.size()+1;

  vector<int> prefix_sum(size);

  for (size_t i = 1; i < size; ++i)
    prefix_sum[i] = prefix_sum[i-1] + A[i-1];

  return prefix_sum;
}

//   (1,2,3, 4, 5, 6)
// (0,1,3,6,10,15,21)

TEST(AlgoPrefixSum, MakePrefixSum)
{
  EXPECT_THAT(make_prefix_sums({1,2,3,4,5,6}),
      ElementsAre(0,1,3,6,10,15,21));

  EXPECT_THAT(make_prefix_sums({2,3,7,5,1,3,9}),
      ElementsAre(0,2,5,12,17,18,21,30));
}


// once prefix was built

Using prefix (or suffix) sums allows us to calculate the total of any slice of
the array very quickly. For example, assume that you are asked about the
totals of m slices [x..y] such that 0 <= x <= y < n, where the total is the
sum ax + ax+1 + . . . + ay−1 + ay.

The simplest approach is to iterate through the whole array for each result
separately; however, that requires O(n·m) time. The better approach is to use
prefix sums. If we calculate the prefix sums then we can answer each question
directly in constant time. Let’s subtract px from the value py+1.

py+1          a0 a1 . . . ax−1  ax ax+1 ... ay−1 ay ay+1
px            a0 a1 . . . ax−1
py+1 − px                       ax ax+1 ... ay−1 ay


5.2: Total of one slice — O(1).
1 def count_total(P, x, y):
2 return P[y + 1] - P[x]

slice[2,4]

 | 0 | 1 | 2 | | 3 | 4 | 5 |
 |------->
 |--------------------->


<code>
int count_total(const vector<int> &P, int x, int y)
{
  // since prefix sum index is +1 more then input index.
  return P[y+1] - P[x];
}

TEST(AlgoPrefixSum, SumAnySlice)
{
  //   {1,2, 3, 4, 5, 6}
  //         2     4
  // (0,1,3,[6,10,15],21)
  //
  // 15-3 = 12

  EXPECT_THAT(count_total(make_prefix_sums({1,2,3,4,5,6}), 2, 4), 12);

  // (0,2,5,[12,17,18],21,30)
  // 18-5 = 13

  EXPECT_THAT(count_total(make_prefix_sums({2,3,7,5,1,3,9}), 2, 4), 13);
}


5.1. Exercise

Problem: 

You are given a non-empty, zero-indexed array A of n (1 <= n <= 100,000)
integers a0, a1, ..., an−1 (0 <= ai <= 1 000). 

This array represents number of mushrooms growing on the consecutive spots
along a road. You are also given integers k and m (0 <= k, m < n). A mushroom
picker is at spot number k on the road and should perform m moves. In one move
she moves to an adjacent spot. She collects all the mushrooms growing on
spots she visits. 

The goal is to calculate the maximum number of mushrooms that the mushroom
picker can collect in m moves.

For example, consider array A such that:

{2 3[7 5 1 3 9]}
 0 1 2 3 4 5 6

The mushroom picker starts at spot k = 4 and should perform m = 6 moves. She
might move to spots 3, 2, 3, 4, 5, 6 and thereby collect 

1(4) + 5(3) + 7(2) + 0(3) + 0(4) + 3(5) + 9(6) = 25 mushrooms. 

This is the maximal number of mushrooms she can collect.

// note:
// do not count mushroom that's already counted.

def mushrooms(A, k, m):

Solution O(m2): 

the best strategy is to move in one direction optionally followed by some
moves in the opposite direction. In other words, the mushroom picker should
not change direction more than once. With this observation we can find the
simplest solution.  Make the first p = 0, 1, 2, . . . ,m moves in one
direction, then the next m - p moves in the opposite direction. This is just a
simple simulation of the moves of the mushroom picker which requires O(m2)
time.


Solution O(n+m): 

A better approach is to use prefix sums. If we make p moves in one direction,
  we can calculate the maximal opposite location of the mushroom picker. The
  mushroom picker collects all mushrooms between these extremes. We can
  calculate the total number of collected mushrooms in constant time by using
  prefix sums.


// start: 4, moves: 6
// loop(0, 5), left:  4, shift:  6, right: 10 -> 10 ->  6, xresult: 13, result: 13
// loop(1, 5), left:  3, shift:  4, right:  8 ->  8 ->  6, xresult: 18, result: 18
// loop(2, 5), left:  2, shift:  2, right:  6 ->  6 ->  6, xresult: 25, result: 25
// loop(3, 5), left:  1, shift:  0, right:  4 ->  4 ->  4, xresult: 16, result: 25
// loop(4, 5), left:  0, shift: -2, right:  2 ->  4 ->  4, xresult: 18, result: 25
// 
// when move window to the left
//          0    1   2   3   4   5   6   7   8   9   10
//          2    3   7   5  [1   3   9   X   X   X   X]
//          2    3   7  [5   1   3   9   X   X]  X   X
//          2    3  [7   5   1   3   9]  X   X   X   X
//          2   [3   7   5   1]  3   9   X   X   X   X
//         [2    3   7   5   1]  3   9   X   X   X   X
//
// when move window to the right
// [X   X   2    3   7   5   1]  3   9   X   X   X   X
//     [X   2    3   7   5   1   3]  9   X   X   X   X
//          2    3  [7   5   1   3   9]  X   X   X   X
//
// when used a bug
// loop(0, 2), right:  4, shift:  6, left: -2 -> -2 ->  0, xresult: 18, result: 25
// loop(1, 2), right:  5, shift:  4, left:  0 ->  0 ->  0, xresult: 21, result: 25
//
// start: 4, moves: 6
// loop(0, 3), shift:  6, left: -2 -> -2 ->  0, right:  4, xresult: 18, result: 25
// loop(1, 3), shift:  4, left:  0 ->  0 ->  0, right:  5, xresult: 21, result: 25
// loop(2, 3), shift:  2, left:  2 ->  2 ->  2, right:  6, xresult: 25, result: 25
//
// from this observation, when shift to left to the start, right end get reduced
// by 2 since uses "move" twice when goes to left and right again.
// 
// After all, get possible max mushroom and moves windows which starts from
// start pos and ends with start pos.
//
// start: 8, moves: 5
// loop(0, 6), left:  8, shift:  5, right: 13 -> 13 -> 13, xresult: 21, result: 21
// loop(1, 6), left:  7, shift:  3, right: 11 -> 11 -> 11, xresult: 27, result: 27
// loop(2, 6), left:  6, shift:  1, right:  9 ->  9 ->  9, xresult: 23, result: 27
// loop(3, 6), left:  5, shift: -1, right:  7 ->  8 ->  8, xresult: 26, result: 27
// loop(4, 6), left:  4, shift: -3, right:  5 ->  8 ->  8, xresult: 30, result: 30
// loop(5, 6), left:  3, shift: -5, right:  3 ->  8 ->  8, xresult: 32, result: 32
//
//   0   1   2  3  4  5  6   7 *8* 9 10 11 12 13 14
//  13  12  11  2  4  6  8  10 [2  3  7  5  1  3] 9     (21)
//  13  12  11  2  4  6  8 [10  2  3  7  5] 1  3  9     (27)
//  13  12  11  2  4  6 [8  10  2  3] 7  5  1  3  9     (23)
//  13  12  11  2  4 [6  8  10  2] 3  7  5  1  3  9     (26)
//  13  12  11  2 [4  6  8  10  2] 3  7  5  1  3  9     (30)
//  13  12  11 [2  4  6  8  10  2] 3  7  5  1  3  9     (32)
//  ...
//
// start: 8, moves: 5
// loop(0, 6), shift:  5, left:  3 ->  3 ->  3, right:  8, xresult: 32, result: 32
// loop(1, 6), shift:  3, left:  5 ->  5 ->  5, right:  9, xresult: 29, result: 32
// loop(2, 6), shift:  1, left:  7 ->  7 ->  7, right: 10, xresult: 22, result: 32
// loop(3, 6), shift: -1, left:  9 ->  8 ->  8, right: 11, xresult: 17, result: 32
// loop(4, 6), shift: -3, left: 11 ->  8 ->  8, right: 12, xresult: 18, result: 32
// loop(5, 6), shift: -5, left: 13 ->  8 ->  8, right: 13, xresult: 21, result: 32
//
// note:
// After all, find the maximum sum while moving a window left and right.


int mushroom_model(const vector<int> A, int start, int moves)
{
  int max_input_index = A.size()-1;
  int result{};
  auto prefix_sum = make_prefix_sums(A);
  int loop_max{};

  // cout << "start: " << start << ", moves: " << moves << endl;
  loop_max = min(start, moves) + 1;
  for (int prefix_index = 0; prefix_index < loop_max; ++prefix_index)
  {
    int left_pos = start - prefix_index;
    int shift_value = (moves-2*prefix_index);
    int possible_right_pos = start+shift_value;

    // max? since right end cannot be less than start
    // *cxx-min-max*
    int max_on_possible_right_pos = max(start, possible_right_pos);

    // min? since right end cannot be greater than max index of input.
    int right_pos = min(max_input_index, max_on_possible_right_pos);

    // collect mushroon only once? count_total use range and counts only once.
    auto xresult = count_total(prefix_sum, left_pos, right_pos);
    result = max(result, xresult);

    // cout << "loop(" << prefix_index << ", " << loop_max << ")" 
    //   << ", left: " << setw(2) << left_pos
    //   << ", shift: " << setw(2) << shift_value 
    //   << ", right: " << setw(2) << possible_right_pos << " -> " 
    //   << setw(2) << max_on_possible_right_pos << " -> " << setw(2) << right_pos 
    //   << ", xresult: " << xresult << ", result: " << result << endl;
  }

  // cout << "start: " << start << ", moves: " << moves << endl;

  // from codility code but looks wrong.
  // loop_max = min(moves+1, max_input_index-start);
  loop_max = min(moves, max_input_index-start)+1;
  for (int prefix_index = 0; prefix_index < loop_max; ++prefix_index)
  {
    int right_pos = start + prefix_index;
    // left_pos = max(0, min(K, K-(M-2*prefix_index)));
    int shift_value = (moves-2*prefix_index);
    int possible_left_pos = start-shift_value;

    // min? left end should be less than the start
    int min_on_possible_left_pos = min(start, possible_left_pos);

    // max? cannot not less than 0
    int left_pos = max(0, min_on_possible_left_pos);

    auto xresult = count_total(prefix_sum, left_pos, right_pos);
    result = max(result, xresult);

    // cout << "loop(" << prefix_index << ", " << loop_max << ")" 
    //   << ", shift: " << setw(2) << shift_value 
    //   << ", left: " << setw(2) << possible_left_pos << " -> " 
    //   << setw(2) << min_on_possible_left_pos << " -> " << setw(2) << left_pos
    //   << ", right: " << setw(2) << right_pos 
    //   << ", xresult: " << xresult << ", result: " << result << endl;
  }

  return result;
}

TEST(AlgoPrefixSum, MushroomPicker)
{
  EXPECT_THAT(mushroom_model({2,3,7,5,1,3,9}, 4, 6), 25);
  EXPECT_THAT(mushroom_model({13,12,11, 2, 4, 6, 8,10, 2, 3, 7, 5, 1, 3, 9}, 8, 5), 32);
}


int mushroom_0704(const vector<int> A, int start, int moves)
{
  int max_input_index = A.size()-1;
  int num_loop{};
  int result{};

  auto prefix_sum = make_prefix_sums(A);

  // moves a window to the left
  // since `start` is actually index, it's sure to have elements in [0,start] so
  // use it directly
  num_loop = min(start, moves)+1;
  for (int i = 0; i < num_loop; ++i)
  {
    int left_end = start - i;
    int shift_value = (moves - 2*i);
    int right_end = start + shift_value;

    // right_end should be in [start, max input index]
    int right_contained = min(max_input_index, right_end);
    int right_end_calculated = max(start, right_contained);

    int prefix_sum_result = count_total(prefix_sum, left_end, right_end_calculated);
    result = max(prefix_sum_result, result);
  }

  // moves a windows to the right
  // unlike `to the left` case, cannot use start and have to use max input
  // index.
  num_loop = min(moves, max_input_index-start)+1;
  for (int i = 0; i < num_loop; ++i)
  {
    int right_end = start + i;
    int shift_value = (moves - 2*i);
    int left_end = start - shift_value;

    // left_end should be in [0, start]
    int left_end_contained = max(0, left_end);
    int left_end_calculated = min(start, left_end_contained);

    int prefix_sum_result = count_total(prefix_sum, left_end_calculated, right_end);
    result = max(prefix_sum_result, result);
  }

  return result; 
}

TEST(AlgoPrefixSum, MushroomPicker_0704)
{
  EXPECT_THAT(mushroom_0704({2,3,7,5,1,3,9}, 4, 6), 25);
  EXPECT_THAT(mushroom_model({13,12,11, 2, 4, 6, 8,10, 2, 3, 7, 5, 1, 3, 9}, 8, 5), 32);
}


={===========================================================================
*kt_dev_algo_0000* algo-max-sum-sub-array

// algo-leetcode-53
// note: accululated sum of contiguous sub-array
/*
53. Maximum Subarray, Easy, algo-max-sub-array

Given an integer array nums, find the contiguous subarray (containing at least
one number) which has the largest sum and return its sum.

Example:

Input: [-2,1,-3,4,-1,2,1,-5,4],
Output: 6
Explanation: [4,-1,2,1] has the largest sum = 6.

Follow up:
If you have figured out the O(n) solution, try coding another solution using the
divide and conquer approach, which is more subtle.

int maxSubArray(vector<int>& nums) {}


In discussion, by _LeetCode,  Last Edit: October 24, 2018 8:10 PM
for python

for i in range(1, len(nums)):
        if nums[i-1] > 0:
            nums[i] += nums[i-1]
    return max(nums)

The key observation is:

[i-1]   [i]

if the previous, [i-1], is positive, then "sum" gets bigger whether or not the
current element is positive or negative.


if make sum regardless of singness of the previous, then it makes *prefix-sum*

-2  1   -3  4   -1  2   1   -5  4
    -1  -4  0   -1  1   2   -3  1

if runs the above code, then 6 is max sum

-2  1   -3 [4   -1  2   1]  -5  4
        -2      3   5   6   1   5 

if runs the prefix-sum but do not allow negative value , then 6 is max sum

-2  1   -3 [4   -1  2   1]  -5  4
0   1   -0  4    3  5   6   1   5 


so, the both are basically the same method to get max sub-array


if make the previous value bigger? affect on next sum and will be covered

-2  100   -3    4    -1     2     1   -5    4
          97  101   100   102   103   98  102 


This is about "sum" but not "sub array" How about returnning "sub array"?

-2  1   -3 [4   -1  2   1]  -5  4
        -2      3   5   6   1   5 
        *       *
        *
"*" starts and max_element() is ends.

*/

namespace leetcode_easy_053
{
  int maxSubArray_1(vector<int>& nums)
  {
    int current_max{};

    // do not solve all
    // if (nums.size() == 1)
    // {
    //   return nums[0];
    // }

    for (size_t i = 1; i < nums.size(); ++i)
    {
      // only for positive previous item
      // why [i-1]? since updates `nums` and refer back to the previous

      if (nums[i-1] > 0)
      {
        // update input to keep *prefix-sum* since do not care changes to the
        // input

        nums[i] += nums[i-1];

        // to find max sum
        if (nums[i] > current_max)
          current_max = nums[i];
      }
    }

    return current_max;
  }

  // Runtime: 12 ms, faster than 98.45% of C++ online submissions for Maximum
  // Subarray.
  //
  // Memory Usage: 10.5 MB, less than 15.81% of C++ online submissions for
  // Maximum Subarray.

  int maxSubArray_2(vector<int>& nums)
  {
    for (size_t i = 1; i < nums.size(); ++i)
    {
      // only for positive previous item
      if (nums[i-1] > 0)
      {
        // update input to keep *prefix-sum* since do not care changes to the
        // input

        nums[i] += nums[i-1];
      }
    }

    return *std::max_element(nums.begin(), nums.end());
  }

  // https://www.geeksforgeeks.org/largest-sum-contiguous-subarray/
  //
  // Simple idea of the Kadane’s algorithm is to look for all positive
  // contiguous segments of the array (max_ending_here is used for this). And
  // keep track of *maximum sum* contiguous segment among all positive segments
  // (max_so_far is used for this). Each time we get a positive sum compare it
  // with max_so_far and update max_so_far if it is greater than max_so_far

  int maxSubArray_3(vector<int>& nums)
  {
    int max_so_far{std::numeric_limits<int>::min()};
    int max_current{};

    for (auto e : nums)
    {
      // works okay
      //
      // in sum, that's to make prefix-sum but do not allow negative value.
      //
      // max_current = e + max_current;
      // if (max_current < 0)
      //   max_current = 0;

      // same as
      max_current = e + max_current;
      max_current = max(0, max_current);

      if (max_current > max_so_far)
        max_so_far = max_current;
    }

    return max_so_far;
  }

} // namespace

TEST(LeetCode, Easy_053_MaxSubArray_1)
{
  using namespace leetcode_easy_053;

  {
    auto func = maxSubArray_1;

    // fails on :
    // input "1" and expected "1"
    {
      vector<int> coll{1};
      EXPECT_THAT(func(coll), Not(1));
    }

    // fails on
    // input "-2, 1" and expected 1
    {
      vector<int> coll{-2, 1};
      EXPECT_THAT(func(coll), Not(1));
    }

    {
      vector<int> coll{-2,1,-3,4,-1,2,1,-5,4};
      EXPECT_THAT(func(coll), 6);
    }

    {
      // >>> sum([100,-3,4,-1,2,1,-5,4])
      // 102
      // >>> sum([100,-3,4,-1,2,1])
      // 103
      vector<int> coll{-2,100,-3,4,-1,2,1,-5,4};
      EXPECT_THAT(func(coll), 103);
    }
  }

  {
    auto func = maxSubArray_2;

    {
      vector<int> coll{1};
      EXPECT_THAT(func(coll), 1);
    }

    {
      vector<int> coll{-2, 1};
      EXPECT_THAT(func(coll), 1);
    }

    {
      vector<int> coll{-2,1,-3,4,-1,2,1,-5,4};
      EXPECT_THAT(func(coll), 6);
    }

    {
      vector<int> coll{-2,100,-3,4,-1,2,1,-5,4};
      EXPECT_THAT(func(coll), 103);
    }
  }

  {
    auto func = maxSubArray_3;

    {
      vector<int> coll{1};
      EXPECT_THAT(func(coll), 1);
    }

    {
      vector<int> coll{-2, 1};
      EXPECT_THAT(func(coll), 1);
    }

    {
      vector<int> coll{-2,1,-3,4,-1,2,1,-5,4};
      EXPECT_THAT(func(coll), 6);
    }

    {
      vector<int> coll{-2,100,-3,4,-1,2,1,-5,4};
      EXPECT_THAT(func(coll), 103);
    }
  }
}


={===========================================================================
*kt_dev_algo_0000* algo-max-profit

// algo-leetcode-121
/*
121. Best Time to Buy and Sell Stock, Easy

Say you have an array for which the ith element is the price of a given stock on
day i.

If you were only permitted to complete at most one transaction (i.e., buy one
and sell one share of the stock), design an algorithm to find the maximum
profit.

Note that you cannot sell a stock before you buy one.

Example 1:

Input: [7,1,5,3,6,4]
Output: 5

Explanation: 
Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5.  Not
7-1 = 6, as selling price needs to be larger than buying price.

Example 2:

Input: [7,6,4,3,1]
Output: 0

Explanation: 
In this case, no transaction is done, i.e. max profit = 0.
 
the key is:

max profit is max (sell - buy)

*/

namespace leetcode_easy_121
{
  /*
  algo-minmax variation which has two seperate if for max and min. But this 
  uses nested if to meet two condition:

  1. buy first and then can sell
  2. buy < sell
   
  buy:  7   1     x   x   x   x   = 1
  sell: min min   5   x   6   x   = 6
 
  buy:  7   6   4   3   1   = 1
  sell: min min min min min = min

  this avoids 1 - 7 case as the problem description

  */

  int maxProfit_1(vector<int>& prices) 
  {
    // max
    int sell{std::numeric_limits<int>::min()};
    // min
    int buy{std::numeric_limits<int>::max()};

    // for (auto e : prices)
    for (size_t i = 0; i < prices.size(); ++i)
    {
      // update buy, min
      if ((i + 1) < prices.size() && prices[i] < buy)
      {
        buy = prices[i];
        sell = std::numeric_limits<int>::min();
      }
      // update sell, max
      else if (prices[i] > sell)
      {
        sell = prices[i];
      }
    }

    // cout << "buy: " << buy << ", sell: " << sell << endl;

    if (sell > buy)
      return abs(buy - sell);
    else
      return 0;
  }

  // based on the graph and to find min and max as above. failes again.

  int maxProfit_1_1(vector<int> &prices)
  {
    int max_price{std::numeric_limits<int>::min()};
    int min_price{std::numeric_limits<int>::max()};

    for (auto e : prices)
    {
      if (min_price != std::numeric_limits<int>::max() && e > max_price)
        max_price = e;

      if (e < min_price)
        min_price = e;
    }

    cout << "max: " << max_price << ", min: " << min_price << endl;

    if (min_price < max_price)
      return max_price - min_price;
    else 
      return 0;
  }

  // Kadane's Algorithm - Since no one has mentioned about this so far :) (In
  // case if interviewer twists the input)
  // andyreadsall
  //
  // As with *algo-max-sub-array*
  //
  // As with maxSubArray_3(), use the same but is to find max difference, e[i] -
  // e[i-1] but not sum. 

  int maxProfit_2(vector<int>& prices) 
  {
    int current_profit{};
    int max_profit{};

    for (size_t i = 1; i < prices.size(); ++i)
    {
      current_profit = current_profit + (prices[i] - prices[i-1]);
      current_profit = max(0, current_profit);

      max_profit = max(max_profit, current_profit);
    }

    return max_profit;
  }


  // Simple java solution, venkim
  // where keep min, bought value

  int maxProfit_3(vector<int>& prices) 
  {
    if (prices.empty())
      return 0;

    int max_profit{};
    int bought{prices[0]};

    for (size_t i = 1; i < prices.size(); ++i)
    {
      // update profit only when it's bigger
      max_profit = max(max_profit, prices[i] - bought);

      // update bought which is min 
      bought = min(bought, prices[i]);
    }

    return max_profit;
  }

  // from solution
  // Approach 2: One Pass
  // The points of interest are the peaks and valleys in the given graph. We
  // need to find the largest peak following the smallest valley.
  //
  // this is approach that I tried to make it work
  // see *algo-water*

  int maxProfit_4(vector<int> &prices)
  {
    int max_profit{};
    int min_price{std::numeric_limits<int>::max()};

    for (auto e : prices)
    {
      if (e < min_price)
        min_price = e;
      else if (e - min_price > max_profit)
        max_profit = e - min_price;
    }

    return max_profit;
  }

  // same as _4().

  int maxProfit_5(vector<int> &prices)
  {
    int min_price{std::numeric_limits<int>::max()};
    int profit{};
    int max_profit{};

    for (auto e : prices)
    {
      if (e < min_price)
        min_price = e;
      else
      {
        profit = e - min_price;
        max_profit = max(max_profit, profit);
      }
    }

    return max_profit;
  }

  // same as _3() 

  int maxProfit_6(vector<int> &prices)
  {
    if (prices.empty())
      return 0;

    int max_profit{};
    int min_price{prices[0]};

    for (size_t i = 1; i < prices.size(); ++i)
    {
      max_profit = max(prices[i] - min_price, max_profit);

      if (prices[i] < min_price)
        min_price = prices[i];
    }

    return max_profit;
  }

} // namespace

TEST(LeetCode, Easy_121_MaxProfit_1)
{
  using namespace leetcode_easy_121;

  {
    auto func = maxProfit_1;
    {
      vector<int> coll{7,1,5,3,6,4};
      EXPECT_THAT(func(coll), 5);
    }
    {
      vector<int> coll{7,6,4,3,1};
      EXPECT_THAT(func(coll), 0);
    }
    {
      vector<int> coll{};
      EXPECT_THAT(func(coll), 0);
    }

    // fails. does it mean that sell should be always after buy in the input?
    // say, 2(buy) and 4(sell) but not update buy 1 since there is no more element
    // to update sell?

    {
      vector<int> coll{2,4,1};
      EXPECT_THAT(func(coll), 2);
    }

    {
      vector<int> coll{2,1,2,0,1};
      EXPECT_THAT(func(coll), 1);
    }

    // // fails
    // {
    //   vector<int> coll{3,2,6,5,0,3};
    //   EXPECT_THAT(func(coll), 4);
    // }
  }

  {
    auto func = maxProfit_2;

    {
      vector<int> coll{7,1,5,3,6,4};
      EXPECT_THAT(func(coll), 5);
    }
    {
      vector<int> coll{7,6,4,3,1};
      EXPECT_THAT(func(coll), 0);
    }
    {
      vector<int> coll{};
      EXPECT_THAT(func(coll), 0);
    }
    {
      vector<int> coll{2,4,1};
      EXPECT_THAT(func(coll), 2);
    }
    {
      vector<int> coll{2,1,2,0,1};
      EXPECT_THAT(func(coll), 1);
    }
    {
      vector<int> coll{3,2,6,5,0,3};
      EXPECT_THAT(func(coll), 4);
    }
  }

  {
    auto func = maxProfit_3;

    {
      vector<int> coll{7,1,5,3,6,4};
      EXPECT_THAT(func(coll), 5);
    }
    {
      vector<int> coll{7,6,4,3,1};
      EXPECT_THAT(func(coll), 0);
    }
    {
      vector<int> coll{};
      EXPECT_THAT(func(coll), 0);
    }
    {
      vector<int> coll{2,4,1};
      EXPECT_THAT(func(coll), 2);
    }
    {
      vector<int> coll{2,1,2,0,1};
      EXPECT_THAT(func(coll), 1);
    }
    {
      vector<int> coll{3,2,6,5,0,3};
      EXPECT_THAT(func(coll), 4);
    }
  }

  {
    auto func = maxProfit_4;

    {
      vector<int> coll{7,1,5,3,6,4};
      EXPECT_THAT(func(coll), 5);
    }
    {
      vector<int> coll{7,6,4,3,1};
      EXPECT_THAT(func(coll), 0);
    }
    {
      vector<int> coll{};
      EXPECT_THAT(func(coll), 0);
    }
    {
      vector<int> coll{2,4,1};
      EXPECT_THAT(func(coll), 2);
    }
    {
      vector<int> coll{2,1,2,0,1};
      EXPECT_THAT(func(coll), 1);
    }
    {
      vector<int> coll{3,2,6,5,0,3};
      EXPECT_THAT(func(coll), 4);
    }
  }

  {
    // auto func = maxProfit_5;
    auto func = maxProfit_6;

    {
      vector<int> coll{7,1,5,3,6,4};
      EXPECT_THAT(func(coll), 5);
    }
    {
      vector<int> coll{7,6,4,3,1};
      EXPECT_THAT(func(coll), 0);
    }
    {
      vector<int> coll{};
      EXPECT_THAT(func(coll), 0);
    }
    {
      vector<int> coll{2,4,1};
      EXPECT_THAT(func(coll), 2);
    }
    {
      vector<int> coll{2,1,2,0,1};
      EXPECT_THAT(func(coll), 1);
    }
    {
      vector<int> coll{3,2,6,5,0,3};
      EXPECT_THAT(func(coll), 4);
    }
  }
}



={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-passing-car

chapter 3, prefix sum.

A non-empty zero-indexed array A consisting of N integers is given. The
consecutive elements of array A represent consecutive cars on a road.

Array A contains only 0s and/or 1s:

0 represents a car traveling east,
1 represents a car traveling west.

The goal is to count passing cars. We say that a pair of cars (P, Q), where 0
≤ P < Q < N, is passing when P is traveling to the east and Q is traveling to
the west.

For example, consider array A such that:

  A[0] = 0
  A[1] = 1
  A[2] = 0
  A[3] = 1
  A[4] = 1

We have five pairs of passing cars: (0, 1), (0, 3), (0, 4), (2, 3), (2, 4).

Write a function:

    int solution(int A[], int N); 

that, given a non-empty zero-indexed array A of N integers, returns the number
  of passing cars.

The function should return -1 if the number of passing cars exceeds
1,000,000,000.

For example, given:

  A[0] = 0
  A[1] = 1
  A[2] = 0
  A[3] = 1
  A[4] = 1

the function should return 5, as explained above.

Assume that:

N is an integer within the range [1..100,000];
each element of array A is an integer that can have one of the following
  values: 0, 1.

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(1), beyond input storage (not
    counting the storage required for input arguments).

Elements of input arrays can be modified.

<code>

// in sum, find (0, X) pair from the input. 
//
// if loop on input to find each (0, X) pair then cannot meet O(N)
//
// How to solve?
//
// the key is whenever see 1, it's counted more depending on preceding 0's
// number.
//
// {0, 1, 0, 1, 1}
//     *     *  *
//           *  *
// so sum is 5

int passing_car_0628_01(const vector<int> A)
{
  int pair_count{}, zero_count{};

  for(size_t i = 0; i < A.size(); ++i)
  {
    if (A[i] == 0)
      ++zero_count;
    else 
    {
      pair_count += zero_count;
    }
  }

  return pair_count;
}

TEST(AlgoPassingCar, 0628_01)
{
  EXPECT_THAT(passing_car_0628_01({0,1,0,1,1}), 5); 
}

// From http://codility-lessons.blogspot.co.uk/2014/07/lesson-3-passingcars.html.
// 
// The idea is that
// 
//    0 1 0 1 1
//    *------->
//        *--->

int passing_car_old_01( vector<int> &A )
{
  int count = 0, countEast = 0;

  for( int i=0; i < (int)A.size(); i++ )
  {
    if( A[i] == 0 )
      countEast++;
    else
    {
      count += countEast;

      if( count > 1000000000 )
        return -1;
    }
  }

  return count;
}


={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-count-div

From chapter 3, prefix sum.

Write a function:

int solution(int A, int B, int K); 

that, given three integers A, B and K, returns the number of integers within
  the range [A..B] that are divisible by K, i.e.:

    { i : A ≤ i ≤ B, i mod K = 0 }

For example, for A = 6, B = 11 and K = 2, your function should return 3,
    because there are three numbers divisible by 2 within the range [6..11],
    namely 6, 8 and 10.

Assume that:

A and B are integers within the range [0..2,000,000,000];
K is an integer within the range [1..2,000,000,000];
A ≤ B.

Complexity:

expected worst-case time complexity is O(1);
expected worst-case space complexity is O(1).

<code>
// Since time O(1), cannot use loop. 
//
// How to solve?
//
// when A is divisible by K:
//    B-S = diff. diff/K + 1 is the number of integers that can be divisible by
//    K. +1 since diff do not include A.
//
// 6,7,8,9,10,11,12, K=2
//
// 12-6=6. 6/2=3. 3+1=4
//
// when A is not diviaible by K:
//    cannot use loop either to find S(start value). so have to find the next
//    K*x element in the input. To do that, if A%K != 0, then S = (A/K + 1)*K.
//
//    B-S = diff. diff/K + 1.

// peformance 100%, correctness 50%
int count_div_0628_01(int A, int B, int K)
{
  int start{}, result{};

  if (A%K == 0)
    start = A;
  else
    start = (A/K+1)*K;

  return result = (B-start)/K + 1;
}

TEST(AlgoCountDiv, 0628_01)
{
  EXPECT_THAT(count_div_0628_01(6, 11, 2), 3); 
}


// failed from the report
// EXPECT_THAT(count_div_0628_01(1, 1, 11), 0); 
// 
// failed from the report
// EXPECT_THAT(count_div_0628_03(1, 1, 11), 0); 
// 
// fails since 0/K and 0%K are 0. WHY 1? Since 0 is still divisible.
// EXPECT_THAT(count_div_0628_03(0, 1, 11), 1); 
//
// why 1?
// EXPECT_THAT(count_div_0628_03(0, 0, 11), 1); 
// 
// fails
// EXPECT_THAT(count_div_0628_03(0, 14, 2), 8); 
//
// after all, missed to handle:
//
// 1. end case which is 0 on both A and B
// 2. 0/K and 0%K are 0.
//
// compared to algo-frog-jump which has no 0 input end in the input.


// 100% pass
int count_div_0628_03(int A, int B, int K)
{
  int start{}, result{};

  if (A%K == 0)
    start = A;
  else
    start = (A/K+1)*K;

  if (B-start >= 0)
    result = (B-start)/K + 1;
  
  return result;
}

TEST(AlgoCountDiv, 0628_03)
{
  EXPECT_THAT(count_div_0628_03(6, 11, 2), 3); 
  EXPECT_THAT(count_div_0628_03(1, 1, 11), 0); 
  EXPECT_THAT(count_div_0628_03(0, 1, 11), 1); 
  EXPECT_THAT(count_div_0628_03(10, 10, 5), 1); 
  EXPECT_THAT(count_div_0628_03(10, 10, 7), 0); 
  EXPECT_THAT(count_div_0628_03(10, 10, 20), 0); 
  EXPECT_THAT(count_div_0628_03(0, 0, 11), 1); 
  EXPECT_THAT(count_div_0628_03(0, 14, 2), 8); 
}


={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-count-identical-pairs

The quiz from a real test. Find the number of identical pairs in an array
where 0 <= P < Q < N, A[P] = A[Q] in O(N) in performace and O(1) in space.

A[0] = 3
A[1] = 5
A[2] = 6
A[3] = 3
A[4] = 3
A[5] = 5

The answer is 4.

<code>

// {3,5,6,3,3,5}
//
// Why the answer is 4 but not 3? Use index and there are 4 pairs
//
// no mention of input value range and assumes 255, 0 <= A[x] <= 255
//
// the same as algo-passing_car

int count_identical_pairs_0629_01(const vector<int> &A)
{
  int count{};

  vector<pair<int, int>> map(256);

  for (auto e : A)
  {
    // not set before
    if (map[e].first == 0)
      map[e] = pair<int, int>(e, 0);

    // add count
    count += map[e].second;

    // update count
    map[e].second += 1;
  }

  return count;
}

TEST(AlgoCountIdenticalPairs, 0629_01)
{
  EXPECT_THAT(count_identical_pairs_0629_01({3,5,6,3,3,5}), 4); 
}


={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-lesson-time-complexity

Time complexity

Use of time complexity makes it easy to estimate the running time of a
program. Performing an accurate calculation of a program's operation time is a
very labour-intensive process (it depends on the compiler and the type of
    computer or speed of the processor). Therefore, we will not make an
accurate measurement; just a measurement of a certain order of magnitude.
Complexity can be viewed as the maximum number of regular operations that a
program may execute. Regular operations are single additions, multiplications,
assignments etc. We may leave some operations uncounted and concentrate on
  those that are performed the largest number of times. Such operations are
  referred to as 'dominant'. The number of dominant operations is considered
  on the basis of the specific input data. We usually want to know how the
  performance time depends on a specific 'aspect' of the data.  This is most
  frequently the data size, but it can also be the size of a square matrix or
  the value of some input variable.

1.1 : Which is the dominant operation?
1 def dominant(N):
2  result = 0
3  for i in xrange(N):
4     result += 1
5  return result

The operation in line 4 is dominant and will be executed N times. The
complexity is recorded in Big-O notation: in this case O(N) - linear
complexity. 

The complexity specifies the order of 'magnitude' within which the program
will perform its operations. More precisely, in the case of O(N), the program
may perform cN operations, where c is a constant; however, it may not perform
N^2 operations, for example, since this involves a different order of
magnitude of data. In other words, when calculating the complexity we omit
constants: i.e.  regardless of whether the loop is executed 20N times or N/5
times, we still have a complexity of O(N), even though the running time of the
program may vary. When analyzing the complexity we must look for specific,
malicious examples of data that the program will take a long time to process.

1.1. Comparison of different time complexities

Let's compare some basic time complexities.

1.2 : Constant time - O(1).
1 def constant(N):
2  result = N * N
3  return result

There is always a fixed number of operations.


1.3 : Logarithmic time - O(log N).
1 def logarithmic(N):
2  result = 0
3  while (N > 1):
4     N = N // 2
5     result += 1
6  return result

The value of N is halved on each iteration of the loop. If N = 2^X then log N
  = X. How long would the program below take to execute, depending on the
  input data?


1.4 : Linear time - O(N).
1 def linear(N, A):
2  for i in xrange(N):
3     if A[i] == 0:
4        return 0
5  return 1

Let's note that if the first value of array A is 0 then the program will end
  immediately. But remember, when analyzing time complexity we should check
  for malicious cases. The program will take the longest time to execute if
    array A does not contain any 0.


1.5 : Quadratic time - O(N^2).
1 def quadratic(N):
2  result = 0
3  for i in xrange(N):
4     for j in xrange(i, N):
5        result += 1
6  return result

The result of the function equals 1/2 · ( N · ( N + 1)) (the explanation is in
    the exercises). When we omit the constants we get quadratic time
  complexity. Sometimes the complexity depends on more variables (see example
      below).

1.6 : Linear time - O(N + M).
1 def linear2(N, M):
2  result = 0
3  for i in xrange(N):
4     result += i
5  for j in xrange(M):
6     result += j
7  return result

Exponential and factorial time

It is worth knowing that there are other types of time complexity such as
factorial time O(N!) and exponential time O(2^N). Algorithms with such
complexities can solve problems only for very small values of N, because they
would take too long to execute for large values of N.

1.2. Time limit

Nowadays, an average computer can perform 10^8 operations in less than a
second. Sometimes we have the information we need about the expected time
complexity, but sometimes we do not (for example, Codility specifies the
    expected time complexity). The time limit set for online tests is usually
1 - 10 seconds. We can therefore estimate the expected complexity. During
contests, we are often given a limit on the size of data, and therefore we can
guess the time complexity within which the task should be solved. This is
usually a great convenience because we can look for a solution that works in a
specific complexity instead of worrying about a faster solution. For example,
      if:

- N <= 1 000 000, the expected time complexity is O(N) or O(N log N),
- N <= 10 000, the expected time complexity is O(N^2),
- N <= 500, the expected time complexity is O(N^3).

Of course, these limits are not precise. They are just approximations, and
will vary depending on the specific task.


1.3. Space complexity

Memory limits provide information about the expected space complexity. You can
estimate the number of variables that you can declare in your programs. In
short, if you have constant numbers of variables, you also have constant space
complexity: in Big-O notation this is O(1). If you need to declare array with
N elements, you have linear space complexity - O(N). 

More specifically, space complexity is the amount of memory needed to perform
the computation. It includes all the variables, both global and local, dynamic
pointer data-structures and, in the case of recursion, the contents of the
stack. Depending on the convention, input data may also be included. It is
more tricky to calculate than the time complexity because not all of these
variables and data-structures may be needed at the same time. Global variables
exist and occupy memory all the time; local variables (and additional
    information kept on the stack) will exist only during invocation of the
procedure. The existence of the dynamic pointer data-structures is explicitly
controlled by the program.


1.4. Exercise

Problem: You are given an integer N. Count the total of 1 + 2 + ...  + N.

Solution: The task can be solved in several ways. A first person, who knows
nothing about time complexity, may implement an algorithm in which the result
is incremented by 1:

1.7 : Solution A - time complexity O(n^2).
1 def solution_A(N):
2  result = 0
3  for i in xrange(N):              // for( i < N )
4     for j in xrange(i + 1):       //  for( j < i+1 )
5        result += 1
6  return result

A second person may increment the result respectively by 1, 2,..., N. This algorithm is much faster:


1.8 : Solution B - time complexity O(n).
1 def solution_B(N):
2  result = 0
3  for i in xrange(N):              // for( i < N )
4     result += (i + 1)
5  return result

But the third person's solution is even quicker. Let us write the sequence 1,
2,..., N and repeat

the same sequence underneath it, but in reverse order. Then just add the
numbers from the same columns:

1     2     3     ...      N-1   N
N     N-1   N-2   ...      2     1
N+1   N+1   N+1   ...      N+1   N+1

The result in each column is N + 1, so we can easily count the final result:

1.9 : Solution C - time complexity O(1).
1 def solution_C(N):
2  result = N * (N + 1) // 2
3  return result


={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-lesson-conunting-element

Chapter 2

Counting elements

A numerical sequence can be stored in an array in various ways. In the
standard approach, the consecutive numbers a0, a1 ,...,an-1 are usually put
into the corresponding consecutive indexes of the array:

A[0] = a0 A[1] = a1 ... A[n-1] = an-1

We can also store the data in a slightly different way, by making an array of
counters. Each number may be counted in the array by using an index that
corresponds to the 'value' of the given number.

a0 a1 a2 a3 a4 a5 
0  0  4  2  4  5

count [] 2 0 1 0 2 1
index    0 1 2 3 4 5    // values

Notice that we do not place elements directly into a cell; rather, we simply
count their occurrences. It is important that the array in which we count
elements is sufficiently large. If we know that all the elements are in the
set {0, 1,..., m}, then the array used for counting should be of size m + 1.

2.1 : Counting elements.
1 def counting(A, m):
2  n = len(A)
3  count = [0] * (m + 1)         // allocate array[m+1]
4  for k in xrange(n):
5     count[A[k]] += 1
6  return count

With this approach, the time complexity is O(n + m).

The limitation here may be available memory. Usually, we are not able to
create arrays of 10^9 integers, because this would require more than one
gigabyte of available memory. 

Counting the number of negative integers can be done in two ways. The first
method is to add some big number to each value: so that, all values would be
greater than or equal to zero. That is, we shift the representation of zero by
some arbitrary amount to accommodate all the negative numbers we need. In the
second method, we simply create a second array for counting negative numbers.

2.1. Exercises

Problem: You are given an integer m such that ( 1 <= m <= 1 000 000) and a
non-empty, zero- indexed array A of <n> integers: a0, a1,..., an-1 such that (
    0 <= ai <= m). Count the number of occurrences of the values 0, 1,..., m.

Solution: The simple way is to iterate through the whole array, searching for
each value 0, 1 ,..., m separately, but that produces a time complexity of
O(nm). The better approach is to count the elements in the array.

2.1. Exercise

Problem:
You are given an integer m ( 1 <= m <= 1000000) and two non-empty,
      zero-indexed arrays A and B of n integers, a0 , a1, ..., an-1 and b0,
      b1, ..., bn-1 respectively ( 0 <= ai, bi <= m). The goal is to check
        whether there is a swap operation which can be performed on these
        arrays in such a way that the sum of elements in array A equals the
        sum of elements in array B after the swap. By swap operation we mean
        picking one element from array A and one element from array B and
        exchanging them.

Solution O(n2): 
The simplest method is to swap every pair of elements and (then) calculate the
  totals. Using that approach gives us O(n3) time complexity. A better
  approach is to calculate the sums of elements at the beginning, and check
  only how the totals change during the swap operation.

2.2 : Swap the elements - O(n2).
1 def slow_solution(A, B, m):
2     n = len(A)
3     sum_a = sum(A)
4     sum_b = sum(B)
5     for i in xrange(n):
6        for j in xrange(n):
7           change = B[j] - A[i]
8           sum_a += change
9           sum_b -= change
10          if sum_a == sum_b:
11             return True
12          sum_a -= change
13          sum_b += change
14    return False

Solution O(n + m) :
The best approach is to count the elements of array A and calculate the
  difference d between the sums of the elements of array A and B. For every
  element of array B, we assume that we will swap it with some element from
  array A. The difference d tells us the value from array A that we are
  interested in swapping, because only one value will cause the two totals to
  be equal. The occurrence of this value can be found in constant time from
  the array used for counting.

2.3 : Swap the elements — O ( n + m) .
1 def fast_solution(A, B, m):
2     n = len(A)
3     sum_a = sum(A)
4     sum_b = sum(B)
5     d = sum_b - sum_a
6        if d % 2 == 1:
7           return False 
8     d //= 2
9     count = counting(A, m)
10    for i in xrange(n):
11       if 0 <= B[i] - d and B[i] - d <= m and count[B[i] - d] > 0:
12          return True
13    return False


={===========================================================================
*kt_dev_algo_0000* dev-algo-problem algo-repairman

On every morning, a repairman is assigned the jobs for the day. The particular
repairman we are interested in has taken charge of jobs located on a straight
road. For convenience, assume that the N jobs are given at locations xi
(i=1,...,N) on a straight line. He should start at one of these locations and
he must visit all the locations to complete the jobs. 

For a client requesting a job located at [xi], the time when he waits for a
repairman is assumed to be proportional to the distance [di] in which the
repairman travels to arrive at xi `from the starting location.` So, to reduce
the waiting times of clients, the repairman should minimize the sum of
distances di. 

Our problem is slightly more complicated because there is a weight [wi] for
the job at location xi which represents the importance of the client. Thus the
repairman should minimize the weighted sum of distances wi di. 

More precisely, given locations (or coordinates) xi and weights wi of points
on a line, the repairman starts at one of these points, say s, and visits all
the points at least once. Let di be the distance in which the repairman
travels to visit a point of location xi for the first time. 

We may find the moving route of the repairman that minimizes 

SUMiWiDi (math summation where i means input)

<problem>
The minimum value is denoted by T(s) for a specific starting point.
Consequently, we can compute T(s) for each starting location s. The problem is
to find a starting location [s] such that T(s) is minimized over all the
locations and to print the minimum value. 

For example, given points on a line, as in Figure 1, if the repairman starts
at location 6, then the red arrows represent a route to minimize the total
weighted distance and the minimum value is 180.


Wi:     1       2       10 3  5          1 
 -------*-------*-------*--*--*----------*--------
Xi:     1       6       12 13 14         24
                ------------------------->
        <---------------------------------

180 = 2*0 + 10*6 + 3*(6+1) + 5*(6+1+1) + 1*(6+1+1+10) + 1*(6+1+1+10+23)

// distance are measured from the starting location so adds all such as 6+1+1.

But if the repairman starts at location 12 as in Figure 2, then a route
minimizing the total `weighted distance` is represented by the red arrows
below and the minimum value is `86`. Also this is the minimum of T(s) over all
the locations s. 

// 86 = 1*3 + 2*5 + (2+8)*2 + (2+8+5)*1 + (2+8+5+23)*1

Wi:     1       2       10 3  5          1 
 -------*-------*-------*--*--*----------*--------
Xi:     1       6       12 13 14         24
                        ------> 
        <----------------------
        --------------------------------->


Time Limit: 
1 second for 20 cases. If your program exceeds this time limit, the answers
that have been already printed are ignored and the score becomes 0.

So, it may be better to print a wrong answer when a specific test case might
cause your program to exceed the time limit. One guide for the time limit
excess would be the size of the input.

[Input]

There can be more than one test case in the input file. The first line has C,
the # of test cases. Then the totally C test cases are provided in the
  following lines (1 <= C <= 20). In each test case, the first line contains
  one integer N representing the number of points on a line (2<= N <=1,000).
  In the second line, the N integers xi representing the locations of the
  points are given (1 <= xi <= 1,000,000). These integers are distinct and
  given in increasing order. In the third line, the N integers wi representing
  the weights of the points are given (1 <= wi <= 1,000).

[Output]

The output for each test case should contain two lines. For the T-th test
  case, "Case #T" should be printed out in the first line. The second line
  should contain the integer, representing the minimum value for the starting
    location s to minimize T(s). This integer may be so large that it cannot
    be stored in 4-byte integer variables. So you can use 64-bit integer (long
        long type) variables. 

[I/O Example]
Input
2                             // There are 2 test cases
6                             // Starting Case 1
1 6 12 13 14 24               // xi
1 2 10 3 5 1                  // wi
15                            // Starting Case 2
5 34 45 49 51 52 53 56 63 81 84 88 93 99 106
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1

Output
Case #1
86
Case #2
630


{winner-code} 
This file should be .cpp to build and run since it mixes C and CPP.

#include <stdio.h>
#include <map>
#include <vector>
#include <set>

using namespace std;

typedef long long lint;

int T, N;

int xi[1000];
int wi[1000];

#define abs(a) (((a) > 0)?(a):-(a))
#define min(a,b) (((a) < (b))?(a):(b))

// {Q} does the order matter? for example, abs(s-e) or abs(e-s)
#define TIME(s,e) (abs(xi[e] - xi[s]))

lint sum(int s, int e, lint time = 0);
lint sum(int s1, int s2, int s3, lint time = 0);

lint sum(int s, int e, lint time)
{
  if(s == e)
  {
    return 0;
  }
  int dx = ((e > s)? 1:-1);
  lint res = 0;

  // [1] 
  // here time is sum of absolute distance of between points and res is the sum of weighted
  // distance.
  //
  // for s < e case
  // s == 0  : i == 1,   dx == 1
  //         TIME(1,0), abs(0-1) res = time*wi[1];
  //
  // for s > e case
  // s == N-1: i == N-2, dx == -1 
  //           TIME(N-2, N-1), res = time*wi[N-2]
  //
  // this is a code to implement the summation above but it is cool to use one single function for
  // both direction. This dx variable is direction.
  //
  // ->  s     e: abs(e-s), abs(1-0), abs(1-0)*w[1]
  //
  //     0th   1th    2th    n-1 : N array
  // ----*-----*------*------*---
  //
  //               <-  e     s: abs(e-s), abs((n-2)-(n-1)), abs((n-2)-(n-1))*w[n-2]
  //
  // [2] no exit condition in for loop
  //
  for(int i = s + dx; ; i+=dx)
  {
    time += TIME(i, i - dx);
    res += time*(lint)wi[i];
    if( i == e )
    {
      return res;
    }
  }

  return res;
}

lint sum(int s1, int s2, int s3, lint time)
{
	// (s2 - s1)*(s3 - s1) < 0
	lint d1 = sum(s1, s2, time);
	//lint d2 = sum(s2, s3);
	lint d3 = sum (s1, s3, time + 2*TIME(s2, s1));

	return d1 + d3;
}

pair<lint, lint> search(int s, int e)
{
  lint dMin = sum(s, e);
  int ind = s;

  if(s == e)
  {
    return make_pair(0, 0);
  }
  int dx = ((e > s)? 1:-1);

  lint sumT = 0;
  lint time = 0;

  for(int i = s + dx; i != e; i += dx)
  {
    lint res = sum(i, s, e);

    if(res < dMin || res == dMin && abs(i - s) > abs(ind - s))
    {
      dMin = res;
      ind = i;
    }
  }

  if(ind != s)
  {
    pair<lint, lint> res = search(ind, s);	
    sumT += res.first;
    time += res.second + TIME(ind, s);		

    //printf("%d->%d->%d\n", ind, s, e);
  }

  sumT += sum(ind, e, time);
  time += TIME(ind, e);

  return make_pair(sumT, time);
}

int main()
{
  scanf("%d", &T);

  for(int t = 0; t < T; ++ t)
  {
    scanf("%d", &N);

    for(int n = 0; n < N; ++ n)
    {
      scanf("%d", xi + n); 
    }

    for(int n = 0; n < N; ++ n)
    {
      scanf("%d", wi + n); 
    }

    pair<lint, lint> res1 = search(0, N - 1);
    pair<lint, lint> res2 = search(N - 1, 0);

    printf("Case #%d\n", t + 1);
    printf("%lli\n", min(res1.first, res2.first));
  }
}


={===========================================================================
*kt_dev_quiz_300* q-code-rally

https://www.ibm.com/developerworks/community/blogs/code-rally/entry/creating_a_car_ai?lang=en

The simplest agent AI you can create will look like the following. This is a
very basic AI - it should do well on the space track but 

* it doesn't slow down for corners, 
* it doesn't limit its top speed or try to avoid obstacles

so you will want to do more than this.


Questions
=========
1. CheckPoint, Position structure. Seems to be the same.

2. getCheckPoint() always returns CP which is nearest and is not visited yet?
Seems to be the case but confusing due to this:

These checkpoints must be passed through in order for a car to complete a lap.
If you do miss a checkpoint and go through other checkpoints afterwards don't
worry - you just need to get your vehicle to go through the checkpoint it missed
and to continue on from there.

  * If needs to figure out nearest and valid CP then put those in the map and
    find the next every time? complicated.
  * If don't need to figure out, then simply call this.

3. What are other API available to use?


@Override

// onCheckpointUpdated - this is called when your vehicle goes through the next
// checkpoint in the race - you are given the checkpoint you passed through. If
// you want to find the `next-checkpoint` to target then call
// getCar().getCheckpoint();
//
// When the car passes through a checkpoint then it will then set its target to
// the next checkpoint in the race. 

public void onCheckpointUpdated(CheckPoint cp) {
  // getCar().setTarget(
  //    AIUtils.getClosestLane(getCar().getCheckpoint(), getCar().getPosition()));

  // `turning`
  //
  // A simple way to check if your car is going to need to turn `before` the
  // next checkpoint is to use 
  //
  // getCar().getCheckpoint().getIntersectionPoint
  //    (getCar().getRotation(), getCar().getPosition());
  // 
  // this will either return a position that is where your car will cross the
  // checkpoint if it does not turn, or it will return null if you car needs to
  // turn.
  //
  // If you detect null then you can choose to slow down and you can also detect
  // if you are now facing the checkpoint to stop slowing down and to
  // accelerate.

  int Position = getCar().getCheckpoint().getIntersectionPoint
                    (getCar().getRotation(), getCar().getPosition());

  // `do-not-need-to-turn`
  // you can also detect if you are now facing the checkpoint to stop slowing
  // down and to accelerate.

  if (Position) {

    // `set-target`
    // How cars steer. You do not directly control steering of the car - when
    // you want to make the car turn you set a "target" and the car will turn to
    // face that target (or, if the target is too close and you have a large
    // turning circle, circle the target until it can pass through it). 

    // setTarget(to, from);

    getCar().setTarget
      (AIUtils.getClosestLane(Position, getCar().getPosition()));

  // `need-to-turn`
  // If you detect null then you can choose to slow down
  // note: null means there is no intersection between them?
  } else {
    
    // `set-acceleration-but-not-speed`
    // Controlling a car's speed. You can set your acceleration and breaking
    // percentages to control the car's acceleration/deceleration but you cannot
    // set a speed for the car to travel at. You can detect how fast a car is
    // going and set your acceleration to 0 when you reach that speed if you do
    // want to control a car's speed more directly.

    // decrease speed and make a turn
    getCar().setAccelerationPercent(20);
    getCar().setTarget(
        AIUtils.getClosestLane(getCar().getCheckpoint(), getCar().getPosition()));
  }
}

@Override

// onRaceStart - this is called when the race begins. Tip: accelerate and set a
// target for the car otherwise it will be a long race.
//
// When the race starts the car sets its acceleration to 100% and aims to drive
// through the center of the next checkpoint. 

public void onRaceStart() {
    getCar().setAccelerationPercent(100);
    getCar().setTarget(
        AIUtils.getClosestLane(getCar().getCheckpoint(), getCar().getPosition()));
}

@Override

// onObstacleCollision - this is called when your vehicle crashes into or is
// crashed into by a non-vehicle object. You will be given a handle on the
// object that you collided with in case it bounced ahead of you and you want
// `to-avoid` it.
//
// onObstacleInProximity - this is called if you get close to a non-vehicle
// object in the race. You are given a handle on the object so you can find its
// location and try `to-avoid` it.
//
// onOpponentInProximity - this is called when a competing vehicle gets close
// to yours - you will be given a handle on that vehicle so you can find out
// its position in case you want `to-avoid` it.

public void onXXXX() {
  // note: How to avoid?
  // As with getIntersectionPoint(), any API to see if it will collide with and
  // API to move a car?
}

// onCarCollision - this is called when your vehicle crashes or is crashed into
// by another vehicle. You will be given the object that represents the vehicle
// you crashed with in case you want to exact revenge and crash back into it.
// note: Don't seem to be necessary

// onOffTrack - this gets called when your vehicle goes off the track. When off
// the track you will have less traction and obviously won't pass through any
// checkpoints, but there is no other penalty for this.
//
// onStalled - this is called if your car doesn't move for 6 seconds. Tip: make
// your car move if this is called.

public void onXXXX() {
  getCar().setAccelerationPercent(100);
  getCar().setTarget(
    AIUtils.getClosestLane(getCar().getCheckpoint(), getCar().getPosition()));
}

// onTimeStep - this is called every 100ms in the race so you can put code in
// here to control your car's top speed, check if you have stopped moving and
// do whatever else you want it to.
//
// By using "getCar().getVelocity().normalize();" you will be given the speed of
// your car in MPH - this can be useful if you want to limit your car's speed as
// when you detect the speed is at or above your limit you can set your
// acceleration to 0 and even apply breaks to slow down. 
// 
// You can also use it to check if your car is going too slowly where you can
// stop applying the breaks and start accelerating again. 
//
// note: to check if it's stopped and set speed and target since onStalled()
// gets called after 6 sec?

// init - this method is called every time you start/update your AI - if you
// update your AI while a race is running onRaceStart will not be called as the
// race has already started, so it can be advisable to use this init method to
// make sure your AI is fully initialized whenever it is updated (as an update
// will lose all stateful information in the AI).


Basics
=======
* You can get a list of all of the checkpoints in the race by calling
  "getTrack().getCheckpoints();" - this can be useful if you want to see all of
  the checkpoints for calculating a good racing line. 


# ============================================================================
#{ ALGORITHM
==============================================================================
*kt_dev_algo_000*	sentinel

{hedge-or-sentinel}

From {ref-001}. A hedge or sentinel is an extra entry put into a data structure so that boundary
conditions need not be treated as a [special-case]. For example of this life game, need to check if
it is in the array when counting neighbours. Can avoid complicated checks by having extra lows and
columns:

arr[MAXROW+2][MAXCOL+2];

0 1 2 3 .... MAX MAX+1
1 X
2
3
.
.
MAX
MAX+1

Where all operation performs in range of [1, MAX] dimension and no need to boundary check when doing
for X.


={============================================================================
*kt_dev_algo_0000* dev-algo-adt

{abstract-data-type} ADT
A spearation between the logical structure of our data and its implementation
will help us in designing problems. If there is no speration, for example, can
implement reverse polish calculator by replacing stack code with manipulating
array and count directly. Problem?

* How to change it to list implementation from array?

* Use unnecessary effort verifying the details of codes rather than being able
  to concentrate on logic to solve problem, that is, the ways in which the
  stack is being used. This is programmer's failure to recognize the general
  concept of stack and to distinguish between this and implementation.


note:
Use this reverse polish calculator to see if someone can use data type such as
stack to solve this problems?


<encapsulation> 
In general, data is said to be 'encapsulated' if it can only be accessed by a
controlled set of functions. Without encapsulation, the operation on a data
structure almost always depend on a [precondition] of data members.

The mathematical definition of type is:
A 'type' is a set, and the elements of the set are called the 'values' of the
type. 

ADT has two parts: First is a description of the way in which the components
are related to each other, and second is a statement of the operation. ADT is
logical data structure such as list or stack and physical implementation can
vary as there are many different implementation of stack.

<stages-of-refinement>
<- concept and algorithm ------->
math      ADT              data           implementation                application
concept                    structure 

sequence  general list
          stack            ...
          queue            physical                                     line of people

                           linear         array

                           circular       array with counter            airport simulation
                                          array with flag
                                          array with skipped entry

                           linked         simple with two pointers
                                          circular with tail pointers
                                          array with two cursors


={============================================================================
*kt_dev_algo_0000* dev-algo-stack

A algo-stack is a version of a 'list' that is particularly useful in
applications involving a `reverse`.  

{algo-stack-contiguous}
The push and pop (insertion and deletion) happens at the the 'end' of storage
and use index. No overhead of moving elements.

// class Stack
// {
//   public:
//     void create();
//     void clear();
//     bool empty();
//     bool full();
//     int size();
//
//     // as push_back();
//     void push(ListEntry const& entry);
//     void pop();
//     ListEntry top();
//
//     // as traverse()
//     std::vector<ListEntry> snap();
// };

o Use 'top' name for a easy reading
o Can have differnt implementation depending on how to define 'empty' and
  value of top.

  when use 0th and use top as 'next' index to insert which is for 1-3 examples.

  0 1 2 3 4 5 [6], init 0, and in push, entry[top] and top++;

  this seems to be norm since ansic use the same:

  *p++ = val;    // push val onto stack
  val = *--p;    // pop top of stack into val

o Examples do not have clear interface of top or pop when stack is empty. C++
  STL also do not say what will happen to call top when stack is empty. <?>

namespace algo_stack_contiguous
{
  struct ListEntry
  {
    explicit ListEntry(int row = 0, int col = 0) noexcept 
      : row_(row), col_(col) {}

    int row_{};
    int col_{};
  };

  bool operator==(ListEntry const& lhs, ListEntry const& rhs)
  {
    return (lhs.row_ == rhs.row_) && (lhs.col_ == rhs.col_) ? true : false;
  }

  bool operator!=(ListEntry const& lhs, ListEntry const& rhs)
  {
    return !(lhs == rhs);
  }

  class Stack
  {
    public:
      void create()
      { top_ = 0; }

      void clear() 
      { top_ = 0;}

      bool empty()
      { return top_ == 0 ? true : false; }

      bool full()
      { return top_ >= MAX_ENTRY ? true : false; }

      int size()
      { return top_; }

      // as push_back();
      void push(ListEntry const& entry)
      {
        if (full())
          throw runtime_error("list is full");

        coll_[top_++] = entry;
      }

      // is it okay not to have empty check?
      void pop()
      {
        --top_;
      }

      ListEntry top()
      {
        if (empty())
          throw runtime_error("list is empty");

        return coll_[top_ - 1];
      }

      std::vector<ListEntry> snap()
      {
        std::vector<ListEntry> coll;

        for (int i = 0; i < top_; ++i)
          coll.push_back(coll_[i]);

        return coll;
      }

    private:

      // cxx-static
      // error: invalid use of non-static data member ‘algo_list_contiguous::List::MAX_ENTRY’
      // const int MAX_ENTRY{5};

      static const int MAX_ENTRY{5};

      // top_ is next positon to push
      int top_;

      ListEntry coll_[MAX_ENTRY];
  };
}

TEST(AlgoStack, ContiguousSimple)
{
  using namespace algo_stack_contiguous;

  std::vector<ListEntry> values{
      ListEntry(1,2), 
      ListEntry(2,3), 
      ListEntry(3,4), 
      ListEntry(4,5), 
      ListEntry(5,6)
  };

  Stack coll;
  coll.create();

  for (auto &e : values)
    coll.push(e);

  EXPECT_THAT(coll.size(), 5);
  EXPECT_THROW(coll.push(ListEntry(6,7)), runtime_error); 

  EXPECT_THAT(coll.top(), ListEntry(5,6));

  coll.pop();
  coll.pop();
  coll.pop();

  EXPECT_THAT(coll.size(), 2);

  // requires cxx-operator-overload
  auto expected{
    ListEntry(1,2), 
    ListEntry(2,3)
  };

  EXPECT_THAT(coll.snap(), expected);
}


{case-app-one} reverse-polish-calculator
We shall write '?' to denote an instruction to read an operand from a user and push it onto the
stack; + , -, * , and / represent arithmetic operations which pops data; and = is an instruction to
print the top of the stack (but not pop it off). Further, we write a, b, c, and d to denote
numerical values such as 3.14 or -7. 

? a ? b + =    // ? 1 ? 2 + =

mean read and store the numbers a and b, calculate and store their sum, and then print the sum. 

? a ? b + ? c ? d + * = 

request four numerical operands, and the result printed is the value of (a + b) * (c + d).

? a ? b ? c - = * ? d + = 

mean push the numbers a, b, c onto the stack, replace the pair b, c by b - c and print its value,
calculate a * (b - c), push d onto the stack, and finally calculate and print (a * (b - c)) + d. 

The advantage of a reverse polish calculator is that any expression, no matter how complicated, can
be specified without the use of parentheses.

<example>
#include <iostream>
#include <stack>

using namespace std;

stack<int> st;

char get_command()
{
  char command = 0;
  bool wait = true;

  while( wait )
  {
    cin >> command;
    command = tolower(command);

    if( command == '?' || command == '=' || command == '-' ||
        command == '+' || command == '*' || command == '/' ||
        command == 'q' )
      wait = false;
    else
      cout << "please enter a valid command : " << endl;
  }

  return command;
}

int do_command( char command )
{
  int p, q;

  switch(command)
  {
    case '?':
      // cout << "enter a int number :" << flush;
      cin >> p;
      st.push( p );
      break;

    case '=':
      if( !st.empty() )
        cout << "result: " << st.top() << endl;
        cout << "select command and press enter: ";
      break;

    case '-':
      if( !st.empty() )
      {
        p = st.top(); st.pop();
        
        if( !st.empty() )
        {
          q = st.top();
          st.pop();

          st.push( p-q );
        }
        else
        {
          cout << "stack has just one entry." << endl;
          st.push(p);
        }
      }
      break;

    case '+':
      if( !st.empty() )
      {
        p = st.top(); st.pop();
        
        if( !st.empty() )
        {
          q = st.top();
          st.pop();

          st.push( p+q );
        }
        else
        {
          cout << "stack has just one entry." << endl;
          st.push(p);
        }
      }
      break;

    case 'q':
      cout << "calc finished" << endl;
      return false;
  }

  return true;
}

int main()
{
  cout << "select command and press enter: ";

  while( do_command( get_command() ) )
    ;
}

This works fine but can be re-written using cpp strings.

<2> from ansic, p 74. no read(?) operator

1 2 - 4 5 + * means ( 1 - 2 ) * ( 4 + 5 )

while( next operator or operand is not end-of-file indicator )
  if (number)
   push it
  else if (operator)
   pop operands
   do operation
   push result
  else if (newline)
   pop and print top of stack
  else
   error

#include <stdio.h>
#include <stdlib.h> 

#define MAXOP  100
#define NUMBER '0'

int getop( char [] );
void push( double );          // see double
double pop( void );

main()
{
  int type;
  double op2;
  char sp[MAXOP];

  while( (type = getop(s)) != EOF )
  {
    switch( type )
    {
      case NUMBER:
        push( atof(s) );
        break;

      case '+':
        push( pop() + pop() );
        break;

      case '*':
        push( pop() * pop() );
        break;

      case '-':                  // note: eval-order matters
        op2 = pop();
        push( pop() - op2 );
        break;

      case '/':
        op2 = pop();

        if( op2 != 0.0 )
          push( pop() / op2 );
        else
          printf("error: zero divisor\n");

        break;

      case '\n':
        printf("\t%.8g\n", pop());
        break;

      default:
        printf("error: unknown command %s\n", s );
        break;
    }
  } // while end
  return 0;
}

The + and * are commutative operators, the order in which the popped operands are combined is
irrelevant, but for - and / the left and right operands must be distinguished.

push( pop() - pop () );

This is wrong since the order in which the two calls of pop are evaluated is not 'defined'.

// stack

#define MAXVAL 100

int sp = 0;             // 'next' free stack position
double val[MAXVAL];

void push( double f )
{
  if( sp < MAXVAL )
    val[sp++] = f;
  else
    printf("error: stack full, can't push %g\n", f);
}

double pop(void)
{
  if( sp > 0 )
    return val[--sp];
  else
  {
    printf("error: stack empty\n");
    return 0.0;
  }
}

// getop: get next operator or numeric operand. if not return a string.

int getch(void);
void ungetch(int);

int getop( char s[] )      // s used only for numbers
{
  int i, c;

  while( (s[0] = c = getch()) == ' ' || c == '\t' )
    ;

  s[1] = '\0';    // this is for when it's not a number to print out a string

  if( !isdigit(c) && c != '.' )
    return c;     // not a number

  i = 0;
  if( isdigit(c) )   // c is read already and collect integer part
    while( isdigit( s[++i] = c = getch()) )
      ;

  if( c == '.' )     // c is read already and collect fraction part
    while( isdigit( s[++i] = c = getch()) )
      ;

  s[i] = '\0';

  if( c != EOF )
    ungetch(c);

  return NUMBER;
}

#define BUFSIZE 100

char buf[BUFSIZE];
int bufp = 0;        // next free position in buf

int getch(void)
{
  return (bufp > 0) ? buf[--bufp] : getchar();
}

void upgetch(int c)
{
  if( bufp >= BUFSIZE )
    printf("ungetch: too many characters\n");
  else
    buf[bufp++] = c;
}

<read-ahead>
It is often the case that a program cannot determine that it has read enough input until it has read
too much. Once instance is collecting the characters that make up a number: until the first
non-digit is seen, the number is not complete. But the program has read one character too far, a
character that it is not perpared for. The problem would be solved if it were possible to "un-read"
the unwanted character.

Why need? To have a token from a stream and to handle newline.

input: "4 2 *NL"
        ^^
          ^^
            ^^
Here a char which is not digit or "." is a seperator and if not ungetch this cannot handle NL since
it is already gone. This is how getop works.

<exercise>
From ansic, p79. exercise 4-3. Given the basic framework, it's straightforward to extend the
calculator. Add the modulus ( % ) operator and provisions for negative numbers.

http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_4:Exercise_3
Adding the modulus is easily done by another case in main and using the fmod function. The standard
library has been mentioned at this point so it should be valid to use this for type 0 compliance.
math.h should be added to the list of #includes for fmod. 

switch(type)
{
  /* other cases snipped for brevity */
  case '%':
    op2 = pop();
    if(op2)
      push(fmod(pop(), op2));
    else
      printf("\nError: Division by zero!");
    break;
    
  OR
  // Answer: Supporting modulus is indeed rather easy. The modulus operator
  // divides the first operand by the second and returns the remainder, and C
  // supports this out of the box, so there's no need to implement much math.
  // Note that the modulus operator does integer division to get its remainder.
  // Doing a "proper" modulus operator would require more work, and floats can
  // be tricky. I might implement this sometime. For now, I typecasted.

  case '%':
    op2 = pop();
    if (op2 != 0.0) {
      push((int)pop() % (int)op2);
    } else {
      printf("Error: Cannot modulo by zero.\n");
    }
    break;
}

// to support negative
int getop( char s[] )      // s used only for numbers
{
  int i, c;

  while( (s[0] = c = getch()) == ' ' || c == '\t' )
    ;

  s[1] = '\0';             // this is not necessary

  if( !isdigit(c) && c != '.' && c != '-' )  // <changed> to pass '-' (minus) through
    return c;     // not a number

  i = 0;
  if( isdigit(c) || c == '-' )   // <changed> c is read already and collect integer part
    while( isdigit( s[++i] = c = getch()) )
      ;

  if( c == '.' )     // c is read already and collect fraction part
    while( isdigit( s[++i] = c = getch()) )
      ;

  s[i] = '\0';

  if( c != EOF )
    ungetch(c);

  return NUMBER;
}


<nested-parentheses>
http://ilovefoobar.wordpress.com/tag/codility/
Nested Parentheses where you will write a code to find if parentheses are properly nested on not.
If your have brackets like this ” ( ) ” or ” ( ( ) ) ( ) ” then it means that it is properly nested
but if you have bracket like this ” ( ( ) ” or ” ) ) ) ( ( ( ” then it means that its not properly
nested. And I was supposed to handle String of length 200,000 characters.

1. Remove all spaces from String.

2. Count the length of String, and find out if its odd or even number. If string is odd number then
it is not properly nested.  
<KT> 1 and 2 are input check which is good. But don't need these in the c approach.

3. If String is even number then run a loop and remove all matching ” () ” character from the
string.  

4. Now check the length of String, if length is zero then String is properly nested else its not.
<KT> This is the same check as size of stack in the c approach.

class Solution
{
  public int nesting ( String S )
  {
    int result = 1;

    if(S.contains(" "))
    {
        S = S.replaceAll(" ","");
    }

    while(S.contains("()"))
    {
        S = S.replaceAll("\\(\\)", "");
    }

    if(S.length() != 0)
    {
        result = 0;
    }

    return result;
  }
}


={============================================================================
*kt_dev_algo_0000* dev-algo-stack-problem

// algo-leetcode-6
/*
20. Valid Parentheses, Easy

Given a string containing just the characters '(', ')', '{', '}', '[' and ']',
determine if the input string is valid.

An input string is valid if:

Open brackets must be closed by the same type of brackets.
Open brackets must be closed in the correct order.
Note that an empty string is also considered valid.

Example 1:
Input: "()"
Output: true

Example 2:
Input: "()[]{}"
Output: true

Example 3:
Input: "(]"
Output: false

Example 4:
Input: "([)]"
Output: false

Example 5:
Input: "{[]}"
Output: true
*/

namespace leetcode_easy_006
{
  bool ValidParentheses_01(string input)
  {
    std::stack<char> coll;

    for (const auto e : input)
    {
      switch (e)
      {
        case '(':
        case '[':
        case '{':
          // cout << "push: " << e << endl;
          coll.push(e);
          break;

        case ']':

          // cout << "]: " << e << endl;

          if (coll.empty())
            return false;
          else if (!coll.empty() && ('[' != coll.top()))
            return false;
          else
            coll.pop();

          break;

        case ')':

          // cout << "): " << e << endl;

          if (coll.empty())
            return false;
          else if (!coll.empty() && ('(' != coll.top()))
            return false;
          else
            coll.pop();

          break;

        case '}':

          // cout << "}: " << e << endl;

          if (coll.empty())
            return false;
          else if (!coll.empty() && ('{' != coll.top()))
            return false;
          else
            coll.pop();

          break;

          // for other chars
        default:
          break;
      } // switch
    } // for

    // should be empty if all matches up
    return coll.empty() ? true : false;
  }

  // algo-stack
  //
  // Runtime: 4 ms, faster than 100.00% of C++ online submissions for Valid
  // Parentheses.  
  //
  // Memory Usage: 8.9 MB, less than 81.58% of C++ online submissions for Valid
  // Parentheses.

  bool ValidParentheses_02(string input)
  {
    std::stack<char> coll;

    for (const auto e : input)
    {
      if (e == '(' || e == '[' || e == '{')
        coll.push(e);

      if (e == ')' || e == ']' || e == '}')
      {
        if (coll.empty())
          return false;
        else
        {
          // do not need to keep item since will return as soon as see
          // not-match.

          auto prev = coll.top();
          coll.pop();

          auto match = (prev == '(' && e == ')') 
            || (prev == '[' && e == ']')
            || (prev == '{' && e == '}');

          if (!match)
            return false;
        }
      }

      // do not handle other chars

    } // for

    // should be empty if all matches up
    return coll.empty() ? true : false;
  }
} // namespace

TEST(LeetCode, Easy_006_ValidParentheses)
{
  using namespace leetcode_easy_006;

  {
    const auto func = ValidParentheses_01;

    EXPECT_THAT(func("()"), true);
    EXPECT_THAT(func("()[]{}"), true);
    EXPECT_THAT(func("(]"), false);
    EXPECT_THAT(func("([)]"), false);
    EXPECT_THAT(func("{[]}"), true);
    EXPECT_THAT(func(""), true);
    EXPECT_THAT(func("([{}"), false);

    EXPECT_THAT(func("abc(defg{hijk}lmn)opq"), true);
  }

  {
    const auto func = ValidParentheses_02;

    EXPECT_THAT(func("()"), true);
    EXPECT_THAT(func("()[]{}"), true);
    EXPECT_THAT(func("(]"), false);
    EXPECT_THAT(func("([)]"), false);
    EXPECT_THAT(func("{[]}"), true);
    EXPECT_THAT(func(""), true);
    EXPECT_THAT(func("([{}"), false);

    EXPECT_THAT(func("abc(defg{hijk}lmn)opq"), true);

    EXPECT_THAT(func("{a = (1 + v(b[3 + c[4]]))"), false);
    EXPECT_THAT(func("{ a = (b[0) + 1]; }"), false);
  }
}


={============================================================================
*kt_dev_algo_0000* dev-algo-list

<algo-list-adt>
A `simple-list` of elements of type T is a finite sequence of elements of T
together with the following operations.

o create the list, leaving it empty.
o determine whether the list is empty or not.
o determine whether the list is full or not.
o find the size of the list.
o add a new entry at the 'end' of the list, provided the list is not full.
o traverse the list, performing a given operation with each entry.
o clear the list to make it empty.

A list is dynamic data-structure because its size can change, while an array
is a static data-structure because it has a fixed size.


{algo-list-contiguous-simple}

The *algo-stack* and `simple-list` are essentially the same implementation
in terms of contiguous and linked implementation.

o ListEntry can be any type.  

o No remove() to remove entry at random position since it's expensive
  operation as with other contiguous implementation; contiguous stack.

// single

class List
{
  public:
    void clear();
    bool empty();
    bool full();
    int size();

    // as push_back()
    void push(ListEntry const& entry);

    // as traverse()
    std::vector<ListEntry> snap();
};

namespace algo_list_contiguous
{
  struct ListEntry
  {
    explicit ListEntry(int row = 0, int col = 0) noexcept 
      : row_(row), col_(col) {}

    int row_{};
    int col_{};
  };

  // cxx-operator-overload
  bool operator==(ListEntry const& lhs, ListEntry const& rhs)
  {
    return (lhs.row_ == rhs.row_) && (lhs.col_ == rhs.col_) ? true : false;
  }

  bool operator!=(ListEntry const& lhs, ListEntry const& rhs)
  {
    return !(lhs == rhs);
  }

  class List
  {
    public:
      explicit List() : count_(0)
      {}

      void clear() 
      { count_ = 0;}

      bool empty()
      { return count_ == 0 ? true : false; }

      bool full()
      { return count_ >= MAX_ENTRY ? true : false; }

      int size()
      { return count_; }

      // as push_back();
      void push(ListEntry const& entry)
      {
        if (full())
          throw runtime_error("list is full");

        coll_[count_++] = entry;
      }

      std::vector<ListEntry> snap()
      {
        std::vector<ListEntry> coll;

        for (int i = 0; i < count_; ++i)
          coll.push_back(coll_[i]);

        return coll;
      }

    private:

      // cxx-static
      // error: invalid use of non-static data member ‘algo_list_contiguous::List::MAX_ENTRY’
      // const int MAX_ENTRY{5};

      static const int MAX_ENTRY{5};

      // count_ should be [0, 4] or [1, 5]? choose [1,5]
      int count_;

      ListEntry coll_[MAX_ENTRY];
  };
}

TEST(AlgoList, ContiguousSimple)
{
  using namespace algo_list_contiguous;

  std::vector<ListEntry> values{
      ListEntry(1,2), 
      ListEntry(2,3), 
      ListEntry(3,4), 
      ListEntry(4,5), 
      ListEntry(5,6)
  };

  List coll;

  for (auto &e : values)
    coll.push(e);

  EXPECT_THAT(coll.size(), 5);

  // requires cxx-operator-overload
  EXPECT_THAT(coll.snap(), values);

  EXPECT_THROW(coll.push(ListEntry(6,7)), runtime_error); 
}


{algo-list-linked-simple}

A problem that never arises with contiguous. How do we find the beginning of
the list? `header` is a pointer variable that locates the beginning of the
list as *algo-stack-linked*

If it has remove function, then less expansive than contiguous implementation
since it is linked but need to search through from header to find the node to
remove.

// single
//
// class List
// {
//   public:
//     void clear();
//     bool empty();
//     int size();
//
//     // as push_back();
//     void push(ListEntry const& entry);
//
//     // as traverse()
//     std::vector<ListEntry> snap();
// };

namespace algo_list_linked
{
  // when node and entry are in a single structure and these can be different
  // structure such as ListEntry and ListNode

  struct ListEntry
  {
    explicit ListEntry(int row = 0, int col = 0) noexcept 
      : row_(row), col_(col), next_(nullptr) 
    {}

    int row_{};
    int col_{};

    ListEntry* next_;
  };

  // cxx-operator-overload
  bool operator==(ListEntry const& lhs, ListEntry const& rhs)
  {
    return (lhs.row_ == rhs.row_) && (lhs.col_ == rhs.col_) ? true : false;
  }

  bool operator!=(ListEntry const& lhs, ListEntry const& rhs)
  {
    return !(lhs == rhs);
  }

  class List
  {
    public:
      explicit List() noexcept
        : head_(nullptr)
        {}

      bool emptry()
      { return count_ == 0 ? true : false; }

      int size()
      { return count_; }

      // push_back()
      void push_old(ListEntry const& entry)
      {
        if (!head_)
          head_ = new ListEntry(entry);
        else
        {
          ListEntry* run = head_;

          // unlike clear(), snap(), run shall be before end() so that can
          // insert new one. Hence check run->next

          while (run->next_)
            run = run->next_;

          run->next_ = new ListEntry(entry);
        }
        
        ++count_;
      }

      // push_back()
      void push(ListEntry const& entry)
      {
        ListEntry* run{};

        // find node for insertion *algo-list-find-end*
        // works both when head_ is null and is not null

        for (run = head_; run && run->next_; run = run->next_)
          ;

        // first item
        if (!run)
          head_ = new ListEntry(entry);
        else
          run->next_ = new ListEntry(entry);

        ++count_;
      }

      void clear()
      {
        ListEntry* run = head_;
        ListEntry* prev{};

        while (run)
        {
          prev = run;
          run = run->next_;
          free(prev);
          --count_;
        }

        head_ = run;
      }

      std::vector<ListEntry> snap()
      {
        ListEntry* run = head_;
        std::vector<ListEntry> coll;

        while (run)
        {
          // ok as well
          // coll.push_back(ListEntry(*run));
          coll.push_back(*run);
          run = run->next_;
        }

        return coll;
      }

    private:
      int count_{};

      // can use ListEntry head_; which changes member implementation

      ListEntry* head_;
  };

} // namespace


TEST(AlgoList, LinkedSimple)
{
  using namespace algo_list_linked;

  std::vector<ListEntry> values{
    ListEntry(1,2), 
    ListEntry(2,3), 
    ListEntry(3,4), 
    ListEntry(4,5), 
    ListEntry(5,6)
  };

  List coll;

  for (auto &e : values)
    coll.push(e);

  EXPECT_THAT(coll.size(), 5);

  coll.push(ListEntry(6,7));
  EXPECT_THAT(coll.size(), 6);

  // requires cxx-operator-overload
  std::vector<ListEntry> expected{
    ListEntry(1,2), 
    ListEntry(2,3),
    ListEntry(3,4),
    ListEntry(4,5),
    ListEntry(5,6),
    ListEntry(6,7)
  };

  EXPECT_THAT(coll.snap(), expected);

  coll.clear();
  EXPECT_THAT(coll.size(), 0);
}


{algo-list-linked-simple-reverse}
http://www.geeksforgeeks.org/write-a-function-to-reverse-the-nodes-of-a-linked-list/

namespace algo_list_linked
{
  // when Node and Entry are different
  //
  // struct ListNode 
  // {
  //   ListNode() : key_(0), next_(nullptr) {}
  //   ListEntry key_;
  //   ListNode *next_;
  // };

  struct ListEntry
  {
    explicit ListEntry(int row = 0, int col = 0) noexcept 
      : row_(row), col_(col), next_(nullptr) {}

    int row_{};
    int col_{};

    ListEntry *next_;
  };

  // when use ListEntry *head

  class List
  {
    public:
      List() : count_(0), head_(nullptr) {}

      bool empty() { return count_ == 0 ? true : false; }

      // no support of max size
      bool full() { return false; }

      size_t size() { return count_; }

      // works
      // void push(ListEntry const& entry)
      // {
      //   // when add the first
      //   if (head_ == nullptr)
      //   {
      //     head_ = new ListEntry(entry);
      //     count_++;
      //   }
      //   else
      //   {
      //     ListEntry *end{};

      //     // find the end *algo-list-find-end*

      //     for (end = head_; end->next_; end = end->next_)
      //       ;

      //     end->next_ = new ListEntry(entry);
      //     count_++;
      //   }
      // }

      // better version
      void push(ListEntry const& entry)
      {
        ListEntry *end{};

        // find the end *algo-list-find-end*

        for (end = head_; end && end->next_; end = end->next_)
          ;

        if (end == nullptr)
          head_ = new ListEntry(entry);
        else
          end->next_ = new ListEntry(entry);

        count_++;
      }

      void clear_old()
      {
        ListEntry *prev{nullptr};
        ListEntry *curr{nullptr};

        for (curr = head_; curr;)
        {
          if (prev)
          {
            free(prev);
            count_--;
          }
          prev = curr;
          curr = curr->next_;
        }

        if (prev)
        {
          free(prev);
          count_--;
        }

        head_ = nullptr;
        assert(count_ == 0);
      }

      // better version
      void clear()
      {
        ListEntry *prev{nullptr};
        ListEntry *curr{nullptr};

        // has different form from *also-list-find-end*

        for (curr = head_; curr;)
        {
          prev = curr;
          curr = curr->next_;

          free(prev);
          count_--;
        }

        head_ = nullptr;
        assert(count_ == 0);
      }

      std::vector<std::pair<int, int>> snap() noexcept
      {
        std::vector<std::pair<int, int>> result{};
        ListEntry *curr{nullptr};

        for (curr = head_; curr; curr = curr->next_)
          result.push_back(make_pair(curr->row_, curr->col_));

        return result;
      }

      void reverse()
      {
        ListEntry *curr{};
        ListEntry *prev{};
        ListEntry *next{};

        curr = head_;

        while (curr)
        {
          next = curr->next_;
          curr->next_ = prev;
          prev = curr;
          curr = next;
        }

        head_ = prev;
      }

    private:
      size_t count_;
      ListEntry *head_;
  };
} // namespace

TEST(AlgoList, LinkedSimpleReverse)
{
  using namespace algo_list_linked;

  {
    auto values{
      ListEntry(1,2), 
        ListEntry(2,3), 
        ListEntry(3,4), 
        ListEntry(4,5), 
        ListEntry(5,6)
    };

    List coll;

    for (auto &e : values)
      coll.push(e);

    EXPECT_THAT(coll.size(), 5);

    // now do not expect exception since there's no max
    // EXPECT_THROW(coll.push(ListEntry(6,7)), runtime_error); 

    coll.push(ListEntry(6,7));
    EXPECT_THAT(coll.size(), 6);

    EXPECT_THAT(coll.snap(), 
        ElementsAre(
          make_pair(1,2), 
          make_pair(2,3), 
          make_pair(3,4), 
          make_pair(4,5), 
          make_pair(5,6), 
          make_pair(6,7))
        );

    coll.reverse();

    EXPECT_THAT(coll.snap(), 
        ElementsAre(
          make_pair(6,7),
          make_pair(5,6), 
          make_pair(4,5), 
          make_pair(3,4), 
          make_pair(2,3), 
          make_pair(1,2)) 
        );

    coll.clear();
    EXPECT_THAT(coll.size(), 0);
  }
}


={============================================================================
*kt_dev_algo_0000* dev-algo-list-general

Unlike a stack or a queue, a list permits operations that alter 'arbitrary'
entries of the sequence:

o Insert an entry at a 'specified' position of the list.
o Remove an entry from a specified position in the list.
o Retrieve the entry from a specified position in the list.
o Replace the entry at a specified position in the list.

The general list support random-read-write-access as oppose to the simple list
that supports only addition at the end:


<position>
To find an entry in a list, we use an integer that gives its position within the list. We shall
number the positions in a list so that the first entry in the list has position 0, the second
position 1, and so on. Hence, locating an entry of a list by its position is superficially like
indexing an array, but there are important differences. First, if we insert an entry at a particular
position, then the position numbers of all later entries increase by 1. If we remove an entry, then
the positions of all following entries decrease by 1. 

implementation independence. Moreover, the position number for a list is defined without regard to
the implementation. For a contiguous list, implemented in an array, the position will indeed be the
index of the entry within the array. But we will also use the position to find an entry within
linked implementations of a list, where no indices or arrays are used at all. 

note that insert allows position==n, since it is permissible to insert an entry after the last
entry of the list. This is only for insert.

void InsertList( position p, ListEntry x, List* list );

// the entry in position p of list has been returned as x and deleted from list.
void DeleteList( position p, ListEntry* x, List* list );

// the entry in position p of list has been returned as x and list remains unchanged.
void RetrieveList( position p, ListEntry* x, List* list);

// list remain unchanged 
void ReplaceList( position p, ListEntry x, List* list );

As with list and others, the general list has two kind of implementation: contiguous and linked. For
contiguous, shift later elements to support inserting and deleting in any position. For both, need
to scan from the first every time. 


<do> Here linked case. Add InsertList and DeleteList to the simple list using SetPosition which is
utility function.

// return a node 'at' the pos in [0, count-1]
void SetPosition( Position p, List* list, ListNode** current )
{
  int count;
  ListNode* q;

  if( p < 0 || p >= list->count )
    Error("attempt to set a position not in the list");
  else 
  {
    q = list->head;
    
    // this is to control loop runs but not to check position/count
    for( count = 1; count <= p; count++ )
      q = q->next;

    *current = q;
  }
}


<code> from the ref-001.
<1>
1. Should handle when add an entry to the the first position.
2. Should have the previous pos(p-1) for pos insertion.

// insert a node at any pos in the list or a new into the list when pos is count. insert a node at p
// meaning that a node is to be placed at position p. p in [0, count]
//
// count:
//  1   2   3   4   5  ...
// pos
//  0   1   2   3   4  
// [ ] [ ] [ ] [ ] [ ] ...
// 
//   [*] new node when insert(1)
// 

void InsertList( Position p, ListEntry x, List* list )
{
   ListNode *newnode, *current;

   // check if pos is in [0, count]
   if( p < 0 || p > list->count )
      Error("attempt to set a position not in the list");
   else 
   {
      newnode = MakeListNode(x);
      // <key> cannot use if( ListEmpty(list) ) since it only handle when the list empty. However,
      // this case also handle to insert a node at pos 0 when the list is not empty.
      if( p == 0 )   
      {
         newnode->next = list->head;
         list->head = newnode;
      }
      // <key> handles p[1, count] that means SetPosition[0, count-1]. In other words, SetPostion
      // returns the previous to the postion to insert. This is idiom.
      else
      {
         SetPosition( p-1, list, &current );
         newnode->next = current->next;
         current->next = newnode;
      }
      list->count++;
   }
}


<2> TODO: needs more to be precise.
The above example has mismatch between count and pos, that is:

count 1 2 3 4 5
pos   0 1 2 3 4

The following uses the same range for both count and pos. Make a note for that always need to handle
the first node separately and <the-previous> node to insert in the list.

#include <iostream>
#include <cstdlib>

typedef int EntryType;
typedef int Position;

typedef struct node
{
  EntryType entry;
  node*     pnext;
} Node;

typedef struct {
  int    count;
  Node*  header;
} List;

Node* MakeNode( EntryType entry )
{
  Node* pnode = NULL;

  if( (pnode = (Node*) malloc( sizeof(Node))) == NULL )
    return NULL;

  pnode->entry = entry;
  pnode->pnext = NULL;

  return pnode;
}

void CreatList( List* list )
{ 
   list->count = 0;
   list->header = NULL; 
}

bool ListEmpty( List* list )
{ return ( list->header == NULL ); }

// add only at the end
bool ListAdd( List* list, EntryType entry )
{
  Node* pnode, *pend;

  if( (pnode = MakeNode(entry)) == NULL )
  {
    std::cout << "add: mem is full" << std::endl;
    return false;
  }

  if( ListEmpty( list ) )
  {
    list->header = pnode;
  }
  else
  {
    // search the end using pnext
    for( pend = list->header; pend->pnext; pend = pend->pnext )
      ;

    pnode->entry = entry;

    pend->pnext = pnode;
  }

  list->count++;

  std::cout << "add: added " << entry << ", count " << list->count << std::endl;

  return true;
}

// support random-access
bool SetPosition( List* list, Position pos, Node** ppNode)
{
   Node* pnode;
   int current;

   // check if pos  is in [1, count]
   if( pos < 1 || pos > list->count )
   {
      std::cout << "error: attempt to insert in a position" << pos << " not in the list" << std::endl;
      return false;
   }

   pnode = list->header;

   #ifdef RETURN_THE_PREVIOUS
   for( current=2; current < pos; current++ )
      pnode = pnode->pnext;
   #endif
   for( current=1; current < pos; current++ )
      pnode = pnode->pnext;

   *ppNode = pnode;
}

 [KT] Compared the previous, this has a protection. If call this when a list empty, that is, pos=1,
 count=0, then error happens and return. Cannot use this when a list is empty. Why? Looks okay.

bool InsertList( List* list, EntryType entry, Position pos )
{
  Node* pnewnode, *pnode;

  // check if pos  is in [1, count]
  if( pos < 1 || pos > list->count )   // <diff>
  {
    std::cout << "error: attempt to insert in a position not in the list" << std::endl;
    return false;
  }

  // get a new node
  pnewnode = MakeNode(entry);
  if(pnewnode==NULL)
  {
    std::cout << "error: no more memory" << std::endl;
    return false;
  }

  if( pos == 1 ) // [KT]
  {
    pnewnode->pnext = list->header;
    list->header = pnewnode;
  }
  else
  {
    // get the prev node of pos node [2, count]
#ifdef RETURN_THE_PREVIOUS
    SetPosition( list, pos, &pnode );
#endif

    SetPosition( list, pos-1, &pnode );

    // insert a new node between pos-1 and pos node
    pnewnode->pnext   = pnode->pnext; 
    pnode->pnext      = pnewnode;
  }

  list->count++;
}

bool DeleteList( List* list, EntryType entry, Position pos )
{
}

typedef void(*TRAVERSEFUNC)(EntryType);

void ListTraverse( List* list, TRAVERSEFUNC func)
{
  Node* pnode;

  if( ListEmpty(list) )
  {
    std::cout << "list is empty" << std::endl;
    return;
  }

  pnode = list->header;

  while(pnode)
  {
    func(pnode->entry);
    pnode = pnode->pnext;
  }
}

void EntryPrint(EntryType item)
{
   std::cout << "item is: " << item << std::endl;
}

int main()
{
  int item = 0;

  List list;
  CreatList(&list);

  std::cout << "type in 5 numbers." << std::endl;

  for(int i=0; i < 5; i++)
  {
    std::cin >> item;
    ListAdd(&list, item );
  }

  InsertList(&list, 10, 6);
  InsertList(&list, 10, 1);  // expects an error
  InsertList(&list, 20, 6);

  ListTraverse(&list, EntryPrint);
}


<3> template contiguous version
#include <iostream>

const int MAXLIST=100;

typedef enum { success, overflow, underflow, range_error} Error_code;

template <typename T>
class List 
{
  public:
    List() { count = 0; };
    int size() const;
    bool full() const;
    bool empty() const;
    void clear();
    void traverse( void(*v)(T &));

    //Error_code retrieve( int pos, T &x) const;
    //Error_code replace( int pos, const T &x );
    // postcondition: If 0 <= position < n, where n is the number of entries in the List, the
    // function succeeds: The entry at position is removed from the List, and all later entries have
    // their position numbers decreased by 1. The parameter x records a copy of the entry formerly
    // at position. Else: The function fails with a diagnostic error code.
    //Error_code remove( int pos, T &x ); 
    Error_code insert( int pos, const T &x );

  protected:
    int count;
    T entry[MAXLIST];
};

template <typename T>
int List<T>::size() const
{
  return count;
}

template <typename T>
bool List<T>::full() const
{
  return count == MAXLIST;
}

template <typename T>
bool List<T>::empty() const
{
  return count == 0;
}

template <typename T>
void List<T>::clear()
{
  count = 0;
}

template <typename T>
void List<T>::traverse( void (*visit)(T &e))
{
  for( T* it = entry; it != entry+count; it++ )
    visit( *it );
}

template <typename T>
Error_code List<T>::insert( int pos, const T &e )
{
  if( full() )
    return overflow;

  if( pos < 0 || pos > count )
    return range_error;

  // <key> moving. make room to insert by moving elements. Thus we say that the amount of work the
  // insertion and deletion does is approximately 'proportional' to n, the length of the list

  // note: when pos==count, it does seems to move entry[count] = count[count-1] which is off-the-end
  // access. Okay? Thing is that this is when list is full and there is no room to move element and
  // this case is checked before so not in this loop.

  for( int i = count-1; i >= pos; i-- )
    entry[i+1] = entry[i];

  entry[pos] = e;
  count++;

  return success;
}

void printList( int &i )
{
  std::cout << i << std::endl;
}

int main()
{
  int iarr[] = { 1, 3, 4, 6, 7, 10, 12, 25, 16, 33, 48, 51, 55 };
  int isize = sizeof iarr/ sizeof iarr[0];
  
  List<int> tlist;

  for( int i = 0; i < isize; i++ )
    tlist.insert( i, iarr[i] );

  std::cout << "-----------" << std::endl;
  tlist.traverse( printList );
}

<4> template linked version
#include <iostream>

using namespace std;

typedef enum { success, overflow, underflow, range_error } Error_code;

// nodes
template<typename T>
struct Node {
  T entry;
  Node<T> *next;

  Node() { next = NULL; }
  Node( T item, Node<T> *link = NULL ) { entry = item; next = link; }
};

template<typename T>
class List {
  public:
    ~List();
    List() { head = NULL; count = 0; };
    // List( const List<T> &copy );
    // void operator=(const List<T> &copy );

    int size() const { return count; }
    bool empty() const { return count == 0; }
    void clear();
    // void traverse( void (*visit)(T&));
    void traverse();

    Error_code retrieve( int position, T& entry) const;
    Error_code replace( int position, const T& entry );
    Error_code remove( int position, T& entry );
    Error_code insert( int position, const T& entry );

  protected:
    int count;
    Node<T> *head;
    Node<T> *set_position( int position ) const;
};

template<typename T>
List<T>::~List()
{
  if( !empty() )
  {
    Node<T> *following;

    for( head; head; head = following )
    {
      following = head->next;
      delete head;
    }

    head = NULL;
    count = 0;
  }
}

// position in 0 <= position < count. returns a pointer to the node 'in' position.
template<typename T>
Node<T> *List<T>::set_position( int position ) const
{
  Node<T> *q = head;
  for( int i = 0; i < position; i++ )
    q = q->next;

  return q;
}

template<typename T>
Error_code List<T>::insert( int position, const T& entry )
{
  if( position < 0 || position > count )
    return range_error;

  Node<T> *new_node, *previous, *following;

  if( position > 0 )
  {
    previous = set_position( position-1 );
    following = previous->next;
  }
  else
    following = head;

  new_node = new Node<T>( entry, following );

  if( new_node == NULL )
    return overflow;

  if( position == 0 )
    head = new_node;
  else
    previous->next = new_node;

  count++;

  return success;
}

template<typename T>
Error_code List<T>::remove( int position, T& entry )
{
  // note: when position > count and tried to remove off the end, get core
  // dump.
  if( position < 0 || position >= count )
    return range_error;

  Node<T> *previous, *following;

  if( position == 0 )
  {
    following = head->next;
    entry = head->entry;

    delete head;
    head = following;
  }
  else
  {
    previous = set_position(position-1);
    following = previous->next;

    previous->next = following->next;
    entry = following->entry;
    delete following;
  }

  count--;

  return success;
}

template<typename T>
void List<T>::traverse()
{
  Node<T>* node = head;

  cout << "{ ";

  for( node; node; node = node->next )
  {
    cout << node->entry << ", ";
  }

  cout << "}" << endl;
}

int main()
{
  int iarr[] = { 1, 3, 4, 6, 7, 10, 12, 25, 16, 33, 48, 51, 55 };
  int isize = sizeof iarr/ sizeof iarr[0];
  int entry;
  
  List<int> tlist;

  for( int i = 0; i < isize; i++ )
    tlist.insert( i, iarr[i] );

  // { 1, 3, 4, 6, 7, 10, 12, 25, 16, 33, 48, 51, 55, }
  cout << "-----------" << endl;
  tlist.traverse();

  tlist.remove( 1, entry ); cout << "removed:" << entry << endl;
  tlist.remove( 1, entry ); cout << "removed:" << entry << endl;

  // { 1, 6, 7, 10, 12, 25, 16, 33, 48, 51, 55, }
  cout << "-----------" << endl;
  tlist.traverse();

  tlist.remove( 0, entry ); cout << "removed:" << entry << endl;
  tlist.remove( 10, entry ); cout << "removed:" << entry << endl;

  // { 6, 7, 10, 12, 25, 16, 33, 48, 51, 55 }
  cout << "-----------" << endl;
  tlist.traverse();
}

note: the use of 'mutable'. For example, retrieve method is defined as a constant method, but its
implementation will need to alter the last-used position, current_position, of a List. We recognize
that although this operation does change some data members of a List object, it does not change the
sequence of entries that represents the actual value of the object


{improved-list}
For cases refering to the same entry several times as an example, this can be improved by keeping
the 'current' position which is the last-used position; <locality-of-reference> that is, if one
entry is accessed, is it likely that it will next be accessed again:

typedef int Position;

// See {list-linked-implementation} for comparison
//
typedef struct list {
  int          count;
  ListNode*    head; 
  Position     currentpos; ~
  ListNode*    current; ~
} List;

void SetPosition( Position p, List* list )
{
  if( p < 0 || p >= list->count )
    Error("attempt to set a position not in the list");
  else 
  {
    if( p < list->currentpos )
    {
      list->currentpos = 0;
      list->current = list->head; // since it has one-way direction
    }

    for( ; list->currentpos != p; list->currentpos++ )   // <key> is for condition
      list->current = list->current->next;
  }
}

This improves its efficiency than the previous but the changes needed to the various functions are
minor: For repeated references to the same position, neither if and for will be excuted; that is
when p equals to currentpos. So takes almost no time. For 'forward' move, will be very fast and for
backward move, operates the same way as the previous.


{doubly-linked-list}
Not a simple DL list but supports <random-access> which is more complicated than thought.

typedef struct listnode {
  ListEntry entry;
  struct listnode* next;
  struct listnode* prev;
} ListNode;

typedef struct list {
  int          count;   // notice that count [1..n] and pos[0..n-1]. no header any more
  ListNode*    current; ~
  Position     currentpos; ~
} List;

// set current to the position in 0.. count-1. see no return of ppNode and no run when
// pos==currentpos.
void SetPosition( Position p, List* list )
{
  if( p < 0 || p >= list->count )
    Error("attempt to set a position not in the list.");
  // move 'forward'
  else if( list->currentpos < p )
  {
    for(; list->currentpos != p; list->currentpos++ )
      list->current = list->current->next;
  }
  // move 'backward'
  else if( list->currentpos > p )
  {
    for(; list->currentpos != p; list->currentpos-- )
      list->current = list->current->prev;
  }
}


void InsertList( Position p, ListEntry x, List* list)
{
  ListNode* newnode, *following;

  if( p < 0 || p > list->count )
    Error("attempt to set a position not in the list.");
  else
  {
    newnode = MakeListNode(x);

    // insert at the beginning as it is not circular. This means that: first node's prev is null.
    //
    if( p == 0 )
    {
      newnode->prev = NULL;

      if( list->count == 0 )     // <key> need to handle when list is empty
        newnode->next = NULL;
      else
      {
        Setposition( 0, list );  // set current to pos 0
        newnode->next = list->current;
        list-current->prev = newnode; 
      }
    }
    else    // insert later in the list
    {
      // For DL, need the prev and the current(following) regardless of return pos from SetPostion.
      // For SL, need to have the previous.
      SetPosition( p-1, list );

      /* is temp really required?
       *
       *             cur(pos-1)  pos(end)
       * [prev next] [prev next] [prev next]
       * 
       *                 new [prev next]
       *
       * if do without temp(following) then
       *
       * cur->next = new;
       * cur->next->prev = new;
       * new->prev = cur;
       * new->next = cur->next; but cur->next is already changed.
       *
       * new->next = cur->next;
       * new->prev = cur;
       * cur->next->prev = new;
       * cur->next = new;
       *
       * seems okay. [NO] because cur->next is null when inserting at the end. REALLY?
       *
       *                 pos-1   pos
       *                 cur     following
       *         [0]     [1]     [2] 
       *          next -> next -> next -> null
       * null <- prev <- prev <- prev
       *
       */
      following = list->current->next;

      // insert between current and following
      newnode->next = following;
      newnode->prev = list->current;
      list->current->next = newnode;

      // <key> this check is required when inserting at the end because cur->next is null
      if(following)
        following->prev = newnode;
    }

    list->current = newnode;
    list->currentpos = p;
    list->count++;
  }
}


{list-contiguous-and-linked} {contiguous-vs-linked}
In summary, contiguous storage is generally preferable when:

o the records are individually very small
o the size of list is known when the program is written
o 'few' insertion or deletion need to be made except at the end of the list
o random (read) access is important

linked storage proves superior when:

o the records are large
o the size of list is not known when the program is written
o flexibility is needed in inserting, deleting and rearranging the entries.

            Searching   Insertion/deletion other then the end
Contiguous: O(1)        O(n)
Linked    : O(n)        O(1)


={============================================================================
*kt_dev_algo_0000* dev-algo-list-problem algo-cycle-detection

{algo-list-tortoise-and-hare}
http://stackoverflow.com/questions/494830/how-to-determine-if-a-linked-list-has-a-cycle-using-only-two-memory-locations

This is known as "floyd's cycle finding algorithm or the tortoise and the hare
algorithm" and has O(n) time and O(1) space.

function boolean hasLoop(Node startNode) {

  Node slowNode = Node fastNode1 = Node fastNode2 = startNode;

  // see how to move two using three variables in while statement.
  // f2(first) -> [f1 -> f2] -> [f1 -> f2 ] -> 
  
  while (slowNode && fastNode1 = fastNode2.next() && fastNode2 = fastNode1.next())
  {
    if (slowNode == fastNode1 || slowNode == fastNode2) return true;

    slowNode = slowNode.next();
  }

  return false;
}


// In order to exercise Divide(), have to have access to list structure but do
// not see any practical way to do it through class interface. so make `head_`
// public. same as algo_list_linked

namespace algo_list_linked_divide
{
  // when node and entry are in a single structure and these can be different
  // structure such as ListEntry and ListNode

  struct ListEntry
  {
    explicit ListEntry(int row = 0, int col = 0) noexcept 
      : row_(row), col_(col), next_(nullptr) 
    {}

    int row_{};
    int col_{};

    ListEntry* next_;
  };

  // cxx-operator-overload
  bool operator==(ListEntry const& lhs, ListEntry const& rhs)
  {
    return (lhs.row_ == rhs.row_) && (lhs.col_ == rhs.col_) ? true : false;
  }

  bool operator!=(ListEntry const& lhs, ListEntry const& rhs)
  {
    return !(lhs == rhs);
  }

  class List
  {
    public:
      explicit List() noexcept
        : head_(nullptr)
        {}

      bool emptry()
      { return count_ == 0 ? true : false; }

      int size()
      { return count_; }

      // push_back()
      void push_old(ListEntry const& entry)
      {
        if (!head_)
          head_ = new ListEntry(entry);
        else
        {
          ListEntry* run = head_;

          // unlike clear(), snap(), run shall be before end() so that can
          // insert new one. Hence check run->next

          while (run->next_)
            run = run->next_;

          run->next_ = new ListEntry(entry);
        }
        
        ++count_;
      }

      // push_back()
      void push(ListEntry const& entry)
      {
        ListEntry* run{};

        // find node for insertion *algo-list-find-end*
        // works both when head_ is null and is not null

        for (run = head_; run && run->next_; run = run->next_)
          ;

        // first item
        if (!run)
          head_ = new ListEntry(entry);
        else
          run->next_ = new ListEntry(entry);

        ++count_;
      }

      void clear()
      {
        ListEntry* run = head_;
        ListEntry* prev{};

        while (run)
        {
          prev = run;
          run = run->next_;
          free(prev);
          --count_;
        }

        head_ = run;
      }

      std::vector<ListEntry> snap()
      {
        ListEntry* run = head_;
        std::vector<ListEntry> coll;

        while (run)
        {
          // ok as well
          // coll.push_back(ListEntry(*run));
          coll.push_back(*run);
          run = run->next_;
        }

        return coll;
      }

    public:
      int count_{};

      // can use ListEntry head_; which changes member implementation
      ListEntry* head_;
  };


  // o slow and ffast starts from same place, begin()
  // o slow goes 1 and ffast goes 2
  // o this is implementation of {algo-list-tortoise-and-hare}

  bool detect_cycle_01(List const &list)
  {
    ListEntry *slow;
    ListEntry *fast;
    ListEntry *ffast;

    for (slow = fast = ffast = list.head_;
        slow && (fast = ffast->next_) && (ffast = fast->next_);)
    {
      if (slow == fast || slow == ffast)
        return true;

      slow = slow->next_;
    }
    
    return false;
  }


  // o use single fast
  // o see *cxx-for-while*

  bool detect_cycle_02(List const &list)
  {
    ListEntry *slow;
    ListEntry *fast;

    for (slow = fast = list.head_;
        slow && (fast = fast->next_) && (fast = fast->next_);)
    {
      if (slow == fast)
        return true;

      slow = slow->next_;
    }
    
    return false;
  }

  bool detect_cycle_03(List const &list)
  {
    ListEntry *slow;
    ListEntry *fast;

    // do not check when head_ is null
    for (slow = list.head_, fast = slow->next_;
        fast && slow != fast; )
    {
      fast = fast->next_;

      if (fast)
      {
        fast = fast->next_;
        slow = slow->next_;
      }
    }

    // loop ends when fast is null or when there is cycle so need to check if it
    // was when there is a cycle

    return fast != slow ? false : true;
  }

} // namespace

TEST(AlgoList, DetectCycle)
{
  using namespace algo_list_linked_divide;

  {
    std::vector<ListEntry> values{
      ListEntry(1,2), 
        ListEntry(2,3), 
        ListEntry(3,4), 
        ListEntry(4,5), 
        ListEntry(5,6)
    };

    List coll;

    for (auto &e : values)
      coll.push(e);

    EXPECT_THAT(detect_cycle_01(coll), false);
    EXPECT_THAT(detect_cycle_02(coll), false);
    EXPECT_THAT(detect_cycle_03(coll), false);
  }

  {
    std::vector<ListEntry> values{
      ListEntry(1,2), 
        ListEntry(2,3), 
        ListEntry(3,4), 
        ListEntry(4,5), 
        ListEntry(5,6)
    };

    List coll;

    for (auto &e : values)
      coll.push(e);

    // to make a cycle
    ListEntry *current;
    ListEntry *next;

    current = coll.head_;

    // find end()-1
    for (next = current; next; next = next->next_)
    {
      current = next;
    }

    // makes a cycle
    current->next_ = coll.head_;

    EXPECT_THAT(detect_cycle_01(coll), true);
    EXPECT_THAT(detect_cycle_02(coll), true);
    EXPECT_THAT(detect_cycle_03(coll), true);
  }
}


Irrespective of the shape of the cycle, one thing is clear; that the Tortoise
can never catch up with the Hare if there is no loop. 
If the two has to meet, the Hare has to catch up with the Tortoise from behind.

With that established, consider the two possibilities

    Hare is one step behind Tortoise
    Hare is two step behind Tortoise

All greater distances will reduce to One or Two. Let us assume always Tortoise
moves first  (it could be even other way).

In the first case were the distance between Hare and Tortoise is one step.
Tortoise moves one step forward and the distance between Hare and Tortoise
becomes 2. Now Hare moves 2 steps forward meeting up with Tortoise.

In the second case were the distance between Hare and Tortoise is two steps.
Tortoise moves one step forward and the distance between Hare and Tortoise
becomes 3. Now Hare moved 2 steps forward which makes the distance between
Hare and Tortoise as 1. It is similar to first case which we already proved
that both Hare and Tortoise will meet up in next step.

Let the length of the loop be 'n' and there are 'p' variables before the loop.
Hare traverses the loop twice in 'n' moves, they are guaranteed to meet in
O(n).


The point is that there is a loop when hare meets tortoise and needs only
single condition to compare.

<ex>
// algo-leetcode-202
/*
202. Happy Number, Easy

Write an algorithm to determine if a number is "happy".

A happy number is a number defined by the following process: Starting with any
positive integer, replace the number by the sum of the squares of its digits,
and repeat the process until:

  the number equals 1 (where it will stay), or 
  it loops endlessly in a cycle which does not include 1. 

Those numbers for which
this process ends in 1 are happy numbers.

Example: 

Input: 19
Output: true

Explanation: 

12 + 92 = 82
82 + 22 = 68
62 + 82 = 100
12 + 02 + 02 = 1
 
*/

namespace leetcode_easy_202
{
  int count{};

  bool isHappy_1(int n) 
  {
    long long sum{n};

    // when sum is 1, this loops endless
    // while ((sum != 1) || (sum != 0))

    while (sum > 1)
    {
      cout << "sum: " << sum << endl;

      int input = sum;
      int value{};
      sum = 0;

      while (input)
      {
        value = input % 10;
        sum += (value*value);
        input /= 10;
      }

      count++;
      if (count > 15)
        return false;
    }

    return sum == 1 ? true : false;
  }


  // My solution in C( O(1) space and no magic math property involved ),  Freezen
  //
  // I see the majority of those posts use hashset to record values. Actually,
  // we can simply adapt the Floyd Cycle detection algorithm. I believe that
  // many people have seen this in the Linked List Cycle detection problem. The
  // following is my code:

  int digitSquareSum(int n)
  {
    int sum{};
    int tmp{};

    while (n)
    {
      tmp = n % 10;
      sum += tmp * tmp;
      n /= 10;
    }

    return sum;
  }

  bool isHappy_2(int n) 
  {
    int slow, fast;
    slow = fast = n;

    do 
    {
      slow = digitSquareSum(slow);
      fast = digitSquareSum(fast);
      fast = digitSquareSum(fast);
    } while (slow != fast);

    return slow == 1 ? true : false;
  }

  // see *algo-cycle-detection*

  bool isHappy_3(int n) 
  {
    int slow, fast;
    slow = fast = n;

    while (slow && (fast = digitSquareSum(fast)) && (fast = digitSquareSum(fast)))
    {
      // this is *not right* to return false since happy number stops loop when
      // slow == fast which includes slow == fast == 1, that's true but not
      // false

      if (slow == fast)
        // return false;
        break;

      slow = digitSquareSum(slow);
    }

    return slow == 1 ? true : false;
  }

} // namespace

TEST(LeetCode, Easy_202_HappyNumber)
{
  using namespace leetcode_easy_202;

  {
    auto func = isHappy_1;

    // okay
    EXPECT_THAT(func(19), true);

    // it loops endless. is something missed from description?
    //
    // Looking at discussion, appears that return false when there is endless
    // loop.
    //
    // EXPECT_THAT(func(2), true);
  }

  {
    auto func = isHappy_2;

    // okay
    EXPECT_THAT(func(19), true);
    EXPECT_THAT(func(2), false);
  }

  {
    auto func = isHappy_3;

    // okay
    EXPECT_THAT(func(19), true);
    EXPECT_THAT(func(2), false);
  }
}


={============================================================================
*kt_dev_algo_0000* dev-algo-queue

The queue has head(front) and tail(rear).

{algo-queue-contiguous-implementations}

<1> use fixed head and tail 

Use always index 0 as a head and the end as a tail. However, use first entry
and then move all the remaining entries up whenever pops. Perfornamce problem.

<2>  use haed and tail but not fixed

Use head and tail but they are not fixed and both are increased but never
decreased. Space problem. 

`If can relocate queue regularly to release space between 0 and head,` two
indices and straight-line storage implementation is very efficient.


{algo-queue-circular} *algo-interview*

To solve space problem, can use `circular` and decide boundary condition to
indicate if a queue is full or empty. However, there is no way, by looking at
the indicies ALONE, to tell a full queue from an empty one.

<1> use vacant item to distinguish empty and full 

o Unlike linear queue, stack, and simple list which has tail and head pointing
  to 'next' available position, tail points to the vacant and head points to
  the last.

o The empty condition is when head == tail and the full is when head ==
  (tail+1)%SIZE.

o When push(), check full condition first which check head+1 and when pop,
  check empty condition which check head == tail. Therefore, there is vacant
  element

|   |   |   |   |   |     tail == head, empty
 t/h

|   | X | X | X | X |     full, 4 - 0 = 4, not 5
  t               h

|   |   |   | X | X |     two items
          t       h

| X | X |   | X | X |     full, `vacant`
      h   t        

(r,f)             full  empty                   full
(0,4) (0,3) (0,2) (0,1) (0,0) (1,0) (2,0) (3,0) (4,0)
-4    -3    -2    -1    0     1     2     3     4     rear-front
 1     2     3     4    5     6     7     8     9     +QSIZE(5)
 1     2     3     4    0     1     2     3     4     length = (rear-front+QSIZE)%QSIZE


  init: head=tail=0;                       // can be any index
  empt: return head==tail;
  full: return (tail+1)%QSIZE == head;
  leng: length = (tail+QSIZE-head)%QSIZE;  // can get any time


namespace queue_circular_vacant
{
  class CircularQueue
  {
    public:

      // *cxx-vector-ctor*
      // CircularQueue() : coll_(MAX_SIZE, 0) {}

      CircularQueue() {}

      bool empty() { return head_ == tail_; }

      bool full() { return (head_ + 1) % MAX_SIZE == tail_; }

      size_t size() { return (head_ - tail_ + MAX_SIZE) % MAX_SIZE; }

      void push(int value)
      {
        if (full())
          throw std::runtime_error("queue is full");

        // to see where exception happens since gmock do not show where it
        // throws
        //
        // if (full())
        // {
        //   cout << "queue is full, value = " << value << endl;
        //   return;
        // }

        head_ = (head_ + 1) % MAX_SIZE;
        coll_[head_] = value;
      }

      int pop()
      {
        if (empty())
          throw std::runtime_error("queue is empty");

        tail_ = (tail_ + 1) % MAX_SIZE;
        return coll_[tail_];
      }

      std::vector<int> snap()
      {
        std::vector<int> result{};

        // do not work like this
        //
        // for (auto run = tail_ + 1; run <= head_; ++run)
        //   result.push_back(coll_[run]);
        //
        // care about start value and <= condition. However, cannot use comparison
        // on head and tail since it warps around after all.
        //
        // for (int i = tail_ + 1; i <= head_; i = (i + 1) % MAX_SIZE)
        //     coll.push_back(coll_[i]);

        auto run = (tail_ + 1) % MAX_SIZE;
        for (size_t i = 0; i < size(); ++i)
        {
          result.push_back(coll_[run]);
          run = (run + 1) % MAX_SIZE;
        }

        return result;
      }

    private:
      static size_t const MAX_SIZE{10};

      // if MAX_SIZE is not static
      // std::vector<int> coll_;
      // and use ctor
      
      // if MAX_SIZE is not static
      // std::array<int, 10> coll_;
      
      // if MAX_SIZE is static
      std::array<int, MAX_SIZE> coll_;

      // if MAX_SIZE is static but still error
      // std::vector<int> coll_(MAX_SIZE, 0);

      // they are indexes
      size_t head_{};
      size_t tail_{};
  };

} // namespace

TEST(Queue, CircularVacant)
{
  using namespace queue_circular_vacant;

  CircularQueue cq;

  cq.push(10);
  cq.push(11);
  cq.push(12);

  EXPECT_THAT(cq.size(), 3);
  EXPECT_THAT(cq.snap(), ElementsAre(10, 11, 12));

  cq.push(13);
  cq.push(14);
  cq.push(15);

  EXPECT_THAT(cq.size(), 6);
  EXPECT_THAT(cq.snap(), ElementsAre(10, 11, 12, 13, 14, 15));

  EXPECT_THAT(cq.pop(), 10);
  EXPECT_THAT(cq.pop(), 11);
  EXPECT_THAT(cq.pop(), 12);

  EXPECT_THAT(cq.size(), 3);

  cq.push(100);
  cq.push(101);
  cq.push(102);

  EXPECT_THAT(cq.size(), 6);
  EXPECT_THAT(cq.snap(), ElementsAre(13, 14, 15, 100, 101, 102));

  EXPECT_THAT(cq.pop(), 13);
  EXPECT_THAT(cq.pop(), 14);

  cq.push(300);
  cq.push(301);
  cq.push(302);

  EXPECT_THAT(cq.size(), 7);
  EXPECT_THAT(cq.snap(), ElementsAre(15, 100, 101, 102, 300, 301, 302));

  cq.push(400);
  cq.push(401);
  EXPECT_THROW(cq.push(402), std::runtime_error);   // full, exception
  EXPECT_THROW(cq.push(403), std::runtime_error);   // full, exception
  EXPECT_THROW(cq.push(404), std::runtime_error);   // full, exception

  // since it is vacant version
  EXPECT_THAT(cq.size(), 9);
  EXPECT_THAT(cq.full(), true);

  EXPECT_THAT(cq.pop(), 15);
  EXPECT_THAT(cq.pop(), 100);
  EXPECT_THAT(cq.pop(), 101);

  // since it is vacant version
  EXPECT_THAT(cq.size(), 6);
  EXPECT_THAT(cq.snap(), ElementsAre(102, 300, 301, 302, 400, 401));

  EXPECT_THAT(cq.full(), false);
}


<2> use flag item to distinguish empty and full 
Use circular array, two indicies and new variable: a bool 'flag' for full or
empty. The flag is toggle: For a case from a book, if q becomes
diff(front-rear) == 1 while flag == full then q becomes empty. Or int variable
to indicate.


<3> use count item to distinguish empty and full 

namespace queue_circular_count
{

class CircularQueue
{
  public:
    // *cxx-vector-ctor*
    CircularQueue() 
      : coll_(MAX_SIZE, 0)
    {
    }

    bool empty() const 
    { return count_ == 0; }

    bool full() const
    { return count_ >= MAX_SIZE; }

    int size() const 
    { return count_; }

    void push(int value) 
    {
      if (full())
        return;

      head_ = head_ % MAX_SIZE;
      coll_[head_++] = value;
      count_++;
    }

    int pop() 
    {
      int value{};

      if (empty())
        return -1;

      tail_ = tail_ % MAX_SIZE;
      value = coll_[tail_++];
      count_--;

      return value;
    }

    std::vector<int> snap()
    {
      std::vector<int> coll;

      int start = tail_;

      for (int i = 0; i < size(); ++i)
      {
        coll.push_back(coll_[start]);
        start = (start+1) % MAX_SIZE;
      }

      return coll;
    }

  private:
    const int MAX_SIZE{10};
    int head_{};
    int tail_{};
    int count_{};
    std::vector<int> coll_; // {MAX_SIZE, 0};
}; 

} // namespace

TEST(Queue, CircularCount)
{
  using namespace queue_circular_count;

  CircularQueue cq;

  cq.push(10);
  cq.push(11);
  cq.push(12);

  EXPECT_THAT(cq.size(), 3);
  EXPECT_THAT(cq.snap(), ElementsAre(10, 11, 12));

  cq.push(13);
  cq.push(14);
  cq.push(15);

  EXPECT_THAT(cq.size(), 6);
  EXPECT_THAT(cq.snap(), ElementsAre(10, 11, 12, 13, 14, 15));

  EXPECT_THAT(cq.pop(), 10);
  EXPECT_THAT(cq.pop(), 11);
  EXPECT_THAT(cq.pop(), 12);

  EXPECT_THAT(cq.size(), 3);

  cq.push(100);
  cq.push(101);
  cq.push(102);

  EXPECT_THAT(cq.size(), 6);
  EXPECT_THAT(cq.snap(), ElementsAre(13, 14, 15, 100, 101, 102));

  EXPECT_THAT(cq.pop(), 13);
  EXPECT_THAT(cq.pop(), 14);

  cq.push(300);
  cq.push(301);
  cq.push(302);

  EXPECT_THAT(cq.size(), 7);
  EXPECT_THAT(cq.snap(), ElementsAre(15, 100, 101, 102, 300, 301, 302));

  cq.push(400);
  cq.push(401);
  cq.push(402);
  cq.push(403);
  cq.push(404);

  EXPECT_THAT(cq.size(), 10);
  EXPECT_THAT(cq.full(), true);

  EXPECT_THAT(cq.pop(), 15);
  EXPECT_THAT(cq.pop(), 100);
  EXPECT_THAT(cq.pop(), 101);

  EXPECT_THAT(cq.size(), 7);
  EXPECT_THAT(cq.snap(), ElementsAre(102, 300, 301, 302, 400, 401, 402));

  EXPECT_THAT(cq.full(), false);
}


<4> use count and supports iterator

// from Problem 46, circular buffer, the modern c++ challenge
// 1. use size(count) and head only
// 2. in push, no full check since it overwrites and in pop, it simply
// calculates first from head substracing size.
// 3. no iterator support is needed if not use begin()/end()

// no need to have `count` since std::vector() has size() to get current size
// and which is different from queue array implementation

namespace queue_circular_count_iterator
{
  template <typename T>
    class circular_buffer_iterator;

  template <typename T>
    class circular_buffer
    {
      typedef circular_buffer_iterator<T> const_iterator;
      friend class circular_buffer_iterator<T>;

      public:
      circular_buffer() = delete;
      explicit circular_buffer(size_t const size) : coll_(size) {}

      bool empty() const noexcept
      { return size_ == 0; }

      bool full() const noexcept
      { return size_ >= coll_.size(); }

      size_t capacity() const noexcept
      { return size_; }

      void clear() noexcept
      { head_ = -1, size_ = 0; }

      T pop()
      {
        if (empty())
          throw std::runtime_error("buffer is empty");

        auto pos = first_pos();

        #ifdef QUEUE_CIRCULAR_DEBUG
        cout << "pop: pos: " << pos 
          << ", coll_[]: " << coll_[pos] << endl;
        #endif // QUEUE_CIRCULAR_DEBUG

        size_--;
        return coll_[pos];
      }

      void push(T const item)
      {
        // this is how the text is implemented and this allows overwrites
        // this make head and tail changed
        //
        // if (full())
        //   throw std::runtime_error("buffer is full");

        head_ = next_pos();
        coll_[head_] = item;

        #ifdef QUEUE_CIRCULAR_DEBUG
        cout << "push: head_: " << head_ 
          << ", coll_[]: " << coll_[head_] << endl;
        #endif // QUEUE_CIRCULAR_DEBUG

        // due to overwrite feature
        if (size_ < coll_.size())
          size_++;
      }

      // iterators
      const_iterator begin() const
      { return const_iterator(*this, first_pos(), empty()); }

      const_iterator end() const
      { return const_iterator(*this, next_pos(), true); }

      private:
      // same as `count`
      size_t size_{};

      // ?, set max value
      // size_t head_{-1};

      // to aviod narrowing warning
      int head_{-1};

      std::vector<T> coll_;

      // return `head` pos to push and the reason of having size_t == 0 is
      // that `head` starts from -1.

      size_t next_pos() const noexcept
      {
        return size_ == 0 ? 0 
          : ((head_ + 1 ) % coll_.size());
      }

      // return `tail` pos to pop and get tail from head and size
      // as with vacant case, normalise and +1 since no vacant item.

      size_t first_pos() const noexcept
      {
        return size_ == 0 ? 0 
          : (head_ - size_ + 1 + coll_.size()) % coll_.size();
      }
    };

  template <typename T>
    class circular_buffer_iterator
    {
      typedef circular_buffer_iterator    self_type;
      typedef T const&                    const_reference;

      public:
      explicit circular_buffer_iterator(circular_buffer<T> const& buffer,
          size_t position, bool is_last)
        : buffer_(buffer), position_(position), is_last_(is_last)
      {}

      // cxx-operator-prefix
      self_type& operator++()
      {
        if (is_last_)
          throw std::out_of_range("past the end");

        position_ = (position_ + 1) % buffer_.coll_.size();

        // although it's circular queue which wraps around, iterator moves
        // around [tail, head] range. If increased pos is the same as head
        // then it reaches to the end.
        //
        // is_last_ get set either from ctor or ++()

        is_last_ = (position_ == buffer_.next_pos());

        return *this;
      }

      // cxx-operator-postfix which use prefix version
      self_type& operator++(int)
      {
        auto temp = *this;
        ++*this();
        return temp;
      }

      bool operator==(self_type const& other) const
      {
        // & address? since buffer do not support operator==() 
        return &buffer_ == &other.buffer_
          && position_ == other.position_
          && is_last_ == other.is_last_;
      }

      bool operator!=(self_type const& other) const
      { return !(*this == other); }

      const_reference operator*() const
      {
        return buffer_.coll_[position_];
      }

      private:
      circular_buffer<T> const& buffer_;
      size_t position_;
      bool is_last_;
    };

  template <typename T>
    std::vector<T> print(circular_buffer<T> & buf)
    {
      std::vector<T> coll{};

      for (auto & e : buf)
        coll.push_back(e);

      return coll;
    }

} // namespace


TEST(Queue, CircularCountIterator)
{
  using namespace queue_circular_count_iterator;

  {
    circular_buffer<int> cbuf(5);   // {0, 0, 0, 0, 0} -> {}

    cbuf.push(1);                   // {1, 0, 0, 0, 0} -> {1}
    cbuf.push(2);                   // {1, 2, 0, 0, 0} -> {1, 2}
    cbuf.push(3);                   // {1, 2, 3, 0, 0} -> {1, 2, 3}

    auto item = cbuf.pop();         // {1, 2, 3, 0, 0} -> {X, 2, 3}
    EXPECT_THAT(item, 1);

    cbuf.push(4);                   // {1, 2, 3, 4, 0} -> {X, 2, 3, 4}
    cbuf.push(5);                   // {1, 2, 3, 4, (5)} -> {X, 2, 3, 4, 5}

    // see that it overwrites
    cbuf.push(6);                   // {(6), 2, 3, 4, 5} -> {2, 3, 4, 5, 6}
    cbuf.push(7);                   // {6, (7), 3, 4, 5} -> {3, 4, 5, 6, 7}
    cbuf.push(8);                   // {6, 7, (8), 4, 5} -> {4, 5, 6, 7, 8}

    item = cbuf.pop();              // {6, 7, 8, 4, 5} -> {5, 6, 7, 8}
    EXPECT_THAT(item, 4);
    item = cbuf.pop();              // {6, 7, 8, 4, 5} -> {6, 7, 8}
    EXPECT_THAT(item, 5);
    item = cbuf.pop();              // {6, 7, 8, 4, 5} -> {7, 8}
    EXPECT_THAT(item, 6);

    cbuf.pop();                     // {6, 7, 8, 4, 5} -> {8}
    cbuf.pop();                     // {6, 7, 8, 4, 5} -> {}
    cbuf.push(9);                   // {6, 7, 8, 9, 5} -> {9}
  }

  // to exercise iterator feature
  {
    circular_buffer<int> cbuf(5);

    cbuf.push(1);
    cbuf.push(2);
    cbuf.push(3);
    cbuf.push(4);
    cbuf.push(5);
    cbuf.push(6);
    cbuf.push(7);
    EXPECT_THAT(print(cbuf), ElementsAre(3,4,5,6,7));
  }
}


{algo-queue-linked-implementations}
Unlike contiguous queue, NO space problem and NO emptiness/fullness problem. So no full check and
only care about emptiness:

1. Addition when queue is empty must be treated 'separately' since addition to an empty queue
requires setting both the front and the rear to the new node, whereas addition to nonempty requires
changing only the rear. 

2. Deletion when queue goes empty must be treated since need to update rear as well.

typedef T QueueEntry;

typedef struct queuenode {
  QueueEntry entry;
  struct queuenode *next;
} QueueNode;

typedef struct queue {
  QueueNode* front;
  QueueNode* rear;
} Queue;

void CreateQueue(Queue *q)
{
  // this is a 'empty' condition which is NULL but the equal
  q->front = q->rear = NULL;
}

// QueueNode* pentry = (QueueNode*) malloc( sizeof(QueueNode) );
// AppendNode( pentry, q );
//
// note: This reveals that it is linked implementation since use of "Node" wording. Not well in
// hiding. The following is better?
//
// QueueItem* pitem = (QueueItem*) malloc( sizeof(QueueItem) );
// AppendQueue( pitem, q );
//
void AppendNode(QueueNode *p, Queue* q)
{
  if(!p)
    Error(...)
  else if( QueueEmpty(q) )
    q->front = q->rear = p;
  else
  {
    q->rear->next = p;
    q->rear = p;
  }
}

// 
// QueueNode* pentry;
// ServeNode( &pentry, q);
// ..
// use entry
// ..
// free(pentry);
//
void ServeNode(QueueNode**p, Queue* q)
{
  if( QueueEmpty(q) )
    Error(...);
  else
  {
    *p = q->front;
    q->front = q->front->next;

    // if q is empty, front is already null so mark rear null as well. Here empty condition is
    // when both are null but not the same.
    if( QueueEmpty(q) )
      q->rear = NULL;
  }
}


{queue-circularly-linked}
This is a linked list in which the node at the tail of the list, instead of
having a null, points back to the node at the head. Need only one pointer tail
to access both ends of the list.


={============================================================================
*kt_dev_algo_005*	array: index shift

{example-one}

From *kt_dev_algo_007*	recursion:

4x4
00 01 02 03 : down diff -3. 4th covers 1 pos. -> 0th
10 11 12 13 : down diff -2. 5th covers 2         1th
20 21 22 23 : down diff -1. 6th covers 3         2th
30 31 32 33 : down diff  0. 0th covers 4         3th
            : down diff  1. 1th covers 3         4th
				: down diff  2. 2th covers 2         5th
				: down diff  3. 3th covers 1         6th

#define BOARDSIZE 	4						// 4x4 space
#define DIAGONAL		(2*BOARDSIZE-1)	// up or down diagonal size. 7
#define DOWNOFFSET	(BOARDSIZE-1)		// down diagonal offset. BOARDSIZE-1

bool downfree[ DIAGONAL ];

downfree[ queenrow - col + DOWNOFFSET ] = false;

Since array index cannot be negative, need to shift index into positive. Here -3...3 to 0...6 and
used DOWNOFFSET(3).

-3 -2 -1 0 1 2 3
 0  1  2 3 4 5 6 	// array[7];


{example-two}

From circular-queue, rear-front can have -4...4 and to get the length of queue can shift. Here
there is one vacant element.

 0  1  2  3  4
[f][h][ ][ ][r]

(r,f)                   empty                   full
(0,4) (0,3) (0,2) (0,1) (0,0) (1,0) (2,0) (3,0) (4,0)
-4    -3    -2    -1    0     1     2     3     4			rear-front
 1     2     3     4    5     6     7     8     9			+QSIZE(5)
 1     2     3     4    0     1     2     3     4			(rear-front+QSIZE)%QSIZE

 0     1     2     3    4     5     6     7     8			+QSIZE-1(4)
 
The difference is that there is one vacant element so used QSIZE to shift but not QSIZE-1. 0th is
not used.


={============================================================================
*kt_dev_algo_008* algo-bigo-notation

<big-o-notation>
To present the operation count or running time for algorithm

O(1) to mean computing time that is bounded by a constant (not dependent on n)
O(n) to mean that the time is directly propotional to n. called liner time.
O(n2) called quadratic time
O(n3) called cubic time
O(2n) called exponential


={============================================================================
*kt_dev_algo_0000* algo-search

{internal-and-external}
The case when to search records in files on disk or tape, external to the
computer memory. The external searching. 

The records to be searched are stored entirely within the computer memory.
Internal searching.


{target}
The key for which we are searching is called the `target-of-the-search`. Here
concerned only with internal search and contiguous list.


{search-analysis}

Two premises:

The `number-of-comparisons` of keys give us the most useful information when
wish to estimate the computer time to require or to compare it with some other
method. This is more useful than the total running time which is too dependant
on programming variations and machines. This number of comparisions of keys is
`measure-of-analysis`.

Use average behavior and means to take each possibility once and average the
results. Limit our attention to where all the possibilities are equally
likely.


={============================================================================
*kt_dev_algo_0000* algo-binary-search

In only twenty steps, will locate any requested key in a list containing more
than a millions keys. 

o The keys in the list should be `sorted` 

o This requires `random-access` so shall limit for `contiguous-implementation`.

One study showed that about 90 percent of professional programmers fail to
code binary search correctly, even after working on it for a full hour.


o recursive version? NO.
 
o How to get middle?

  If use array index, then no difference between:

  middle = (first + last)/2; or middle = first + (diff/2);

// 2. GT or LT version?
//
// Before, thought it only affect whether or not it would find the first when
// there are multiple matches in the input:
//
// <gt-comparison>
// if( GT(key, middle) )     // key > middle
//   bot = middle+1;         // remove `lower-part`
// else                      // key <= middle
//   top = middle;           // remove `upper-part` including middle
// 
// <lt-comparison>
// if( LT(key, middle) )     // key < middle
//   top = middle-1;
// else                      // key >= middle
//   bot = middle;           
// 
// The `gt-comparison` will find the `first-occurance` of the target when
// there are multiples since it removes the upper and the `lower-part` still
// remains in search.  For example, search 2 in the list and middle is ^:
//  
// 
// ..2222...
//    ^
//
// *However*, turns out LT version DO NOT work since:
//
//
//      0  1  2  3   4   5   6   7   8   9  10  11  12
// coll{2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33};
//
// lt runs when key is 15:
//
// 0, 12  12/2=6  c[6]=13
// 6, 12  18/2=9  c[9]=29
// 6,  8  14/2=7  c[7]=15
// 7,  8  15/2=7  c[7]=15
// 7,  8  15/2=7  c[7]=15
// ...
//
// gt runs when key is 15:
//
// 0, 12  12/2=6  c[6]=13
// 7, 12  19/2=9  c[9]=29
// 7,  9  16/2=8  c[8]=17
// 7,  8  15/2=7  c[7]=15
// 7,  7  ends

o equality version

  these gt/lt version forgets(ignores) the possibility that the target might
  be found in the middle and continue to search until when there is only one
  item, that is when top == bottom. Then see either hit the target or not
  found. So it makes possibly unnecessary iterations. 
  
  So have equality check in the loop.


o Which is better?
  
Which one will do fewer comparisons? `equality-version` will if found 
in the beginning of the search but requires 
`two comparisons at each iteration.`
 
Can draw a `comparison-tree` to compare.
 
                   (5) ; root node representing a key
     '<='                       '>'
     (3)                        (8)
'<='       '>'
(2)        (4)
      '<='      '>'
...   (4)       (5)
    '=' '!='  '=' '!='
... [4] [F]   [5] [F]
 
For n=10, Binary1 does slightly fewer comparisons both for successful and
for unsuccessful searches. However, an optimizing compiler may not do as
much work as two full comparisons. In that case, Binary2 may be slightly
better choice.
 
 
Sequential search needs O(n) and binary search needs `O(logn) comparisons`
which is excellent since log n grows very slowly as n increases.
 
These are only approximate. For large values of n, the difference between
log n and log(n+1) is insignificant and (n+1)/n is very nearly 1. Hence can
simply results as:
 
               Successful     Unsuccessful search
Binary1Search  logn + 1       logn + 1              `forgettable-version`
Binary2Search  2logn-3        2logn                 `equality-version`
 
All four cases are proportional to logn and the coefficients of logn are
the number of comparisons inside the loop.
 
To conclude, two points:
 
o For large n, Binary1, `forgetful-version` is better and for small,
  sequential search is better since when looks at logn and n graph, logn is
  bigger for small n. Binary2 may be better when there is optimizing compiler.
 
o Binary1 pickes up the first occurance when there are many same occurances
  but Binary2 don't.


namespace algo_binary_search
{
  // greater-than-version

  // o should have empty input check? not necessary since do not run for loop
  //   anyway.
  //
  // o since there is no match check in the loop, have to check if it found the
  //   match and return index or iterator found or return something to mean `not
  //   found`. 
  //
  // o iterator or index? 
  //
  // When use iterator, there's no more element when first and last are the
  // same. When use array index, there is one element and (last-first) == -1
  // when express there is no element. 
  //
  // Whether or not use iterator or array, have the same number of comparison
  // tree and exit the loop when there is no more comparison to do.
  
  template <typename _Iterator, typename _T> 
    _Iterator binary_search_1(_Iterator begin, _Iterator end, _T const key) 
    { 
      _Iterator result = end;

      while (begin < end)
      {
        auto middle = std::distance(begin, end)/2;

        // cout << "while: middle : " << middle << endl;

        if (key > *(begin + middle))
          begin = begin + middle + 1;
        else
          end = begin + middle;
      }

      // cout << "while: distance : " << std::distance(begin, end) << endl;

      return key == *begin ? begin : result;
    }


  // returns index either found or to insert than boolean

  template <typename _Iterator, typename _T> 
    _T binary_search_2(_Iterator begin, _Iterator end, _T const key) 
    { 
      _Iterator result = begin;

      while (begin < end)
      {
        auto middle = std::distance(begin, end)/2;

        if (key > *(begin + middle))
          begin = begin + middle + 1;
        else
          end = begin + middle;
      }

      return std::distance(result, begin);
    }

  template <typename _Coll, typename _T> 
    _T binary_search_3(_Coll coll, _T const key) 
    { 
      auto begin = coll.begin();
      auto end = coll.end();

      while (begin < end)
      {
        auto middle = std::distance(begin, end)/2;

        if (key > *(begin + middle))
          begin = begin + middle + 1;
        else
          end = begin + middle;
      }

      return std::distance(coll.begin(), begin);
    }


  // `equality-version`

  template <typename _Iterator, typename _T> 
    _Iterator binary_search_4(_Iterator begin, _Iterator end, _T const key) 
    { 
      _Iterator result = end;

      while (begin <= end)
      {
        auto middle = std::distance(begin, end)/2;

        // cout << "while: middle : " << middle << endl;

        if (key == *(begin + middle))
          return begin + middle;
        else if (key > *(begin + middle))
          begin = begin + middle + 1;
        else
          end = begin + middle -1;
      }

      // when not found only
      return result;
    }

  // TODO: do not work as expected
  template <typename _Iterator, typename _T> 
    _T binary_search_5(_Iterator begin, _Iterator end, _T const key) 
    { 
      _Iterator saved_begin = begin;
      _Iterator saved_end = end;

      while (begin <= end)
      {
        auto middle = std::distance(begin, end)/2;

        // cout << "while: middle : " << middle << endl;

        if (key == *(begin + middle))
          return std::distance(saved_begin, begin + middle);
        else if (key > *(begin + middle))
          begin = begin + middle + 1;
        else
          end = begin + middle -1;
      }

      // when not found only
      return std::distance(saved_begin, begin);
    }

  // ansic, p58 `equality-version`
  // cracking the coding interview, p120
  // Programming Pearl, p46
  //
  // note:
  //
  // it can cause `overflow` when array is huge so can use:
  // 
  // mid = (high-low)/2 + low;
  // 
  // it has the same as distance() in iterator version or can use
  // length approach as stl version.
  
  int binary_search_6(vector<int> &coll, int key)
  {
    // *cxx-undefined* since can be negative
    // size_t low{}; size_t high{}; size_t mid{};

    int low{};
    int high{};
    int mid{};

    low = 0;
    high = coll.size()-1;

    while (low <= high)
    {
      mid = (low + high)/2;

      if (key == coll[mid])
        return mid;
      else if (key < coll[mid])
        high = mid - 1;
      else
        low = mid + 1;
    }
   
    // to return index
    return low;

    // return -1;
  }

  // gt-version, stl version
  //
  // Repeat:
  // Whether or not use iterator or array, have the same number of
  // comparison tree and exit the loop when there is no more comparison to do;
  // either found or not found when first/end is 0 or end.
  //
  // to return bool
  // return (first != last && *first == key);
  //
  // if return iterator, when not found, first can be either end() or the
  // first. Is it right to return the first to mean that not found?
  //
  // template<typename _ForwardIterator, typename _Tp>
  //   bool
  //   binary_search(_ForwardIterator __first, _ForwardIterator __last,
  //       const _Tp& __val)
  //   {
  //     typedef typename iterator_traits<_ForwardIterator>::value_type
  //       _ValueType;
  //
  //     _ForwardIterator __i
  //       = std::__lower_bound(__first, __last, __val,
  //           __gnu_cxx::__ops::__iter_less_val());
  //     return __i != __last && !(__val < *__i);
  //   }
  //
  // // lower_bound moved to stl_algobase.h
  //
  // /**
  //  *  @brief Finds the first position in which @p __val could be inserted
  //  *         without changing the ordering.
  //  *  @ingroup binary_search_algorithms
  //  *  @param  __first   An iterator.
  //  *  @param  __last    Another iterator.
  //  *  @param  __val     The search term.
  //  *  @param  __comp    A functor to use for comparisons.
  //  *  @return An iterator pointing to the first element <em>not less
  //  *           than</em> @p __val, or end() if every element is less
  //  *           than @p __val.
  //  *  @ingroup binary_search_algorithms
  //  *
  //  *  The comparison function should have the same effects on ordering as
  //  *  the function used for the initial sort.
  // */
  // 
  // template<typename _ForwardIterator, typename _Tp>
  //   inline _ForwardIterator
  //   lower_bound(_ForwardIterator __first, _ForwardIterator __last,
  //       const _Tp& __val)
  //   {
  //     return std::__lower_bound(__first, __last, __val,
  //         __gnu_cxx::__ops::__iter_less_val());
  //   }
  //
  // As with lower_bound(), it reutns a value "equal to or greater than" and
  // for "0" scale, goes path "<=" since key is 1.
  //
  // {
  //   vector<int> coll{2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33};
  //
  //   // lower_bound() returns the position of the first element that has a value
  //   // equal to or greater than value. This is the first position where an
  //   // element with value value could get inserted without breaking the sorting
  //   // of the range [beg,end).
  //
  //   auto first = lower_bound(coll.cbegin(), coll.cend(), 1);
  //   EXPECT_THAT(*first, 2);
  // }

  namespace algo_code
  {
    // /usr/include/c++/4.9/bits/stl_algobase.h
    template<typename _ForwardIterator, typename _Tp, typename _Compare>
      _ForwardIterator
      __lower_bound(_ForwardIterator __first, _ForwardIterator __last,
          const _Tp& __val, _Compare __comp)
      {
        typedef typename iterator_traits<_ForwardIterator>::difference_type
          _DistanceType;

        _DistanceType __len = std::distance(__first, __last);

        while (__len > 0)
        {
          _DistanceType __half = __len >> 1;
          _ForwardIterator __middle = __first;
          std::advance(__middle, __half);
          if (__comp(__middle, __val))
          {
            __first = __middle;
            ++__first;
            __len = __len - __half - 1;
          }
          else
            __len = __half;
        }
        return __first;
      }
  } // namespace

  template <typename _Iterator, typename _T> 
    _T binary_search_7(_Iterator begin, _Iterator end, _T const key) 
    {
      auto saved_begin = begin;
      auto length  = std::distance(begin, end);

      while (0 < length)
      {
        auto half = length >> 1;

        // cxx-advance
        _Iterator middle = begin;
        std::advance(middle, half);

        // error since: void advance().
        // ITERATOR middle = advance(first, half);

        if (*middle < key)
        {
          begin = ++middle;
          length = length - half - 1;
        }
        else
        {
          length = half;
        }
      }

      return std::distance(saved_begin, begin);
    }

  int binary_search_8(std::vector<int> &coll, int key)
  {
    int begin{};
    int length = coll.size();

    while (0 < length)
    {
      auto half = length >> 1;
      auto middle = begin + half;

      if (key > coll[middle])
      { 
        // update begin and work towards the right
        begin = ++middle;

        // note that length is length but not index
        length = length - half -1;
      }
      else
      {
        // work towards the left
        length = half;
      }
    }

    return begin;
  }

} // namespace

TEST(AlgoSearch, BinarySearch)
{
  using namespace algo_binary_search;

  // cxx-binary-search, stl version
  //
  // 11.10 Sorted-Range Algorithms
  //
  // The following algorithms search certain values in sorted ranges.  Checking
  // Whether One Element Is Present
  //
  // bool binary_search (ForwardIterator beg, ForwardIterator end, const T&
  // value)
  //
  // bool binary_search (ForwardIterator beg, ForwardIterator end, const T&
  // value, BinaryPredicate op)

  {
    //               0  1  2  3   4   5   6   7   8   9  10  11  12
    vector<int> coll{2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33};
    EXPECT_THAT(binary_search(coll.begin(), coll.end(), 15), true);
    EXPECT_THAT(binary_search(coll.begin(), coll.end(), 32), false);
  }


  // gt-version
  {
    //               0  1  2  3   4   5   6   7   8   9  10  11  12
    vector<int> coll{2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33};

    auto it = binary_search_1(coll.begin(), coll.end(), 15);
    EXPECT_THAT(std::distance(coll.begin(), it), 7);

    EXPECT_THAT(binary_search_1(coll.begin(), coll.end(), 32), 
        coll.end());
  }

  {
    //               0 1 2 3
    vector<int> coll{1,3,5,6};

    EXPECT_THAT(binary_search_1(coll.begin(), coll.end(), 2), 
        coll.end());
  }

  {
    //               0 1 2 3
    vector<int> coll{1,3,5,6};
    EXPECT_THAT(binary_search_2(coll.begin(), coll.end(), 5), 2);
    EXPECT_THAT(binary_search_2(coll.begin(), coll.end(), 2), 1);
    EXPECT_THAT(binary_search_2(coll.begin(), coll.end(), 7), 4);
    EXPECT_THAT(binary_search_2(coll.begin(), coll.end(), 0), 0);
  }

  {
    //               0 1 2 3
    vector<int> coll{1,3,5,6};
    EXPECT_THAT(binary_search_3(coll, 5), 2);
    EXPECT_THAT(binary_search_3(coll, 2), 1);
    EXPECT_THAT(binary_search_3(coll, 7), 4);
    EXPECT_THAT(binary_search_3(coll, 0), 0);
  }

  // equality-version
  {
    //               0  1  2  3   4   5   6   7   8   9  10  11  12
    vector<int> coll{2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33};

    auto it = binary_search_4(coll.begin(), coll.end(), 15);
    EXPECT_THAT(std::distance(coll.begin(), it), 7);

    EXPECT_THAT(binary_search_4(coll.begin(), coll.end(), 32), 
        coll.end());
  }
  // {
  //   //               0 1 2 3
  //   vector<int> coll{1,3,5,6};
  //   EXPECT_THAT(binary_search_5(coll.begin(), coll.end(), 5), 2);
  //   EXPECT_THAT(binary_search_5(coll.begin(), coll.end(), 2), 1);
  //   EXPECT_THAT(binary_search_5(coll.begin(), coll.end(), 7), 4);
  //   EXPECT_THAT(binary_search_5(coll.begin(), coll.end(), 0), 0);
  // }

  {
    //               0 1 2 3
    vector<int> coll{1,3,5,6};
    EXPECT_THAT(binary_search_6(coll, 5), 2);
    EXPECT_THAT(binary_search_6(coll, 2), 1);
    EXPECT_THAT(binary_search_6(coll, 7), 4);
    
    // when use size_t
    // /usr/include/c++/4.9/debug/vector:357:error: attempt to subscript container
    //     with out-of-bounds index 9223372036854775807, but container only holds 4
    //      elements.

    EXPECT_THAT(binary_search_6(coll, 0), 0);
  }
}

TEST(AlgoSearch, BinarySearchStl)
{
  using namespace algo_binary_search;

  // AlgoUpperLowerBound
  {
    vector<int> coll{1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9};

    //  0  1  2  3  4  5  6  7  8  9 10 11 12
    // {1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9};
    //                          ^^^^^^^
    // lower_bound() returns the position of the first element that has a value
    // equal to or greater than value. This is the first position where an
    // element with value could get inserted without breaking the sorting of the
    // range [beg,end).

    // : error: no matching function for call to 
    // ‘distance(std::vector<int>::iterator, __gnu_cxx::__normal_iterator<const int*, std::vector<int> >&)’
    // since lower_bound() uses cbegin().
    // EXPECT_THAT(distance(coll.begin(), first), 8);

    auto first = lower_bound(coll.cbegin(), coll.cend(), 5);
    EXPECT_THAT(*first, 5);
    EXPECT_THAT(distance(coll.cbegin(), first), 8);

    auto pos = binary_search_7(coll.begin(), coll.end(), 5);
    EXPECT_THAT(pos, 8);
  }
  {
    vector<int> coll{2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33};

    auto first = lower_bound(coll.cbegin(), coll.cend(), 1);
    EXPECT_THAT(*first, 2);

    EXPECT_THAT(binary_search_7(coll.begin(), coll.end(), 1), 0);
  }
  {
    //               0 1 2 3
    vector<int> coll{1,3,5,6};
    EXPECT_THAT(binary_search_7(coll.begin(), coll.end(), 5), 2);
    EXPECT_THAT(binary_search_7(coll.begin(), coll.end(), 2), 1);
    EXPECT_THAT(binary_search_7(coll.begin(), coll.end(), 7), 4);
    EXPECT_THAT(binary_search_7(coll.begin(), coll.end(), 0), 0);
  }

  {
    //               0 1 2 3
    vector<int> coll{1,3,5,6};
    EXPECT_THAT(binary_search_8(coll, 5), 2);
    EXPECT_THAT(binary_search_8(coll, 2), 1);
    EXPECT_THAT(binary_search_8(coll, 7), 4);
    EXPECT_THAT(binary_search_8(coll, 0), 0);
  }
}

// algo-leetcode-11
/*
35. Search Insert Position, Easy

Given a sorted array and a target value, return the index if the target is
found. If not, return the index where it would be if it were inserted in order.

You may assume no duplicates in the array.

Example 1:
Input: [1,3,5,6], 5
Output: 2

Example 2:
Input: [1,3,5,6], 2
Output: 1

Example 3:
Input: [1,3,5,6], 7
Output: 4

Example 4:
Input: [1,3,5,6], 0
Output: 0

*/

Runtime: 8 ms, faster than 99.32% of C++ online submissions for Search Insert
Position.

Memory Usage: 9.3 MB, less than 29.57% of C++ online submissions for Search
Insert Position.

int binary_search_8(std::vector<int> &coll, int key);


<formal-verification>
// Programming Pearl, p38
// see invariant, "{ mustbe(l, u) }" is maintained through the loop

{
  // {} means assertion

  { mustbe(0, n-1) }

  // l(lower), u(upper)

  l = 0; u = n -1

  { mustbe(l, u) }

  loop
  {
    { mustbe(l, u) }

    if l > u
    {
      { 1 > u && mustbe(l, u) }
      { t is not in the array }
      p = -1; break;
    }

    { mustbe(l, u) && l <= u }

    m = (l + u)/2

    { mustbe(l, u) && l <= m <= u }

    {
      case x[m] < t:
        { mustbe(l, u) && cantbe(0, m) }
        { mustbe(m+1, u) }
        l = m + 1;
        { mustbe(l, u) }

      case t == x[m]:
        { x[m] == t }
        p = m; break;

      case t < x[m]:
        { mustbe(l, u) && cantbe(m, n-1) }
        { mustbe(l, m-1) }
        u = m - 1;
        { mustbe(l, u) }
    }

    { mustbe(l, u) }
  }
}


={============================================================================
*kt_dev_algo_008* algo-ordered-list

{ordered-list-adt}
An `ordered-list` is a list in which each entry `contains-a-key`, such that the
keys are in order. That is, if entry i comes before entry j in the list, then
the key of entry i is less than or equal to the key of entry j. [min...max]

... [c] ...
  <  |  =>

void InsertOrder(List* list, ListEntry x)
{
  int current;
  ListEntry currententry;

  // searching.
  for( current=0; current < ListSize(*list); current++ )
  {
    currententry = RetrieveList(*list, current);
    if( LE(x.key, currententry.key )) or if( GT( current, insert ))
      break;
  }

  // inserting. use SetPostion( current-1 );
  InsertList(list, x, current);
}


={============================================================================
*kt_dev_algo_0000* algo-sort

<algo-sort-comparisons>

// VM

sort, 1.6.1, input size: 10000000, library version qsort
real    0m14.734s
user    0m11.484s
sys     0m0.060s

sort, 1.6.1, input size: 10000000, stl set container
real    0m43.617s
user    0m38.804s
sys     0m0.428s

*algo-sort-bigo*
sort, 1.6.1, input size: 10000000 array size: 1250004, bit set array version qsort
real    0m10.624s
user    0m8.384s
sys     0m0.016s

sort, 1.6.1, input size: 10000000, stl algorithm sort on std::vector
real    3m28.243s
user    3m20.356s
sys     0m0.032s

sort, 1.6.1, input size: 10000000, stl algorithm sort on std::vector via iterator
real    3m24.242s
user    3m21.280s
sys     0m0.028s

sort, 1.6.1, input size: 10000000, stl algorithm sort on array
real    0m14.751s
user    0m11.436s
sys     0m0.028s

sort, 1.6.1, input size: 10000000, ppp version qsort
real    0m14.552s
user    0m11.352s
sys     0m0.032s

sort, 1.6.1, input size: 10000000, ppp version heap sort
real    0m18.773s
user    0m15.524s
sys     0m0.016s



<ex>
A problem that is 'not' easy to solve is how to sort objects according to two
different sorting criteria.

The automatic sorting of associative containers does 'not' mean that these
containers perform better when sorting is needed. This is because an
associative container sorts 'each' time a new element gets inserted. An often
'faster' way is to use a sequence container and to sort 'all' elements 'after'
they are all inserted, by using one of the several sort algorithms

When I tried both programs with about 350,000 strings on one system, the
'vector' version was approximately 10% 'faster'. Inserting a call of reserve()
made the vector version 5% faster. 

Allowing duplicates - using a multiset instead of a set and calling copy()
instead of unique_copy(), respectively - changed things dramatically: The
vector version was more than 40% faster.  note: make both run fast

  "However, on 'another' system, the vector versions were up to 50% slower.
  These measurements are not representative, but they show that it is often
  'worth' trying 'different' ways of processing elements."


{algo-sort}

Here consider only internal sorting. Analysis concentrate on two actions:
comparison and changing pointers or moving entries. 

Sample sort question:

Given a very large array of Person objects, sort the people in increasing
order of age.

We are given two interesting bits of knowledge here. 

1: A large array, so efficiency is very important. 

2: Sorting based on ages, so we know the values are in a small range.

By scanning through the various sorting algorithms, we might notice that
bucket sort(radixsort) would be a perfect candidate for this problem. 
In fact, can make the buckets small(just 1 year each) and get O(n) running time.

The merge, quick, and bucket are the most commonly used in interviews.


{algo-sort-insertion}

From {ordered-list-adt}, the ordered list is ADT which has three more
operations since they use 'keys' rather than position to locate the entry:
retrieve, insert and sort. The retrieve and insert need searching and the list
must be ordered after insertion and deletion.

One method to do ordered insertion into a 'contiguous' ordered list is do
binary search to find the position since it is ordered and move entries to
make a space to insert. Finally insert new entry into the list. Since so much
time is needed to 'move' entries <no-matter-how-the-search-is-done>, it turns
out in many cases to be just as fast to use sequential search as binary
search: the search and the movement of entries can be combined in a single
loop, thereby reducing the overhead.

// {Q} how can we use binary search to find a position which is less than or
// greater than a key to insert? Think that unsorted set and sorted set and do
// binary search on sorted set with an entry from unsorted set. To do this,
// change binary search function to return any of bot, top, or middle whether
// or not binary search found a key since the returned position is either the
// last occurance of the key or the position which is less than big entry in
// the sorted set. <= [m] > when use GT in binary search. Then make a space at
// the position by moving down and insert.
// 
// Do not understand this now. The other is: two outcomes from binary search.
// when found, do not matter to insert a new before or after the found. when
// not found, compare the middle which is the last of search and decide after
// or before.


Move one entries from unsorted list to sorted list and use this observations:
`a list of length 1 is automatically ordered.`

[hen] sorted   [cow]           [cat]
$cow$ unsorted [hen] sorted    [cow]
$cat$          $cat$ unsoerted [hen] sorted
$ram$          $ram$           $ram$ unsorted
$ewe$          $ewe$           $ewe$
$dog$          $dog$           $dog$


<ex> 

// `current` starts from the unsorted and uses swap
// depending on > or < in `coll[current_index] < coll[current_index-1]` it
// sort decending or ascending.
void sort_insertion_03(vector<int> &coll)
{
  for (int unsorted_index = 1; unsorted_index < (int)coll.size(); ++unsorted_index)
    for (int current_index = unsorted_index;
        0 < current_index && coll[current_index] < coll[current_index-1];
        --current_index)
    {
      // swap current and current-1
      swap(coll[current_index], coll[current_index-1]);
    }
}

// https://www.codeproject.com/Articles/854127/Top-Beautiful-Cplusplus-std-Algorithms-Examples
void sort_insertion_04(vector<int> &coll)
{
  auto first = coll.begin();

  for (auto run = first; run != coll.end(); ++run)
    rotate(upper_bound(first, run, *run), run, next(run));
}

// From Programming Pearl 11.1
//
// for i = [1, n)
//  // invariant: x[0..i-1] is sorted
//  // shift x[i] down to its proper place in x[0..i]
//
// From the swap version which do two operations, move down elements and put the
// saved back when loop ends as 01/02 version. So one update rather than doing
// it every time which runs faster.

void sort_insertion_05(vector<int> &coll)
{
  int size = (int) coll.size(); 

  for (int unsorted_index = 1; unsorted_index < size; ++unsorted_index)
  {
    int unsorted = coll[unsorted_index];
    int current_index = unsorted_index;

    for (; 0 < current_index && unsorted < coll[current_index-1];
        --current_index)
    {
      // swap current and current-1
      // swap(coll[current_index], coll[current_index-1]);
      coll[current_index] = coll[current_index-1];
    }

    coll[current_index] = unsorted;

#ifdef SORT_INSERT_DEBUG
    cout << "coll(" << unsorted_index << ", " << current_index << "): ";

    for (int i = 0; i < size; ++i)
      cout << coll[i] << ", ";

    cout << endl;
#endif // SORT_INSERT_DEBUG
  }
}

// 2018.12.06
void sort_insertion_06(vector<int> &coll)
{
  size_t sorted{0}, unsorted{0};
  int target{0}, source{0};

  for (unsorted = 1; unsorted < coll.size(); ++unsorted, sorted = unsorted-1)
  {
    for (target = sorted, source = unsorted; target >= 0; --target, --source)
    {
      // ascending order
      if (coll[target] > coll[source])
        std::swap(coll[target], coll[source]);
      else
        break;
    }
  }
}

// when move comparison in for loop, can remove `else` as sort_insertion_03

void sort_insertion_07(vector<int> &coll)
{
  size_t sorted{0}, unsorted{0};
  int target{0}, source{0};

  for (unsorted = 1; unsorted < coll.size(); ++unsorted, sorted = unsorted-1)
  {
    // ascending order
    for (target = sorted, source = unsorted; 
        target >= 0 && coll[target] > coll[source]; --target, --source)
    {
      std::swap(coll[target], coll[source]);
    }
  }
}

template <typename T, typename F = std::greater<T>>
void sort_insertion_08(vector<T> &coll, F f)
{
  size_t sorted{0}, unsorted{0};
  int target{0}, source{0};

  for (unsorted = 1; unsorted < coll.size(); ++unsorted, sorted = unsorted-1)
  {
    // ascending order
    for (target = sorted, source = unsorted; 
        target >= 0 && f(coll[target], coll[source]); --target, --source)
    {
      std::swap(coll[target], coll[source]);
    }
  }
}

TEST(AlgoSort, Insertion_01)
{
  {
    vector<int> coll{ 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
    sort_insertion_05(coll);
    EXPECT_THAT(coll, 
        ElementsAreArray({2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 }));
  }
}


note:
This is similar to *algo-remove* *algo-partition* *algo-rotate* in that it
uses two partitions; one that is sorted or meets condition and the other that
is not.

where s is start and r is run

algo-sort-insertion, use swap to keep elements

| meet condition | not meet condition    |
|                | |                     |
                  s 

algo-remove, algo-unique, use assign(overwrite)

| not meet condition | meet condition    |
|                    | | |               |
                      s r

algo-partition, algo-gather, use swap

| meet condition | not meet condition    |
|                | | |                   |
                  s r

algo-rotate, algo-slide, use swap

| 1 | 2 | 3 |[4 | 5 | 6]| 7 | 8 | 9 |
| 1 | 2 |[4 | 5 | 6]| 7 | 8 | 9 | 3 |
| 1 |[4 | 5 | 6]| 7 | 8 | 9 | 2 | 3 |
...


<selection-sort>
The insertion-sort has major disadvantage: even after most entries have been sorted properly into
the sorted set, the insertion of a later entry may require that many of them should be moved because
the position of each entry is not a 'final' position. So would be far more efficient if an entry
being moved could be placed in its final position. How?

Start from empty sorted set which is different from insertion sort, scan unsorted list to find the
one that comes last in order; 'largest', alphabetical in this case. Swap this with the 'last' one of
the unsorted list. Repeat this until no more items in the unsorted list.

$hen$ scan and $hen$ *  $ewe$    ...
$cow$ swap     $cow$    $cow$
$cat$          $cat$    $cat$
$ram$ *        $dog$    $dog$ unsorted
$ewe$          $ewe$ *  [hen] sorted
$dog$ *        [ram]    [ram]

From {ref-004}, can do the opposite. Find the smallest and swap it with the first. Repeat it until
it is sorted.

<do> Write the below function using int array:
void SelectionSort(int* arr, int length);

// find the position of the largest key in the sublist
Position MaxKey(int begin, int end, int* arr);

// swap two entries in the contiguous list
void Swap(int begin, int end, int* arr);

<code> 

// the reference code from the book, p290.
void SelectionSort(List* list)
{
  Position current, max;

  // when the size of unsorted set is 1, means all sorted and do not need to do the last loop. Loop
  // size-1 times.
  for( current = list->count -1; current > 0; current-- )
  {
    max = MaxKey(0, current, list);
    Swap( max, current, list );
  }
}

// find the max whether or not input is positive or negative since picks up the first as a start.
// that is why 'low+1'
Position MaxKey( Position low, Position high, List* list )
{
  Position largest, current;

  largest = low;

  for( current = low+1; current <= high; current++ )
    if( LT( list->entry[largest].key, list->entry[current].key ))
      largest = current;

  return largest;
}

void Swap( Position low, Position high, List* list )
{
  ListEntry temp = list->entry[low];
  list->entry[low] = list->entry[high];
  list->entry[high] = temp;
}

// two. same as the reference but used array.
#include <iostream>

#define GT(x,y) ((x)>(y))
#define LT(x,y) ((x)<(y))
#define EQ(x,y) ((x)==(y))

typedef int Position;
typedef int Entry;

// expects start and end index
Position findPosofMax( Position start, Position end, int* array)
{
  Position max = start;

  for ( Position current = start+1; current <= end ; current++) 
  {
    if( GT( array[current], array[max] )) // when positive only, picks up the first of the array.
      max = current;
  }

  return max;
}

// expects start and end in index
void swapEntry( Position x, Position y, int* array )
{
  int xval = array[x];
  array[x] = array[y];
  array[y] = xval;
}

// expects the length of array. NO if in for loop.
void sortSelection(int* array, int length)
{
  for( ;length > 1; length--) {
    Position posMax = findPosofMax( 0, length-1, array );
    // std::cout << "posMax:length-1 = (" << posMax << ", " << length-1 << ")" << std::endl;
    swapEntry( posMax, length-1, array );
  }
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  sortSelection( arr, size );

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}

<code-three> outline by self
void ssort(list* list)
{
  int size = list->count-1;

  // use index. loop backwards until there is one unsorted
  for( int unsorted = size; unsorted > 0; unsorted-- )
  {
    // find the largest in [0, unsorted]
    int largest = max( 0, unsorted );

    // swap the largest with the the last of unsorted
    swap( largest, unsorted );
  }
}

note: must use swap and sorted set starts from empty.


<insertion-vs-selection>
The selection sort is useful for contiguous list with large entries for which movement of entries is
expensive since it uses fewer moves.

The selection do (n-1)x(n-2)x(n-3)x...x2x1 = 1/2*n(n-1) = 1/2*n^2+1/2n = 1/2*n^2+O(n) = 0.5n^2+O(n)
on comparisons. But the insertion do O(n2) for 'worst' case and less than this on average.

               comparison             moving
insertion         less                 more
selection         more                 less

If the entries are small, or if the list is linked, so that only pointers need be changed to sort
the list, then insertion-sort is usually faster than selection-sort since the insertion do more on
moving. For many applications, insertion can prove to be the best choice as easy to write and
maintain, runs efficiently for short list. Even for long list, if they are nearly in the correct
order, insertion will be very efficient. 

<key> insertion is generally better than selection.

<shell-sort>
This is an 'optimization' of insertion sort by reducing moves. How? Use increment(distance) between
keys to compare rather and when increment becomes 1, finally performs ordinary insertion sort. Each
pass moves elements 'close' to their final position so the sort goes rapidly. There is no magic
about choice of 'increment' and no complete the analysis of this. However, emprical studies shows
a subtantial improvement over insertion sort.

Unsorted    Sublist when inc is 5         5-sorted,      Recombined
 Tim        Tim                              Jim         Jim
 Dot              Dot                            ...     Dot
 Eva                    Eva                              Eva
 Roy                          Roy                        ...
 Tom                                Tom
 Kim        Kim                              Kim
 Guy              Guy
 Amy                    Amy
 Jon                          Jon
 Ann                                Ann
 Jim        Jim                              Tim
 Kay              Kay
 Ron                    Ron
 Jan                          Jan


As with insertion, shell checks on element(s) by increment towards beginning(backwards)
As with insertion, shell stops scanning backwards as soon as found a right place to insert.

                                    10                                  19
          0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18

g=9, i= 9, j=0 : v[0], v[ 9]               // start(unsorted)=9, 0
     i=10, j=1 : v[1], v[10]
     i=11, j=2 : v[2], v[11]
     i=12, j=3 : v[3], v[12]
     i=13, j=4 : v[4], v[13]
     i=14, j=5 : v[5], v[14]
     i=15, j=6 : v[6], v[15]
     i=16, j=7 : v[7], v[16]
     i=17, j=8 : v[8], v[17]
     i=18, j=9 : v[9], v[18] : v[0], v[9]  // start(unsorted)=18, 9, 0
g=4, i= 4, j=0 : v[0], v[ 4]
     i= 5, j=1 : v[1], v[ 5]
     ...
     i= 8, j=4 : v[4], v[ 8] : v[0], v[4]
     i= 9, j=5 : v[5], v[ 9] : v[1], v[5]
     ...
     i=12, j=8 : v[8], v[12] : v[4], v[8] : v[0], v[4]


<code>
// reference example, p294.
void ShellSort( List *list )
{
  int increment;
  Position start;

  increment = list->count;

  do {
    increment = increment/3 + 1;

    for( start = 0; start < increment; start++ )
      SortInterval( start, increment, list );

  } while( increment > 1 );
}

SortInterval is modified insertion sort except that the list starts at start instead of 0 and the
increment between successive values is as given instead of 1.

// shellsort from ansic, p62.
void ssort_one( int v[], int n )
{
  int gap, i, j, temp;

  for( gap = n/2; gap > 0; gap /= 2 )
    for( i = gap; i < n; i++ )
      for( j = i-gap; j >= 0 && v[j] > v[j+gap]; j -= gap )
      {
        temp = v[j];
        v[j] = v[j+gap];
        v[j+gap] = temp;
      }
}

// own implementation which extends insertion-sort
void ssort_two( int array[], int length )
{
  for( int gap = length/2; gap > 0; gap /= 2)
  {
    for( int unsorted = gap; unsorted < length; unsorted++ )
    {
      for( int key = unsorted; key-gap >= 0 && array[key] < array[key-gap]; key -= gap )
      {
        // swap
        int temp     = array[key];
        array[key]   = array[key-gap];
        array[key-gap] = temp;
      }
    }
  }
}


int main()
{
  { // <ssort_one>
    // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
    int arr[] = { 33, 28, 2, 31, 27, 5, 25, 19, 30, 11, 7, 34, 40, 6, 12, 10, 13, 15, 17, 29, 3 };
    int size = ( sizeof(arr)/sizeof(arr[0]) );

    ssort_one( arr, size );

    printf("{ ");
    for(int idx = 0; idx < size; idx++)
      printf( (idx < size-1) ? "%d, " : "%d ", arr[idx] );
    printf("}\n");
  }

  { // <ssort_two>
    // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
    int arr[] = { 33, 28, 2, 31, 27, 5, 25, 19, 30, 11, 7, 34, 40, 6, 12, 10, 13, 15, 17, 29, 3 };
    int size = ( sizeof(arr)/sizeof(arr[0]) );

    ssort_two( arr, size );

    printf("{ ");
    for(int idx = 0; idx < size; idx++)
      printf( (idx < size-1) ? "%d, " : "%d ", arr[idx] );
    printf("}\n");
  }
}


// the result
// { 2, 3, 5, 6, 7, 10, 11, 12, 13, 15, 17, 19, 25, 27, 28, 29, 30, 31, 33, 34, 40 }
// { 2, 3, 5, 6, 7, 10, 11, 12, 13, 15, 17, 19, 25, 27, 28, 29, 30, 31, 33, 34, 40 }


{algo-sort-merge} divide-and-conquer-sort

It is much easier to sort short list than long ones; divide and conquer. Two
methods which has two basic actions: partitioning and combining. sort-merge
does more work in combining and sort-quick does more work(sorting) in
partitioning.

Sort(list)
{
  if the list has length greater than 1 then
  {
    // partition the list into lowlist and highlist
    Sort(lowlist);
    Sort(highlist);
    Combine(lowlist, highlist);
  }
}


<recursion-tree> <algo-sort-merge-nlogn>
This is recursion-tree of 7 numbers. Combine() or merge part do most of work
and sort. This is an excellent method for 'external' sorting, linked list in
random order but spends significant time finding the center of the list. For
contiguous list, not an unqualified success because needs one of extra
space(temp) to merge, computer time, or programming effort in merging two
contiguous list. 

<Q> Why excellent for external?

The best time is O(nlogn)

                     start[down]   finish[up]
          <26 33 35 29 19 12 22> () 12 19 22 26 29 33 35
           list        second

     <26 33 35 29> () 26 29 33 35            <19 12 22> () 12 19 22
      list  second                           list

 <26 33> () 26 33  <35 29> () 29 35        ...
  list             list

[26] [33]        [35] [29]


<algo-sort-merge-linked-list>

From the reference book. Here list and secondhalf are list structure having a
head so not a problem when run recursive tree.

// sort linked list and the keys in all the entries are sorted into increasing
// order.

void MergeSort(List* list)
{
  List secondhalf;

  if( ListSize(list) > 1 )    // is there a need to sort? 2 at least
  {
    // divide the list into two parts. If list has an odd number of entries,
    // then its first half will be one entry larger than its second

    Divide( list, &secondhalf );

    MergeSort(list);          // when list size is 2, be called with 1 and has no effect
    MergeSort(&secondhalf);

    // merge two list producing a thrid list. first and second are ordered
    // linked list. out is an ordered list containing all entries that were in
    // first and second. The first and second have been destroyed.

    Merge( list, &secondhalf, list );  // see list used as out
  }
}


<combine>

namespace list_simple_linked_list_public
{
  // C version list from the reference

  typedef int ListEntry;

  typedef struct node {
    int       key;
    struct node *pnext;
  } ListNode;

  typedef struct {
    ListNode *header;
    int count;
  } List;

  void CombineList(List *first, List *last, List *result)
  {
    // handle when one of lists is empty
    if( !first->header )
    {
      *merged = *second;
      return;
    }
    else if ( !second->header ) 
    {
      *merged  = *first;
      return;
    }

    // handle first comparison
    ListNode *pfirst = first->header, *psecond = second->header;
    ListNode *psorted;

    if( LE( pfirst->key, psecond->key ) )
    {
      merged->header = pfirst;
      pfirst = pfirst->pnext;
    }
    else
    {
      merged->header = psecond;
      psecond = psecond->pnext;
    }

    psorted = merged->header;

    // sort until finish one of lists because first and second is alreay sorted itself
    while( pfirst && psecond )
    {
      if( LE( pfirst->key, psecond->key ) )
      {
        psorted->pnext = pfirst;
        psorted = pfirst;
        pfirst = pfirst->pnext;
      }
      else
      {
        psorted->pnext = psecond;
        psorted = psecond;
        psecond = psecond->pnext;
      }
    }

    // when one of lists are finished, simply append the other list to the sorted
    if(!pfirst)
      psorted->pnext = psecond;
    else
      psorted->pnext = pfirst;
  }
} // namespace


TEST(CollList, Devide)
{
  list<int> coll{26, 33, 35, 29, 19, 12, 22};
  auto slow = coll.begin();
  auto fast = next(slow);

  for(;fast != coll.end();)
  {
    ++fast;

    if (fast != coll.end())
    {
      ++fast;
      ++slow;
    }
  }

  list<int> coll1;
  list<int> coll2;

  // due to open end of iterator, increase one more compared to C version.
  ++slow;

  // c.splice(pos,c2, c2beg,c2end) 
  // Moves all elements of the range [c2beg,c2end) in c2 in
  // front of pos of list c (c and c2 may be identical)

  coll1.splice(coll1.begin(), coll, coll.begin(), slow);
  coll2.splice(coll2.begin(), coll, slow, coll.end());

  EXPECT_THAT(coll1, ElementsAre(26,33,35,29));
  EXPECT_THAT(coll2, ElementsAre(19,12,22));
}


/*
If List is proper class which has copy or move context then it would be easy to
implement this since can simply call result.Add() to create merged list.

However, this is for C and result is the same as first and have to handle with
care such as handle the first comparison.

{
  set current of first;
  set current of last;

  while (there is element in the first AND there is element in the last)
  {
    compare key between element from the first and the last;

    if (the one of the first is equal or greater then the one of the last)
    {
      then write the one of the last and get the next from the last;
    }

    if (the one of the first is less than the last)
    {
      then, write it out and get the next from the first;
    }
  }

  if (no more from the first and there are some from the last)
  {
    then write the rest of the last since the rest is already sorted;
  }
  else if (no more from the second and there are some from the first)
  {
    then write the rest of the first;
  }
  else
  {
    when both are finished;
  }

  set the end of the result for all caese;
}
*/

TEST(CollList, Combine)
{
  list<int> coll1{26,33,35,29};
  list<int> coll2{9,12,22};
  list<int> coll;

  auto first = coll1.begin();
  auto second = coll2.begin();

  while ((first != coll1.end()) && (second != coll2.end()))
  {
    if (*second <= *first)
    {
      coll.push_back(*second);
      ++second;
    }
    else
    {
      coll.push_back(*first);
      ++first;
    }
  }

  if ((first == coll1.end()) && (second != coll2.end())) 
  {
    coll.splice(coll.end(), coll2, second, coll2.end());
  }
  else if ((first != coll1.end()) && (second == coll2.end())) 
  {
    coll.splice(coll.end(), coll1, first, coll1.end());
  }
  else
  {
    // no left from both.
  }

  // combined
  EXPECT_THAT(coll, ElementsAre(9, 12, 22, 26, 33, 35, 29));
}


<mergesort-contiguous>
This is a java code from {ref-004}.

void MergeSort(int[] array, int low, int high)
{
  if (low < high) // 2 at least
  {
    int middle = (low+high)/2;
    MergeSort( array, low, middle );      // sort left
    MergeSort( array, middle+1, high );   // sort right
    Merge( array, low, middle, high );    // merge them
  }
}

small                 big
low        middle     high
[0.........x..........x]
left        right(middle+1)

void Merge( int[] array, int low, int middle, int high )
{
  int[] = helper = new int[array.length];

  for( int i = low; i <= high; i++ )
    helper[i] = array[i];

  int helperLeft = low, helperRight = middle+1;
  int current = low;

  while( helperLeft <= middle && helperRight <= high )
  {
    if( helper[helperLeft] <= helper[helperRight])	// [KT] used <=
    {
      array[current] = helper[helperLeft];
      helperLeft++;
    }
    else
    {
      array[current] = helper[helperRight];
      helperRight++;
    }

    current++;
  }

  // Similar to the linked version, should handle the remaining items. Why Left? Since all items
  // are already copied to the temp array and if done for the left part which has items with small
  // keys then no need to do the right part. So only check on left part.

  int remaining = middle - helperLeft;
  for( int i = 0; i <= remaining; i++ )
    array[current+i] = helper[helperLeft+i];
}


<code-eample>
When tried to do the same myself, got crashes.

#include < iostream>

#define GT(x,y) ((x)>(y))
#define LT(x,y) ((x)<(y))
#define EQ(x,y) ((x)==(y))

typedef int Position;
typedef int Entry;

unsigned int depthRecursion;
void PrintDepth( bool dash, unsigned int depth )
{
  for( unsigned int i=0; i <= depth; ++i)
  {
    if(dash)
      std::cout << "--";
    else
      std::cout << "  ";
  }

  if(dash)
    std::cout << "(" << depth << ") ";
  else
    std::cout << "      ";
}

// see the use of the same array in recursion but within the [start,end] for each iteration.
void Merge( Entry* array, Position length, Position start, Position middle, Position end )
{
  // have temp space for unsorted
  Entry out[length];
  int posLeft = start, posRight = middle+1;

  // [KT] got a crash when not init with start like int posCurrent;
  int posCurrent = start;

  PrintDepth( false, depthRecursion );
  std::cout << "Mege(" << length << ", " << start << ", " << middle << ", " << end << ")" << std::endl;

  // copy entries from array and out
  for(int pos = start; pos <= end; pos++)
    out[pos] = array[pos];

  // sort and copy entries
  while( posLeft <= middle && posRight <= end )
  {
    // [KT] use of LT which is different from the above but not matter. This sort cover the same
    // elements.
    if( LT( out[posLeft], out[posRight] ))
    {
      // [KT] use of posCurrent
      array[posCurrent] = out[posLeft];
      posLeft++;
    }
    else
    {
      array[posCurrent] = out[posRight];
      posRight++;
    }

    posCurrent++;

    // refactored
    // if( LT( out[posLeft], out[posRight] ))
    //   array[posCurrent++] = out[posLeft++];
    // else
    //   array[posCurrent++] = out[posRight++];
  }

  // [KT] 1st crash error since posCurrent can bigger if middle is big enough since used pos <=
  // middle but not pos <= remaining
  //for( int pos = middle - posLeft; pos <= middle;)
  // array[posCurrent++] = out[pos++];

  // [KT] 2nd crash error as the same above.
  //for( int pos = middle - posLeft; pos <= middle; pos++)
  //  array[posCurrent+pos] = out[posLeft+pos];

  // copy remaining entries in the left if they are. Only need to check on the left because the
  // right is already in array.
  int remaining = middle - posLeft;
  for( int pos = 0; pos <= remaining; pos++)
    array[posCurrent+pos] = out[posLeft+pos];
}

// this includes [start, end] and need length arg since need to have temp space.
void sortMerge( Entry* array, Position length, Position start, Position end )
{
  if( start < end )
  {
    depthRecursion++;
    PrintDepth( true, depthRecursion );

    int middle = (start + end )/2;

    // PrintDepth( false, depthRecursion );
    std::cout << "sortMerge(" << length << ", " << start << ", " << middle << ", " << end << ")" << std::endl;

    sortMerge( array, length, start, middle ); // [start, middle]
    sortMerge( array, length, middle+1, end ); // [middle+1, end]
    Merge( array, length, start, middle, end);

    depthRecursion--;
  }
}


int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  sortMerge( arr, size, 0, size-1 );

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}


{Q}
In an attempt to save sapce in Merge and changed to have a temp[start,end]. But didn't work as
planned. More wriedly, why size in main changes? Cannot reduce the size of temp array since combine
call use position left and right without adjustment when the sub array near to the right end which
has big start and end. So use the same length and the eaiser code.

void sortMerge( Entry* array, Position length, Position start, Position end )
{
  if( start < end )
  {
    depthRecursion++;
    PrintDepth( true, depthRecursion );

    int middle = (start + end )/2;

    // PrintDepth( false, depthRecursion );
    std::cout << "sortMerge(" << length << ", " << start << ", " << middle << ", " << end << ")" << std::endl;

    //sortMerge( array, length, start, middle );
    //sortMerge( array, length, middle+1, end );
    sortMerge( array, middle-start+1, start, middle );
    sortMerge( array, end-(middle+1)-1, middle+1, end );
    Merge( array, length, start, middle, end);

    depthRecursion--;
  }
}


int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  // int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 3 };
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  std::cout << "size: " << size << std::endl;

  sortMerge( arr, size, 0, size-1 );

  std::cout << "size: " << size << std::endl;

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}

size: 13
----(1) sortMerge(13, 0, 6, 12)
------(2) sortMerge(7, 0, 3, 6)
--------(3) sortMerge(4, 0, 1, 3)
----------(4) sortMerge(2, 0, 0, 1)
                Mege(2, 0, 0, 1)
----------(4) sortMerge(0, 2, 2, 3)
                Mege(0, 2, 2, 3)
              Mege(4, 0, 1, 3)
--------(3) sortMerge(1, 4, 5, 6)
----------(4) sortMerge(2, 4, 4, 5)
                Mege(2, 4, 4, 5)
              Mege(1, 4, 5, 6)
            Mege(7, 0, 3, 6)
------(2) sortMerge(4, 7, 9, 12)
--------(3) sortMerge(3, 7, 8, 9)
----------(4) sortMerge(2, 7, 7, 8)
                Mege(2, 7, 7, 8)
              Mege(3, 7, 8, 9)
--------(3) sortMerge(1, 10, 11, 12)
----------(4) sortMerge(2, 10, 10, 11)
                Mege(2, 10, 10, 11)
              Mege(1, 10, 11, 12)
            Mege(4, 7, 9, 12)
          Mege(13, 0, 6, 12)
size: 2 ~
{ 2, 5, }


<excution-tree-or-recursion-tree>
----(1) sortMerge(13, 0, 6, 12)
------(2) sortMerge(13, 0, 3, 6)
--------(3) sortMerge(13, 0, 1, 3)
----------(4) sortMerge(13, 0, 0, 1)
                Mege(13, 0, 0, 1)
----------(4) sortMerge(13, 2, 2, 3)
                Mege(13, 2, 2, 3)
              Mege(13, 0, 1, 3)
--------(3) sortMerge(13, 4, 5, 6)
----------(4) sortMerge(13, 4, 4, 5)
                Mege(13, 4, 4, 5)
              Mege(13, 4, 5, 6)
            Mege(13, 0, 3, 6)
------(2) sortMerge(13, 7, 9, 12)
--------(3) sortMerge(13, 7, 8, 9)
----------(4) sortMerge(13, 7, 7, 8)
                Mege(13, 7, 7, 8)
              Mege(13, 7, 8, 9)
--------(3) sortMerge(13, 10, 11, 12)
----------(4) sortMerge(13, 10, 10, 11)
                Mege(13, 10, 10, 11)
              Mege(13, 10, 11, 12)
            Mege(13, 7, 9, 12)
          Mege(13, 0, 6, 12)
{ 2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33, }


{algo-sort-quick}
This is `great for contiguous` list and the contiguous list is the most
important application for quicksort because prove to be fast and has the
advantage over contiguous mergesort of not requiring extra space, complicated
and difficult programming effort. Unlike mergesort, the size of the sublist
cannot be predicted in advance since it depends on pivot selection. 

*algo-sort-bigo* *algo-bigo*
Poor worst case, O(n2) and excellent average case `O(nlogn)`.

o uses swapping entries and keep sublists(subsets) in the same list so no
  extra space. 

o `sorted during partition; exclude pivot(lastsmall)` from next sort and it has
  `a final position.`
 
o choose different pivot for each sublist. 

o The final step of combining sorted list is not necessary.

o The sublists `are not sorted` and entry is `not in the final position`
  during running. 

o sublists are sorted via recursive quick sort call

o Compared with the mergesort, see that it has rather simple tree. Hence
  better.


<partioning> <choice-of-pivot> 
There are several methods but the algorithm we develop is much simpler and
easier to understand, and not slow; in fact it does the smallest possible
number of key comparisons of any partitioning algorithm. 

How to partition as evenly as possible?

This algorithm uses the `middle as a pivot and swap it to the first`, and do
partitioning.

The first is often a poor choice for pivot when the list is already sorted and
one of the sublists will be empty. Hence the careful choice of pivot to make
this worst case unlikey: use near the center of list as a pivot in the hope
that it will partition the keys so that about half come on each side of the
pivot. 

The average when applied to lists in random order turns out to be the best of
any sorting algorithms.

// note:
// not sure why the sorted input is worst since do almost comparison but swap
// calls can be different.
//
// Why is it better to have about half on each side? Otherwise, will end up
// with long and narrow comparison tree, meaning a chain which is a bad case
// for comparison tree. The worst case is when the keys are in their natural
// order or in their reverse order if choose the pivot as the first or the
// last key. 


To allow for the possibility that more than one entry has key equal to p, 

*algo-loop-invariant* 
the left of pivotpos have keys strictly less than p and the right have greater
than or equal to p


|  < p   | p |    p <=      |
low                      high

Suppose that pivot starts in the first position and leave it there
temporarily.

| p |  < p  *|   p <=   |* ?   |
low         lastsmall    i

When inspect i, there are two cases: 

o if the entry is >= p then simply increase i and maintain the property. 

o if the entry < p then restore the property by increasing pivotpos(lastsmall)
  and swapping it with entry i. 

note that swap happens when list[i] < p and 'lastsmall' starts from beginning.
swapping on the same index happens during this swap phase.


| p |  < p   |*| p <=   |*| ?  |
low           lastsmall  i

When loop ends, will have:

| p |           < p     |      >= p  | 
low                    lastsmall     

Then swap(low, lastsmall) and get 

|      < p     | p |      p <=       | 


<ex>
// From Programming Pearl 11.1

namespace algo_sort_quick
{

// #define SORT_QUICK_DEBUG

int build_partition(vector<int> &coll, int first, int last)
{
  int pivot_pos = (first + last) / 2;
  int pivot_value = coll[pivot_pos];

#ifdef SORT_QUICK_DEBUG
    cout << "pivot_pos(" << pivot_pos << ") build before(" << first << ", " << last << "): ";

    for (int i = first; i <= last; ++i)
      cout << coll[i] << ", ";

    cout << endl;
#endif // SORT_QUICK_DEBUG

  // move the pivot to the first pos
  swap(coll[first], coll[pivot_pos]);

  int last_small = first;

  for (int inspect = first + 1; inspect <= last; ++inspect)
  {
    // *cxx-less*
    if (coll[inspect] < pivot_value)
    {
      ++last_small;

      // last_small == inspect case does happens and it is enhancement from the
      // previous code

      if (last_small != inspect)
      {
        swap(coll[last_small], coll[inspect]);
      }
    }
  }

  // move the pivot back
  swap(coll[first], coll[last_small]);

#ifdef SORT_QUICK_DEBUG
    cout << "pivot_pos(" << pivot_pos << ") build after (" << first << ", " << last << "): ";

    for (int i = first; i <= last; ++i)
      cout << coll[i] << ", ";

    cout << endl;
#endif // SORT_QUICK_DEBUG

  return last_small;
}

int build_partition_descending(vector<int> &coll, int first, int last)
{
  int pivot_pos = (first + last) / 2;
  int pivot_value = coll[pivot_pos];

  // move the pivot to the first pos
  swap(coll[first], coll[pivot_pos]);

  int last_small = first;

  for (int inspect = first + 1; inspect <= last; ++inspect)
  {
    // *cxx-greater*
    if (coll[inspect] > pivot_value)
    {
      ++last_small;

      // last_small == inspect case does happens and it is enhancement from the
      // previous code

      if (last_small != inspect)
      {
        swap(coll[last_small], coll[inspect]);
      }
    }
  }

  // move the pivot back
  swap(coll[first], coll[last_small]);

  return last_small;
}

void sort_quick_01(vector<int> &coll, int first, int last)
{
  int last_small{};

  if (first < last)
  {
    last_small = build_partition(coll, first, last); 
    sort_quick_01(coll, first, last_small-1);
    sort_quick_01(coll, last_small+1, last);
  }
}

void sort_quick_01_descending(vector<int> &coll, int first, int last)
{
  int last_small{};

  if (first < last)
  {
    last_small = build_partition_descending(coll, first, last); 
    sort_quick_01_descending(coll, first, last_small-1);
    sort_quick_01_descending(coll, last_small+1, last);
  }
}

// from ansic, p87. exactly same way.
void sort_quick_02(vector<int> &v, int left, int right)
{
  int i, last;

  // do nothing if array contains fewer than two elements
  if( left >= right )
    return;

  // move partition elem
  // swap( v, left, (left+right)/2 );
  swap( v[left], v[(left+right)/2]);

  last = left;  // to v[0]

  // partition
  for(i = left+1; i <= right; i++)
    if( v[i] < v[left] )
    {
      // swap( v, ++last, i );   // shall ++last
      swap(v[++last], v[i]);   // shall ++last
    }

  // restore partition elem
  // swap(v, left, last);
  swap(v[left], v[last]);

  sort_quick_02( v, left, last-1 );
  sort_quick_02( v, last+1, right );
}

} // namespace

TEST(AlgoSort, Quick)
{
  using namespace algo_sort_quick;

  // pivot_pos(3) build before(0, 6): 29, 33, 35, |26|, 19, 12, 22,
  // pivot_pos(3) build after (0, 6): 22, 19, 12, 26, 33, 35, 29,
  // pivot_pos(1) build before(0, 2): 22, |19|, 12,
  // pivot_pos(1) build after (0, 2): 12, 19, 22,
  // pivot_pos(5) build before(4, 6):                 33, |35|, 29,
  // pivot_pos(5) build after (4, 6):                 29, 33, 35,
  // pivot_pos(4) build before(4, 5):                 |29|, 33,
  // pivot_pos(4) build after (4, 5):                 29, 33,
  //                                  12  19  22  26  29  33  35

  {
    vector<int> coll{29, 33, 35, 26, 19, 12, 22};

    sort_quick_01(coll, 0, coll.size()-1);

    EXPECT_THAT(coll, 
        ElementsAre(12, 19, 22, 26, 29, 33, 35));
  }

  {
    vector<int> coll{29, 33, 35, 26, 19, 12, 22};

    sort_quick_01_descending(coll, 0, coll.size()-1);

    EXPECT_THAT(coll, 
        ElementsAre(35, 33, 29, 26, 22, 19, 12));
  }

  // build i(0, 12): 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6,
  // build o(0, 12): 6, 2, 5, 6, 10, 12, 30, 33, 13, 15, 17, 29, 31,
  // build i(0, 4): 6, 2, 5, 6, 10,
  // build o(0, 4): 2, 5, 6, 6, 10,
  // build i(2, 4): 6, 6, 10,
  // build o(2, 4): 6, 6, 10,
  // build i(3, 4): 6, 10,
  // build o(3, 4): 6, 10,
  // build i(6, 12): 30, 33, 13, 15, 17, 29, 31,
  // build o(6, 12): 13, 15, 33, 30, 17, 29, 31,
  // build i(8, 12): 33, 30, 17, 29, 31,
  // build o(8, 12): 17, 30, 33, 29, 31,
  // build i(9, 12): 30, 33, 29, 31,
  // build o(9, 12): 31, 30, 29, 33,
  // build i(9, 11): 31, 30, 29,
  // build o(9, 11): 29, 30, 31,

  {
    vector<int> coll{30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6};

    sort_quick_01(coll, 0, coll.size()-1);

    EXPECT_THAT(coll, 
        ElementsAreArray({2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33}));
  }

  // when input is already sorted
  //
  // build i(0, 12): 2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33,
  // build o(0, 12): 2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33,
  // build i(0, 5): 2, 5, 6, 6, 10, 12,
  // build o(0, 5): 2, 5, 6, 6, 10, 12,
  // build i(0, 1): 2, 5,
  // build o(0, 1): 2, 5,
  // build i(3, 5): 6, 10, 12,
  // build o(3, 5): 6, 10, 12,
  // build i(7, 12): 15, 17, 29, 30, 31, 33,
  // build o(7, 12): 15, 17, 29, 30, 31, 33,
  // build i(7, 8): 15, 17,
  // build o(7, 8): 15, 17,
  // build i(10, 12): 30, 31, 33,
  // build o(10, 12): 30, 31, 33,

  {
    vector<int> coll{2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33};

    sort_quick_01(coll, 0, coll.size()-1);

    EXPECT_THAT(coll, 
        ElementsAreArray({2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33}));
  }
}


Programming Pearl, 11.3 Better Quicksorts

The algo-sort-quick sorts an array of random integers, O(nlogn), but how does
it perform on non-random inputs? An extreme case: an array of n identical
elements. Insertion sort performs very well on this input: each element is
sifted down zero positions, so the total run time is O(n). The quicksort, on
the other hand, blows this case badly. Each of n-1 partitioning passes uses
O(n) time to peel off a single element, so the total run time is O(n^2).


{algo-sort-heap}

From Programming Pearls, Column 14

A heap is a data structure for representating a collection of items and the
elements in the heap  may be of any ordered type. Use to solve two important
problems:

*algo-sort-bigo* *algo-bigo*

o sorting. heap sort never takes more than O(nlogn)

o priority queue. inserting new elements and exttracting the smallest elements
  in the set. each requires O(logn), O(nlogn) for n

// map                 O(log(n))       O(log(n))+                    bi
// multimap                            O(log(n))+                    bi
// set                                 O(log(n))+                    bi
// multiset                            O(log(n))+                    bi


The heap has two properties

o order

the value at any node is `less than or equal` to the values of the children;
left or right. This means that the least element is at the root of the tree.


o shape

a binary tree with the shape property has its terminal nodes on at most two
levels, with those on the bottom level as far as left as possoble. 

(that is terminal nodes are within two levels and those on the bottom level
 are as far as left.)

          12
     /         \ 
    20         15
   /   \      / \
  29   23    17  22
 / \   / \   /            1   2   3   4   5   6   7   8   9  10  11  12
35 40 26 51 19          {12, 20, 15, 29, 23, 17, 22, 35, 40, 26, 51, 19}

root = 1                // use one-based array and waste x[0]
value(i) = x[i]
leftchild(i) = 2i
rightchild(i) = 2i + 1
parent(i) = i/2
null(i) = i < 1 or i > n (n is current size of heap)

<two-functions>

o siftup()
  re-establish the heap property when inserts a new element. sifts the new up
  the tree as far as it should go, swapping it with its parent along the way.
  contines until it is `greater than or equal to` is parent or it is at the
  root of the tree.

  // n is the size of set after insertion
  void siftup(n):

  // pre    n > 0 && heap(1, n-1)
  // post   heap(1, n)

  i = n

  loop:
  // invariant: heap(1, n) except perhaps between i and its parent
  // where i be the index of the new

    // reaches at the top
    if i == 1
      break
    
    p = i / 2

    // terminate when meet heap property
    if x[p] <= x[i]
      break;

    swap(p, i);

    // i and p are index and update i
    i = p;


o siftdown()
  assign(insert) a new value to x[i] when x[1..n] is a heap which leaves
  heap(2,n)

  void siftdown(n)

  // pre    heap(2, n) && n >= 0
  // post   heap(1, n)
  
  i = 1

  loop:
  // invariant: heap(1, n) except perhaps between i and its (0, 1, or 2)
  // children
  
  // c is the left child of i
  c = 2 * i

  // terminate the loop if it has none of children
  if c > n
    break

  // c+1 is the right child of i
  if c+1 <= n

    // if i does have children, set c to the lesser child of i
    if x[c+1] < x[c]
      c++

  // c is the lesser child of i

  // terminate when meet heap property
  if x[i] <= x[c]
    break

  swap(i, c);

  i = c;

<ex>  

// while version
void siftup_01(vector<int> &coll, int n)
{
  int i = n;
  int p = i / 2;

  for (; (i != 1) && (coll[i] <= coll[p]);)
  {
    swap(coll[i], coll[p]);
    i = p;
    p = i / 2;
  }
}

void siftup_02(vector<int> &coll, int n)
{
  int i = n;
  int p = i / 2;

  while (i != 1 && coll[i] <= coll[p])
  {
    swap(coll[i], coll[p]);
    i = p;
    p = i / 2;
  }
}

// // for version, (cxx-error) 
// void siftup_01(vector<int> &coll, int n)
// {
//   int i = n;
//   int p = i / 2;
// 
//   for (; (i != 1) && (coll[i] <= coll[p]); i = p)
//   {
//     swap(coll[i], coll[p]);
//     p = i / 2;
//   }
// 
//   // effectively this and should update p after i so this is an error
//   //
//   // for (; (i != 1) && (coll[i] <= coll[p]);)
//   // {
//   //   swap(coll[i], coll[p]);
//   //   p = i / 2;
//   //   i = p;
//   // }
// }

// // for version, (cxx-error) 
// void siftup_01_error(vector<int> &coll, int n)
// {
//   int i = n;
//   int p = i / 2;
// 
//   // for (; (i != 1) && (coll[i] <= coll[p]); i = p)
//   // {
//   //   p = i / 2;
//   //   swap(coll[i], coll[p]);
//   // }
// 
//   // effectively this and cause error since has different pair of i and p in
//   // check of the lopp.
//   for (; (i != 1) && (coll[i] <= coll[p]);)
//   {
//     p = i / 2;
//     swap(coll[i], coll[p]);
//     i = p;
//   }
// }

// for version from text
void siftup_min_text(vector<int> &coll, int n)
{
  int i, p;
  for (i = n; i > 1 && coll[p = i/2] > coll[i]; i = p)
    swap(coll[i], coll[p]);
}


void siftdown_01(vector<int> &coll, int n)
{
  int i = 1;
  int c = i * 2;

  if (c+1 <= n)
    if (coll[c] > coll[c+1])
      c++;

  while ((c < n) && (coll[i] > coll[c]))
  {
    swap(coll[i], coll[c]);

    i = c;

    c = i * 2;

    if (c+1 <= n)
      if (coll[c] > coll[c+1])
        c++;
  }
}

// void siftdown_01(vector<int> &coll, int n)
// {
//   int i = 1;
//   int c = i * 2;
// 
//   if (c+1 <= n)
//     if (coll[c] > coll[c+1])
//       c++;
// 
//   for (; (c < n) && (coll[i] > coll[c]); i = c)
//   {
//     swap(coll[i], coll[c]);
// 
//     if (c+1 <= n)
//       if (coll[c] > coll[c+1])
//         c++;
// 
//     c = i * 2;
//   }
// }


void siftdown_min_text(vector<int> &coll, int n)
{
  int c;

  for (int i = 1; (c = i*2) <= n; i = c)
  {
    if (c+1 <= n && coll[c] > coll[c+1])
      c++;

    if (coll[i] <= coll[c])
      break;

    swap(coll[i], coll[c]);
  }
}


TEST(Heap, SiftUp)
{
  {
    // not use coll[0], 13 elements 
    vector<int> coll{0, 12, 20, 15, 29, 23, 17, 22, 35, 40, 26, 51, 19};
    // +1, 14 elements
    coll.push_back(13);

    // range is [1, 13]
    siftup_01(coll, 13);

    //                   {0, 12,/20, 13,/29, 23, 15, 22,/35, 40, 26, 51, 19, 17}
    EXPECT_THAT(coll, 
        ElementsAreArray({0, 12, 20, 13, 29, 23, 15, 22, 35, 40, 26, 51, 19, 17}));
  }

  {
    // not use coll[0], 13 elements 
    vector<int> coll{0, 12, 20, 15, 29, 23, 17, 22, 35, 40, 26, 51, 19};
    // +1, 14 elements
    coll.push_back(13);

    siftup_min_text(coll, 13);

    //                   {0, 12,/20, 13,/29, 23, 15, 22,/35, 40, 26, 51, 19, 17}
    EXPECT_THAT(coll, 
        ElementsAreArray({0, 12, 20, 13, 29, 23, 15, 22, 35, 40, 26, 51, 19, 17}));
  }
}

TEST(Heap, SiftDown)
{
  {
    // when did x[1] = 18
    vector<int> coll{0, 18, 20, 15, 29, 23, 17, 22, 35, 40, 26, 51, 19};
    siftdown_01(coll, coll.size()-1);
    EXPECT_THAT(coll,
        ElementsAreArray({0,15,20,17,29,23,18,22,35,40,26,51,19}));
  }
  {
    // when did x[1] = 18
    vector<int> coll{0, 18, 20, 15, 29, 23, 17, 22, 35, 40, 26, 51, 19};
    siftdown_min_text(coll, coll.size()-1);
    EXPECT_THAT(coll,
        ElementsAreArray({0,15,20,17,29,23,18,22,35,40,26,51,19}));
  }
}


// template <typename T>
// class PriQueue {
//   public:
//     PriQueue(int m)
//     {
//       maxsize_ = m;
//       x_ = new T[maxsize_ +1];
//       n_ = 0;
//     }
// 
//     void insert(T t)
//     {
//       if (n_ >= maxsize_)
//         error;
// 
//       x_[++n] = t;
// 
//       // pre : heap(1, n-1)
//       siftup();
//       // post: heap(1, n)
//     }
// 
//     int extractmin()
//     {
//       T t;
// 
//       if (n_ < 1)
//         error;
// 
//       t = x_[1];
// 
//       x_[1] = x[n--];
// 
//       // pre : heap(2, n)
//       siftdown();
//       // post: heap(1, n)
// 
//       return t;
//     }
// 
//   private:
//     int n_, maxsize_;
//     T *x_;
// };

template <typename T>
class PriQueue {
  public:
    PriQueue(int size)
    {
      maxsize_ = size;
      coll_ = new T[maxsize_ +1];
      n_ = 0;
    }
    ~PriQueue()
    {
      if (coll_)
        delete coll_;
      n_ = 0;
    }

    void insert(T value)
    {
      int parent{};

      // error
      if (n_ >= maxsize_)
        return;

      coll_[++n_] = value;

      // heap(1, n-1)
      // siftup()
      // heap(1, n)
      // siftup(n) 
      for (int i = n_; i > 1 && coll_[i] < coll_[parent = i/2]; i = parent) 
        swap(coll_[i], coll_[parent]);
    }

    int extractmin()
    {
      T min_value{};
      int child{};

      // error
      if (n_ < 1)
        return -1;

      min_value = coll_[1];

      coll_[1] = coll_[n_--];

      // heap(2, n)
      // siftdown(n)
      // heap(1,n)

      for (int i = 1; (child = i*2) <= n_; i = child)
      {
        if (child+1 <= n_ && coll_[child] > coll_[child+1])
          child++;

        if (coll_[i] <= coll_[child])
          break;

        swap(coll_[i], coll_[child]);
      }

      return min_value;
    }

  private:
    int n_, maxsize_;
    T *coll_;
};


// simply use `opposite` comparisons
template <typename T>
class PriQueueMax {
  public:
    PriQueueMax(int size)
    {
      maxsize_ = size;
      coll_ = new T[maxsize_ +1];
      n_ = 0;
    }
    ~PriQueueMax()
    {
      if (coll_)
        delete coll_;
      n_ = 0;
    }

    void insert(T value)
    {
      int parent{};

      // error
      if (n_ >= maxsize_)
        return;

      coll_[++n_] = value;

      // heap(1, n-1)
      // siftup()
      // heap(1, n)
      // siftup(n) 
      for (int i = n_; i > 1 && coll_[i] > coll_[parent = i/2]; i = parent) 
        swap(coll_[i], coll_[parent]);
    }

    int extractmin()
    {
      T min_value{};
      int child{};

      // error
      if (n_ < 1)
        return -1;

      min_value = coll_[1];

      coll_[1] = coll_[n_--];

      // heap(2, n)
      // siftdown(n)
      // heap(1,n)

      for (int i = 1; (child = i*2) <= n_; i = child)
      {
        if (child+1 <= n_ && coll_[child] < coll_[child+1])
          child++;

        if (coll_[i] >= coll_[child])
          break;

        swap(coll_[i], coll_[child]);
      }

      return min_value;
    }

  private:
    int n_, maxsize_;
    T *coll_;
};


template <typename T, typename F = std::less<T>>
class PriQueueTemplate {
  public:
    PriQueueTemplate(int size)
    {
      maxsize_ = size;
      coll_ = new T[maxsize_ +1];
      n_ = 0;
      f_ = F();
    }
    ~PriQueueTemplate()
    {
      if (coll_)
        delete coll_;
      n_ = 0;
    }

    void insert(T value)
    {
      int parent{};

      // error
      if (n_ >= maxsize_)
        return;

      coll_[++n_] = value;

      // heap(1, n-1)
      // siftup()
      // heap(1, n)
      // siftup(n) 
      for (int i = n_; i > 1 && f_(coll_[i], coll_[parent = i/2]); i = parent) 
        swap(coll_[i], coll_[parent]);
    }

    int extractmin()
    {
      T min_value{};
      int child{};

      // error
      if (n_ < 1)
        return -1;

      min_value = coll_[1];

      coll_[1] = coll_[n_--];

      // heap(2, n)
      // siftdown(n)
      // heap(1,n)

      for (int i = 1; (child = i*2) <= n_; i = child)
      {
        if (child+1 <= n_ && !f_(coll_[child], coll_[child+1]))
          child++;

        if (f_(coll_[i], coll_[child]) || coll_[i] == coll_[child])
          break;

        swap(coll_[i], coll_[child]);
      }

      return min_value;
    }

  private:
    int n_, maxsize_;
    T *coll_;
    F f_;
};


TEST(Heap, PriQueue)
{
  // min
  {
    vector<int> coll;

    int n = 10;
    PriQueue<int> pq(n);

    for (int i = 0; i < n; ++i)
      pq.insert(i);

    for (int i = 0; i < n; ++i)
      coll.push_back(pq.extractmin());

    EXPECT_THAT(coll, ElementsAreArray({0,1,2,3,4,5,6,7,8,9}));
  }
  {
    vector<int> coll{4,5,6,7,8,9,1,2,3,0};
    vector<int> collo;

    int n = 10;
    PriQueue<int> pq(n);

    for (int i = 0; i < n; ++i)
      pq.insert(coll[i]);

    for (int i = 0; i < n; ++i)
      collo.push_back(pq.extractmin());

    EXPECT_THAT(collo, ElementsAreArray({0,1,2,3,4,5,6,7,8,9}));
  }

  // max
  {
    vector<int> coll;

    int n = 10;
    PriQueueMax<int> pq(n);

    for (int i = 0; i < n; ++i)
      pq.insert(i);

    for (int i = 0; i < n; ++i)
      coll.push_back(pq.extractmin());

    EXPECT_THAT(coll, ElementsAreArray({9,8,7,6,5,4,3,2,1,0}));
  }
  {
    vector<int> coll{4,5,6,7,8,9,1,2,3,0};
    vector<int> collo;

    int n = 10;
    PriQueueMax<int> pq(n);

    for (int i = 0; i < n; ++i)
      pq.insert(coll[i]);

    for (int i = 0; i < n; ++i)
      collo.push_back(pq.extractmin());

    EXPECT_THAT(collo, ElementsAreArray({9,8,7,6,5,4,3,2,1,0}));
  }

  // min, template
  {
    vector<int> coll;

    int n = 10;
    PriQueueTemplate<int> pq(n);

    for (int i = 0; i < n; ++i)
      pq.insert(i);

    for (int i = 0; i < n; ++i)
      coll.push_back(pq.extractmin());

    EXPECT_THAT(coll, ElementsAreArray({0,1,2,3,4,5,6,7,8,9}));
  }
  {
    vector<int> coll{4,5,6,7,8,9,1,2,3,0};
    vector<int> collo;

    int n = 10;
    PriQueueTemplate<int> pq(n);

    for (int i = 0; i < n; ++i)
      pq.insert(coll[i]);

    for (int i = 0; i < n; ++i)
      collo.push_back(pq.extractmin());

    EXPECT_THAT(collo, ElementsAreArray({0,1,2,3,4,5,6,7,8,9}));
  }

  // max, template
  {
    vector<int> coll;

    int n = 10;
    PriQueueTemplate<int, std::greater<int>> pq(n);

    for (int i = 0; i < n; ++i)
      pq.insert(i);

    for (int i = 0; i < n; ++i)
      coll.push_back(pq.extractmin());

    EXPECT_THAT(coll, ElementsAreArray({9,8,7,6,5,4,3,2,1,0}));
  }
  {
    vector<int> coll{4,5,6,7,8,9,1,2,3,0};
    vector<int> collo;

    int n = 10;
    PriQueueTemplate<int, std::greater<int>> pq(n);

    for (int i = 0; i < n; ++i)
      pq.insert(coll[i]);

    for (int i = 0; i < n; ++i)
      collo.push_back(pq.extractmin());

    EXPECT_THAT(collo, ElementsAreArray({9,8,7,6,5,4,3,2,1,0}));
  }
}


void sort_heap_min(vector<int> &coll)
{
  int n = coll.size() - 1;

  // convert input to heap
  for (int i = 2; i <= n; ++i)
    siftup_min_text(coll, i);

  // // convert heap to sorted
  // for (int i = n; i > 1; --i)
  // {
  //   swap(coll[1], coll[i]);
  //   siftdown_min_text(coll, i-1);
  // }

  // convert heap to sorted
  for (int i = n; i > 1;)
  {
    swap(coll[1], coll[i]);
    siftdown_min_text(coll, --i);
  }
}

TEST(Heap, Sort)
{
  {
    // add the dummpy at 0 to make heap
    vector<int> coll{0,4,5,6,7,8,9,1,2,3,0};

    sort_heap_min(coll);

    // descending order
    EXPECT_THAT(coll, ElementsAreArray({0,9,8,7,6,5,4,3,2,1,0}));
  }
  
  // max verison will make ascending order
  //
  // {
  //   // add the dummpy at 0 to make heap
  //   vector<int> coll{0,4,5,6,7,8,9,1,2,3,0};
  //
  //   sort_heap_02(coll);
  //
  //   EXPECT_THAT(coll, ElementsAreArray({0,0,1,2,3,4,5,6,7,8,9}));
  // }
  // {
  //   vector<int> coll{ 0, 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
  //   sort_heap_02(coll); 
  //   EXPECT_THAT(coll, 
  //       ElementsAreArray({0, 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 }));
  // }
}


TEST(AlgoHeap, Calls)
{
  vector<int> coll{3, 4, 5, 6, 7, 5, 6, 7, 8, 9, 1, 2, 3, 4};

  // convert collection into a heap
  //
  // note that the default uses *std-less* and this makes `max version` as can
  // see here.
  
  make_heap(coll.begin(), coll.end());
  EXPECT_THAT(coll, ElementsAreArray({9, 8, 6, 7, 7, 5, 5, 3, 6, 4, 1, 2, 3, 4}));

  // pop next element, root, out of the heap
  //
  // Both forms move the highest element of the heap [beg,end), which is the
  // first element, to the last position and create a new heap from the
  // remaining elements in the range [beg,end-1).

  pop_heap(coll.begin(), coll.end());
  coll.pop_back();
  EXPECT_THAT(coll, ElementsAreArray({8,7,6,7,4,5,5,3,6,4,1,2,3}));

  // push new element into the heap
  coll.push_back(17);
  push_heap(coll.begin(), coll.end());
  EXPECT_THAT(coll, ElementsAreArray({17,7,8,7,4,5,6,3,6,4,1,2,3,5}));

  // convert heap into a sorted collection but note that after this, it is no
  // lonner a heap
  sort_heap(coll.begin(), coll.end());
  EXPECT_THAT(coll, ElementsAreArray({1,2,3,3,4,4,5,5,6,6,7,7,8,17}));
}


{algo-sort-summary}

o in choosing a method, take into account the ways in which the keys will
  usually be arranged before sorting, the size of application, the amount of
  time available for programming, the need to save computer time and space.
  Futhermore, see statistical analysis such as standard deviation and
  empirical testing.

o merge, quick and heapsort are powerful and efficient but more difficult to
  program when applied to large lists.

o algo-sort-heap is like an insurance: usually slower than algo-sort-quick but
  guarantees that sorting will be completed in O(nlogn) comparison of keys,
  something that quicksort cannot always do.


={============================================================================
*kt_dev_algo_010* table and hash

{logn-barrier}
As seen in binary search, by use of key comparisons alone, impossible to complete a search of n
items in fewer than logn on average: <binary-search-comparison-which-is-better>

The table lookup and searching share the same purpose: information retrieval. Searching uses key
comparison, whereas table lookup do not. Here assumes that each entry has only ''one'-key. The table
look-up is O(1) and can be more efficient than any searching method. Provides functions from set of
'keys' to 'location' of the entry.

Here study ways to implement and access tables in contiguous storage.


{index-function} {access-table}
Think a representation of rectangular array in a computer since computer storage is in a contiguous
sequence. So about how a way to store and read a rectangular table. 

This is row-major ordering. m x n where the columns from 0 to n-1:

Entry(i,j) goes to position ni+j

A formular of this kind is called index function. Rather than calculate index, can have a table
having pre-calculated-index then used for all later references. This is called an access-table to
eliminate the calculations.

rectangular    access table
array
[cost]    ->   [0]                  [costareatear] 
[area]         [4]                   0   4   8 
[tear]         [8]

This index function or access table describes mapping meaning that can represent various shape of
array. For example, triangular matrix(table).


{multiple-access-table} multikey-access-array
Consider the problem faced by the telephone company in accessing the records of its customers. To
publish the telephone book, the records must be sorted alphabetically by the name but to process
long-distance charges, the accounts must be sorted by telephone number. The company could keep
three(or more) set of its records, one sorted by name, one by number, and one by address. Doing this
would, however, not only be very wasteful of storage but it would introduce endless headaches if one
set of records were updated but another was not. note: each set has actuall copy of records.

By using access arrays we can avoid the multiple sets of records, and we can still find the records
by any of the three keys almost as quickly as if the records were fully sorted by that key. note:
this only has access array for each key and has only one set of records as with having pointers.

There is no particular reason why the records themselves need to be sorted according to one key
rather than another, or, in fact, why they need to be sorted at all. The records themselves can be
kept in an arbitrary order.

There is no reason why the records themselves need to be sorted according to one key rather than
another and also no difference whether the records are in array or in dynamic storage with the
access tables holding pointers to records.

It also makes no difference whether the records are in an array, with entries in the access arrays
being indices of the array, or whether the records are in dynamic storage, with the access arrays
holding pointers to individual records. In any case, it is the 'access' arrays that are used for
information retrieval, and, as ordinary contiguous arrays, they may be used for table lookup, or
binary search, or any other purpose for which a contiguous implementation is appropriate.

index    name     address     phone
1        Hill     High...     2829478
2        Baker    17 King     2884285
...
7        Moody    High King   2822214


access array(tables)

name     address     phone
2        3           5 
6        7           7
1        1           1
5        4           4
4        2           2
7        5           3
3        6           6


{table-adt}
This table is ADT which has 'domain'(index set) and the 'codomain'(base type or value type). A table
with index set I and base type T is a 'function' from I into T; which maps elements of domain to one
of codomain.

The table is ADT which has domain(index set) and the codomain(base type or value type). If, for
example, we have the array declaration

double array[n];

then the index set is the set of integers between 0 and n - 1, and the base type is the set of all
real numbers.

<definition>
A table with index set I and base type T is a 'function' from I into T; which maps elements of domain
to one of codomain.

1. Table access: Evaluate the function at any index in I .
2. Table assignment: Modify the function by changing its value at a specified index in I to the new
value specified in the assignment.
3. Creation: Set up a new function from I to T .
4. Clearing: Remove all elements from the index set I , so the remaining domain is empty.
5. Insertion: Adjoin a new element x to the index set I and define a corresponding value of the
function at x.
6. Deletion: Delete an element x from the index set I and restrict the function to the resulting
smaller domain.

<comparison>
retrieval
Let us compare the abstract data types list and table. The underlying mathematical construction for
a list is the sequence, and for a table, it is the set and the function. Sequences have an
'implicit' order; a first element, a second, and so on, but sets and functions have no such order.
Hence information retrieval from a list naturally involves a search like the ones studied in the
previous chapter, but information retrieval from a table requires different methods, access methods
that go directly to the desired entry. The time required for searching a list generally depends on
the number n of entries in the list and is at least lgn, but the time for accessing a table does not
usually depend on the number of entries in the table; that is, it is usually O(1). For this reason
in many applications, table access is significantly faster than list searching.

traversal
On the other hand, traversal is a natural operation for a list but not for a table. It is generally
easy to move through a list performing some operation with every entry in the list. In general, it
may not be nearly so easy to perform an operation on every entry in a table, particularly if some
special order for the entries is specified in advance.


{radixsort}
The idea is to consider the key, one character, at a time and to divide entries into as many sublists
as there are possibilities for the given character from the key. For example, if keys are words or
other alpabetic strings, divide the list into 26 sublists at 'each' stage.

note: The key is that set up a table of 26 sublists and distribute the entries from input list into
the sublist. Here use index to find corresponding list. Hence table.

<approach-one>
A person sorting words by working on only one column like mechanical card sorter might first
distribute the words into 26 lists according to the initial letter, then devide each sublist into
further sublist according to the second letter, and so on. (means do second list within the first).
This causes multiplicity of sublist.

<approach-two>
To eliminates multiplicity of sublists: partition the items into the table of sublists first by the
least significant position and to the most. When, after repetition of these steps, the list has been
partitioned by the most significant place and recombined, it will be completely sorted.

note: Why sorted? because uses alphabet order which is sorted so will be sorted by distributing keys
into sublist according to alphabet order.

This process is illustrated by sorting the list of nine three-letter words from 3rd, least
significant position to 1st, most siginificant position.

init     by 3rd      by 2nd      by 1st
rat      mop {       map {       car
mop      map         rap         cat
cat      top         car         cot
map      rap }       tar         map
car      car {       rat         mop
top      tar }       cat }       rap
cot      rat {       mop {       rat
tar      cat         top         tar
rap      cot }       cot }       top

<approach-three>
To see why should use LSB first to partition, try to use MSB first but the result is not sorted. 

init     by 1st char    by 2nd      by 3rd
rat      cat            cat         cat { not sorted
mop      car            car         car
cat      cot            map         cot }
map      mop            rat         map
car      map            rap         mop
top      rat            tar         rat {
cot      rap            cot         rap }
tar      top            mop         tar
rap      tar            top         top 

<example> reference example in C
Set up an array of 28 linked queues which is a table ADT. position 0 corresponds to a blank
character, position 1 through 26 to the letters and position 27 to any other character that appears
in the key. 

note: Why queue for a sublist? Since entries are always inserted at the end of a sublist and removed
from the beginning. (but not the first)

Traverse the linked list and add each item to the end of the appropriate queue. After partitioned,
recombine the queues into one list.

<assumptions>
The assumption is that no case since only lower case, ASCII

// this is EntryType and means that each entry has char array[KEYSIZE].
typedef char QueueEntry[KEYSIZE];

// shall set up array of 28 linked queue. position 0 corresponds to a blank character, position 1-26
// to the letters (no case), position 27 to any other character which is non-alphabet.
int QueuePosition(char c)
{
  if( c == ' ' ) return 0;
  else if( isalpha(c) )
    return tolower(c) - 'a' +1;
  else
    return 27;

  or to support upper and lower case

  if( c == ' ' ) return 0;
  if ('a' <= c && c <= 'z') return c − 'a' + 1;
  if ('A' <= c && c <= 'Z') return c − 'A' + 1;
  return 27;
}

// recombine all queues into one list
void Rethread(List* list, Queue queues[] )
{
  int i;
  Node* x;

  for( i=0; i < MAXQARRAY; i++ )
    while( !QueueEmpty( &queues[i] ))
    {
      ServeNode( &x, &queues[i] );
      InsertList( ListSize(list), x, list );
    }
}

void RadixSort(List *list)
{
  int i, j;
  Node *x;
  Queue queues[MAXQARRAY];

  for( i=0; i < MAXQARRAY; i++ )
    CreateQueue(&queue[i]);

  // for each key(char) starting from LSB in the key set
  for( j=KEYSIZE-1; j >= 0; j-- )
  {
    // get all node from input list and put it back to the corresponding queue. 
    // note: take a entry from list and put it to the queue as a node. so there is interface
    // difference between queue and list.
    while( !ListEmpty(list) )
    {
      // get the first entry from a list. DeleteList( pos, ListEntry*, List*) and see general list. 
      DeleteList( 0, &x, list );

      // make a node and put it into a corresponding queue. 
      AppendNode( x, &queue[ QueuePosition( x->entry[j]) ]);
    }

    // connect 28 queues together as a single list
    Rethread( list, queue );
  }
}

<analysis>
The radix sort is 'proportional' to nk, where n is the number of items and k is the number of
characters in a key. The time for all our other sorting methods denpends on n but not directly on
the length of a key.

To compare the relative performance with the best time of mergesort which is nlogn. So the relative
size of nk vs nlogn:

<key>
The relative performance of the methods will therefore relate in some ways to the relative sizes of
nk and nlgn; that is, of k and lgn. If the keys are long but there are relatively few of them, then
k is large and lgn relatively small, and other methods (such as mergesort) will outperform radix
sort; but if k is small (the keys are short) and there are a large number of keys, then radix sort
will be faster than any other method we have studied.

note: Very efficient sorting method for linked list implementations. For example, if input list and
sublist are lined implementation and can move around nodes when moving around between them.


{hash-table}
For cases where the key is no longer an index that can be used directly as in array indexing. What
we can do is to set up a one-to-one correspondence between the keys by which we wish to retrieve
information and indices that we can use to access an array.

The only difficulty arises when the number of possible keys exceeds the amount of space available
for our table. If, for example, our keys are alphabetical words of eight letters, then there are
26^8 = 2*10^11 possible keys, a number likely greater than the number of positions that will be
available in high-speed memory. In practice, however, only a small fraction of these keys will
actually occur. That is, the table is sparse. Conceptually, we can regard it as indexed by a very
large set, but with relatively few positions actually occupied. note: this is why hash table allows
collision.

Hash table is to allow many of the different possible keys that might occur to be mapped to the
'same' location under the action of index function. This 'index' function is 'hash' function which
map several different keys to the same index. This is 'collision'. So two questions: find good hash
function and how to resolve collisions.

<hash-function>
The good hash function has:

1. should be easy and quick to compute.
2. should achieve an 'even' distribution of the keys that actually occur across the range of indices.

Need even distribution of the keys but do not know in advance what keys will occur. There is nothing
random about a hash function. Three methods that can be put together in various way to build a hash
function. All about even distribution to avoid collisions.

The various to build good hash function:

<truncation>
Use part of key directly as the index. For example, for key 62538194, use 394 which is 1, 2 and 5
digits as the index. This is very fast but often fail to get even distribution.

<folding>
Partition the key into several parts and combine in convenient way. For example, 62538194 maps to
625+381+94 = 1100 which is truncated to 100. Since all information in the key is used, often have
better spread than truncation.

<modular>
Divide by the size of the index range and take remainder as the result. The spread depends very much
on the modulus( in this case, the size of the hash array). If the modulus is a power of a small
integer like 2 or 10, then many keys tend to map to the same index, while other indices remain
unused. The best is to use 'prime' numbers: not 1000 or 1024 but use 997 or 1009.

This is the best since can get good 'spread' and ensures that the result is in the proper range at
the same time. 

int Hash( Key s )
{
  unsigned h = 0;

  while(*s)
    h += *s++;

  return h % HASHSIZE;
}


// ansic, p144. form hash value for string
unsigned hash( char *s )
{
  unsigned hashval;

  for( hashval = 0; *s != '\0'; s++ )
    hashval = *s + 31 * hashval;

  return hashval % HASHSIZE;
}


<collision-resolution> 
rehashing:
There are many ways to do. rehashing uses a second hash function to obtain the second position to
consider.

chaining: Collision Resolution by Chaining

Up to now we have implicitly assumed that we are using only contiguous storage while working with
hash tables. Contiguous storage for the hash table itself is, in fact, the 'natural' choice, since
we wish to be able to refer quickly to random positions in the table, and linked storage is not
suited to random access. There is, however, no reason why linked storage should not be used for the
'records' themselves. We can take the hash table itself as an array of linked lists.

It is traditional to refer to the linked lists from the hash table as chains and call this method
collision resolution by chaining.

table
[ ]   -> list
[ ]   -> list
[ ]   -> list
[ ]   -> list


{summary}
We can summarize these observations for retrieval from n entries as follows:

1. Sequential search is O(n)
2. Binary search is Ò(log n)
3. Hash-table retrieval is Ò(1)

For speed and convenience, ordinary lookup in contiguous table is superior but there are many
applications to which it is inapplicable: when keys is sparse, when insertion or deletion are
frequent.


={============================================================================
*kt_dev_algo_0000* dev-algo-binary-tree

The linked list have great advantages of flexibility over contiguous implementation but have one
weak feature: {list-contiguous-and-linked} they are sequential list; that is, have to access through
them only one position at a time, not random access.

Tree overcome this and is valuable for problems of information retrieval.


{adt-definition} # binary-tree
A binary tree is either empty, or consist of a node called the 'root' together with two binary tree
called the 'left-subtree' and the 'right-subtree' of the root.

<condition>
The left and right are important for binary tree and has recursive nature that allows empty binary
tree and the empty tree is base case for recursive and determine when to stop.

2-tree is different from binary tree since 2-tree has always 0 or 2 children but never 1.

Excercise: get all fourteen binary trees with four nodes.


{traversal-orders}
There are many different traversal orders for trees and reduced to 'three' by permitting only the ways
in which the left is traversed before the right.

The (V)isiting a node, traversing the left subtree L, and the right subtree R. <note> that visit,
traverse and subtree in wording since traverse is not visit.

VLR(preorder) LVR(inorder) LRV(postorder)
^              ^             ^
Do this order for every node so has recursive nature. For example, traverse the following tree

  ()1
    ()2
  ()3
()4  ()5

pre 12345, in 14352 and post 45321


{linked-implementation}
A binary tree has a natural implementation in linked strorage. The root variable enable us to find
the tree and it will point to the root of the tree.

typedef struct treenode TreeNode;
typedef struct treenode {
  TreeEntry entry; // application dependant
  TreeNode  *left;
  TreeNode  *right;
} TreeNode;

// TreeNode* ttree; CreateTree(&ttree);
void CreateTree( TreeNode** root )
{ *root = NULL; }

Bool TreeEmpty( TreeNode* root )
{ return root == NULL; }

void Preorder( TreeNode* root, void (*Visit)(TreeEntry x))
{
  if(root)
  {
    Visit(root->entry);
    Preorder( root->left, Visit);
    Preorder( root->right, Visit);
  }
}

void Inorder( TreeNode* root, void (*Visit)(TreeEntry x))
{
  if(root)
  {
    Inorder( root->left, Visit );
    Visit(root->entry);
    Inorder( root->right, Visit );
  }
}

// ansic, p142. in-order print of tree
void treeprint( struct tnode *p )
{
  if( p != NULL )
  {
    treeprint( p->left );
    printf("%4d %s\n", p->count, p->word );
    treeprint( p->right );
  }
}


{binary-search-tree}
In {ref-004}, when given a binary tree question, many candidates assumes that it means binary search
tree. Be sure to ask whether or not the tree is a binary search tree(BST). A BST imposes the
'condition' that, for all nodes, the left children are less than or equal to the current node, which
is less than all the right nodes. BST is a 'special' kind of a binary tree.

The searching through the linked list always reduce to a sequential search and contiguous list is
much slower when frequently need to make changes in the list. The binary search tree is excellent
solution to this problem:

Can we find an implementation for ordered list in which we can search quickly (as with binary search
on a contiguous list) and in which we can make insertions and deletions quickly (as with a linked
list)?

By making the entries of an 'ordered' list into the nodes of a binary tree, O(logN) for search and
O(logN) for insertion and deletion as with binary search. The main design is to store the nodes as a
binary tree with the structure of comparison tree itself, with links used to describe the relations
of the tree. See {list-contiguous-and-linked}

This is especially appropriate when random access, traversal in predetermined order, and flexibility
are 'all' required.

<adt-definition>
The binary search tree is a binary tree that is either empty or in which every node contains a
key(entry) and satisfies the conditions:

1. The key in the 'left' child of a node (if it exists) is 'less' than the key in its parent node.
2. The key in the 'right' child of a node (if it exists) is 'greater' than the key in its parent node.
3. The left and right subtrees of the root are again binary search tree.

This ensures that 'no' two entries in a binary search tree can have 'equal' keys since keys are strictly
less or greater. Possible to change the definition to allow entries with equal keys, but doing so
make the algorithm complicated.

<comparison-trees>
This is a BST and here 0 means NULL for left or right subtree.

              Jim
     Dot              Ron
  Amy     Guy     Kay     Tim
0   Ann Eva Jan Jon Kim Roy Tom
    0 0 0 0 0 0 0 0 0 0 0 0 0 0
 
Preorder: Jim Dot Amy Ann Guy Eva Jan Ron Kay Jon Kim Tim Toy Tom
Inoder  : Amy Ann Dot Eva Guy Jan Jim Jon Kay Kim Ron Roy Tim Tom

<tree-search>
The search in a linked binary search tree and termination condition is if we find the key and if
not, then continue searching until hit an empty subtree. This is based closely on binary search so
do the same comparisons as binary search do. O(logN)

// Returns node pointer if an entry in the binary search tree has key equal to target; that is when
// root is not null and LT and GT are false. Otherwise, returns NULL which is a leaf. See returning
// root up the chain and 'else if (GT)' but not 'else'. Strictly less or greater.
TreeNode* TreeSearch( TreeNode* root, KeyType target )
{
  if(root)
  {
    if( LT( target, root->entry.key) )
      root = TreeSearch( root->left, target );
    else if( GT(target, root->entry.key) )            // see else if
      root = TreeSearch( root->right, target );
  }

  return root;    // return null or node ptr for a equal key
}

// Recursion removal version as it is tail recursion. returns node if found; otherwise, return null.
// Q: Why use 'position' variable? Seems that it is okay not to use position and use root.
TreeNode* TreeSearch( TreeNode* root, KeyType target)
{
  TreeNode* position = root;

  // note 1. Already checked equal case in while so no need to the same in if and else clause Why?
  // since run only equal case in recursion version and exit call when equal but here use while
  // instead. In other words, NE is 'hidden'(implicit) case in recursion version.

  // note 2. This finds equal (remember binary search has two versions) and when reaches a leaf then
  // means 'not found'.

  while( position && NE( target, position->entry.key ))
  {
    if( LT(target, position->entry.key ))
      position = position->left;
    else
      position = position->right;
  }

  return position;
}

Can think that the leaf node has imaginary left and right null node.


{random-binary-search-tree}
The same keys which are letters in this case can have quite different shapes of trees depending on
<how-a-tree-is-made>. In other words, how it is inserted into a tree range from the best which is
bushiest meaning fewerer "tree-height, comparison, or recursion depth" to the worst which is a
single chain and is equal to sequential search.

"dbacfeg" ->               d()                "abcdefg" -> ?
                       b()     f()
                     a() c() e() g()

Remember that binary search requires ordered list. The search performance of BST 'depends' on how a
tree constructed. The TreeInsert can handle the random input and when the input is ordered, BST
degenerates to the worst case, single chain. Think a tree shape when use TreeInsert with ordered
input. The worst case is extremely unlikely in practice so TreeSearch performs nearly as well as
binary search. 

For random order, it is 39% slower than the optimum(completely balanced) of (logN) comparisons.
Still better than sequential search. This is average.

Why random? This tree handles random input order in which includes worst case. Hence called random
BST.

<tree-insert> which supports the random input
The worst of a random binary search tree is when the keys are inserted into an initially empty tree
in their natural order, sorted. This will produce a chain, a tree with a single line. The same holds
if the keys are in reverse order or if they are nearly but not quite sorted into order. TreeInsert
should never be used with keys that are 'already' sorted into order.

<equal-key-support>
If the keys are equal, we shall adopt the convention of inserting the duplicate key into the 'right'
subtree. It inserts a new key that duplicates a previous key on the right side of the old entry.
TreeSearch, the searching function will always find the 'first' entry of duplicated keys.

note. Looks like searching will find the first entry regardless of right or left for duplicated
keys.

Example, "e, b, d, f, a, g, c"
          0  1

// See how return value is used; used to set left or right of the previous node. The last return
// value is always root. Also this shall be used once searching to insert is done. That is search
// and insert.
TreeNode* TreeInsert( TreeNode* root, TreeNode* newnode )
{
  if(!root)
  {
    root = newnode;
    root->left = root->right = NULL;
  }
  else if( LT(newnode->key.entry, root->key.entry ) )
    root->left = TreeInsert( root->left, newnode );
  else                                                      // see else that is <=
    root->right = TreeInsert( root->right, newnode );

  return root;
}

In regard to performance, TreeInsert will be very much the same as that of TreeSearch to find a
place to insert: O(logN)

The ansic example, p141, which is word frequency count example.

// addtree: add a node with w, at or below p
struct tnode *addtree( struct tnode *p, char *w )
{
  int cond;

  if( p == NULL )    // a new word has arrived
  {
    p = talloc();    // make a now node
    p->word = strdup(w);
    p->count = 1;
    p->left = p->right = NULL;
  }
  else if((cond = strcmp( w, p->word )) == 0 )
    p->count++;
  else if( cond < 0 )
    p->left = addtree( p->left, w );
  else
    p->right = addtree( p->right, w );

  return p;
}


<treesort>
The inorder(LVR) traversal of binary search tree always give the 'sorted' order for the keys. So
simply takes the entries to be sorted, use TreeInsert to build them into a binary search tree, and
use inorder traversal to put them out in order.

Notice the similarity with quicksort. The quicksort is usually an excellent method and treesort
makes the same comparisons as does quicksort. In the average, on a randomly ordered list of n,
treesort performs:

1.39 nlogn + O(n)

<why-bst-is-useful-for-a-stream>
For a use case, see <8> in *kt_dev_quiz_015* 

Treesort has one advantage over quicksort: Quicksort needs to have access to all the items to be
sorted but with treesort, the nodes need not all be available at the start of the process, but are
built into the tree one by one as they become available since as each node comes in, it goes into its
'final' position in the linked list. 

This is major advantage that 1) search tree 'remains' avaiable for later <insertions-and-deletions>, and
that 2) can be searched in logarithmic time, whereas all previous sorting either requires contiguous
list or produce linked list for sequential search.

As with quicksort, the major drawback is the worst case when input is already sorted, or are nearly
so.

<code-example>
#include <iostream>
#include <string>
#include <cstdlib>

#define LT(a,b) ((a) < (b))

typedef struct {
  int key;
} TreeEntry;

typedef struct treenode {
  TreeEntry entry; // application dependant
  treenode  *left;
  treenode  *right;
} TreeNode;

TreeNode* MakeTreeNode(int key)
{
  TreeNode* pnode = NULL;

  if( (pnode = (TreeNode*) malloc(sizeof(TreeNode))) == NULL )
  {
    std::cout << "MakeTreeNode: out of memory" << std::endl;
    return pnode;
  }

  pnode->entry.key = key;
  pnode->left = pnode->right = NULL;

  return pnode;
}

void CreateTree( TreeNode** root )
{ *root = NULL; }

TreeNode* TreeInsert( TreeNode* root, TreeNode* newnode )
{
  if(!root)
  {
    root = newnode;
    root->left = root->right = NULL;
    std::cout << "inserted: " << root->entry.key << std::endl;
  }
  else if( LT(newnode->entry.key, root->entry.key) )
    root->left = TreeInsert( root->left, newnode);
  else
    root->right = TreeInsert( root->right, newnode);

  return root;
}

void TreeInorder( TreeNode* root, void (*Visit)(TreeEntry x))
{
  if(root)
  {
    TreeInorder( root->left, Visit);
    Visit(root->entry);
    TreeInorder( root->right, Visit);
  }
}

void PrintTreeNode( TreeEntry entry )
{
  std::cout << ":" << entry.key << std::endl;
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  TreeNode *proot, *pnode;

  CreateTree( &proot );    // make proot is NULL

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
  {
    std::cout << "insert " << arr[idx] << " into a tree" << std::endl; 
    pnode = MakeTreeNode( arr[idx] );

    // TreeInsert( proot, pnode );
    // <key> <call-by-value-problem> notice that this is an bug. It is  call-by-value-problem since
    // TreeInsert get a copy and this causes always to insert new to the null root sicne proot is
    // not updated. Hence no output when traversing. 

    proot = TreeInsert( proot, pnode );
  }

  TreeInorder( proot, PrintTreeNode );

  std::cout << "}" << std::endl; 
}


{Q} can change these to use reference?


<tree-delete>
Why care about deleting a node in a tree? because it is one of advantages treesort provides and
which is that search remains avaialbe after insertion and 'deletion'. It is more complicated when
the node to be deleted has both left and right subtrees which are nonempty since it is easy to
delete a leaf and a node with only one subtree.

One possible solution when it has both subtrees:

1. To which of the subtree should the parent of the deleted node now point? Right or left subtree?
The one approach in this book is to attach the 'right' subtree in place of the deleted node.

2. What is to be done with the other subtree which is the left in this approach? Since every key in
the left subtree precedes(less than) every key of the right subtree, must be as 'far' to the 'left'
as possible. Remember the left subtree is also a tree. This point can be found by taking left
branches until an empty left subtree is found.

TreeNode* x;
DeleteNodeTree(&x->left);  // equals to DeleteNodeTree(&(x->left)); pointer to a node to delete;

// The parameter p is the address of actual node(not a copy) in a tree since the object is to update
// the BST, the actual parameter is the address of one of the links of the tree.
//
//              [ left, right ]                       // &x->left (*p)
//            
//                      [ left, right ]               // r
//
//            [ left, right]       [ left, right ]    // r->left or r->right
//
// <note> As shown <call-by-value-problem> in TreeInsert, this is why this has "**" argument type.
//
void DeleteNodeTree( TreeNode** p )
{
  // r points to node to delete which is *p (left or right child ptr of the parent)
  TreeNode *r = *p, *q;

  if( r == NULL )
    Error("attempt to delete a nonexistent node from binary search tree");

  // when a node has only either left or right subtree, attach subtree to a parent
  else if( r->right == NULL )
  {
    *p = r->left;    // reattach left subtree
    free(r);
  }
  else if( r->left == NULL )
  {
    *p = r->right;   // reattach right subtree. *p now points to r->right.
    free(r);
  }
  // when a node has both subtrees
  else
  {
    // get to the leftmost node of the 'right' subtree. this is the same as <list-find-end-idiom> in
    // 'list'. This becomes a searching of single linked list.
    for( q = r->right; q->left; q = q->left )
      ;

    // reattach left subtree to the far left of right subtree. notice how easy to move the whole
    // subtree.
    q->left = r->left;     

    *p = r->right;         // reattach right subtree

    free(r);
  }
}

For many cases, not given a pointer to a node to delete but instead given a key for which the
corresponding node must be deleted. So combine 'search' and delete function. Compare TreeSearch
which do not have EQ comarison.Why does this have? Since this time it has to delete when found.

void DeleteKeyTree( TreeNode** root, TreeNode** keyposition, KeyType target )
{
  // not found
  if(*root == NULL)
    Error("attempt to delete a nonexistent node from binary search tree");
  else if ( EQ( target, (*root)->entry.key ) )
  {
    // <Q> why need keyposition? since root will be deleted?
    *keyposition = *root;
    DeleteNodeTree(root);
  } 
  else if( LT( target, (*root)->entry.key ))
    DeleteKeyTree( &root->left, keyposition, target);
  else
    DeleteKeyTree( &root->right, keyposition, target);
}


{random-binary-search-tree-template-version}

#include <iostream>

typedef enum { success, overflow, underflow, duplicate_error, not_present} Error_code;

template <typename Entry>
struct Binary_node
{
  Entry data;
  Binary_node<Entry> *left;
  Binary_node<Entry> *right;

  Binary_node() { left = right = NULL; };
  Binary_node( const Entry &x ) { left = right = NULL; data = x;};
};

// Binary_tree {{
//
template <typename Entry>
class Binary_tree 
{
  public:
    Binary_tree() { root = NULL; }
    Binary_tree(const Binary_tree<Entry> &original);
    Binary_tree & operator=(const Binary_tree<Entry> &original);
    // ~Binary_tree();

    bool empty() const { return root == NULL; }
    int size() const;
    void clear();
    int height() const;

    void insert( const Entry & );
    void inorder( void (*visit)(Entry &));

  protected:
    void recursive_inorder( Binary_node<Entry> *sub_root, void (*visit)(Entry &));
    Binary_node<Entry> *root;
};

template <typename Entry>
void Binary_tree<Entry>::inorder( void (*visit)(Entry &))
{
  recursive_inorder(root, visit);
}

template <class Entry>
void Binary_tree<Entry>::recursive_inorder(Binary_node<Entry> *sub_root, void (*visit)(Entry &))
{
  if (sub_root != NULL) 
  {
    recursive_inorder(sub_root->left, visit);
    (*visit)(sub_root->data);
    recursive_inorder(sub_root->right, visit);
  }
}
//
// Binary_tree }}


// Search_tree {{
//
template <typename Record>
class Search_tree: public Binary_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    Error_code remove( const Record &old_data );

    // If there is an entry in the tree whose key matches that in target, the parameter target is
    // replaced by the corresponding record from the tree and a code of success is returned.
    // Otherwise a code of not_present is returned.
    // <note> it seems unuseful to replace target parameter when found since that's the same value.
    // May be useful to return some other value?
    Error_code tree_search( Record &target ) const;

  private:
    Error_code search_and_insert( Binary_node<Record> *&sub_root, const Record &new_data ); 
    Binary_node<Record> *search_for_node( Binary_node<Record> *sub_root, 
        const Record &target) const;

    // to support removal with record.
    Error_code search_and_destroy( Binary_node<Record>* &sub_root, const Record &target);

    // If sub_root is NULL, a code of not_present is returned. Otherwise, the root of the subtree is
    // removed in such a way that the properties of a binary search tree are preserved. The
    // parameter sub_root is reset as the root of the modified subtree, and success is returned.
    Error_code remove_root( Binary_node<Record> *&sub_root );
};

// If the key of target is not in the subtree, a result of NULL is returned. Otherwise, a pointer
// to the subtree node containing the target is returned.

// template <typename Record>
// Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
//     const Record &target) const
// {
//   if( sub_root == NULL || sub_root->data == target )
//     return sub_root;
//   else if( target > sub_root->data )
//     return search_for_node( sub_root->right, target );
//   else
//     return search_for_node( sub_root->left, target );
// }

// recursion removal version
template <typename Record>
Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
    const Record &target) const
{
  while( sub_root && sub_root->data != target )
  {
    if( target > sub_root->data )
      sub_root = sub_root->right;
    else
      sub_root = sub_root->left;
  }

  return sub_root;
}

template <typename Record>
Error_code Search_tree<Record>::tree_search( Record &target ) const
{
  Error_code result = success;

  Binary_node<Record> *found = search_for_node( this->root, target );
  if( found == NULL )
    return not_present;
  else
    target = found->data;

  return result;
}

template <typename Record>
Error_code Search_tree<Record>::insert( const Record &new_data )
{
  return search_and_insert( this->root, new_data );
}

// <key> <call-by-value-problem> notice the use of "*&" here or else this is an bug as the same of
// TreeInsert() since sub_root is a local copy and the same wrong output.
// Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *sub_root, const Record
// &new_data); 
template <typename Record>
Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *&sub_root, 
    const Record &new_data ) 
{
  if( sub_root == NULL )
  {
    sub_root = new Binary_node<Record>(new_data);
    return success;
  }
  else if( new_data < sub_root->data )
    return search_and_insert( sub_root->left, new_data );
  else if( new_data > sub_root->data )
    return search_and_insert( sub_root->right, new_data );
  else 
    return duplicate_error;
}

// the parameter is one of links of the tree, and not just a copy.
// remove_root(x->left);
//
// <note> that the argument type.
//
// <note> this it different approach from DeleteNodeTree( TreeNode** p ): 
//
// First, move to to-delete node's left subtree and find the immediate predecessor of to-delete node
// when do inorder traversal at the node's left subtree. How? This is the node as far right as
// possible and it has no right child since we went as far right as possible. So it can be removed
// from its current position without difficulty. 
//
// Second, swap this node with the to-delete node that was supposed to be removed.
//
// The key is that the properties of a binary search tree will still be satisfied, since there were
// no keys in the original tree whose ordering comes between the removed key and its immediate
// predecessor.
//
template <typename Record>
Error_code Search_tree<Record>::remove_root( Binary_node<Record> *&sub_root )
{
  if( sub_root == NULL ) return not_present;

  Binary_node<Record> *to_delete = sub_root;

  if( sub_root->right == NULL )
    sub_root = sub_root->left;
  else if ( sub_root->left == NULL )
    sub_root = sub_root->right;
  else  // neither subtree is empty
  {
    to_delete = sub_root->left;   // move left

    Binary_node<Record> *parent = sub_root;

    while( to_delete->right != NULL )
    {
      parent = to_delete;
      to_delete = to_delete->right;
    }

    // move from to_delete(predecessor) to root(node to delete)
    sub_root->data = to_delete->data;   

    // <note> this is interesting and cases for when predecessor does have left subtree but right
    // null.
    //          ...               or              ...           
    //        [ ] sub_root                      [ ] sub_root
    //                                        ...                 
    //     [ ]    to_delete                  [ ]    parent
    //                                        
    //  [ ]  N                            [ ]  [ ]  to_delete             
    // ...                                   ...  N                
    //
    if(parent == sub_root)  // this is when didn't run while loop
      sub_root->left = to_delete->left;
    else
      parent->right = to_delete->left;
  }

  // remove it from the tree 
  delete to_delete;
  return success;
}

template <typename Record>
Error_code Search_tree<Record>::search_and_destroy( Binary_node<Record>* &sub_root, const Record &target)
{
  // remove_root handles sub_root is NULL
  if( sub_root == NULL || sub_root->data == target )
    return remove_root( sub_root );
  else if( target < sub_root->data )
    return search_and_destroy( sub_root->left, target );
  else
    return search_and_destroy( sub_root->right, target );
}

template <typename Record>
Error_code Search_tree<Record>::remove( const Record &target )
{
  return search_and_destroy( this->root, target ); 
}
//
// Search_tree }}


void PrintTreeNode( int &entry )
{
  std::cout << " " << entry << ",";
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  Search_tree<int> bst;
  Error_code result;

  // insert
  for(int idx = 0; idx < size; idx++)
  {
    result = bst.insert( arr[idx] );
    if( result != success )
    {
      std::cout << "insert failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  bst.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 

  // remove
  for(int idx = 0; idx < size; idx++)
  {
    result = bst.remove( arr[idx] );
    if( result != success )
    {
      std::cout << "remove failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  bst.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 
}

kt@kt-ub-vb:~/work$ ./a.out 
{ 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33,}
{}
kt@kt-ub-vb:~/work$ 


{balanced-binary-search-tree}
<tree-balance> <balancing>
This delete approach is 'far' from optimal as it could greatly increase the height of the tree. For
example:

     (r)                       (x)    
   (b) (x)    delete r       (b) (y)  
 (a)     (y)               (a)      (z) 
           (z)                       

       (r)    delete r          (z)
    (c)  (z)                  (y)
  (b)  (y)                  (x)
(a)  (x)                  (c)
                        (b)
                      (a)

The second example increases its height. Thus the time required for a later search can substantially
increase, even though the total size of the tree has decreased. Hence to optimise the use of binary
search tree, 'need' methods to make the left and right subtree more nearly 'balanced' meaning reduced
height.

<more-cost-to-balance>
Is it worthwhile, on average, to keep a binary search tree balanced or rebalance it for a random
input order? The average cost of not balancing a binary search tree is approximately 39% more
comparisons because not balanced tree becomes random binary search tree. See 9.3.6 in {ref-001}

<build-balanced-bst>
For example, when receives inputs 'numbered' 1...31 in the order, build them into a tree that will be
as 'bushy' as possible. This is inorder sequence.

                                       (16)                                               2^4 (level4)
                  (8)                                          (24)                       2^3
      (4)                  (12)                    (20)                    (28)           2^2
  (2)      (6)      (10)         (14)        (18)        (22)        (26)        (30)     2^1
(1) (3)  (5) (7)  (9) (11)    (13) (15)   (17) (19)   (21) (23)   (25) (27)   (29) (31)   2^0

Two things to draw algorithm:

1. The observation from the above diagram. 2, 6, 10, 14, 18, 22, 26, 30 are 'divisible' by 2 and so
on. "each node is exactly as many 'levels' above the 'leaves' as the highest power of 2 that divides
its label(number)"

2. The assumption that do not know in advnace how many nodes will be built into the tree. So
determine how to tidy up the tree when all the nodes have been received but there is a dangling
subtree. <tidy-up>

The sequences to build a tree are:
When node number 1 arrives, is a leaf and therefore its left and right pointers should both be NULL.
When node number 2 arrives, goes above node 1 and should remember where node 1 is. 
When node number 3 arrives, is a leaf but is in the right of node 2 and remember node 2. 

                                 (4)*        (4)*        level 2
         (2)*     (2)*        (2)         (2)            level 1
(1)*  (1)      (1)   (3)   (1)   (3)   (1)   (3)   (5)*  level 0
n=1   n=2      n=3         n=4         n=5

where * is a node that must be remembered to build future links as the tree grows

Must keep a list of all nodes previously processed? No and need 'only' to remember one node on each
level, the last node processed on that level from one level above('parent' level). Pointers in
lastnode array that will quite small. For example, 20 levels can have 2^20-1 > 1,000,000 nodes.

<handle-leaf>
As each new node arrives, can set its right pointer to NULL (at least temporarily). The left pointer
is NULL if it's a leaf; that is to be on level 0, index of 'lastnode' array. Otherwise, it is the
entry in 'lastnode' array one level lower than the new node. lastnode[0] is always NULL and by doing
this can treat the leaves in the 'same' way as other nodes.

<left-right-child>
For some nodes, the right link should not permanently NULL since the node to insert may be the right
child of some previous node. For some, it may be left child, in which case its parent node has not
yet arrived. Can tell which case occurs by looking at lastnode. 

1. If level is the level of new node then parent level is level+1. Look at lastnode[level+1] and if
the right is still null, its right must be the new node. E.g., 3, 6, 14, ...

2. Look at lastnode[level+1] and if the right is not null then the right is aleady arrived. The new
node must be the left of some future node. E.g., 5 when parent is 2

<code>
// This can be used to build the fresh tree from inputs or to 'reorganize' the unbalanced tree?
TreeNode *BuildTree(void)
{
  TreeNode *newnode;
  int count = 0;
  int level;

  TreeNode* lastnode[ MAXHEIGHT ];

  for( level = 0; level < MAXHEIGHT; level++ )
    lastnode[level] = NULL;

  while((newnode = GetNode()) != NULL )
    Insert( newnode, ++count, lastnode );

  // after all the nodes have been inserted into the new tree, find the root of the tree and then
  // connect any right subtrees that may be dangling. For example, n=5 and 21 node.
  newnode = FindRoot(lastnode);

  ConnectSubtree( lastnode );

  // return root of the tree
  return newnode;
}

// If there is information available, GetNode creates a TreeNode, copies the information into the
// node, and returns a pointer to this TreeNode. Otherwise, returns NULL. This is to obtain each new
// node.
TreeNode *GetNode();

<insert> which assumes the ordered input. counts is [1, n]
// level n
// ...
// level 3        lastnode[3], points to a node on level 2
// level 2        lastnode[2], points to a node on level 1
// level 1        lastnode[1], points to a node on level 0
// level 0        lastnode[0], points to a node on level -1 (imaginary)
//
void Insert( TreeNode *newnode, int count, TreeNode *lastnode[] )
{
  // make a level+1 as in <handle-left>
  int level = Power2(count)+1;

  newnode->right = NULL;
  newnode->left = lastnode[level-1];   // leaf or left of one level lower

  lastnode[level] = newnode;           // set current level

  // for example, when n=6
  if(lastnode[level+1] && !lastnode[level+1]->right ) // parent level
    lastnode[level+1]->right = newnode;
}

<power> this is interesting to know
// find the 'highest' power of 2 that divides count. requires input x != 0. 
// returns level = 0,1,2,3,4,5...
// count:   4        12       20
// level, x 0  4     0  12    0  20
//          1  2     1  6     1  10
//          2* 1     2* 3     2* 5

// true when x is odd number
#define ODD(x)    ((x)/2*2 != (x))

int Power2(int x)
{
  int level;

  // run when x is even
  for(level=0; !ODD(x); level++)
    x/=2;

  return level;
}

<find-root>
// the root is the highest node in the tree; hence its pointer is the highest entry 'not' equal to
// NULL in the lastnode array. lastnode[level] points to the root which is on level-1 level.
TreeNode *FindRoot(TreeNode *lastnode[])
{
  int level;

  // skip NULL entries
  for( level = MAXHEIGHT-1; level > 0 && !lastnode[level]; level--)
    ;

  if( level <= 0 )   // notice that not consider level 0
    return NULL;
  else
    return lastnode[level];
}

<tidy-up>
// How to tie in any subtrees that may not yet be connected properly after all the nodes have been
// received? The difficulty is that some nodes in the upper part of tree may still have their right
// links set to null, even though further nodes have come in that belong in their right subtrees.
// Any node for which the right child is 'still' null will be one of the nodes in lastnode. Its right
// child should be set to the highest node in lastnode that is not already in its left subtree.
//
// See when n==5.

void ConnectSubtree( TreeNode *lastnode[] )
{
  TreeNode *p;
  int level, templevel;

  // find the root but don't care level 0 and 1 since it is alerady a complete tree when n==3.
  for( level = MAXHEIGHT-1; level > 2 && !lastnode[level]; level--)
    ;

  // scan a node in lastnode which has its right node NULL.
  while( level > 2 ) // level 1 and 2 are already okay
  {
    if( lastnode[level]->right )
      level--; // search for highest dangling node
    else // right subtree is undefined
    {
      // a child and level which a child is on
      p = lastnode[level]->left;
      templevel = level-1;

      // find highest entry not in left subtree. on one level below. when exit loop,
      // lastnode[tempnode] is a node which is not in left.
      do {     
        p = p->right;
      } while( p && p == lastnode[--templevel]);

      // set right
      lastnode[level]->right = lastnode[templevel];

      // to exit the while
      level = templevel;
    }
  } // while end
}


This algorithm produces a binary tree that is not always completed balanced. For n=32, it will
become the root of the tree and all 31 node will be in its left. 5 steps from the root to leaf.
Hence one comparison more than necessary will usually be done and it is not really a high price.

This algorithm is never more than one level away from optimality. There are sophisticated methods
for building a binary tree that is as balanced as possible but recommend a simpler method, one that
does not need to know in advance how many nodes are in the tree. For many practical purposes, this
should prove sufficient.


={============================================================================
*kt_dev_algo_012* avl tree

{avl-tree}
In many application, insertions and deletions occur continually with no predictable order. AVL tree
is a method to keep the tree very nearly balanced at all times for all search, insertion and
deletions to optimise search times even in the worst case. In almost all cases, AVL tree closely
approximates that of ideal, completely balanced binary search tree. O(logN).

<definition> height difference between left and right never be more than 1
An AVL tree is a binary search tree in which the heights of the left and right subtrees of the root
differ by at 'most' 1 and in which the left and right subtrees are 'again' AVL trees. This means
that this most 1 rule applies to all but not just to root. 

With each node of an AVL tree is associated a <balance-factor> that is left-higher, equal-height, or
right-higher according, respectively, as the left subtree has height greater than, equal to, or less
than that of the right subtree.

            [-]            where "-" equal, "/" left high, and "\" right high

      [-]         [\]

   [-]   [-]         [-]

<insert> see avl_insert()
The insertions of AVL tree proceed in exactly the same way as insertions example into an ordinary
binary search tree, except that the balance factors must be 'adjusted'.

Note, however, that the balance factors can only be determined 'after' the insertion is made.

The only case that can cause difficulty occurs when the new node is added to a subtree of the root
and make height difference 2.

The basic structure of our algorithm will thus be the same as the ordinary recursive binary tree
insertion algorithm, but with significant additions to accommodate the processing of balance factors
and other structure of AVL trees.

e ->     [-] k  

      [-] e    [-] t

v ->     [\] k             // blance of k changes 

      [-] e    [\] t

                  [-] v

p ->     [\] k             // blance of k not changes 

      [-] e    [-] t

            [-]p  [-] v


<rebalance> <rotations>
Now consider the case when a new node has been inserted into the taller subtree of a root node and
its height has increased, so that now one subtree has height 2 more than the other, and the tree no
longer satisfies the AVL requirements. We must now rebuild part of the tree to restore its balance.

Let's consider that have inserted the new node into the right subtree, its height has increased, and
the original tree(sub_root) was right higher. There are three cases to consider, 'depending' on the
balance factor of right_tree; cases covered by the function right_balance.

<case-one> <right-higher> <left-rotation>
When the balance factor of right_tree is right higher 'after' insertion. The action needed in this
case is called a left rotation; we have rotated the node right_tree upward to the root, dropping
root down into the left subtree of right_tree; the subtree T2 of nodes with keys between those of
root and right_tree now becomes the right subtree of root rather than the left subtree of
right_tree.

      [\\] sub_root           : h+1+1+1   -- becomes -->                 [-] right_tree

            <- rotate left

   T1(h)       [\] right_tree : (h+1)+1                          [-] root       T3(h+1)

         T2(h)    T3(h)+1                                   T1(h)    T2(h)

<case-two> <left-higher> <double-rotation-left>
The second case, when the balance factor of right_tree is left higher, is slightly more complicated.
It is necessary to move two levels, to the node sub_tree that roots the left subtree of right_tree,
to find the new root. called double rotation.

<note> 
double rotation left = firstly, rotation right on right sub tree + secondly, rotation left
double rotation right = firstly, rotation left on left sub tree + secondly, rotation right

One of T2 or T2 has height h; Take case when T2(h-1) and T3(h)

        [\\] root               =>      [ ] root               =>                [-] sub_root 
                                                                            /           \
                                            <- rotate left               [/] root        [-] right_tree
 /             \                      /     \                           /   \           /   \
T1(h)          [/] right_tree   =>  T1(h)   [ ] sub_root       =>   T1(h)   T2(h-1)  T3(h)  T4(h)
                                          /     \
            -> rotate right             T2(h-1) [-] right_tree
          /            \                       /   \
        [ ] sub_tree   T4(h)                T3(h)  T4(h)
       /   \
   T2(h-1)  T3(h)                                     

In this second case, the new balance factors for root and right_tree depend on the previous balance
factor for sub_tree. (The new balance factor for sub_tree will always be equal_height.) The
resulting balance factors are:

old sub_tree      new root    new right_tree       new sub_tree
   -                 -              -                 -
   /                 -              \                 -
   \                 /              -                 -


<case-three> <equal-height>
This is the case when right_tree has the equal height after insertion but this case, in fact, can
'never' happen. To see why, let us recall that we have just inserted a new node into the subtree
rooted at right_tree, and this subtree now has height 2 more than the left subtree of the root.
(this is why right_balance is called in the first place). 

If these subtrees had equal heights after the insertion, the full tree has 1 difference and meets
AVL property. That is, the height of the full subtree rooted at right_tree was not changed by the
insertion, contrary to what we already know. In other words, contrary to why this function was
called.


<example>
Do run avl_insert on input k, m, u, t, v, p. This has one rotation left and double rotation left.
The final tree is:

        [-] t
     /      \ 
   [-] m     [-] u
 /    \        \
[-] k  [-] p    [-] v


<key>
This avl_insert add new entry at the leaf, update balance factors while goes up the recursive chain
and if necessary, balance sub tree. When do balance, uses the 'previous' balance value to decide which
action it requires but after all, these are actiona 'after' insertion.

<performance>
At first glance it may appear that each one of these calls might induce either a single or double
rotation of the appropriate subtree, but, in fact, at most 'only' one (single or double) rotation
will ever be done. 

To see this, let us recall that rotations are done only in functions right_balance and left_balance
and that these functions are called only when the height of a subtree has increased. When these
functions return, however, the rotations have removed the increase in height, so, for the remaining
(outer) recursive calls, the height has not increased, so no further rotations or changes of balance
factors are done.

Most of the insertions into an AVL tree will induce no rotations. Even when rotations are needed,
they will usually occur near the leaf that has just been inserted.

Later we shall see that we can expect the height of AVL trees to be much 'less' than that of random
search trees, and therefore both insertion and retrieval will be significantly more efficient in AVL
trees than in random binary search trees.

<code> TODO: needs more functions to make it run

#include <iostream>

enum Error_code { success, overflow, underflow, duplicate_error, not_present};
enum Balance_factor { left_higher, equal_height, right_higher };

template <typename Entry>
struct Binary_node
{
  Entry data;
  Binary_node<Entry> *left;
  Binary_node<Entry> *right;

  Binary_node() { left = right = NULL; };
  Binary_node( const Entry &x ) { left = right = NULL; data = x;};

  // <note> why these virtuals? two points:
  //
  // One slightly tricky point about this specification is that the left and right pointers of a
  // Binary_node have type Binary_node *. The apparent pointer type incompatibility is not a serious
  // problem, because a pointer to an object from a base class can also point to an object of a
  // derived class.
  //
  // The benefit that we get in return for implementing AVL nodes with a derived structure is the
  // reuse of all of our functions for processing nodes of binary trees and search trees.
  //
  virtual void set_balance( Balance_factor b ) { };
  virtual Balance_factor get_balance() const { };
};

// Binary_tree {{
//
template <typename Entry>
class Binary_tree 
{
  public:
    Binary_tree() { root = NULL; }
    Binary_tree(const Binary_tree<Entry> &original);
    Binary_tree & operator=(const Binary_tree<Entry> &original);
    // ~Binary_tree();

    bool empty() const { return root == NULL; }
    int size() const;
    void clear();
    int height() const;

    void insert( const Entry & );
    void inorder( void (*visit)(Entry &));

  protected:
    void recursive_inorder( Binary_node<Entry> *sub_root, void (*visit)(Entry &));
    Binary_node<Entry> *root;
};

template <typename Entry>
void Binary_tree<Entry>::inorder( void (*visit)(Entry &))
{
  recursive_inorder(root, visit);
}

template <class Entry>
void Binary_tree<Entry>::recursive_inorder(Binary_node<Entry> *sub_root, void (*visit)(Entry &))
{
  if (sub_root != NULL) 
  {
    recursive_inorder(sub_root->left, visit);
    (*visit)(sub_root->data);
    recursive_inorder(sub_root->right, visit);
  }
}
//
// Binary_tree }}


// Search_tree {{
//
template <typename Record>
class Search_tree: public Binary_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    Error_code remove( const Record &old_data );
    // If there is an entry in the tree whose key matches that in target, the parameter target is
    // replaced by the corresponding record from the tree and a code of success is returned.
    // Otherwise a code of not_present is returned.
    // <note> it seems unuseful to replace target parameter when found since that's the same value.
    // May be useful to return some other value?
    Error_code tree_search( Record &target ) const;

  private:
    Error_code search_and_insert( Binary_node<Record> *&sub_root, const Record &new_data ); 
    Binary_node<Record> *search_for_node( Binary_node<Record> *sub_root, 
        const Record &target) const;

    // to support removal with record.
    Error_code search_and_destroy( Binary_node<Record>* &sub_root, const Record &target);

    // If sub_root is NULL, a code of not_present is returned. Otherwise, the root of the subtree is
    // removed in such a way that the properties of a binary search tree are preserved. The
    // parameter sub_root is reset as the root of the modified subtree, and success is returned.
    Error_code remove_root( Binary_node<Record> *&sub_root );
};

// If the key of target is not in the subtree, a result of NULL is returned. Otherwise, a pointer
// to the subtree node containing the target is returned.

// template <typename Record>
// Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
//     const Record &target) const
// {
//   if( sub_root == NULL || sub_root->data == target )
//     return sub_root;
//   else if( target > sub_root->data )
//     return search_for_node( sub_root->right, target );
//   else
//     return search_for_node( sub_root->left, target );
// }

// recursion removal version
template <typename Record>
Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
    const Record &target) const
{
  while( sub_root && sub_root->data != target )
  {
    if( target > sub_root->data )
      sub_root = sub_root->right;
    else
      sub_root = sub_root->left;
  }

  return sub_root;
}

template <typename Record>
Error_code Search_tree<Record>::tree_search( Record &target ) const
{
  Error_code result = success;

  Binary_node<Record> *found = search_for_node( this->root, target );
  if( found == NULL )
    return not_present;
  else
    target = found->data;

  return result;
}

template <typename Record>
Error_code Search_tree<Record>::insert( const Record &new_data )
{
  return search_and_insert( this->root, new_data );
}

// <key> <call-by-value-problem> notice the use of "*&" here or else this is an bug as the same of
// TreeInsert() since sub_root is a local copy and the same wrong output.
// Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *sub_root, const Record
// &new_data); 
template <typename Record>
Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *&sub_root, 
    const Record &new_data ) 
{
  if( sub_root == NULL )
  {
    sub_root = new Binary_node<Record>(new_data);
    return success;
  }
  else if( new_data < sub_root->data )
    return search_and_insert( sub_root->left, new_data );
  else if( new_data > sub_root->data )
    return search_and_insert( sub_root->right, new_data );
  else 
    return duplicate_error;
}

// the parameter is one of links of the tree, and not just a copy.
// remove_root(x->left);
//
// <note> that the argument type.
//
// <note> this it different approach from DeleteNodeTree( TreeNode** p ): 
// First, move to to-delete node's left subtree and find the immediate predecessor when do inorder
// traversal. This finds the node as far right as possible and it has no right child since we went
// as far right as possible.  So it can be removed from its current position without difficulty. 
//
// Second, swap this node with the node that was supposed to be removed.
//
// The key is that the properties of a binary search tree will still be satisfied, since there were
// no keys in the original tree whose ordering comes between the removed key and its immediate
// predecessor.
template <typename Record>
Error_code Search_tree<Record>::remove_root( Binary_node<Record> *&sub_root )
{
  if( sub_root == NULL ) return not_present;

  Binary_node<Record> *to_delete = sub_root;

  if( sub_root->right == NULL )
    sub_root = sub_root->left;
  else if ( sub_root->left == NULL )
    sub_root = sub_root->right;
  else  // neither subtree is empty
  {
    to_delete = sub_root->left;   // move left

    Binary_node<Record> *parent = sub_root;

    while( to_delete->right != NULL )
    {
      parent = to_delete;
      to_delete = to_delete->right;
    }

    // move from to_delete(predecessor) to root(node to delete)
    sub_root->data = to_delete->data;   

    // <note> this is interesting and cases for when predecessor does have left subtree but right
    // null.
    //          ...               or              ...           
    //        [ ] sub_root                      [ ] sub_root
    //                                        ...                 
    //     [ ]    to_delete                  [ ]    parent
    //                                        
    //  [ ]  N                            [ ]  [ ]  to_delete             
    // ...                                   ...  N                
    //
    if(parent == sub_root)  // this when don't have while loop run  
      sub_root->left = to_delete->left;
    else  
      parent->right = to_delete->left;
  }

  // remove it from the tree 
  delete to_delete;
  return success;
}

template <typename Record>
Error_code Search_tree<Record>::search_and_destroy( Binary_node<Record>* &sub_root, const Record &target)
{
  // remove_root handles sub_root is NULL
  if( sub_root == NULL || sub_root->data == target )
    return remove_root( sub_root );
  else if( target < sub_root->data )
    return search_and_destroy( sub_root->left, target );
  else
    return search_and_destroy( sub_root->right, target );
}

template <typename Record>
Error_code Search_tree<Record>::remove( const Record &target )
{
  return search_and_destroy( this->root, target ); 
}
//
// Search_tree }}

// AVL_node {{
//
template <typename Record>
struct AVL_node: public Binary_node<Record>
{
  Balance_factor balance;

  AVL_node();
  AVL_node( const Record &x );

  void set_balance( Balance_factor b ) { balance = b; };
  Balance_factor get_balance() const { return balance; };
};

template <typename Record>
AVL_node<Record>::AVL_node()
{
  Binary_node<Record>::Binary_node();
  balance = equal_height;
}

template <typename Record>
AVL_node<Record>::AVL_node( const Record &x )
{
  Binary_node<Record>::Binary_node(x);
  balance = equal_height;
}
//
// AVL_node }}


// AVL_tree {{
//
template <typename Record>
class AVL_tree: public Search_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    Error_code remove( const Record &old_data );

  private:
    Error_code avl_insert( Binary_node<Record> *&sub_root, const Record &new_data,
        bool &taller );

    void right_balance( Binary_node<Record> *&sub_root );
    void rotate_left( Binary_node<Record> *&sub_root );
};

template <typename Record>
Error_code AVL_tree<Record>::insert( const Record &new_data )
{
  bool taller;
  return avl_insert( this->root, new_data, taller );
}

template <typename Record>
Error_code AVL_tree<Record>::avl_insert( Binary_node<Record> *&sub_root, const Record &new_data,
    bool &taller )
{
  Error_code result = success;

  if( sub_root == NULL )
  {
    sub_root = new AVL_node<Record>(new_data);
    taller = true;
  }
  else if( new_data < sub_root->data )  // insert in left subtree
  {
    result = avl_insert( sub_root->left, new_data, taller );
    if( taller == true )  // new node made
      switch( sub_root->get_balance())
      {
        // <note> parent balance was left and added one more in left. so difference > 1 and needs rebalancing
        case left_higher:         
          left_balance(sub_root); // rebalancing
          taller = false;         // rebalancing always shorten the tree
          break;

        case equal_height:        // parent balance
          sub_root->set_balance(left_higher);
          break;

        case right_higher:        // parent balance
          sub_root->set_balance(equal_height);
          taller = false;
          break;
      }
  }
  else if( new_data > sub_root->data )  // insert in right subtree
  {
    result = avl_insert( sub_root->right, new_data, taller );
    if( taller == true )  // new node made
      switch( sub_root->get_balance())  // get parent balance
      {
        case left_higher:         
          sub_root->set_balance(equal_height);
          taller = false;
          break;

        case equal_height:     
          sub_root->set_balance(right_higher);
          break;

        case right_higher:        
          right_balance(sub_root);
          taller = false;       
          break;
      }
  }
  else
  {
    result = duplicate_error;
    taller = false;
  }

  return result;
}

// Pre: sub_root points to a subtree of the AVL_tree. This subtree has a nonempty right subtree.
// Post: sub_root is reset to point to its former right child, and the former sub_root node is the
// left child of the new sub_root node.
// <note> rotate right child but argument is its parent
template <typename Record>
void AVL_tree<Record>::rotate_left( Binary_node<Record> *&sub_root )
{
  // impossible case
  if( sub_root == NULL || sub_root->right == NULL )
    std::cout << "warning: program error detected in rotate_left" << std::endl;
  else
  {
    Binary_node<Record> *right_tree = sub_root->right;

    sub_root->right = right_tree->left;
    right_tree->left = sub_root;
    sub_root = right_tree;
  }
}

template <typename Record>
void AVL_tree<Record>::right_balance( Binary_node<Record> *&sub_root )
{
  // <note> see how to take reference from a pointer and to use in rotate_right
  Binary_node<Record> *&right_tree = sub_root->right;

  switch( right_tree->get_balance() )   // get right tree balance 'after' insertion
  {
    // <case-one> single rotation left
    case right_higher:
      // set balance before rotation since rotation moves pointers
      sub_root->set_balance(equal_height);
      right_tree->set_balance(equal_height);
      rotate_left(sub_root);
      break;

    // <case-three> impossible case
    case equal_height:
      std::cout << "warning: program error detected in right_balance" << std::endl;
      break;

    // <case-two> double rotation left
    case left_higher:
      Binary_node<Record> *sub_tree = right_tree->left;

      switch( sub_tree->get_balance() )
      {
        case equal_height:
          sub_root->set_balance(equal_height);
          right_tree->set_balance(equal_height);
          break;
        case left_higher:
          sub_root->set_balance(equal_height);
          right_tree->set_balance(right_higher);
          break;
        case right_higher:
          sub_root->set_balance(left_higher);
          right_tree->set_balance(equal_height);
          break;
      }

      sub_tree->set_balance(equal_height);
      rotate_right(right_tree);   // see the argument
      rotate_left(sub_root);

      break;
  }
}
//
// AVL_tree }}

void PrintTreeNode( int &entry )
{
  std::cout << " " << entry << ",";
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  Search_tree<int> bst;
  Error_code result;

  // insert
  for(int idx = 0; idx < size; idx++)
  {
    result = bst.insert( arr[idx] );
    if( result != success )
    {
      std::cout << "insert failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  bst.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 

  // remove
  for(int idx = 0; idx < size; idx++)
  {
    result = bst.remove( arr[idx] );
    if( result != success )
    {
      std::cout << "remove failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  bst.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 
}


{splay-tree}

Like hospital example, want to keep records that are newly inserted or frequently accessed very
close to the root, while records that are inactive may be placed far off, near or in the leaves.

Also cannot shut down the hospital for an hour to rebuild the tree into the desired shape, so do
self-adjusting data that automatically changes its shape to meet the above.


={============================================================================
*kt_dev_algo_013* multiway trees

Binary trees, as we have seen, are a powerful and elegant form of data structure. Even so, the
'restriction' to no more than two children at each node is severe, and there are many possible
applications for trees as data structures where the number of children of a node can be 'arbitrary'.

<ordered-tree> which is different from a binary tree.
Hence we define an ordered tree to be a rooted tree in which the children of each vertex are
assigned an order.

Note that ordered trees for which no vertex has more than two children are still not the same class
as binary trees. If a vertex in a binary tree has only one child, then it could be either on the
left side or on the right side, and the two resulting binary trees are different, but both would be
the same as ordered trees.

<computer-implementation>
To use an ordered tree as a data structure, the obvious way to implement it in computer memory would
be to extend the standard way to implement a binary tree, keeping as many link members in each node
as there may be subtrees, in place of the two links needed for binary trees. 

Clearly this method of representing ordered trees is very wasteful of space. So linked list. To keep
the children of each node in a linked list, we shall need two kinds of links. first_child and
next_sibling. By using these two links we now have the structure of a binary tree; that is, the
linked implementation of an ordered tree is a linked 'binary' tree. why binary? since each node has
two links; first_child(left) and next_sibling(right).

    ()      first_child: / , next_sibling: ->
   /
  () -----------------> () ------------------> ()
  /                     /                      /
 ()-> () -> () -> ()   ()                     () -> ()
      /                /                            /
     ()               () -> () -> () -> ()         ()


{b-tree} balanced multiway tree. external searching
Given disk access is slow(expensive) how can we minimize the number of disk access? With each
access, however, we obtain a block that may have room for several records. Using these records we
may be able to make a 'multiway' decision concerning which block/page to access next. Hence multiway
trees are especially appropriate for external searching.

The devised is a multiway search tree to make the 'height' of the tree as small as possible. The
definition is:

<definition>
A B-tree of order 'm' is an m-way search tree in which

1. All leaves are on the same level.

2. All internal nodes except the root have at most m 'nonempty' children, and at least [m/2]
nonempty children.

3. The number of keys in each internal node is 'one' less than the number of its nonempty children,
  and these keys partition the keys in the children in the fashion of a search tree.

4. The root has at most m children, but may have as few as 2 if it is not a leaf, or none if the
tree consists of the root alone.

<insertion>
The condition that all leaves be on the same level forces a characteristic behavior of B-trees: In
contrast to binary search trees, B-trees are not allowed to grow at their leaves; instead, they are
forced to 'grow' at the 'root'.

When a search is later made through the tree, therefore, a comparison with the median key will serve
to direct the search into the proper subtree.

When a key is added to a full root, then the root splits in two and the median key sent upward
becomes a new root. This is the only time when the B-tree grows in height.

<example>
input: a g f b,k,d h m,j,e s i r,x,c l n t u,p

1. a g f b     ->    [a b f g]    // [a] -> [a g] -> [a f g] -> [a b f g ]

2. k           ->         [f]
                         /   \
                     [a b]    [g k]

3. d h m       ->         [f]
                         /   \
                   [a b d]    [g h k m]

4. j           ->         [f       j]
                         /   \    /  \
                   [a b d]    [g h]  [k m]

5. e s i r     ->         [f         j]
                         /   \      /  \
                   [a b d e]  [g h i]  [k m r s]

6. x           ->         [f         j      r]
                         /   \      /  \   /  \
                   [a b d e]  [g h i]  [k m]  [s x]

7. c i n t u   ->      [c      f        j          r]
                       /  \  /   \     /  \       /  \
                   [a b]  [d e]  [g h i]  [k l m n]  [s t u x]

8. p           ->                [     j    ]
                                /            \
                       [c      f]             [m     r]
                       /  \  /   \           /  \   /  \
                   [a b]  [d e]  [g h i]  [k l]  [n p]  [s t u x]

From 7 to 8:
inset, push_down, split     [c      f        j          r]
                            /  \  /   \     /  \       /  \
push_down, split        [a b]  [d e]  [g h i]  [k l m n]  [s t u x]

push_down(hit null)

<code> TODO: how to traverse?

#include <iostream>

// Since these list are short, for simplicity, use contiguous array and count
//
// The relationship between count, data, and branch when order is 5, m == 5.
//
// count : 0 for emptiness and [1, m]
//
// position : [0, m-1]
//
// data       [0]     [1]     [2]     [3]     : target ==
//          /    \   /   \   /   \   /  \
// branch [0]     [1]     [2]     [3]   [4]   : target < or target >
//        left    right
//
// '/' means < and '\' menas <
//
// branch[0] points to the subtree containing all records with keys less than the key in data[0];
// branch[1] points to the subtree with keys between data[pos-1] and data[pos]
// ...
// branch[4] points to the subtree containing all records with keys greater than the key in data[3];
// 
// So it seems one large constuct which has four binary search trees.
//

typedef enum { success, overflow, underflow, duplicate_error, not_present} Error_code;

template <typename Record, int order>
struct B_node
{
  // # of records in the tree, [1,m]. count-1 is # of keys
  int count;
  // list of entries(keys or records), m-1
  Record data[order-1];
  // list of pointers to the children(branches), m
  B_node<Record, order> *branch[order];

  B_node() { count = 0; };
};

// For simplicity, construct B tree in high-speed memory. These pointers would be replaced by the
// address of various blocks or pages on disk, and taking a pointer reference would become making a
// disk access.
template <typename Record, int order>
class B_tree 
{
  public:
    Error_code search_tree( Record &target );
    Error_code insert( const Record &entry );
    B_tree() { root = NULL; }

    void inorder( void (*visit)(Record &));

    // aux functions
  private:
    void recursive_inorder( B_node<Record, order> *sub_root, void (*visit)(Record &));

    Error_code recursive_search_tree( B_node<Record, order> *current, Record &target );
    Error_code search_node( B_node<Record, order> *current, const Record &target, int &position );
    Error_code push_down( B_node<Record, order> *current, const Record &new_entry, 
        Record &median, B_node<Record, order>* &right_branch );
    Error_code push_in( B_node<Record, order> *current, const Record &new_entry, 
        B_node<Record, order> *right_branch, int position );
    void split_node( B_node<Record, order> *current, const Record extra_entry, 
        B_node<Record, order> *extra_branch, int position, B_node<Record, order> *right_branch, Record &median );

  private:
    B_node<Record, order> *root;
};

// <traverse> do not work.
//
template <typename Record, int order>
void B_tree<Record, order>::inorder( void (*visit)(Record &))
{
  recursive_inorder(root, visit);
}

template <typename Record, int order>
void B_tree<Record, order>::recursive_inorder(B_node<Record, order> *sub_root, void (*visit)(Record &))
{
  if (sub_root != NULL) 
  {
    recursive_inorder(sub_root->left, visit);
    (*visit)(sub_root->data);
    recursive_inorder(sub_root->right, visit);
  }
}

// <search>
//

// The assumption is that records can be compared with standard operators.
//
// Post: If there is an entry in the B-tree whose key matches that in target, the parameter target
// is replaced by the corresponding Record from the B-tree and a code of success is returned.
// Otherwise a code of not_present is returned.
template <typename Record, int order>
Error_code B_tree<Record, order>::search_tree( Record &target )
{
  return recursive_search_tree( root, target );
}

// <note> In multiway tree, however, we must examine each node more 'extensively' to find which branch to
// take at the next step. use search_node().
//
// <note> This is tail recursion so can be replaced by iteration.
//
// Pre: current is either NULL or points to a subtree of the B_tree.  
// Post: If the Key of target is not in the subtree, a code of not_present is returned. Otherwise,
// a code of success is returned and target is set to the corresponding Record of the subtree.
//
template <typename Record, int order>
Error_code B_tree<Record, order>::recursive_search_tree( B_node<Record, order> *current, Record &target )
{
  Error_code result = not_present;

  int position;

  if( current != NULL )
  {
    // The function search_node uses an output parameter 'position', which is the index of the target
    // if found within the current node and otherwise is the index of the branch on which to
    // continue the search.
    result = search_node( current, target, position );

    if( result == not_present )
      result = recursive_search_tree( current->branch[position], target );
    else
      target = current->data[position];
  }

  return result;
}

// determine the position where target should be in; data position when the target is found or the
// branch position to be searched/inserted when not found.
//
// if found, return success and the position in data
// if not found, return the position in branch to be searched/inserted.
//
// <note> the same position used for data or for branch.
// <note> for branch position, 'else' case can return either the last branch(greater-than) or the
// less-than branch.
// <note> this is effectively 'sort' function.
//
template <typename Record, int order>
Error_code B_tree<Record, order>::search_node( B_node<Record, order> *current, const Record &target, 
    int &position )     // @out, position
{
  position = 0;

  // perform a sequential search
  // For B-trees of large order, this function should be modified to use binary search instead of
  // sequential search. In some applications, a significant amount of information is stored with
  // each record of the B-tree, so that the order of the B-tree will be relatively small, and
  // sequential search within a node is appropriate. In many applications, only keys are kept in the
  // nodes, so the order is much larger, and binary search should be used to locate the position of
  // a key within a node.
  //
  // Yet another possibility is to use a linked binary search tree instead of a sequential array of
  // entries for each node; this possibility will be investigated at length later in this chapter.
  //
  while( position < current->count && target > current->data[position] )
    position++;

  // check position again since position == current->count when while ends
  if( position < current->count && target == current->data[position] )
    return success;
  else // <key> ( position == count or target < current->data[position] )
    return not_present;
}

// <insert>
// Insertion into a B-tree can be most naturally formulated as a recursive function
// For the push_down recursion, however, we need three additional output parameters; current,
// median, and right_branch.
// 
// <note> we shall require that the key being inserted is 'not' already present in the tree.


// insert splits current node by push_down() recursive function to maintain B tree property.
//
//                                              [median]
//                                            /         \
// new entry -> [ *current(node) ]  =>  [ node ]      [ node ]
//
//              (a) (b) (c) (d)         (a) (b)       (c) (d)
// 
template <typename Record, int order>
Error_code B_tree<Record, order>::insert( const Record &new_entry )
{
  Record median;

  B_node<Record, order> *right_branch, *new_root;

  Error_code result = push_down( root, new_entry, median, right_branch ); 
  if( result == overflow )
  {
    new_root = new B_node<Record, order>;
    new_root->count = 1;
    new_root->data[0] = median;         // median from a split
    new_root->branch[0] = root;         // the previous which is now left
    new_root->branch[1] = right_branch; // the right from a split
    root = new_root;
    result = success;
  }

  return result;
}

// Otherwise, new_entry is inserted into the subtree: If this causes the height of the subtree to
// grow, a code of overflow is returned, and the Record median is extracted to be reinserted higher
// in the B-tree, together with the subtree right_branch on its right. If the height does not grow,
// a code of success is returned.
template <typename Record, int order>
Error_code B_tree<Record, order>::push_down( B_node<Record, order> *current, const Record &new_entry, 
    Record &median, 
    B_node<Record, order>* &right_branch )
{
  Error_code result;
  int position;

  // stopping rule
  // In a B-tree, a new record is first inserted into a leaf. Shall thus use the condition current
  // == NULL to terminate the recursion; that is, we shall continue to move down the tree searching
  // for new_entry until we hit an empty subtree.
  //
  // Since the B-tree does not grow by adding new leaves, we do not then immediately insert
  // new_entry, but instead we return a code of overflow (since an empty subtree cannot have a
  // record inserted) and send the record back up (now called median) for later insertion.
  // This handles the first insertion when the tree is empty.
  if( current == NULL )
  {
    median = new_entry;
    right_branch = NULL;
    result = overflow;    // this passes up to insert call
  }
  else
  {
    if( search_node( current, new_entry, position ) == success )
      result = duplicate_error;
    // not found and insert entry into the tree
    else
    {
      Record extra_entry;
      B_node<Record, order> *extra_branch;

      // result = push_down( current->branch[position], new_entry, median, right_branch );
      result = push_down( current->branch[position], new_entry, extra_entry, extra_branch );
      // hit the leaf subtree
      if( result == overflow )
      {
        // the leaf has a room to insert
        if( current->count < order -1 )
        {
          result = success;
          // here position means branch position to insert
          push_in( current, extra_entry, extra_branch, position ); 
        }
        else
          split_node( current, extra_entry, extra_branch, position, right_branch, median );
      }
    } // search_node else
  } // else

  return result;
}

// inserts the Record entry and its 'right-hand' pointer right_branch into the node *current,
// provided there is room for the insertion.
template <typename Record, int order>
Error_code B_tree<Record, order>::push_in( B_node<Record, order> *current, const Record &new_entry, 
    B_node<Record, order> *right_branch, int position )
{
  // <note> count(# of children) and position(array index) has 1 difference. see loop and indexing.
  // <note> see move difference in data and branch. this is why said 'right-hand' pointer.
  //
  //           0   1   2   3   4       0   1   2   3   4   5
  //  data    [0] [1] [2] '\0'        [0] [1] [N] [2] '\0' 
  //  branch  [0] [1] [2] [3] '\0'    [0] [1] [2] [3] [N] '\0'
  //                                              <Q>

  // shift all later from position to right
  for( int i = current->count; i > position; i-- )
  {
    current->data[i] = current->data[i-1];
    current->branch[i+1] = current->branch[i];
  }

  // <Q> this set branch[pos+1] = NULL. Given branch[pos] was a less-than subtree before insertion,
  // when insert new entry, should there be 'rearrange' [pos] and [pos+1] subtree? If not now, then
  // later somepoint? NO. since insertion always happens at leaf level, all branch pointers are
  // actually null. It is just for the sake of simpliticy.
  // 
  current->data[position] = new_entry;
  current->branch[position+1] = right_branch;
  current->count++;
}

template <typename Record, int order>
void B_tree<Record, order>::split_node( 
    B_node<Record, order> *current,       // @in, node to be split 
    const Record extra_entry,             // @in, new entry to insert
    B_node<Record, order> *extra_branch,  // @in, right-hand subtree of new entry
    int position,                         // @in, index in node where new entry goes
    B_node<Record, order> *right_branch,  // @out, right-hand subtree after a split
    Record &median )                      // @out, median after a split (in neither half)
{
  right_branch = new B_node<Record, order>;

  int mid = order/2;    // same as arrary size/2

  // first case: new entry belongs in left branch
  if( position <= mid )
  {
    // move right half of current to right branch
    for( int i = mid; i < order-1; i++ )
    {
      right_branch->data[i-mid] = current->data[i];
      right_branch->branch[i+1-mid] = current->branch[i+1];
    }

    // set count for left and right branch
    current->count = mid;
    right_branch->count = order-1-mid;

    // push into the left(current)
    push_in( current, extra_entry, extra_branch, position );
  }
  // second case: new entry belongs in right branch
  else
  {
    mid++; // temporarily leave the median in left

    // move right half of current to right branch. <note> same as first case
    for( int i = mid; i < order-1; i++ )
    {
      right_branch->data[i-mid] = current->data[i];
      right_branch->branch[i+1-mid] = current->branch[i+1];
    }

    // set count for left and right branch. <note> same as first case
    current->count = mid;
    right_branch->count = order-1-mid;

    // push into the right. <note> pos-mid
    push_in( right_branch, extra_entry, extra_branch, position-mid );
  }

  // <Q> This seems to be working only for second case.
  median = current->data[current->count-1];
  current->count--;

  right_branch->branch[0] = current->branch[current->count];
}

void PrintTreeNode( char &entry )
{
  std::cout << " " << entry << ",";
}

int main()
{
  char arr[] = "abcdefghijklmnopqrstuvwxyz";
  int size = ( sizeof(arr)/sizeof(arr[0]));

  B_tree<char, 5> btree;
  Error_code result;

  // insert
  for(int idx = 0; idx < size; idx++)
  {
    result = btree.insert( arr[idx] );
    if( result != success )
    {
      std::cout << "insert failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  btree.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 
}


{red-black-tree}
In the last section, we used a contiguous list to store the entries within a single node of a
B-tree. Doing so was appropriate because the number of entries in one node is usually relatively
'small' and because we were emulating methods that might be used in external files on a disk, where
dynamic memory may not be available, and records may be stored contiguously on the disk.

<key> notice that this says about 'node' itself.

In general, however, we may use <any-ordered-structure> we wish for storing the entries in each
B-tree node. <small-binary-search-trees> turn out to be an excellent choice. We need only be careful
to distinguish between the links 'within' a single B-tree node and the links from one B-tree node to
another. Let us therefore draw the links within one B-tree node as curly colored lines(red) and the
links between B-tree nodes as straight black lines(black).

This shows a B-tree of order 4 constructed this way and each node construction contains one, two, or
three entries.

      [ a b c ]           =>           [b]
      /  / \  \                       // \\     : red 
     T1 T2 T3 T4                     a     c
                                    / \   / \   : black
                                   T1 T2 T3 T4

A red-black tree is a binary search tree, with links colored red or black, obtained from a B-tree of
order 4 in the way just described. After we have converted a B-tree into a red-black tree, we can
use it like 'any' other binary search tree. In particular, searching and traversal of a red-black
tree are 'exactly' the same as for an ordinary binary search tree; 

How? we simply ignore the color of the links. Insertion and deletion, however, require more care to
maintain the underlying B-tree structure.

<convention>
1. each node colored nodes of a red-black tree as colored with the same color as the link
immediately 'above' it. 

2. the convention that the root is colored black since the root has no link above it. Similarly, we
shall consider that all the empty subtrees (corresponding to NULL links) are colored black.


<definition>
A red-black tree is a binary search tree in which each node has either the color red or black and
that satisfies the following conditions:

The first condition defining a B-tree, that all its empty subtrees are on the same level, means that
every simple path from the root to an empty subtree (NULL) goes through the same number of B-tree
nodes. The corresponding red-black tree has one black node (and perhaps one or two red nodes) for
each B-tree node. Hence black condition we obtain the black condition:

black condition. Every simple path from the root to an empty subtree (a NULL link) goes through the
same 'number' of black nodes.

We need a condition on red-black trees that will guarantee that no more than three nodes are
identified together (by red links) as one B-tree node, and that nodes with three entries are in red
condition the balanced form we are using. This guarantee comes from the red condition:

red condition. If a node is red, then its parent exists and is black.

<performance>
The height of a red-black tree containing n nodes is no more than 2 lg n.

Hence the time for searching a red-black tree with n nodes is O(log N) in every case. We shall find
that the time for insertion is also O(log N)

<insert>
we can 'reuse' all of our earlier methods and functions for manipulating binary search trees and their
nodes. In particular, searching and traversal are identical for red-black trees and for binary
search trees.

<the-new-node-is-red>
The recursive insertion process terminates when we hit an empty subtree, whereupon we create a new
node and attach it to the tree in place of the empty subtree. Should this new node be red or black?
Were we to make it black, we would new node increase the number of black nodes on one path (and only
one path), thereby violating the black condition. Hence the new node 'must' be 'red'.

<when-the-parent-is-red>
If the parent of the new red node is black, then the insertion is finished, but if the parent is
red, then we have introduced a violation of the red condition into the tree. The major work of the
insertion algorithm is to remove such a violation of the red condition

<postpone-work>
Our algorithm is considerably simplified, however, if we do not consider these cases immediately,
but instead postpone the work as long as we can.

the node inserted:
Hence, when we make a node red, we do not immediately try to repair the tree, but instead simply
return from the recursive call with a status indicator set to indicate that the node just processed
is 'red'.

the parent node:
After this return, we are again processing the 'parent' node. If it is black, then conditions for a
red-black tree are satisfied and the process terminates. If it is red, then again we do not
immediately attempt to repair the tree, but instead we set the status variable to indicate that we
have 'two' 'red' 'nodes' together, and then simply return from the recursive call.

whether the inserted is right or left:
It turns out, in this case, to be helpful to use the status variable also to indicate if the two red
nodes are related as left child or right child.

the grandparent:
After returning from the second recursive call, we are processing the grandparent node. Here is
where our convention that the root will always be black is helpful: Since the parent node is red, it
cannot be the root, and hence the grandparent exists.  This grandparent, moreover, is guaranteed to
be black, since its child (the parent node) is red, and the only violation of the red condition is
farther down the tree.

<key> At the grandparent, need to restore the tree only when the parent is red.

restore:
We shall examine 'only' the cases where the parent is the 'left' child of the grandparent; those
where it is the right child are 'symmetric'. We need to distinguish two cases according to the 'color'
of the other (the 'right') child of the grandparent, that is, the 'aunt' or "uncle" of the original
node.

<aunt-is-black> First suppose this aunt node is black. This case also covers the possibility
that the aunt node does not exist. (Recall that an empty subtree is considered black.) Then the
red-black properties are restored by a single or double 'rotation' to the right. In both these
diagrams, verify that the rotation (and associated color changes) removes the 'violation' of the
'red' condition and preserves the black condition by 'not' changing the number of black nodes on any
path down the tree.

Here "// or \\" for 'red' and "/ or \" for black.

1. notice that parent and child are in the same side(left)
             /                                              /
grandparent []             => rotate right          parent []
           //  \                                         //  \\
   parent []   aunt T4                            child []    [] grandparent
         //  \                                         /  \  /  \
  child []   T3                                       T1  T2 T3 T4 aunt
       /  \
     T1    T2

>
2. notice that parent and child are in the different side. child is on right.
             /                double                        /
grandparent []             => rotate right          parent []
           //  \                                         //  \\
   parent []   aunt T4                            child []    [] grandparent
         / \\                                          /  \  /  \
       T1   [] child                                  T1  T2 T3 T4 aunt
           /  \
          T2  T3


<aunt-is-red>
No rotation occurs, but the colors are changed. The parent and aunt nodes become black, and the
grandparent node becomes red. Should verify that the number of black nodes on any path down the tree
remains the same.

Since the grandparent node has become red, however, it is quite possible that the red condition is
'still' violated: The great-grandparent node may also be red. Hence the process may 'not' terminate.
We need to set the status indicator to show that we have a newly red node, and then we can continue
to work out of the recursion. Any violation of the red condition, however, moves two levels up the
tree, and, since the root is black, the process will 'eventually' terminate.

<make-root-black>
It is also possible that this process will change the root from black to red; hence, in the
outermost call, we need to make sure that the root is changed 'back' to 'black' if necessary.


               /                                          //             
  grandparent []             => color flip    grandparent []             
           //    \\                                     /    \           
   parent []      []aunt T4                    parent []      []aunt T4  
         // \    /  \                                // \    /  \        
  child []   T1  T2 T3                        child []   T1  T2 T3       

               /                                          //             
  grandparent []             => color flip    grandparent []             
           //    \\                                     /    \           
   parent []      []aunt T4                    parent []      []aunt T4  
         /  \\   /  \                                /  \\   /  \        
        T1  []   T2 T3                              T1   []  T2 T3       
            child                                        child


It is in this function, modify_left that our decision to postpone the restoration of the red-black
properties pays off. When modify_left is invoked, we know that the insertion was made in the left
subtree of the current node; we know its color; and, by using the RB_code status variable, we know
the condition of the subtree into which the insertion went. By using all this information, we can
now 'determine' exactly what 'actions', if any, are needed to 'restore' the red-black properties.

<code>
#include <iostream>

// RB TREE
// We might go back to our original motivation and implement red-black trees as B-trees whose nodes
// store search trees rather than contiguous lists. This approach would force us to recode most of
// the methods and auxiliary functions of a B-tree, because the original versions relied heavily on
// the contiguous representation of node entries. We shall therefore investigate an alternative
// implementation, where we construct a red-black tree class that inherits the properties of our
// search-tree class

enum Error_code { success, overflow, underflow, duplicate_error, not_present, internal_error };
enum Color { red, black };

// These outcomes from a call to the recursive insertion function describe the following results:
//
// okay: The color of the current root (of the subtree) has not changed; the tree now satisfies the
// conditions for a red-black tree.
//
// red_node: The current root has changed from black to red; modification may or may not be needed
// to restore the red-black properties.
//
// right_red: The current root and its right child are now both red; a color flip or rotation is
// needed.
//
// left_red: The current root and its left child are now both red; a color flip or rotation is
// needed.
//
// duplicate: The entry being inserted duplicates another entry; this is an error.
// 
enum RB_code { okay, red_node, left_red, right_red, duplicate };

// Binary_node {{
//
template <typename Entry>
struct Binary_node
{
  Entry data;
  Binary_node<Entry> *left;
  Binary_node<Entry> *right;

  Binary_node() { left = right = NULL; };
  Binary_node( const Entry &x ) { left = right = NULL; data = x;};

  virtual void set_color( Color c ) { };
  virtual Color get_color() const { return red; };
};
// Binary_node }}

// Binary_tree {{
//
template <typename Entry>
class Binary_tree 
{
  public:
    Binary_tree() { root = NULL; }
    Binary_tree(const Binary_tree<Entry> &original);
    Binary_tree & operator=(const Binary_tree<Entry> &original);
    // ~Binary_tree();

    bool empty() const { return root == NULL; }
    int size() const;
    void clear();
    int height() const;

    void insert( const Entry & );
    void inorder( void (*visit)(Entry &));

  protected:
    void recursive_inorder( Binary_node<Entry> *sub_root, void (*visit)(Entry &));
    Binary_node<Entry> *root;
};

template <typename Entry>
void Binary_tree<Entry>::inorder( void (*visit)(Entry &))
{
  recursive_inorder(root, visit);
}

template <class Entry>
void Binary_tree<Entry>::recursive_inorder(Binary_node<Entry> *sub_root, void (*visit)(Entry &))
{
  if (sub_root != NULL) 
  {
    recursive_inorder(sub_root->left, visit);
    (*visit)(sub_root->data);
    recursive_inorder(sub_root->right, visit);
  }
}
// Binary_tree }}


// Search_tree {{
//
template <typename Record>
class Search_tree: public Binary_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    Error_code remove( const Record &old_data );
    // If there is an entry in the tree whose key matches that in target, the parameter target is
    // replaced by the corresponding record from the tree and a code of success is returned.
    // Otherwise a code of not_present is returned.
    // <note> it seems unuseful to replace target parameter when found since that's the same value.
    // May be useful to return some other value?
    Error_code tree_search( Record &target ) const;

  private:
    Error_code search_and_insert( Binary_node<Record> *&sub_root, const Record &new_data ); 
    Binary_node<Record> *search_for_node( Binary_node<Record> *sub_root, 
        const Record &target) const;

    // to support removal with record.
    Error_code search_and_destroy( Binary_node<Record>* &sub_root, const Record &target);

    // If sub_root is NULL, a code of not_present is returned. Otherwise, the root of the subtree is
    // removed in such a way that the properties of a binary search tree are preserved. The
    // parameter sub_root is reset as the root of the modified subtree, and success is returned.
    Error_code remove_root( Binary_node<Record> *&sub_root );
};

// If the key of target is not in the subtree, a result of NULL is returned. Otherwise, a pointer
// to the subtree node containing the target is returned.

// template <typename Record>
// Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
//     const Record &target) const
// {
//   if( sub_root == NULL || sub_root->data == target )
//     return sub_root;
//   else if( target > sub_root->data )
//     return search_for_node( sub_root->right, target );
//   else
//     return search_for_node( sub_root->left, target );
// }

// recursion removal version
template <typename Record>
Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
    const Record &target) const
{
  while( sub_root && sub_root->data != target )
  {
    if( target > sub_root->data )
      sub_root = sub_root->right;
    else
      sub_root = sub_root->left;
  }

  return sub_root;
}

template <typename Record>
Error_code Search_tree<Record>::tree_search( Record &target ) const
{
  Error_code result = success;

  Binary_node<Record> *found = search_for_node( this->root, target );
  if( found == NULL )
    return not_present;
  else
    target = found->data;

  return result;
}

template <typename Record>
Error_code Search_tree<Record>::insert( const Record &new_data )
{
  return search_and_insert( this->root, new_data );
}

// <key> <call-by-value-problem> notice the use of "*&" here or else this is an bug as the same of
// TreeInsert() since sub_root is a local copy and the same wrong output.
// Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *sub_root, const Record
// &new_data); 
template <typename Record>
Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *&sub_root, 
    const Record &new_data ) 
{
  if( sub_root == NULL )
  {
    sub_root = new Binary_node<Record>(new_data);
    return success;
  }
  else if( new_data < sub_root->data )
    return search_and_insert( sub_root->left, new_data );
  else if( new_data > sub_root->data )
    return search_and_insert( sub_root->right, new_data );
  else 
    return duplicate_error;
}

// the parameter is one of links of the tree, and not just a copy.
// remove_root(x->left);
//
// <note> that the argument type.
//
// <note> this it different approach from DeleteNodeTree( TreeNode** p ): 
// First, move to to-delete node's left subtree and find the immediate predecessor when do inorder
// traversal. This finds the node as far right as possible and it has no right child since we went
// as far right as possible.  So it can be removed from its current position without difficulty. 
//
// Second, swap this node with the node that was supposed to be removed.
//
// The key is that the properties of a binary search tree will still be satisfied, since there were
// no keys in the original tree whose ordering comes between the removed key and its immediate
// predecessor.
template <typename Record>
Error_code Search_tree<Record>::remove_root( Binary_node<Record> *&sub_root )
{
  if( sub_root == NULL ) return not_present;

  Binary_node<Record> *to_delete = sub_root;

  if( sub_root->right == NULL )
    sub_root = sub_root->left;
  else if ( sub_root->left == NULL )
    sub_root = sub_root->right;
  else  // neither subtree is empty
  {
    to_delete = sub_root->left;   // move left

    Binary_node<Record> *parent = sub_root;

    while( to_delete->right != NULL )
    {
      parent = to_delete;
      to_delete = to_delete->right;
    }

    // move from to_delete(predecessor) to root(node to delete)
    sub_root->data = to_delete->data;   

    // <note> this is interesting and cases for when predecessor does have left subtree but right
    // null.
    //          ...               or              ...           
    //        [ ] sub_root                      [ ] sub_root
    //                                        ...                 
    //     [ ]    to_delete                  [ ]    parent
    //                                        
    //  [ ]  N                            [ ]  [ ]  to_delete             
    // ...                                   ...  N                
    //
    if(parent == sub_root)  // this when don't have while loop run  
      sub_root->left = to_delete->left;
    else  
      parent->right = to_delete->left;
  }

  // remove it from the tree 
  delete to_delete;
  return success;
}

template <typename Record>
Error_code Search_tree<Record>::search_and_destroy( Binary_node<Record>* &sub_root, const Record &target)
{
  // remove_root handles sub_root is NULL
  if( sub_root == NULL || sub_root->data == target )
    return remove_root( sub_root );
  else if( target < sub_root->data )
    return search_and_destroy( sub_root->left, target );
  else
    return search_and_destroy( sub_root->right, target );
}

template <typename Record>
Error_code Search_tree<Record>::remove( const Record &target )
{
  return search_and_destroy( this->root, target ); 
}
// Search_tree }}

// RB_node {{
//
template <typename Record>
struct RB_node: public Binary_node<Record>
{
  Color color;

  RB_node();
  RB_node( const Record &x );

  // RB_node() { Binary_node<Record>::Binary_node(); color = red; };
  // RB_node( const Record &x ) { Binary_node<Record>::Binary_node(x); color = red; };

  void set_color( Color c ) { color = c; };
  Color get_color() const { return color; };
};

template <typename Record>
RB_node<Record>::RB_node()
{
  Binary_node<Record>::Binary_node(); 
  color = red;
}

template <typename Record>
RB_node<Record>::RB_node( const Record &x)
{
  // Binary_node<Record>::Binary_node(x); 
  this->data = x;
  this->left = this->right = NULL;
  color = red;
}
// RB_node }}


// RB_tree {{
//
template <typename Record>
class RB_tree: public Search_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    // Error_code remove( const Record &old_data );

  private:
    RB_code rb_insert( Binary_node<Record> *&current, const Record &new_data );
    RB_code modify_left( Binary_node<Record> *&current, RB_code &child_status );
    RB_code modify_right( Binary_node<Record> *&current, RB_code &child_status );
    RB_code rotate_right( Binary_node<Record> *&current );
    RB_code rotate_left( Binary_node<Record> *&current );
    RB_code flip_color( Binary_node<Record> *&current );
};

template <typename Record>
Error_code RB_tree<Record>::insert( const Record &new_data )
{
  RB_code status = rb_insert( this->root, new_data );

  // convert private RB_code to public Error_code
  switch( status )
  {
    // see <make-root-black>
    case red_node:
      this->root->set_color(black);
    case okay:
      return success;

    case duplicate:
      return duplicate_error;

    case right_red:
    case left_red:
      std::cout << "warning: program error detected in RB_tree::insert" << std::endl;
      return internal_error;
  }
}

// Pre: current is either NULL or points to the first node of a subtree of an RB_tree
//
// Post: If the key of new_entry is already in the subtree, a code of duplicate is returned.
// Otherwise, the Record new_entry is inserted into the subtree pointed to by current. The
// properties of a red-black tree have been restored, except possibly at the root current and one of
// its children, whose status is given by the output RB_code.
template <typename Record>
RB_code RB_tree<Record>::rb_insert( Binary_node<Record> *&current, const Record &new_data )
{
  RB_code status, child_status;

  if( current == NULL )
  {
    current = new RB_node<Record>(new_data);
    status = red_node;
  }
  else if( new_data < current->data )  // insert in left subtree
  {
    child_status = rb_insert( current->left, new_data );
    status = modify_left( current, child_status );
  }
  else if( new_data > current->data )  // insert in right subtree
  {
    child_status = rb_insert( current->right, new_data );
    status = modify_right( current, child_status );
  }
  else
  {
    status = duplicate;
  }

  return status;
}

// Pre: An insertion has been made in the left subtree of *current that has returned the value of
// child_status for this subtree.
//
// Post: Any color change or rotation needed for the tree rooted at current has been made, and a
// status code is returned.
template <typename Record>
RB_code RB_tree<Record>::modify_left( Binary_node<Record> *&current, RB_code &child_status )
{
  RB_code status = okay;

  Binary_node<Record> *aunt = current->right;
  Color aunt_color = black;

  if( aunt != NULL )
    aunt_color = aunt->get_color();

  switch( child_status )
  {
    // no action needed as tree is already okay
    case okay: 
      break;

    case red_node:
      if( current->get_color() == red )   // red inserted at current-1 and current is red. need to restore at the current+1.
        status = left_red;                // <note> left_red
      else                                // red inserted and current black. so okay.
        status = okay;
      break;

    case left_red:
      if( aunt_color == black )
        status = rotate_right(current);
      else
        status = flip_color(current);
      break;

    case right_red:
      if( aunt_color == black )
      {
        // status = double_rotate_right(current);
        Binary_node<Record> *&left_tree = current->left;
        status = rotate_left(left_tree);
        status = rotate_right(current);
      }
      else
        status = flip_color(current);
      break;
  }
  return status;
}

// Pre: An insertion has been made in the 'right' subtree of *current that has returned the value of
// child_status for this subtree.
//
// Post: Any color change or rotation needed for the tree rooted at current has been made, and a
// status code is returned.
template <typename Record>
RB_code RB_tree<Record>::modify_right( Binary_node<Record> *&current, RB_code &child_status )
{
  RB_code status = okay;

  Binary_node<Record> *aunt = current->left;
  Color aunt_color = black;

  if( aunt != NULL )
    aunt_color = aunt->get_color();

  switch( child_status )
  {
    // no action needed as tree is already okay
    case okay: 
      break;

    case red_node:
      if( current->get_color() == red )   // red inserted at current-1 and current is red. need to restore at the current+1.
        status = right_red;               // <note> right_red
      else                                // red inserted and current black. so okay.
        status = okay;
      break;

    case left_red:
      if( aunt_color == black )
      {
        // status = double_rotate_left(current);
        Binary_node<Record> *&right_tree = current->right;
        status = rotate_right(right_tree);
        status = rotate_left(current);
      }
      else
        status = flip_color(current);
      break;

    case right_red:
      if( aunt_color == black )
        status = rotate_left(current);
      else
        status = flip_color(current);
      break;
  }
  return status;
}

// From AVL tree codes:
// Pre: current points to a subtree of the RB_tree. This subtree has a nonempty 'left' subtree.
// Post: current is updated to point to its former 'left' child, and the former current node is the
// 'right' child of the new current node.
//
// <note> rotate left child but argument is its parent
//
// <Q> what's the return for error case
template <typename Record>
RB_code RB_tree<Record>::rotate_right( Binary_node<Record> *&current )
{
  // impossible case
  if( current == NULL || current->left == NULL )
    std::cout << "warning: program error detected in rotate_right" << std::endl;
  else
  {
    Binary_node<Record> *left_tree = current->left;

    current->left = left_tree->right;
    left_tree->right = current;
    current = left_tree;
  }

  return okay;
}


// From AVL tree codes:
// Pre: current points to a subtree of the RB_tree. This subtree has a nonempty 'right' subtree.
// Post: current is updated to point to its former 'right' child, and the former current node is the
// 'left' child of the new current node.
//
// <note> rotate right child but argument is its parent
//
template <typename Record>
RB_code RB_tree<Record>::rotate_left( Binary_node<Record> *&current )
{
  // impossible case
  if( current == NULL || current->right == NULL )
    std::cout << "warning: program error detected in rotate_left" << std::endl;
  else
  {
    Binary_node<Record> *right_tree = current->right;

    current->right = right_tree->left;
    right_tree->left = current;
    current = right_tree;
  }

  return okay;
}

template <typename Record>
RB_code RB_tree<Record>::flip_color( Binary_node<Record> *&current )
{
  // impossible case
  if( current == NULL || current->right == NULL || current->left == NULL )
    std::cout << "warning: program error detected in flip_color" << std::endl;
  else
  {
    current->set_color(red);
    current->right->set_color(black);
    current->left->set_color(black);
  }

  return okay;
}
// RB_tree }}

void PrintTreeNode( int &entry )
{
  std::cout << " " << entry << ",";
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  RB_tree<int> rbt;
  Error_code result;

  // insert
  for(int idx = 0; idx < size; idx++)
  {
    result = rbt.insert( arr[idx] );
    if( result != success )
    {
      std::cout << "insert failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  rbt.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 

  // remove
  //for(int idx = 0; idx < size; idx++)
  //{
  //  result = bst.remove( arr[idx] );
  //  if( result != success )
  //  {
  //    std::cout << "remove failed: " << arr[idx] << " into a tree" << std::endl; 
  //  }
  //}

  // print
  // std::cout << "{"; 
  // bst.inorder( PrintTreeNode );
  // std::cout << "}" << std::endl; 
}


={============================================================================
*kt_dev_algo_050* comparison of methods

Three(five) imporant efficiency criteria when choosing algorithms: p330 in {ref-001}

1) use of space
2) computer time
3) programming effort

4) statistical analysis. to see difference between worst and best case.
5) empirical testing


# ============================================================================
#{ CASES
={============================================================================
*kt_dev_algo_100*	double linked list

// size of hash table.
#define MHV_HASH_SIZE 3

// hash function for handles.
#define HASH(handle) (((uint32_t)(handle)) % MHV_HASH_SIZE)

typedef struct SPfmListHead_
{
  struct SPfmListHead_ *nxt, *prv;
} SPfmListHead;

static SPfmListHead m_apstStreamHashTable[MHV_HASH_SIZE];

<DN-one>
This double linked list has an entry which has also a double linked list.

m_apstStreamHashTable

     prev           prev          prev
      |               |             |
    [0]             [1]           [2]   : headers
    |               |             |
   next            next          next 

     prev           prev          prev
      |               |             |
    [E]             [E]           [E]   : entries
    <- prev
       next ->
    |               |             |
   next            next          next 

<DN-two>
The hash table is simple mod operation. % HASH_SIZE and handles is an counter whcih increase by one.
So all handles will belongs one of {0,1,2} when HASH_SIZE is 3.

<DN-three>
This is implemented as circular but no use of it.

<DN-four>
Typical list structure has following structures and can define the entry as we want. However, how
can we use this List for different entry structure?

typedef struct listnode {
     ListEntry entry;
     struct listnode* next;
     struct listnode* prev;
} ListNode;

typedef struct list {
     ListNode*  current;
   ...
} List;


{generic-support} 
Here, trick is to have ListNode as the first member for <any> entry structure and to have a link to
that member. This build a linked list on that. In this example, it uses is as the first member, uses
its offset, and use type cast to what want to have. Why the first member? Because need to get the
start address of the object. This is C way since it assumes that memory layout or internal representation.  

typedef struct listnode {     <DN> no entry in a node
     struct listnode* next;
     struct listnode* prev;
} ListNode;

typedef struct list {
     ListNode*  current;
   ...
} List;

typedef struct {
  ListNode node;
  ...
} A_type_entry;

typedef struct {
  ListNode node;
  ...
} B_type_entry;

<init>

for( ii=0; ii < MHV_HASH_SIZE; ii++ )
{
  PFM_INIT_LIST_HEAD(m_apstStreamHashTable + ii);
}

void PFM_INIT_LIST_HEAD(SPfmListHead *ptr)
{
  ptr->nxt = ptr;
  ptr->prv = ptr;
}

<add>

typedef struct _SMhvStream
{
    SPfmListHead list;  // [DN] this is the first member of a structure
    ...
    SPfmListHead subs;
    SPfmListHead triggers;
    ...
} SMhvStream;

p = (SMhvStream *)blkAlloc(&m_StreamHashBlockCtrl);

PFM_INIT_LIST_HEAD(&p->subs);
PFM_INIT_LIST_HEAD(&p->triggers);

pfmListAddTail(m_apstStreamHashTable + HASH(p->handle), &(p->list));
/* add to stream. */
pfmListAddTail(&p->subs, &ev->strlist);

// Add an item to the tail of a list.
// @param   list    The list to modify
// @param   entry   The entry to add at the tail of list.
void pfmListAddTail(SPfmListHead * list, SPfmListHead * entry)
{
  entry->nxt = list;
  entry->prv = (list)->prv;
  list->prv->nxt = entry;
  (list)->prv = entry;
}

// Add an item to the head of a list.
// @param   list    The list to modify
// @param   entry   The entry to add at the start of list.
void pfmListAddHead(SPfmListHead * list, SPfmListHead * entry)
{
  entry->nxt = list->nxt;
  entry->prv = list;
  list->nxt->prv = entry;
  list->nxt = entry;
}

// Remove an item from its list.
// @param   item    The item to remove.
void pfmListRemove(SPfmListHead * item)
{
  item->nxt->prv = item->prv;
  item->prv->nxt = (item)->nxt;
}

<search> simple sequential search from each head

SPfmListHead *item;

for( int ii=0; ii < MHV_HASH_SIZE; ii++ )
{
  pfmForEach(item, m_apstStreamHashTable + HASH(h))
  {
    SMhvStream *p;
    p = pfmListEntry(item, SMhvStream, list);
    if (p != NULL) // should p ever be NULL?
    {
      use p;
    }
  }
}

#define pfmForEach(item, head) \
    for (item = (head)->nxt; item != (head); item = item->nxt)

#define pfmListEntry(item, type, member) \
    ((type *)((void*)((uint8_t *)(item)-(size_t)(&((type *)0)->member))))
                     |                                                |     : get memeber offset
             |                                                         |    : type cast to void*
                                                                            : type cast to type*


# ============================================================================
#{ DISCUSSION
={============================================================================
*kt_dev_algo_300* C++ map insertion and lookup performance and storage overhead

http://stackoverflow.com/questions/1822114/c-map-insertion-and-lookup-performance-and-storage-overhead

The question is:

I would like to store a mapping of an integer key to a float value in-memory. I have roughly 130
million keys (and, accordingly, 130 million values). My focus is on lookup performance. I have to do
many, many millions of lookups. The C++ STL library has a map class for associative arrays of this
sort. I have several questions about map. What is the storage overhead of map for a dataset of the
size mentioned above? How does storage overhead scale, in general, with map? It looks like the
underlying data structure for map is a red-black, balanced binary tree. It sounds like the
real-world performance for this is O(log n) for insertion and retrieval. It mentions O(1) for a
hinted insertion. My input is pre-sorted, so I believe I should be able to provide a hint for
insertion events. How would I provide this hint, using the methods listed here? Is there an STL
container that provides better lookup performance?  Are there other publicly-available, open-source
frameworks with an associate array class that uses an underlying data structure that would perform
better than STL map? If writing my own container class would provide better lookup performance, what
data structures might I research? I am using GCC 4 for this task, running under either Linux or Mac
OS X. I apologize in advance if these are dumb questions. Thank you for your advice.

Given what you've said, I'd think very hard about using an std::vector<pair<int, float> >, and using
std::lower_bound, std::upper_bound, and/or std::equal_range to look up values.

While the exact overhead of std::map can (and does) vary, there's little or no room for question
that it will normally consume extra memory and look up values more slowly than a binary search in a
vector. As you've noted, it's normally (and almost unavoidably) implemented as some sort of balanced
tree, which imposes overhead for the pointers and the balancing information, and typically means
each node is allocated separately as well. Since your nodes are pretty small (typically 8 bytes)
that extra data is likely to be at least as much as what you're actually storing (i.e. at least 100%
overhead). Separate allocations often mean poor locality of reference, which leads to poor cache
usage.

Edit: Looking just at implementations of std::map, it's probably worth noting that most use a
red-black tree. If you were going to use an std::map, an implementation that uses an AVL tree would
probably suit your purposes better -- an AVL tree has slightly tighter constraints on balancing.
This gives slightly faster lookup at the expense of slightly slower insertion and deletion (since it
has to re-balance more often to maintain its stricter interpretation of "balanced"). As long as
your data remains constant during use, however, an std::vector is still almost certainly better.

One other possibility worth noting: if your keys are at least fairly even distributed, you might
want to try looking up using interpolation instead of bisection. i.e. instead of always starting at
the middle of the vector, you do a linear interpolation to guess at the most likely starting point
for the lookup. Of course, if your keys follow some known non-linear distribution, you can use a
matching interpolation instead.

Edit 2: Assuming the keys are reasonably even distributed, the interpolation search has a complexity
of O(log log N). For 130 million keys, that works out to around 4 probes to find an item. To do
significantly better than that with (normal/non-perfect) hashing, you need a good algorithm, and you
need to keep the load factor in the table around 75% or so -- i.e. you need to allow for something
like 32 million extra (empty) spots in your table to improve the expected complexity from four
probes to three. I may just be old fashioned, but that strikes me as a lot of extra storage to use
for such a small speed improvement.

OTOH, it's true that this is nearly the ideal situation for perfect hashing -- the set is known
	ahead of time, and the key is quite small (important, since hashing is normally linear on the key
			size). Even so, unless the keys are distributed pretty unevenly, I wouldn't expect any huge
	improvement -- a perfect hash function is often (usually?) fairly complex.  share|improve this
	answer
	
definitely just use a binary search in the vector. Least memory, fastest too. –  Will Nov 30 '09 at
20:33
	
What about insertions? To use binary search, you'll have to keep the array sorted. Random
insertions in a vector are not particularly efficient. –  Raphaël Saint-Pierre Nov 30 '09 at 20:36
	
@RaphealSP: yes, if the data were dynamic (i.e. you need to support insertions/deletions during
		use), a sorted vector isn't a good choice. He notes, however, that the data starts out sorted,
	which I took as indicating that he's just reading in data, but not modifying it afterwards. –
		Jerry Coffin Nov 30 '09 at 20:41
	 
I am only inserting once. I do not need to modify my input set afterwards. –  Alex Reynolds Nov 30
'09 at 20:45 


# ============================================================================
#{ GLIBC
==============================================================================
*kt_dev_glib_000* glib sites

http://www.gnu.org/software/libc/libc.html
https://sourceware.org/glibc/wiki/GlibcGit

git clone git://sourceware.org/git/glibc.git

o use tabstop=6 for better view.


={============================================================================
*kt_dev_algo_0000* algo-atoi algo-itoa dev-algo-htoi

{atoi-man-page}
NAME
       atoi, atol, atoll, atoq - convert a string to an integer

SYNOPSIS
       #include <stdlib.h>

       int atoi(const char *nptr);
       long atol(const char *nptr);
       long long atoll(const char *nptr);
       long long atoq(const char *nptr);

DESCRIPTION
       The atoi() function converts the initial portion of the string  pointed
       to by nptr to int.  The behavior is the same as
       
           strtol(nptr, (char **) NULL, 10);

       note: except that atoi() does not detect errors.

//< from comments in tail excercise
   1.  atoi() has a normally annoying property of not being able to
       tell the caller conclusively whether the input was bad ("abc")
       or it was really zero ("0"), because it returns 0 for both    
       cases.  Here, we exploit that property, because we only want
       to accept options in the form of "-n".                      
//>
       The atol() and atoll() functions behave the same as atoi(), except that
       they convert the initial portion of the string to their return type  of
       long or long long.  atoq() is an obsolete name for atoll().

RETURN VALUE
       The converted value.

<strtol>
NAME
       strtol, strtoll, strtoq - convert a string to a long integer

SYNOPSIS
       #include <stdlib.h>

       long int strtol(const char *nptr, char **endptr, int base);
       long long int strtoll(const char *nptr, char **endptr, int base);

DESCRIPTION
       The strtol() function converts the initial part of the string  in  nptr
       to  a  long  integer  value  according to the given 'base', which must be
       between 2 and 36 inclusive, or be the special value 0.

       // note. handle leading white space, 0x, and sign

       The string may begin with an arbitrary amount of white space (as deter‐
       mined by isspace(3)) followed by a single optional '+' or '-' sign.  
       
       If base is zero or 16, the string may then include a "0x" prefix, and
       the number  will  be read in base 16; otherwise, a zero base is taken
       as 10 (decimal) unless the next character is '0', in which case it  is
       taken as 8 (octal).

       // note: zero base is 10 base

       The  remainder  of  the  string is converted to a long int value in the
       obvious manner, stopping at the first character which is  not  a  valid
       digit  in the given base.  (In bases above 10, the letter 'A' in either
       upper or lower case represents 10, 'B' represents  11,  and  so  forth,
       with 'Z' representing 35.)

       // note see how return and error are handled.

       If endptr is not NULL, strtol() stores the address of the first
       `invalid` character in *endptr.  
       
       If there were no digits at all, strtol()  stores the  original value of
       nptr in *endptr (and returns 0).  
       
       In particular, if *nptr is not '\0' but **endptr is '\0' on return, the
       entire  string is valid.

       The  strtoll()  function  works  just  like  the  strtol() function but
       returns a long long integer value.

RETURN VALUE
       The strtol() function returns the result of the conversion, unless  the
       value  would  underflow  or overflow.  If an underflow occurs, strtol()
       returns LONG_MIN.  If an overflow occurs,  strtol()  returns  LONG_MAX.
       In  both  cases,  errno is set to ERANGE.  Precisely the same holds for
       strtoll()  (with  LLONG_MIN  and  LLONG_MAX  instead  of  LONG_MIN  and
       LONG_MAX).

ERRORS
       EINVAL (not in C99) The given base contains an unsupported value.

       ERANGE The resulting value was out of range.

       The  implementation  may also set errno to EINVAL in case no conversion
       was performed (no digits seen, and 0 returned).

EXAMPLE
       The  program  shown  below demonstrates the use of strtol().  The first
       command-line argument specifies a string  from  which  strtol()  should
       parse  a  number.  The second (optional) argument specifies the base to
       be used for the conversion.  (This argument  is  converted  to  numeric
       form  using atoi(3), a function that performs no error checking and has
       a simpler interface than strtol().)  Some examples of the results  pro‐
       duced by this program are the following:

           $ ./a.out 123
           strtol() returned 123

           $ ./a.out '    123'
           strtol() returned 123

           $ ./a.out 123abc
           strtol() returned 123
           Further characters after number: abc

           $ ./a.out 123abc 55
           strtol: Invalid argument

           $ ./a.out ''
           No digits were found

           $ ./a.out 4000000000
           strtol: Numerical result out of range

   Program source

       #include <stdlib.h>
       #include <limits.h>
       #include <stdio.h>
       #include <errno.h>

       int
       main(int argc, char *argv[])
       {
           int base;
           char *endptr, *str;
           long val;

           if (argc < 2) {
               fprintf(stderr, "Usage: %s str [base]\n", argv[0]);
               exit(EXIT_FAILURE);
           }

           str = argv[1];
           base = (argc > 2) ? atoi(argv[2]) : 10;

           errno = 0;    /* To distinguish success/failure after call */
           val = strtol(str, &endptr, base);

           /* Check for various possible errors */
           if ((errno == ERANGE && (val == LONG_MAX || val == LONG_MIN))
                   || (errno != 0 && val == 0)) {
               perror("strtol");
               exit(EXIT_FAILURE);
           }

           if (endptr == str) {
               fprintf(stderr, "No digits were found\n");
               exit(EXIT_FAILURE);
           }

           /* If we got here, strtol() successfully parsed a number */
           printf("strtol() returned %ld\n", val);

           if (*endptr != '\0')        /* Not necessarily an error... */
               printf("Further characters after number: %s\n", endptr);

           exit(EXIT_SUCCESS);
       }

<code>

// algo-atoi
//
// * input type? digits only? no space?
// * input size?
// * what base? 10 or 2?
// * sign support? 

// from ansic, p43.
//
// when base is 10.
//
// this is 'naive' implementation since no error handlings and return 0 when
// failed to convert. compare to strtol
//
// there is no check on the end of string input? '0' is not the same as
// 0(null) and when see any other than numbers, for loops ends.

namespace algo_conversion
{
  uint32_t atoi_navie(const char *str)
  {
    uint32_t value{0}, i{0};

    for (; str[i] >= '0' && str[i] <= '9'; ++i)
    {
      value = value*10 + (str[i] - '0');
    }

    return value;
  }

  // use isdigit()

  uint32_t atoi_isdigit(const char *str)
  {
    uint32_t value{0}, i{0};

    for (; isdigit(str[i]); ++i)
    {
      value = value*10 + (str[i] - '0');
    }

    return value;
  }

  // To support sign and leading space

  uint32_t atoi_sign(const char *str)
  {
    uint32_t value{0}, i{0}, sign{0};

    while (isspace(str[i]))
      ++i;

    // check sign but don't need to increase i
    sign = str[i] == '-' ? -1 : 1;

    // have to increase
    if (str[i] == '-' || str[i] == '+')
      ++i;

    for (; isdigit(str[i]); ++i)
    {
      value = value*10 + (str[i] - '0');
    }

    return sign*value;
  }

  // use base 2. value is right but not representation

  // Chapter 7: String Fundamentals, 207
  // #!/usr/bin/python
  //
  // B = '1101'
  // I = 0
  //
  // while B != '':
  //     I = I*2 + (ord(B[0]) - ord('0'))
  //     B = B[1:]
  //
  // print(I)

  uint32_t atoi_binary(const char *str)
  {
    uint32_t value{0}, i{0};

    for (; str[i] >= '0' && str[i] <= '9'; ++i)
    {
      value = value*2 + (str[i] - '0');
    }

    return value;
  }


  // use base 16. htoi
  //
  // From ansic, exercise 2-3. 
  //
  // Write the function htoi(s), which converts a string of hexadecimal digits
  // (including an 'optional' 0x or 0X) into its equivalent integer value. The
  // allowable digits are 0 through 9, a through f, and A through F.
  //
  // isxdigit()
  //        checks for hexadecimal digits, that is, one of
  //        0 1 2 3 4 5 6 7 8 9 a b c d e f A B C D E F.

  // previous try
  //
  // int htoi(char s[])
  // {
  //   int n, i = 0, v = 0;
  // 
  //   // optional 0x or 0X
  //   if(s[0] == '0' && ( s[1] == 'x' || s[1] == 'X' ))
  //     i = 2;
  // 
  //   // isxdigit()
  //   // checks for a hexadecimal digits, that is, one of 
  //   // 0 1 2 3 4 5 6 7 8 9 a b c d e f A B C D E F.
  //    
  //   for(n = 0; isxdigit(s[i]); i++)
  //   {
  //     if( s[i] >= '0' && s[i] <= '9' )
  //       v = s[i] - '0';
  //     else if( s[i] >= 'a' && s[i] <= 'f' )
  //       v = s[i] - 'a' + 10;
  //     else 
  //       v = s[i] - 'A' + 10;
  // 
  //     n = n*16 + v;
  //   }
  // 
  //   return n;
  // }

  uint32_t atoi_hex(const char *str)
  {
    uint32_t value{0}, i{0};
    const std::string hex{"0123456789abcdef"};

    for (; hex.find(std::tolower(str[i])) != std::string::npos; ++i)
    {
      value = value*16 + hex.find(std::tolower(str[i]));
    }

    return value;
  }
} // namespace

TEST(AlgoConversion, StringToInteger)
{
  using namespace algo_conversion;

  EXPECT_THAT(atoi_navie("123"), Eq(123));
  EXPECT_THAT(atoi_isdigit("123"), Eq(123));

  EXPECT_THAT(atoi_sign("123"), Eq(123));
  EXPECT_THAT(atoi_sign("-123"), Eq(-123));

  EXPECT_THAT(atoi_binary("1101"), Eq(13));

  EXPECT_THAT(atoi_hex("1a"), Eq(26));
  EXPECT_THAT(atoi_hex("1A"), Eq(26));
}

// algo-itoa
//
// * what base? 10 or 2?
// * sign support? 

// from ansic, p43.
//
// when base is 10.
//
// there is no check on the end of string input? '0' is not the same as
// 0(null) and when see any other than numbers, for loops ends.

namespace algo_conversion
{
  std::string itoa_navie(const int input)
  {
    int value{input};
    char letter{0};
    std::string result{};

    for (; value;)
    {
      letter = '0' + (value % 10);
      result += letter;
      value /= 10;
    }

    return std::string(result.crbegin(), result.crend());
  }

  std::string itoa_no_reverse(const int input)
  {
    std::string result{};
    std::string temp{};
    char letter{0};
    int value{input};

    for(; value;)
    {
      letter = '0' + (value % 10);
      result.insert( result.begin(), 1, letter );
      value /= 10;
    }

    return result;
  }

} // namespace

TEST(AlgoConversion, IntegerToString)
{
  using namespace algo_conversion;

  EXPECT_THAT(itoa_navie(123), Eq("123"));
  EXPECT_THAT(itoa_no_reverse(123), Eq("123"));
}


// returns EOF for end of file, zero if the next input is not a number, and a
// positive value if the input contains a valid number. ansic p97.
int getint(int *pn)
{
  int c, sign;

  // skip white spaces
  while( isspace(c = getc() ))
      ;

  // not a number
  if( !isdigit(c) && c != EOF && c != '+' && c != '-' )
  {
    ungetc(c);
    return 0;
  }

  sign = (c == '-') ? -1 : 1;

  if( c == '+' || c == '-' )
    c = getc();

  for( *pn = 0; isdigit(c); c = getc() )
    *pn = *pn * 10 + (c - '0');

  *pn *= sign;

  if( c != EOF )
    ungetc(c);

  return c;
} 

To make it compile in gcc:

int getint(int *pn)
{
  int c, sign;

  // skip white spaces
  while( isspace(c = getchar() ))
      ;

  // not a number
  if( !isdigit(c) && c != EOF && c != '+' && c != '-' )
  {
    ungetc(c, stdin);
    return 0;
  }

  sign = (c == '-') ? -1 : 1;

  if( c == '+' || c == '-' )
    c = getchar();

  for( *pn = 0; isdigit(c); c = getchar() )
    *pn = *pn * 10 + (c - '0');

  *pn *= sign;

  if( c != EOF )
    ungetc(c, stdin);

  return c;
} 

<exercise> 
From ansic, exercise 5-1. As written, getint treats a + or - not followed by a digit as a valid
representation of zero. Fix it to push such a character back on the input.


<getchar-and-eof>
From ansic 1.5.1, "we can't use char since c must be big enough to hold EOF in addition to any
possible char. Therefore we use int"

GETS(3)                    Linux Programmer's Manual
int getchar(void);

int main(int argc, char* argv[])
{
  // int c;
  char c;

  printf("EOF (0x%x)\n", EOF);

  c = getchar();

  while( c != EOF )
  {
    putchar(c);
    c = getchar();
  }
}

kt@kt-ub-vb:~/work$ ./a.out 
EOF (0xffffffff)
a b v <1>
a b v <2>
(waiting input)

For <1>, a b v (ENTER) then <2> comes. This means that when press ENTER, input stream ends and is
ready to process. The getchar and putchar runs on this stream and only runs when press ENTER.

EOF is an integer defined in stdio.h but the specific numeric value doesn't matter as long as it is
not the same as any char value. This is why use symbolic constant.


<code-glibc>
Here only consider usual char type which is not wide char and 10 base. So disregard followings:

#ifdef USE_NUMBER_GROUPING
# ifdef USE_WIDE_CHAR

// stdlib/atio.c
int
atoi (const char *nptr)
{
  return (int) strtol (nptr, (char **) NULL, 10);
}

// stdlib/strtol.c
INT
strtol (nptr, endptr, base)
     const STRING_TYPE *nptr;
     STRING_TYPE **endptr;
     int base;
{
  return INTERNAL (__strtol_l) (nptr, endptr, base, 0, _NL_CURRENT_LOCALE);
}

// stdlib/strtol_l.c
// The interesting bit are: base handling, overflow handling,
//
INT
INTERNAL (__strtol_l) (nptr, endptr, base, group, loc)
     const STRING_TYPE *nptr;
     STRING_TYPE **endptr;
     int base;
     int group;
     __locale_t loc;
{
  const STRING_TYPE *s;
  UCHAR_TYPE c;
  const STRING_TYPE *save, *end;

  unsigned LONG int i;
  int overflow;

  save = s = nptr;

  /* Skip white space.  */
  while (ISSPACE (*s))
    ++s;

  /* Check for a sign.  */
  negative = 0;
  if (*s == L_('-'))
  {
    negative = 1;
    ++s;
  }
  else if (*s == L_('+'))
    ++s;

  /* Recognize number prefix and if BASE is zero, figure it out ourselves.  */
  // skip
  
  /* Save the pointer so we can check later if anything happened.  */
  // so handled the sign from s
  save = s;

  end = NULL;

  /* Avoid runtime division; lookup cutoff and limit.  */
  cutoff = cutoff_tab[base - 2];
  cutlim = cutlim_tab[base - 2];

  overflow = 0;
  i = 0;
  c = *s;

  // this is for QUAD
  if (sizeof (long int) != sizeof (LONG int))
  {
    unsigned long int j = 0;
    // same as cutoff_tab
    unsigned long int jmax = jmax_tab[base - 2];

    // scan through each char
    for (;c != L_('\0'); c = *++s)
    {
      // is it possible case?
      if (s == end)
        break;

      // convert to digit
      if (c >= L_('0') && c <= L_('9'))
        c -= L_('0');
      else if (ISALPHA (c))
        c = TOUPPER (c) - L_('A') + 10;
      else
        break;

      // cannot bigger than base
      if ((int) c >= base)
        break;
      /* Note that we never can have an overflow.  */
      else if (j >= jmax)
      {
        /* We have an overflow.  Now use the long representation.  */
        i = (unsigned LONG int) j;
        goto use_long;
      }
      // make a digit in corresponding unit
      else
        j = j * (unsigned long int) base + c;
    } // for end

    i = (unsigned LONG int) j;
  }
  // this is usual case
  else
    for (;c != L_('\0'); c = *++s)
    {
      if (s == end)
        break;

      if (c >= L_('0') && c <= L_('9'))
        c -= L_('0');
      else if (ISALPHA (c))
        c = TOUPPER (c) - L_('A') + 10;
      else
        break;

      // when c is alphabet
      if ((int) c >= base)
        break;

      /* Check for overflow.  */
      if (i > cutoff || (i == cutoff && c > cutlim))
        overflow = 1;
      else
      {
use_long:
        i *= (unsigned LONG int) base;
        i += c;
      }
    }

  /* Check if anything actually happened.  */
  // nothing converted
  if (s == save)
    goto noconv;

  /* Store in ENDPTR the address of one character
     past the last character we converted.  */
  if (endptr != NULL)
    *endptr = (STRING_TYPE *) s;

  /* Return the result of the appropriate sign.  */
  return negative ? -i : i;
}

// the bellow is the pre-calculated table for each base and the value are the
// max value for division and remainder. for example, cutoff = cutoff_tab[base
// - 2]; get the value for base 10.

/* Define tables of maximum values and remainders in order to detect
   overflow.  Do this at compile-time in order to avoid the runtime
   overhead of the division.  */
extern const unsigned long __strtol_ul_max_tab[] attribute_hidden;
extern const unsigned char __strtol_ul_rem_tab[] attribute_hidden;

#define DEF(TYPE, NAME)							   \
  const TYPE NAME[] attribute_hidden =					   \
  {									   \
    F(2), F(3), F(4), F(5), F(6), F(7), F(8), F(9), F(10), 		   \
    F(11), F(12), F(13), F(14), F(15), F(16), F(17), F(18), F(19), F(20),  \
    F(21), F(22), F(23), F(24), F(25), F(26), F(27), F(28), F(29), F(30),  \
    F(31), F(32), F(33), F(34), F(35), F(36)				   \
  }

#if !UNSIGNED && !defined (USE_WIDE_CHAR) && !defined (QUAD)
# define F(X)	ULONG_MAX / X
  DEF (unsigned long, __strtol_ul_max_tab);
# undef F
# define F(X)	ULONG_MAX % X
  DEF (unsigned char, __strtol_ul_rem_tab);
# undef F
#endif

/* Define some more readable aliases for these arrays which correspond
   to how they'll be used in the function below.  */
#define jmax_tab	__strtol_ul_max_tab
#if defined(QUAD) && __WORDSIZE == 32
# define cutoff_tab	__strtol_ull_max_tab
# define cutlim_tab	__strtol_ull_rem_tab
#else
# define cutoff_tab	__strtol_ul_max_tab
# define cutlim_tab	__strtol_ul_rem_tab
#endif

#ifdef QUAD
...
#else
# define LONG long


={============================================================================
*kt_dev_glib_002* atof

{man-page}
<atof>
NAME
       atof - convert a string to a double

SYNOPSIS
       #include <stdlib.h>

       double atof(const char *nptr);

DESCRIPTION
       The  atof() function converts the initial portion of the string pointed
       to by nptr to double.  The behavior is the same as

           strtod(nptr, (char **) NULL);

       except that atof() does not detect errors.

RETURN VALUE
       The converted value.

<strtod>       
NAME
       strtod, strtof, strtold - convert ASCII string to floating-point number

SYNOPSIS
       #include <stdlib.h>

       double strtod(const char *nptr, char **endptr);
       float strtof(const char *nptr, char **endptr);
       long double strtold(const char *nptr, char **endptr);

DESCRIPTION
       The strtod(), strtof(), and strtold() functions convert the initial
       portion of the string pointed to by nptr to double, float, and long
       double representation, respectively.

{code-glibc}
Here only consider usual char type which is not wide char and 10 base. So disregard followings:

// stdlib/atof.c
/* Convert a string to a double.  */
double
atof (const char *nptr)
{
  return strtod (nptr, (char **) NULL);
}

// stdlib/strtod.c
FLOAT
STRTOF (nptr, endptr)
     const STRING_TYPE *nptr;
     STRING_TYPE **endptr;
{
  return INTERNAL(STRTOF_L) (nptr, endptr, 0, _NL_CURRENT_LOCALE);
}

# ifdef USE_WIDE_CHAR
#  define STRTOF wcstod
#  define STRTOF_L __wcstod_l
# else
#  define STRTOF strtod
#  define STRTOF_L __strtod_l <use>
# endif

// stdlib/strtod_l.c

/* Return a floating point number with the value of the given string NPTR.
   Set *ENDPTR to the character after the last used one.  If the number is
   smaller than the smallest representable number, set `errno' to ERANGE and
   return 0.0.  If the number is too big to be represented, set `errno' to
   ERANGE and return HUGE_VAL with the appropriate sign.  */
FLOAT
____STRTOF_INTERNAL (nptr, endptr, group, loc)
     const STRING_TYPE *nptr;
     STRING_TYPE **endptr;
     int group;
     __locale_t loc;
{
  // more than 1000 lines
}

<example> ansic, p71.

int atoi(char s[])
{
  int i, n, sign;

  // skip white spaces
  for(i = 0; isspace( s[i] ); i++)
    ;

  sign = (s[i] == '-') ? -1 : 1;

  // skip sign
  if( s[i] == '+' || s[i] == '-' )
    i++;

  for(n = 0; isdigit( s[i] ); i++)
    n = n*10 + (s[i]-'0');

  return sign*n;
}

The atof extends atoi and the point is that do it as a normal decimal and devide it later by the
width of decimal point. For example, 3.14 means 314/100

double atof(char s[])
{
  int i, sign;
  double val, power;

  for(i = 0; isspace( s[i] ); i++)     // skip white spaces
    ;

  sign = (s[i] == '-') ? -1 : 1;

  if( s[i] == '+' || s[i] == '-' )     // skip sign
    i++;

  for(val = 0.0; isdigit( s[i] ); i++)
    val = val*10 + (s[i]-'0');

  if( s[i] == '.' )                    // skip decimal point
    i++;

  // do integer or fractional part
  for(power = 1.0; isdigit( s[i] ); i++)
  {
    val = val*10 + (s[i]-'0');
    power *= 10.0;
  }

  return sign*val/power;
}

Given atof, properly declared, we could write atoi in terms of it:

int atoi( char s[] )
{
  double atof( char s[] );

  return (int) atof(s);          // discard information but intended
}

<exercise>
The ansic, page 73, exercise 4-2. Extend atof to handle scientific notation of the form 123.45e-6
where a floating-point number may be followed by e or E and an optionally signed exponent.


={============================================================================
*kt_dev_algo_0000* dev-algo-itoa

non-standard and not part of glibc and should use sprintf instead.

// itoa
//
// * input type? digits only? no space?
// * input size?
// * what base? 10 or 2?
// * sign support? 

// from ansic, p43.
//
// when base is 10.
//
// there is no check on the end of string input? '0' is not the same as
// 0(null) and when see any other than numbers, for loops ends.

std::string itoa_navie(const int input)
{
    uint32_t value{input}, i{0};
    char letter{0};
    std::string result{};

    for (; value;)
    {
        letter = '0' + (value % 10);
        result += letter;
        value /= 10;
    }

    return std::string(result.crbegin(), result.crend());
}

TEST(CxxAlgoItoaTest, RunWithVariousValues)
{
    EXPECT_THAT(itoa_navie(123), Eq("123"));
}


{1}
// * supports 10 base
// * not use reverse()
// * supports the sign
// * return the allocated string
//
// char* itoa(int n);
//
// Key points:
//
// * % and / operation
// * do-while which is necessary since at least one char must be installed in
//   the array even if n is zero.

<code>
char* itoa(int n)
{
  char* ret = NULL;
  int nchar = 0;
  bool negative = false;

  if( n < 0 )
  {
    n = -n;
    negative = true;
    nchar++;
  }

  // how many spaces are needed?
  int temp = n;
  do {
    nchar++;
    temp /= 10;
  } while(temp);

  ret = new char[nchar+1];
  ret[nchar] = 0;

  // convert number to string
  if(negative)
    ret[0] = '-';

  int i = nchar-1;

  do {
    ret[i--] = n%10 + '0';
    n /= 10;
  } while(n);

  return ret;
}


<mine>
#include <iostream>
#include <string>
#include <memory>

using namespace std;

char* itoa_one(int n)
{
  unsigned int num_chars = 0;
  bool sign = false;
  char* buffer = NULL;

  // check sign and make it positive
  if( n < 0 )
  {
    sign = true;
    n = -n;
  }

  // needs a space for the sign?
  if(sign)
    num_chars++;

  // works out num_chars
  int temp = n;
  do {
    temp /= 10;
    num_chars++;
  } while(temp);

  // allocate string and null
  buffer = new char[num_chars+1];

  // note: missed
  buffer[num_chars] = 0;

  // needs the sign?
  if(sign)
    buffer[0] = '-';

  // converts integer from the end

  // note: missed
  num_chars--;

  do {
    buffer[num_chars--] = '0' + n % 10;
  } while(n/=10);

  return buffer;
}

int main()
{
  char *str = itoa_one(-256);
  cout << "converted string: " << str << endl;
}

// <2> From internet.
// https://android.googlesource.com/kernel/lk/+/qcom-dima-8x74-fixes/lib/libc
// /* Copyright (c) 2012, The Linux Foundation. All rights reserved.
//  */
// 
// #include <stdlib.h>
// #include <string.h>
// #include <ctype.h>
// 
// int itoa(int num, unsigned char* str, int len, int base)
// {
//   int sum = num;
//   int i = 0;
//   int digit;
// 
//   if (len == 0)
//     return -1;
// 
//   do
//   {
//     // sign will remain after %
//     digit = sum % base;
// 
//     if (digit < 0xA)
//       str[i++] = '0' + digit;
//     else
//       str[i++] = 'A' + digit - 0xA; // what is it?
// 
//     sum /= base;
// 
//   }while (sum && (i < (len - 1)));
// 
//   if (i == (len - 1) && sum)
//     return -1;
// 
//   str[i] = '\0';
//   strrev(str); // reverse a string. note this is not part of standard c
// 
//   return 0;
// }


{2} ansic, p64

<code>
void itoa( int n, char s[] )
{
  int i, sign;

  if( (sign = n) < 0 )     // record sign
    n = -n;                // make n positive

  i = 0;

  do {                        // generate digits in reverse order
    s[i++] = '0' + n % 10;    // get next digit
  } while( (n /= 10) > 0 );   // delete it

  if(sign < 0)
    s[i++] = '-';

  s[i] = '\0';

  reverse(s);
}


<mine>
#include <iostream>
#include <string>
#include <cstring>

using namespace std;

void reverse(char *s)
{
  int start, end, temp;

  // note: strlen(s)-1 ?
  for(start = 0, end = strlen(s)-1; start < end; start++, end--)
  {
    temp = s[start];
    s[start] = s[end];
    s[end] = temp;
  }
}

void itoa_two( int n, char s[] )
{
  int num_chars = 0, sign = 0;

  // note: can be shorten as code
  if( n < 0 )
  {
    sign = 1;
    n = -n;
  }

  do {
    s[num_chars++] = '0' + n % 10;
  } while( n/=10 );

  if( sign )
    s[num_chars++] = '-';

  s[num_chars] = 0;

  reverse(s);
}

int main()
{
  char text[100] = {0};
  itoa_two( -256, text );
  cout << "converted string: " << text << endl;
}


<ex>
The ansic, page 64, exercise 3-5. Write the function itob(n,s,b) that converts
the integer n into a base b character representation in the string s. In
particular, itob(n,s,16) formats n as a hexadecimal integer in s. 

#include <stdio.h>
#include <string.h>

void reverse(char s[])
{
  int c, i, j;

  for( i = 0, j = strlen(s)-1; i < j; i++, j-- )
    c = s[i], s[i] = s[j], s[j] = c;
}

// The point is that bit representation is the same regardless of base and so do
// the mod operation. The problem is that char set from 0 to Z used is not
// contiguous in ASCII and the below is handy.
// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_3:Exercise_5 Of course,
// this version do not support XXX_MIN handling.

void itob_one(int n, char s[], int b) 
{
  static char digits[] = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ";
  int i, sign;

  if ( b < 2 || b > 36 ) {
    fprintf(stderr, "EX3_5: Cannot support base %d\n", b);
    return;
  }

  if ((sign = n) < 0)
    n = -n;

  i = 0;

  do {
    s[i++] = digits[n % b];
  } while ((n /= b) > 0);

  if (sign < 0)
    s[i++] = '-';

  s[i] = '\0';

  reverse(s);
}

// this do not use char array but not works for singed case. 
int itob_two(int num, char* str, int base)
{
  int sum = num;
  int i = 0;
  int digit;

  //if (len == 0)
  //  return -1;

  do
  {
    // sign will remain after %
    digit = sum % base;

    if (digit < 0xA)
      str[i++] = '0' + digit;
    else
      str[i++] = 'A' + digit - 0xA; // what is it?

    sum /= base;

  // }while (sum && (i < (len - 1)));
  }while (sum );

  // if (i == (len - 1) && sum)
  //   return -1;

  str[i] = '\0';
  reverse(str);
  // strrev(str); // reverse a string. note this is not part of standard c

  return 0;
}

int main(int argc, char* argv[])
{
  char text1[100] = {0};

  {
    printf("-------------------\n");

    itob_one( 256, text1, 10 );
    printf("itoa'ed string:%s\n", text1);

    itob_one( -256, text1, 10 );
    printf("itoa'ed string:%s\n", text1);

    itob_one( 256, text1, 8 );
    printf("itoa'ed string:%s\n", text1);

    itob_one( 256, text1, 16 );
    printf("itoa'ed string:%s\n", text1);
  }

  {
    printf("-------------------\n");

    itob_two( 256, text1, 10 );
    printf("itoa'ed string:%s\n", text1);

    itob_two( -256, text1, 10 );
    printf("itoa'ed string:%s\n", text1);

    itob_two( 256, text1, 8 );
    printf("itoa'ed string:%s\n", text1);

    itob_two( 256, text1, 16 );
    printf("itoa'ed string:%s\n", text1);
  }
} 

-------------------
itoa'ed string:256
itoa'ed string:-256
itoa'ed string:400
itoa'ed string:100
-------------------
itoa'ed string:256
itoa'ed string:.+*
itoa'ed string:400
itoa'ed string:100


<exercise>
The ansic, page 64, exercise 3-6. Write a version of itoa that accepts three
arguments instead of two. The third argument is a minimum field width; the
converted number must be padded with blanks on the left if necessary to make it
wide enough.

void itoa_w(int n, char s[], int w)
{
  int sign;

  if( (sign = n ) < 0 )
    n = -n;

  int i = 0;

  do {
    s[i++] = n % 10 + '0';
  } while( ( n /= 10 ) );

  if(sign < 0)
    s[i++] = '-';

  // here, the value of i is both the number of characters in number
  // representation and the index of array for a next char.
  // '2' '5' '6' '\0'
  //  0   1   2   3 

  int fill;
  for( fill = i; fill < w; fill++ )
    s[fill] = '0';

  s[fill] = '\0'; 

  reverse(s);
}

int main(int argc, char* argv[])
{
  int tests[5] = {256, INT_MAX, -300, 172, 38478235};
  char st[101] = "";
  int i;

  for (i = 0; i < 5; i++) {
    mitoa_width(tests[i], st, 9);
    printf("%12d in string form is %12s\n", tests[i], st);
  }

  return 0;
} 

The simpler is:

void itoa_w(int n, char s[], int w)
{
  int sign;

  if( (sign = n ) < 0 )
    n = -n;

  int i = 0;

  do {
    s[i++] = n % 10 + '0';
  } while( ( n /= 10 ) );

  if(sign < 0)
    s[i++] = '-';

  while( i < w )
    s[i++] = '0';

  s[i] = '\0'; 

  reverse(s);
}


<example> ansic, p87
This is recursive version that do not need reverse function.

void printd(int n)
{
  if( n < 0 )
  {
    putchar('-');
    n = -n;
  }

  if(n/10)
    printd(n/10);

  putchar( n%10 + '0');
}


<exercise>
The ansic, page 88, exercise 4-12. Adapt the ideas of printd to write a recursive version of itoa ;
that is, convert an integer into a string by calling a recursive routine.

// when use printd directly. got idea from mitoa_rec_two

char *mitoa_rec(int n, char s[])
{
  if( n < 0 )
  {
    // putchar('-');
    *s++ = '-';
    n = -n;
  }

  if(n/10)
    s = mitoa_rec(n/10, s );

  // putchar( n%10 + '0');
  *s++ = (n%10 + '0');
  *s = '\0';

  return s;
}

// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_4:Exercise_12
// Here is the first solution by Flash Gordon, which uses pointers which have not been introduced by
// this point. It relies on the C99 behaviour of dividing a negative number rounding towards zero. 

char *mitoa_rec_two(int n, char s[], int base)
{
  int d = n % base;
  int r = n / base;
  if (n < 0) {
    *s++ = '-';
    d = -d;
    r = -r;
  }
  if (r)
    s = itoa_rec(r, s, base);
  *s++ = "0123456789abcdefghijklmnopqrstuvwxyz"[d]; // note how to use
  *s = 0;
  return s;
}


int main(int argc, char* argv[])
{
  int tests[5] = {256, INT_MAX, -300, 172, 38478235};
  char st[101] = "";
  int i;

  printf("---------------------\n");

  for (i = 0; i < 5; i++) {
    mitoa_rec_two(tests[i], st, 10);
    printf("%12d in string form is %12s\n", tests[i], st);
  }

  printf("---------------------\n");

  for (i = 0; i < 5; i++) {
    mitoa_rec(tests[i], st);
    printf("%12d in string form is %12s\n", tests[i], st);
  }

  return 0;
}


={============================================================================
*kt_dev_glib_004* printf

// stdio-common/printf.c
/* Write formatted output to stdout from the format string FORMAT.  */
/* VARARGS1 */
int
__printf (const char *format, ...)
{
  va_list arg;
  int done;

  va_start (arg, format);
  done = vfprintf (stdout, format, arg);
  va_end (arg);

  return done;
}

#undef _IO_printf
ldbl_strong_alias (__printf, printf);


={============================================================================
*kt_dev_glib_005* qsort

The ansic said that the standard qsort can sort 'any' object type. Wondered how?

NAME
       qsort - sorts an array

SYNOPSIS
       #include <stdlib.h>

       void qsort(void *base, size_t nmemb, size_t size,
                  int(*compar)(const void *, const void *));

DESCRIPTION
       The  qsort()  function sorts an array with nmemb elements of size size.
       The base argument points to the start of the array.

The example in the man page.

static int
cmpstringp(const void *p1, const void *p2)
{
  /* The actual arguments to this function are "pointers to
     pointers to char", but strcmp(3) arguments are "pointers
     to char", hence the following cast plus dereference */

  return strcmp(* (char * const *) p1, * (char * const *) p2);
}

int main(int argc, char *argv[])
{
  int j;

  if (argc < 2) {
    fprintf(stderr, "Usage: %s <string>...\n", argv[0]);
    exit(EXIT_FAILURE);
  }

  qsort(&argv[1], argc - 1, sizeof(argv[1]), cmpstringp);

  for (j = 1; j < argc; j++)
    puts(argv[j]);
  exit(EXIT_SUCCESS);
}

$ ./a.out h e l l o w o r l d
d
e
h
l
l
l
o
o
r
w


<code>
int compint(const void *p1, const void *p2)
{
  return *(const int *)p1 - *(const int *)p2;
}

int main()
{
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  qsort( arr, size, sizeof(int), compint );

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}

kt@kt-ub-vb:~/work$ ./a.out 
{ 2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33, }


<ansic-version>

// ansic, p110 which is pointer array version
void qsort( char *v[], int left, int right )
{
  int i, last;

  // do nothing if array contains fewer than two elements
  if( left >= right )
    return;

  // move partition elem
  swap( v, left, (left+right)/2 );

  last = left;  // to v[0]

  // partition
  for(i = left+1; i <= right; i++)
    if( strcmp(v[i], v[left]) < 0 )
      swap( v, ++last, i );

  // restore partition elem
  swap(v, left, last);

  qsort( v, left, last-1 );
  qsort( v, last+1, right );
}

How can make this to support 'any' data type and 'independent' of comparison and exchange
operations? ansic, p119.

char *lineptr[MAXLINES];

void qsort( void *v[], int, int, int (*)(void*, void*) );
int numcmp( char *, char *);

int main()
{
  int numeric = 0;

  // set numeric from argv

  qsort( (void*) lineptr, 0, nlines-1, 
      (int(*)(void*, void*))( numeric ? numcmp : strcmp ));
}

void qsort( void *v[], int left, int right, int (*comp)(void*, void*) )
{
  int i, last;

  if( left >= right )
    return;

  swap( v, left, (left+right)/2 );
  
  last = left;

  for( i = left+1; i <= right; i++ )
    if( (*comp)( v[i], v[left] ) < 0 )    // or comp(...)
      swap( v, i, ++last );

  swap( v, left, last );

  qsort( v, left, last-1 );
  qsort( v, last+1, right );
}

// not sure how it's supposed to sort 'numerically' since atof("abc") returns 0.0 as atoi does
int numcmp( char *s1, char *s2 )
{
  double v1, v2;

  v1 = atof(s1);
  v2 = atof(s2);

  if( v1 < v2 )
    return -1;
  else if ( v1 > v2 )
    return 1;
  else
    return 0;
}

void swap( void *v[], int i, int j )
{
  void *temp;     // <diff>

  temp = v[i];
  v[i] = v[j];
  v[j] = temp;
}

The first is to use (void) pointer since can cast to void * and back again without loss of
information. The second is to use function pointers.


<exercise>
ansic, exercise 5-14. Modify the sort program to handle a -r flag, which indicates sorting in
reverse (decreasing) order.  Be sure that -r works with -n.

void cqsort( int v[], int left, int right )
{
  int i, last;

  // do nothing if array contains fewer than two elements
  if( left >= right )
    return;

  // move partition elem
  swap( v, left, (left+right)/2 );

  last = left;  // to v[0]

  // partition
  for(i = left+1; i <= right; i++)
    //if( v[i] < v[left] )
    if( v[i] > v[left] )         // to reverse
      swap( v, ++last, i );

  // restore partition elem
  swap(v, left, last);

  cqsort( v, left, last-1 );
  cqsort( v, last+1, right );
}


int compint(const void *p1, const void *p2)
{
  //return *(const int *)p1 - *(const int *)p2;
  return *(const int *)p2 - *(const int *)p1;      // to reverse
}

int main()
{
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  cqsort( arr, 0, size-1 );
  // qsort( arr, size, sizeof(int), compint );

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}


<exercise>
ansic, exercise 5-15. Add the option -f to fold upper and lower case together, so that case
distinctions are not made during sorting; for example, a and A compare equal.

http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_15

The key is to use strcmp which support no case.

/* strcmp_f */
int strcmp_f(char *s, char *t)
{
  for ( ; toupper(*s) == toupper(*t); s++, t++)
    if (*s == '\0')
      return 0;

  return toupper(*s) - toupper(*t);
}


={============================================================================
*kt_dev_glib_006* glib-tail

<ex> *ex-tail* *ex-interview*
A question of google first phone screening.

The ansic, page 118, exercise 5-13. Write the program tail, which prints the
last n lines of its input. By default, n is 10, say, but it can be changed by an
optional argument, so that

tail -n

prints the last n lines. The program should behave rationally no matter how
unreasonable the input or the value of n. Write the program so it makes the best
use of available storage; lines should be stored as in the sorting program of
Section 5.6, not in a two-dimensional array of fixed size.

Keys: 

* Handle -n option; get and set n variable, allocate n `pointer-array`
* Use `modulo-operator` n to fill pointer array in circular fashion.
* Check NULL to avoid to distinguish cases if the number of lines read is
greater or smaller than n. These are:
  * if the readlines is smaller than n, then print lines from 0.
  * if the readlines is greater than n, then print n lines in circular.


<1> mine based on sort example in p108.

#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define MAXLINES 100
char *lineptr[MAXLINES];

#define MAXLEN  1000

// <one> notice that it includes '\n'
int mygetline(char line[], int maxlen )
{
  int c, i;

  // <Q1> also notice that ' < maxlen-1' leave one space for a null
  for(i = 0; i < maxlen-1 && ((c = getchar()) != EOF) && c != '\n'; i++)
    line[i] = c;

  // <Q2>
  if( c == '\n')
  {
    line[i] = c;
    ++i;
  }

  line[i] = '\0';
  return i;
}

// reads n line when [0, n-1]
// allocate and free each line
int readlines( char *v[], int max )
{
  char *p, line[MAXLEN];
  int len, cline, rlines = 0;

  while((len = mygetline(line, MAXLEN)) > 0 )
  {
    // Use `operator-%` n to fill pointer array in circular fashion
    cline = rlines++%max;

    // if v[] is used before
    if( v[cline] != NULL )
      free( v[cline] );
   
    if( (p = (char *)malloc(len)) == NULL )
    {
      printf("readline: error: p is null\n");
      return -1;
    }

    // this depends on how it will be printed out in writelines. use
    // line[len-1] = '\0';
    // "%s\n" or "%s"
    strcpy( p, line );
    v[cline] = p;
  }

  return rlines;
}

// first try
//void writelines( char *v[], int lines, int max )
//{
//  int wlines = 0;
//
//  if( lines <= max )
//  {
//    // print from 0 for lines
//    int n;
//    for(n = 0; n < lines; n++)
//      printf("%s", lineptr[n] );
//  }
//  else
//  {
//    // print from lines%max for max
//    int n;
//    int cline;
//
//    for( n = 0, cline = lines%max; n < max; n++, cline++ )
//      printf("%s", lineptr[cline%max] );
//  }
//}

// second try based on the <2>
void writelines( char *v[], int lines, int max )
{
  // print from lines%max for max
  int n;
  int cline;

  for( n = 0; n < max; n++ )
  {
    cline = (lines+n)%max;
    if( lineptr[cline] )
    {
      printf("%s", lineptr[cline] );
      free( lineptr[cline] );
    }
  }
}

// do not handle error of handling argvs.
// do not use malloc on lineptr.
int main( int argc, char *argv[] )
{
  int max_line = 10;

  if( --argc > 0 && (*++argv)[0] == '-' )
  {
    max_line = atoi( ++argv[0] ); 
    printf("set max line is %d\n", max_line );
  }

  printf("max line is %d\n", max_line );

  int nlines;

  if(( nlines = readlines( lineptr, max_line )) >= 0 )
  {
    writelines( lineptr, nlines, max_line );
    return 0;
  }
  else
  {
    printf("error: input too big to tail\n");
    return 1;
  }
}


<2> Steven Huang's solution, 
http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_13
/* K&R Exercise 5-13 */
/* Steven Huang */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define DEFAULT_NUM_LINES      10
#define MAX_LINE_LEN           1000

// Points of interest for a novice:
//
// 1. atoi() has a normally annoying property of not being able to tell the
// caller conclusively whether the input was bad ("abc") or it was really zero
// ("0"), because it returns 0 for both cases. Here, we exploit that property,
// because we only want to accept options in the form of "-n".                      
//
// note:
// 2. Try to understand how this program deals with input that doesn't even have
// as many lines as the line_ptrs[] array. That is, how does this program
// degenerate into just displaying everything it read?  (Hint:  what does it
// mean when line_ptrs[x] is NULL?)
//
// note:
// 3. Using `modulo-operation` on an index to a 'circular' array is a common and
// useful technique.
//
// Try to understand the range of values that current_line (and j, later) will
// take. In particular, why shouldn't we just do this:
//
//     for (i = 0; i < num_lines; i++)
//       if (line_ptrs[i])    
//         printf("%s", line_ptrs[i]);
//
// 5.  There is a bug in this program, where you see:
//
//     numlines = -numlines;
//
//     When will this break? 
//
//     note: This means when the largest negative number is used

/* K&R2 p29 */
int mgetline(char s[], int lim)
{
  int c, i;

  for (i = 0; i < lim - 1 && (c = getchar()) != EOF && c != '\n'; i++)
    s[i] = c;
  if (c == '\n')
    s[i++] = c;
  s[i] = '\0';
  return i;
}

/* duplicates a string */
char *dupstr(const char *s)
{
  char *p = malloc(strlen(s) + 1); 

  if (p)
    strcpy(p, s);
  return p;
}

int main(int argc, char *argv[])
{
  int num_lines = DEFAULT_NUM_LINES;
  char **line_ptrs;
  char buffer[MAX_LINE_LEN];
  int i;
  unsigned j, current_line;

  if (argc > 1) {
    // We use a little trick here. The command line parameter should be in the
    // form of "-n", where n is the number of lines. We don't check for the "-",
    // but just pass it to atoi() anyway, and then check if atoi() returned us a
    // negative number.  note: the trick is to expect -10 from atoi("-10");

    num_lines = atoi(argv[1]);

    if (num_lines >= 0) {
      fprintf(stderr, "Expected -n, where n is the number of lines\n");
      return EXIT_FAILURE;                                           
    }

    // Now make num_lines the positive number it's supposed to be.
    num_lines = -num_lines;
  } 

  // First, let's get enough storage for a list of n pointers...
  line_ptrs = malloc(sizeof *line_ptrs * num_lines);
  if (!line_ptrs) {
    fprintf(stderr, "Out of memory.  Sorry.\n");
    return EXIT_FAILURE;
  }

  // and make them all point to NULL
  for (i = 0; i < num_lines; i++)
    line_ptrs[i] = NULL;

  // Now start reading
  current_line = 0;
  do {
    mgetline(buffer, sizeof buffer);
    if (!feof(stdin)) {
      if (line_ptrs[current_line]) {
        // there's already something here
        free(line_ptrs[current_line]);
      }

      line_ptrs[current_line] = dupstr(buffer);
      if (!line_ptrs[current_line]) {
        fprintf(stderr, "Out of memory.  Sorry.\n");
        return EXIT_FAILURE;
      }

      current_line = (current_line + 1) % num_lines;
    }

  } while (!feof(stdin));

  // Finished reading the file, so we are ready to print the lines
  for (i = 0; i < num_lines; i++) {
    j = (current_line + i) % num_lines;
    if (line_ptrs[j]) {
      printf("%s", line_ptrs[j]);
      free(line_ptrs[j]);
    }
  }

  return EXIT_SUCCESS;
}


<ex> C++ version *cxx-modulus*

#include <iostream>
#include <fstream>
#include <vector>

// * Can use argv for MAXSIZE but uses the fixed value for simplicity.
// * See how C++ is simpler than C.
// *TN* there shall be elements before using [] access operator.

// output:
// (4) Please see http://www.gnu.org/software/libc/bugs.html for bug reporting
// (5) information.  We are now using the Bugzilla system to track all bug reports.
// (6) This web page gives detailed information on how to report bugs properly.
// (7)
// (8) The GNU C Library is free software.  See the file COPYING.LIB for copying
// (9) conditions, and LICENSES for notices about a few contributions that require
// (0) these additional notices to be distributed.  License copyright years may be
// (1) listed using range notation, e.g., 2000-2013, indicating that every year in
// (2) the range, inclusive, is a copyrightable year that would otherwise be listed
// (3) individually.

// no reverse() and push_back() in while
void tail_01()
{
    using namespace std;

    vector<string> svec;
    ifstream ifs{"README", ifstream::in};
    string line;

    // assume that this tail supports 10 lines
    const size_t MAXLINE = 10;

    size_t current_line = 0;

    while (getline(ifs, line))
    {
        if (current_line < MAXLINE)
            svec.push_back(line);
        else
            svec[current_line % MAXLINE] = line;

        ++current_line;
    }

    // print out MAXLINE after the last written
    for (size_t i = 0; i < MAXLINE; ++i)
    {
        current_line %= MAXLINE;

        cout << "(" << current_line << ") " << svec[current_line] << endl;

        ++current_line;
    }
}

// reserve()
void tail_02()
{
    using namespace std;

    vector<string> svec;
    ifstream ifs{"README", ifstream::in};
    string line;

    // assume that this tail supports 10 lines
    const size_t MAXLINE = 10;

    // reads input
    // * makes a vector available by adding empty strings and which simplify code
    //   to read a file.
    svec.reserve(MAXLINE);

    for (size_t i = 0; i < MAXLINE; ++i)
        svec.push_back(string());

    size_t current_line = 0;

    while (getline(ifs, line))
    {
        svec[current_line % MAXLINE] = line;
        ++current_line;
    }

    // print out MAXLINE after the last written
    for (size_t i = 0; i < MAXLINE; ++i)
    {
        current_line %= MAXLINE;

        cout << "(" << current_line << ") " << svec[current_line] << endl;

        ++current_line;
    }
}

// move version
void tail_03()
{
    using namespace std;

    vector<string> svec;
    ifstream ifs{"README", ifstream::in};
    string line;

    // assume that this tail supports 10 lines
    const size_t MAXLINE = 10;

    // reads input
    // * makes a vector available by adding empty strings and which simplify code
    //   to read a file.
    svec.reserve(MAXLINE);

    for (size_t i = 0; i < MAXLINE; ++i)
        svec.push_back(string());

    size_t current_line = 0;

    while (getline(ifs, line))
    {
        svec[current_line % MAXLINE] = std::move(line);
        ++current_line;
    }

    // print out MAXLINE after the last written
    for (size_t i = 0; i < MAXLINE; ++i)
    {
        current_line %= MAXLINE;

        cout << "(" << current_line << ") " << svec[current_line] << endl;

        ++current_line;
    }
}


={============================================================================
*kt_dev_glib_008* isdigit


include/ctype.h

/* The spec says that isdigit must only match the decimal digits.  We
   can check this without a memory access.  */
#  undef isdigit
#  define isdigit(c) ({ int __c = (c); __c >= '0' && __c <= '9'; })

note that if there is no second part, x && y, then emits compile error.

if(({ int __c = (c); __c >= '0' && __c <= '9'; }))


<isspace>
This includes '\n'


={============================================================================
*kt_dev_glib_010* abs

stblib/abs.c

/* Return the absolute value of I.  */
int
abs (int i)
{
  return i < 0 ? -i : i;
}


={============================================================================
*kt_dev_glib_101* general tips

o use tabstop=6 to view
o each function has a single c file so search file than using a tag since tag search do not work for
some.

<def-wide>
#ifdef USE_WIDE_CHAR
# include <wctype.h>
# define L_(Ch) L##Ch
# define UCHAR_TYPE wint_t
# define STRING_TYPE wchar_t
# define ISSPACE(Ch) __iswspace_l ((Ch), loc)
# define ISALPHA(Ch) __iswalpha_l ((Ch), loc)
# define TOUPPER(Ch) __towupper_l ((Ch), loc)
#else
# if defined _LIBC \
   || defined STDC_HEADERS || (!defined isascii && !defined HAVE_ISASCII)
#  define IN_CTYPE_DOMAIN(c) 1
# else
#  define IN_CTYPE_DOMAIN(c) isascii(c)
# endif
# define L_(Ch) Ch   <use>
# define UCHAR_TYPE unsigned char
# define STRING_TYPE char
# define ISSPACE(Ch) __isspace_l ((Ch), loc)
# define ISALPHA(Ch) __isalpha_l ((Ch), loc)
# define TOUPPER(Ch) __toupper_l ((Ch), loc)
#endif


={============================================================================
*kt_dev_glib_200* strcpy and strncpy

{reference-code}
/* strcpy: copy t to s; pointer version 
 * lib: The strcpy() and strncpy() functions return a pointer to the destination string dest
 */
void strcpy( char *s, char *t )
{
  while( *s++ = *t++ ) 
    ;
}

{man-page}
#include <string.h>

char *strcpy(char *dest, const char *src);
char *strncpy(char *dest, const char *src, size_t n);

DESCRIPTION
The strcpy() function copies the string pointed to by src, 'including' the terminating null byte
('\0'), to the buffer pointed to by dest. The strings may not overlap, and the destination string
dest must be large enough to receive the copy.

The  strncpy()  function  is similar, except that at most n bytes of src are copied.

Warning: If there is no null byte among the first n bytes of src, the string  placed in dest will
'not' be null-terminated.

If the length of src is less than n, strncpy() 'pads' the remainder of dest with null bytes.

       A simple implementation of strncpy() might be:

           char *
           strncpy(char *dest, const char *src, size_t n)
           {
               size_t i;

               for (i = 0; i < n && src[i] != '\0'; i++)
                   dest[i] = src[i];
               for ( ; i < n; i++)
                   dest[i] = '\0';

               return dest;
           }

NOTES
       Some  programmers consider strncpy() to be inefficient and error prone.  If the pro‐
       grammer knows (i.e., includes code to test!)  that the size of dest is greater  than
       the length of src, then strcpy() can be used.

       If  there  is  no  terminating null byte in the first n characters of src, strncpy()
       produces an unterminated string in dest.  Programmers often prevent this mistake  by
       forcing termination as follows:

           strncpy(buf, str, n);
           if (n > 0)
               buf[n - 1]= '\0';

BUGS
       If  the  destination  string  of a strcpy() is not large enough, then anything might
       happen.  Overflowing fixed-length string buffers is a favorite cracker technique for
       taking  complete  control  of  the machine.  Any time a program reads or copies data
       into a buffer, the program first needs to check that there's enough space.  This may
       be unnecessary if you can show that overflow is impossible, but be careful: programs
       can get changed over time, in ways that may make the impossible possible.

<KT> 
strcpy can be a problem in two points:
1) there is no null in src. do not know when stop copying.
2) dest is not large enough.

strncpy can be a problem.
1) there is no null in n bytes of src then dest is not null terminated. 


{glibc}
// string/strcpy.c
/* Copy SRC to DEST.  */
char *
strcpy (dest, src)
     char *dest;
     const char *src;
{
  char c;
  char *s = (char *) src;

  // this is offset between src and dest. then why -1? because used in do-loop below and increase s
  // anyway so need to -1.
  //
  // src
  // [ ] [ ] [ ] [ ]
  //                     by off
  //     [ ] [ ] [ ] [ ]
  //     dst
  //
  const ptrdiff_t off = dest - s - 1;

  do
  {
    c = *s++;
    s[off] = c;
  }
  while (c != '\0');

  return dest;
}


// string/strncpy.c
char *
STRNCPY (char *s1, const char *s2, size_t n)
{
  char c;
  char *s = s1;

  --s1;

  if (n >= 4)
  {
    size_t n4 = n >> 2;

    for (;;)
    {
      c = *s2++;
      *++s1 = c;
      if (c == '\0')
        break;
      c = *s2++;
      *++s1 = c;
      if (c == '\0')
        break;
      c = *s2++;
      *++s1 = c;
      if (c == '\0')
        break;
      c = *s2++;
      *++s1 = c;
      if (c == '\0')
        break;
      if (--n4 == 0)
        goto last_chars;
    }
    n = n - (s1 - s) - 1;
    if (n == 0)
      return s;
    goto zero_fill;
  }

last_chars:
  n &= 3;
  if (n == 0)
    return s;

  do
  {
    c = *s2++;
    *++s1 = c;
    if (--n == 0)
      return s;
  }
  while (c != '\0');

zero_fill:
  do
    *++s1 = '\0';
  while (--n > 0);

  return s;
}


<exercise> 
From ansic, p107, exercise 5-5. Write versions of the library functions strncpy, strncat, and
strncmp, which operate on at most the first n characters of their argument strings. For example,
strncpy(s,t,n) copies at most n characters of t to s. Full descriptions are in Appendix B.


={============================================================================
*kt_dev_algo_0000* lib-strlen

{man-page}
NAME
       strlen - calculate the length of a string

SYNOPSIS
       #include <string.h>
       size_t strlen(const char *s);

DESCRIPTION
       The  strlen()  function  calculates the length of the string s,
       'excluding' the terminating null byte ('\0').

RETURN VALUE
       The strlen() function returns the number of characters in s.

CONFORMING TO
       SVr4, 4.3BSD, C89, C99.

SEE ALSO
       string(3), strnlen(3), wcslen(3), wcsnlen(3)

{glibc}
string/strlen.c

/* Return the length of the null-terminated string STR. Scan for
   the null terminator <DN> quickly by testing four bytes at a time.  */

size_t
strlen (str) const char *str;
{
  const char *char_ptr;
  const unsigned long int *longword_ptr;
  unsigned long int longword, himagic, lomagic;

  /* Handle the first few characters by reading one character at a time.
     Do this until CHAR_PTR is aligned on a longword boundary.  */
  // [KT] this moves a pointer until found the alignment boundary and return if found null before
  // the boundary.
  for (char_ptr = str; ((unsigned long int) char_ptr & (sizeof (longword) - 1)) != 0; ++char_ptr)
    if (*char_ptr == '\0')
      return char_ptr - str;

  /* All these elucidatory comments refer to 4-byte longwords,
     but the theory applies equally well to 8-byte longwords.  */
  longword_ptr = (unsigned long int *) char_ptr;

  /* Bits 31, 24, 16, and 8 of this number are zero. Call these bits
     the "holes." Note that there is a hole just to the left of
     each byte, with an extra at the end:

    bits:  01111110 11111110 11111110 11111111
    bytes: AAAAAAAA BBBBBBBB CCCCCCCC DDDDDDDD

    The 1-bits make sure that carries propagate to the next 0-bit.
    The 0-bits provide holes for carries to fall into.  */

  himagic = 0x80808080L; 
  lomagic = 0x01010101L;

  // [KT]
  // if (sizeof (longword) > 4)
  // {
  //   /* 64-bit version of the magic.  */
  //   /* Do the shift in two steps to avoid a warning if long has 32 bits.  */
  //   himagic = ((himagic << 16) << 16) | himagic;
  //   lomagic = ((lomagic << 16) << 16) | lomagic;
  // }
  // if (sizeof (longword) > 8)
  //   abort ();

  /* Instead of the traditional loop which tests each character,
     we will test a longword at a time. The tricky part is testing
     if *any of the four* bytes in the longword in question are zero.  */
  for (;;)
  {
    longword = *longword_ptr++;
    // [KT] '&' is left-to-right and '~' is higher.
   
    /* Which of the bytes was the zero?  If none of them were, it was
       a misfire; continue the search.  */
    if (((longword - lomagic) & ~longword & himagic) != 0)
    {
      const char *cp = (const char *) (longword_ptr - 1);

      if (cp[0] == 0)
        return cp - str;
      if (cp[1] == 0)
        return cp - str + 1;
      if (cp[2] == 0)
        return cp - str + 2;
      if (cp[3] == 0)
        return cp - str + 3;
    }
    // [KT] removed the checks for sizeof(longword) > 4
  }
}

<case-one> char arr[] = {"abcdefghijkl"};

skipped a(0x61) and read four bytes as little endian.
                                       .         .         .         .
0x65646362; longword         "0110 0101 0110 0100 0110 0011 0110 0010
0x01010101; lomagic          "        1 0000 0001 0000 0001 0000 0001
0x64636261; longword-lomagic "0110 0100 0110 0011 0110 0010 0110 0001 
0x9A9B9C9D; ~logword         "1001 1010 1001 1011 1001 1100 1001 1101
0x80808080; himagic          "1000 0000 1000 0000 1000 0000 1000 0000
0x0       ; & result

<case-two> char arr[] = {"abcde"};

skipped first two and read three chars and null.

0x656463; longword       
0x00656463;                " <0000-0000> 110 0101 0110 0100 0110 0011
0x01010101; lomagic          "        1 0000 0001 0000 0001 0000 0001
0xFF646362; longword-lomagic:"1111 1111 0110 0100 0110 0011 0110 0010
0xFF9A9B9C; ~logword        :"1111 1111 1001 1010 1001 1011 1001 1100
0x80808080; himagic         :"1000 0000 1000 0000 1000 0000 1000 0000
0x80000000;                  "1000 0000 0000 0000 0000 0000 0000 0000

So if there is a null byte in the sequence then this byte will become 0x80 and if not, the end
result will be 0x0. So if the result is null, keep scanning.

<DN> There is no NULL pointer check on the input string. Of course, one can also argue that not
checking for NULL is fine as well. There is an asumption that there is an NULL in the input.


<ex> 
// ansic, p103. return the length of s excluding NULL.
int strlen( char s[] )
{
  int i = 0;

  while( s[i] != '\0' )
    ++i;

  return i;
}

int strlen( char *s )
{
  char *p = s;

  while( *p != '\0' )
    p++;

  return p-s;
}

// this is wrong since *cpp-side-effect* and will have one more.
int strlen_wrong(char *s)
{
  char *p = s;

  while (*p++)
    ; 

  return p-s;
}


={============================================================================
*kt_dev_glib_202* strcat

<ansic-example>
/* strcat: concatenate t to end of s; s must be big enough. note lib version returns a pointer of
 * resulting string
 */
void strcat( char s[], char t[] ) 
{
  int i, j;

  i = j = 0;
  while( s[i] != '\0' )                // find end of s
    i++;

  while( (s[i++] = t[j++]) != '\0' )   // copy t
    ;
}

<exercise> 
From ansic, exercise 5-3. Write a pointer version of the function strcat that we showed in Chapter
2: strcat(s,t) copies the string t to the end of s.

#include <stdio.h>

#define STR_BUFFER 10000

void mstrcat_one(char *, char *);
void mstrcat_two(char *s, char *t);
void mstrcat_three(char *s, char *t);
void mstrcat_four(char *s, char *t);

int main(int argc, char *argv[])
{
  //char string1[STR_BUFFER] = "What A ";
  char string1[STR_BUFFER] = "";
  char string2[STR_BUFFER] = "Wonderful World!";

  printf ("String 1:%s\n", string1);

  //mstrcat_one(string1, string2);
  //mstrcat_two(string1, string2);
  mstrcat_three(string1, string2);

  printf ("String 2:%s\n", string2);
  printf ("Cat Result:%s\n", string1);

  return 0;
}

// NOT OK.
// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_3
/* Concatenate t to s. */
void mstrcat_one(char *s, char *t)
{
  /*
   * '*++s' is used to reference the pointer before incremmenting it so
   * that the check for falsehood ('\0') is done with the next character
   * instead of '*s++' which would check, then increment. Using '*s++'
   * would increment the pointer to the base string past the null
   * termination character. When outputting the string, this made it
   * appear that no concatenation occurred because the base string is
   * cut off by the null termination character ('\0') that was never
   * copied over.
   */
  while(*++s); /* Get to the end of the string */
  while((*s++ = *t++));
}

// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_3
void mstrcat_two(char *s, char *t)
{
  /* run through the destination string until we point at the terminating '\0' */ 
  while('\0' != *s)
  {
    ++s;
  }

  /* now copy until we run out of string to copy */
  while('\0' != (*s = *t))
  {
    ++s;
    ++t;
  }
}

// NOT OK as mstrcat_one.
void mstrcat_three(char *s, char *t)
{
  while(*s++)
    ;

  while(*s++ = *t++)
    ;
}

void mstrcat_four(char *s, char *t)
{
  while(*s)
    s++;

  while(*s++ = *t++)
    ;
}


={============================================================================
*kt_dev_glib_203* strstr, strindex

From ansic p68, simple grep example. The strstr is similar to strindex, except that it returns a
pointer instead of an index.

// my outline
int strindex( char s[], char t[] )
{
  // scan trhough s
  for(int si = 0; s[si]; si++)
  {
    // scan through s and t as long as both matches and t[] or s[] is not null
    // when t[] ends first, loops ends and do not need consider.
    // when s[] ends first, loops ends and do not need consider.
    // when both ends at the same time, to prevent overrun, have a check one of them if it's null.
    for( int ti = 0, int tsi = si; t[ti] && s[tsi] == t[ti]; tsi++, ti++ )
      ;

    // if t[ti] is null, that means t is found.
    if( !t[ti] )
      return si;
  }

  return -1;
}

// reference code
int strindex( char s[], char t[] )
{
  int i, j, k;

  for( i = 0; s[i] != '\0'; i++ )
  {
    for( j=i, k=0; t[k] != '\0' && s[j]==t[k]; j++, k++ )
      ;

    // why k>0 ? when t is null string input, t[] = ""; 
    if( k > 0 && t[k] == '\0' )
      return i;

  return -1;
}

However, the reference code do +1 on s[] regardless of how many matched in t. For example, think
cases:

s: a b a b c d e ...   a a a b c d e ...
t: a b c d e

If know how many char mached in the inner search then the outer search could to that to skip and
could run a bit faster.

// strindex: return index of t in s, -1 if none
int strindex( char s[], char t[] )
{
  int sidx, tidx, start;

  start = -1;

  // loop through s
  for( sidx = 0, tidx = 0; s[sidx]; )
  {
    if( s[sidx] == t[tidx] )
    {
      start = sidx;

      // if s matches to the second of t
      while( s[++sidx] == t[++tidx] )
        ;

      // seen mismatch and exited while. exited since t reches the end?
      if( t[tidx] == '\0' )
        return start;
      // seem mismatch and exited while since different chars.
      else
      {
        start = -1;
        tidx = 0;
      }
    }
    else
      sidx++;
  }

  return start;
}


<exercise>
The ansic, page 71, exercise 4-1. Write the function strindex(s,t) , which returns the position of
the rightmost occurrence of t in s , or -1 if there is none. 

# idea 01
# Have the same approach as the original but keep going on the outer loop while updating the match
# rather than stop at the first match. That is to return the last match.

# idea 02
# Have the same structure as the original but starts from end of both. To do this, need to know the
# length of both which means loop through both.

# idea 03
# If can change input, reverse both array and run the original.

It seems that idea 01 may be the best since has less performance penalty but hae a bit more code.

int strindex_one( const char s[], const char t[] )
{
  // scan trhough s
  for(int si = 0; s[si]; si++)
  {
    int ti, tsi;
    // scan through s and t as long as both matches and t[] or s[] is not null
    for( ti = 0, tsi = si; t[ti] && s[tsi] == t[ti]; tsi++, ti++ )
      ;

    // if t[ti] is null, that means t is found.
    if( ti > 0 && t[ti] == '\0' )
      return si;
  }

  return -1;
}

// this is idea 01
int strindex_two( const char s[], const char t[] )
{
  int lsi = -1;

  // scan trhough s
  for(int si = 0; s[si]; si++)
  {
    int ti, tsi;
    // scan through s and t as long as both matches and t[] or s[] is not null
    for( ti = 0, tsi = si; t[ti] && s[tsi] == t[ti]; tsi++, ti++ )
      ;

    // if t[ti] is null, that means t is found.
    if( ti > 0 && t[ti] == '\0' )
      lsi = si;
  }

  return lsi;
}

int main(int argc, char* argv[])
{
  char line[MAXLINE];
  int found = 0;

  //                     012345678901
  found = strindex_one( " this is a long ago story, long really", "long" );
  printf("found %d\n", found );

  found = strindex_one( " this is a long ago story, long really", "longg" );
  printf("found %d\n", found );

  //                     012345678901234567890123456789
  found = strindex_two( " this is a long ago story, long really", "long" );
  printf("found %d\n", found );

  found = strindex_two( " this is a long ago story, long really", "longg" );
  printf("found %d\n", found );

  return found;
} 

$ ./a.out 
found 11
found -1
found 27
found -1


<exercise> strrstr?
From ansic, exercise 5-4. Write the function strend(s,t) , which returns 1 if the string t occurs at
the end of the string s, and zero otherwise.

Is the same approach as the above exercise 4-1? Not necessarily.

// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_4
int strend(char *s, char *t)
{
  s += (strlen(s) - strlen(t));     //increments to the point of comparison
  while (*s++ == *t++)              //tests for equality
    if (*s == '\0')                 //checks for null character while lines are equal
      return 1;
  return 0;
}

If has a check on.

int strend(char *s, char *t)
{
  int slen = strlen(s);
  int tlen = strlen(t);

  if( slen >= tlen )
  {
    s += (slen - tlen);     //increments to the point of comparison

    while (*s++ == *t++)              //tests for equality
      if (*s == '\0')                 //checks for null character while lines are equal
        return 1;

    return 0;
  }

  return -1;
}


={============================================================================
*kt_dev_glib_204* strcmp

From ansic p106. return <0 if s < t, 0 if s == t, > 0 if s > t.

int strcmp( char *s, char *t )
{
  for( int i = 0; s[i] == t[i]; i++ )
    if( s[i] == '\0' )
      return 0;

  return s[i] - t[i];
}

int strcmp( char *s, char *t )
{
  for( ; *s == *t; s++, t++ )
    if( *s == '\0' )
      return 0;

  return *s - *t;
}


={============================================================================
*kt_dev_glib_205* strpbrk, strtok

<exercise> <strpbrk>
From ansic, exercise 2-5. Write the function any(s1,s2), which returns the first location in the
string s1 where 'any' character from the string s2 occurs, or -1 if s1 contains no characters from
s2. (The standard library function strpbrk does the same job but returns a pointer to the location.)

STRPBRK(3)                 Linux Programmer's Manual                STRPBRK(3)

NAME
strpbrk - search a string for any of a set of characters

SYNOPSIS
#include <string.h>
char *strpbrk(const char *s, const char *accept);

DESCRIPTION
The  strpbrk() function locates the first occurrence in the string s of
any of the characters in the string accept.

RETURN VALUE
The strpbrk() function returns a pointer to the  character  in  s  that
matches  one  of the characters in accept, or NULL if no such character
is found.

// one
// not good since based on the "squeeze" approach which means more work to find the first time since
// key chars can happen any order and did not stop on "first" match
int any_mine( char s[], char t[] )
{
  int ret = -1;
  int i;

  // run through t[]
  for(; *t; t++)
  {
    // run through s[]
    for( i = 0; s[i]; i++ )
    {
      // found a match
      if( s[i] == *t )
      {
        // update found index when either it's the first time or found the less than the previous
        if( ret < 0 || i < ret )
        {
          ret = i;
          break;
        }
      }
    }
  }

  return ret;
}

// two
http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_2:Exercise_5

// The pedestrian solution is Richard Heathfield's
// Here is my solution, which is very simple but quite naive and inefficient. It has a worst-case
// time complexity of O(nm) where n and m are the lengths of the two strings.

int any_online_one(char s1[], char s2[])
{
  int i;
  int j;
  int pos;

  pos = -1;

  // by having "pos == -1" checks, two for loops stops as soon as found a match and means the
  // "first" location as the problem states. But the worst still O(nm).
  //
  // <Q> is this check on pos really needed? not really here since it returns when found. However,
  // if want to exit loop and continue doing, then pos is useful to exit loop as soon as found
  // rather than looping to the end. Like <goto-alternative> in dev_01.
  for(i = 0; pos == -1 && s1[i] != '\0'; i++)
  {
    for(j = 0; pos == -1 && s2[j] != '\0'; j++)
    {
      if(s2[j] == s1[i])
      {
        return pos = i;
      }
    }
  }

  return pos;
}

// three
// Could anything be simpler? Pilcrow 22:46, 24 August 2011 (UTC)
int any_online_two(char s1[], char s2[])
{
  int i;
  int j;

  // no need for further code when found a match
  for(i = 0; s1[i] != '\0'; i++)
  {
    for(j = 0; s2[j] != '\0'; j++)
    {
      if(s2[j] == s1[i])
      {
        return i;
      }
    }
  }

  return -1;
}

// four
http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_2:Exercise_5

Here's a much better solution, by Partha Seetala. This solution has a worst- case time complexity of
only O(n + m) which is considerably better.

It works in a very interesting way. He first defines an array with one element for each possible
character in the character set, and then takes the second string and 'ticks' the array at each
position where the second string contains the character corresponding to that position. It's then a
simple matter to loop through the first string, quitting as soon as he hits a 'ticked' position in
the array.

#include <stdio.h> /* for NULL */

int any(char *s1, char *s2)
{
  char array[256]; /* rjh comments
                    * (a) by making this char array[256] = {0}; the first loop becomes unnecessary.
                    * (b) for full ANSIness, #include <limits.h>, make the array unsigned char,
                    *     cast as required, and specify an array size of UCHAR_MAX(255) + 1.
                    * (c) the return statements' (parentheses) are not required.
                    */
  int  i;
  if (s1 == NULL) {
    if (s2 == NULL) {
      return(0);
    } else {
      return(-1);
    }
  }

  for(i = 0; i < 256; i++) {
    array[i] = 0;
  }

  while(*s2 != '\0') {
    array[*s2] = 1;
    s2++;
  }

  i = 0;
  while(s1[i] != '\0') {
    if (array[s1[i]] == 1) {
      return(i);
    }
    i++;
  }
  return(-1);
}


<getword> <getop>

#include <stdio.h>
#include <ctype.h>
#include <string.h>

// This is to emulate getchar and not need. However shows the overrun issue.
// there shall be ' ' at the end to end the getop while loop since there is no ungetch. If there is
// no space at the end, get the last token and getop will get NULL since no ungetch and '\n' is
// already used. So get op return null but not '\n'. Hence run until core dumped. This is the result
// of overrun. 
static char input[] = "10.2 30 .2 101010.202020 \n";

static char words[] = "this is a string to tokenize \n\n";

int getch()
{
  static int i = 0;
  return input[i++];
}

int getchw()
{
  static int i = 0;
  return words[i++];
}

// ansic, p78. see <reverse-polish-calculator> for full example.
//
// int type;
// char s[MAXOP];
//
// while(( type = getop(s)) != EOF )
// {...}
int getop( char s[] )
{
  int i, c;

  // skip spaces. save the first when exits
  while( (s[0] = c = getch()) == ' ' || c == '\t' )
    ;

  // not a number such as EOF/NL but string is not used when get EOF. 
  // make a string for a caller to print.
  if( !isdigit(c) && c != '.' ) 
  {
    s[1] = '\0'; return c;
  }

  i = 0;

  // collect integer part
  if( isdigit(c) )
    while( isdigit( s[++i] = c = getch()) )
      ;

  // collect fraction part
  if( c == '.' )
    while( isdigit( s[++i] = c = getch()) )
      ;

  s[i] = '\0';

  //if( c != EOF )
  //  ungetch(c);

  return 1;     // to signal it's got the number
  // return NUMBER;     // '0' to signal it's got the number
}

// ansic, p136. get next word or character from input.
// char word[MAXWORD];
//
// while( getword( word, MAXWORD ) != EOF )
//  if( isalpha( word[0] ))
//  {...}
int getword( char *word, int lim )
{
  int c;
  char *w = word;

  // skip spaces.
  while(isspace(c = getchw()))
      ;

  if( c != EOF )
    *w++ = c;

  // not a alphabet such as EOF and make the output null sting. isspace includes '\n'.
  if( !isalpha(c) )
  {
    *w = '\0'; return c;
  }

  for(; --lim > 0; w++ )
    if( !isalpha(*w = getchw()) )
    {
      // ungetch(*w);
      break;
    }

  *w = '\0';

  return word[0];
}

int main( int argc, char *argv[] )
{
  char line[100];

  {
    while( getop(line) != '\n' )
      printf("%s\n", line ); 
  }

  {
    while( getword(line, 100) )
      printf("%s\n", line ); 
  }

  {
    char *token = NULL;
    token = strtok(input, " \n" );
    while( token )
    {
      printf("tok: %s\n", token );
      token = strtok(NULL, " \n" );
    }
  }
}

<getop-vs-getword>
1. getop handles only numeric values and for non-numeric, save it as a string for a caller to print.
This makes difference in handling not supported chars.

2. getop may have overrun when there are inputs more than buffer size since no check on that.

3. getwords prevents overrun and do not use return value as char (getop uses return value as a
operator to use). Also, uses word[0] to check

4. getop and getword assumes stdin which uses EOF to signal the end. May change to use on string to
get token.

<strtok>
The strtok() function parses a string into a sequence of tokens. On the first call to strtok() the
string to be parsed should be specified in str. In each subsequent call that should parse the same
string, str should be NULL.

strtok modify input string since replace delimiter with null so that user can have string operation
or print out. This means that can use strpbrk instead of using strtok.


={============================================================================
*kt_dev_glib_206* strdup

From ansic, p143.

char *strdup( char *s )
{
  char *p;

  p = (char *) malloc( strlen(s) + 1 ); // +1 for '\0'
  if( p != NULL )
    strcpy( p, s );

  return p;
}

This leaves error-handling to its caller when malloc returns NULL.


={============================================================================
*kt_dev_glib_207* strchr and basename

#include <string.h>

char *strchr(const char *s, int c);
char *strrchr(const char *s, int c);

The strchr() function returns a pointer to the first occurrence of the character c in the string s.

The strrchr() function returns a pointer to the last occurrence of  the character c in the string s.

<example> to get filename
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

int main(int argc, char** argv)
{
  char *argVec[5];

  argVec[0] = strrchr( argv[1], '/' );
  if( argVec[0] != NULL )
    argVec[0]++;
  else
    argVec[0] = argv[1];

  printf( "Usage: %s: %s cmd [args]\n\n"
          "Run `cmd` passing it `args` and run nexus-inspect"
          " when that completes\n"
          , argVec[0], basename(argv[1]));

  exit(EXIT_SUCCESS);
}


$ ./a.out /home/keitee/work/home/keitee/work
Usage: work: work cmd [args]

Run `cmd` passing it `args` and run nexus-inspect when that completes
$ 

note: man 3 basename which is glibc version.


={============================================================================
*kt_dev_glib_208* getopt

#include <unistd.h>

int getopt(int argc, char * const argv[], const char *optstring);

extern char *optarg;
extern int optind, opterr, optopt;

The getopt() function parses the command-line arguments. An element of argv that starts with '-'
    (and is not exactly "-" or "--") is an option element. The characters of this element (aside
            from the initial '-') are "option characters". If getopt() is called repeatedly, it
    'returns' successively each of the option characters from each of the option elements.

// note: return option characters whenever gets called successfully

The  variable  optind  is the index of the next element to be processed in argv.  The system
initializes this value to 1.  The caller can reset it to 1 to restart scanning of the same argv, or
when scanning a new argument vector.

// note: optind is index of argv[]

If getopt() finds another option character, it returns that character, updating the external
variable optind and a static variable nextchar so that the next call to getopt()  can resume the
scan with the following option character or argv-element.

// note: updates global optind

The  variable  optind  is the index of the next element to be processed in argv.  The system
initializes this value to 1.  The caller can reset it to 1 to restart scanning of the same argv, or
when scanning a new argument vector.

If there are no more option characters, getopt() returns -1.  Then optind is the index in argv of
the first argv-element that is not an option.

If  getopt()  does  not recognize an option character, it prints an error message to stderr, stores
the character in optopt, and returns '?'.  The calling program may prevent the error message by
setting opterr to 0.

#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>

int main( int argc, char* argv[])
{
  int opt, nsecs;

  while(( opt = getopt( argc, argv, "nt:")) != -1 )
  {
    switch(opt)
    {
      case 'n':
        fprintf( stderr, "got option n\n");
        break;

      case 't':
        nsecs = atoi( optarg );
        fprintf( stderr, "got option t, nsecs(%d)\n", nsecs );
        break;

        // note: this is for when fails to parse options but not there is 'no' options given.
      default:
        fprintf( stderr, "usuage: %s [-t nsecs] [-n] name \n", argv[0] );
        exit(EXIT_FAILURE);
    }
  }

  printf("opt=%d, optind=%d\n", opt, optind );

  if( optind >= argc )
  {
    fprintf( stderr, "expected arg after options\n");
    exit(EXIT_FAILURE);
  }

  exit(EXIT_SUCCESS);
}


$ ./a.out 
opt=-1, optind=1
expected arg after options

$ ./a.out -n
got option n
opt=-1, optind=2                                   // note: opt is -1 always outside of a loop
expected arg after options

$ ./a.out -t
./a.out: option requires an argument -- 't'        // note: message from getopt
usuage: ./a.out [-t nsecs] [-n] name 

So there should be a handing of case when there is no arguments given.

  if( argc == 1 ) 
  {
    usage( argv[0] );
    return EXIT_FAILURE;
  }


={============================================================================
*kt_dev_glib_300* malloc

From ansic 8.7, stroage allocator, p185

//**
// <arena>
// Since other activities in the program/system may also request space without calling 'this'
// allocator, malloc, the space that malloc manages may not be 'contiguous'. Its free storage is
// kept as a list of free blocks and it is a single circular linked list since the last points to
// the first.
//
// The blocks are kept in order of increasing address.
//
// ..| XXXX | in use | free | free | in use | free | XXXX | in use | free | in use | free | XXXX
//
// in use and free, owned by malloc. XXXX not owned by malloc.
//
// In sum, areana means the address space consisting of 'in use' and 'free' blocks and managed by
// malloc/free. Note that it is both 'use' and 'free' block.
//

typedef long Align;   // for alignment to long boundary

union header {  // block header
  struct {
    union header *ptr;  // next block if on free list. <Q> why union?
    unsigned size;
  } s;

  Align x;
};

typedef union header Header;

//
//   points to next free block
//   ^
// +---+------+-----------------------+
// |   | size |                       |
// +---+------+-----------------------+
//            ^
//            address returned to user

static Header base;           // empty list to get started
static Header *freep = NULL;  // start of free list


//**
// free: put block ap in free list
//
// <key> assumption to a caller. that pointers to different blocks returned by sbrk can be
// 'meaningfully' compared. This is not guranteeded by the standard, which permits pointer
// comparisons 'only' within an array. Thus this version is 'portable' only for machines which
// general pointer comparison is meaningful.
//
// <Q> what will happen when 'double-free' happens? In this implemenatation, seems to be causing
// infinite loop to find a place to insert.
//
void free( void *ap )
{
  Header *bp, *p;

  bp = (Header *)ap -1; // point to block header since ap is block+1

  // Scans the free list starting at freep and look for the place to insert <the-free-block>. To
  // free means that it will insert that block into the free list. The free block is either between
  // two existing free blocks or at the end of the list. (when either it is the first time or is to
  // have more new memory from the system, or to free block.)
  //
  // for( starts from freep and scan the list to find a [p, nextp] which p < block < nextp )
  //   if( p is greater then nextp in address and block is out of <arena> )
  //     break;
  //
  // So end the loop in two cases:
  // 1. when found [p, nextp] which is p < block < nextp.
  // 2. when p hits the last of the free list meaning not in the arena, do check if block is out of
  // arena and then break. this is the case when add new space into the areana including when
  // malloc/free starts
  //
  // freep                                                 points to the first
  // [ ]      [ ]         [ ]       [ ]     ...            [ ] 
  // p        nextp
  //                      p         nextp
  //                                        ...
  // nextp                                                 p
  //
  // or
  // ( when ininted, there is only one node in the free list )
  //
  // [ ] which is base; base->nextp = freep = prevp = &base;
  //
  // <key> In other words, two cases to insert; when free a block which is in use before and when
  // add new space from operating system into the list. 
  //
  // <key> Having a base pointing to self makes 'search' generic for all cases.
  //
  for( p = freep; !(bp > p && bp < p->s.ptr); p = p->s.ptr )
    if( p >= p->s.ptr && (bp > p || bp < p->s.ptr ))
      break;

  // In any case, if the block being freed is adjacent to 'either' neighbor, the blocks are
  // 'combined'.
  //
  // ----------------------------------------------------------> increasing address
  //        lower            upper
  // p                       nextp 
  // [ free ]                [ free ]                   [ free ]
  //        |           bp   |
  //        |        <------>| CASE01 (combined to upper)
  //        |                |
  //        |    <------>    | CASE02
  //        |                |
  //        |<------>        | CASE03 (combined to lower)
  //        |                |
  //        |<-------------->| CASE04 (conbined to both)
  //
  // <key> The troubles are keeping the pointers pointing to the right things and the size correct.
  // See how the combination of four cases are used.

  // handle 'right' side of the list
  if( bp + bp->s.size == p->s.ptr ) // join to upper nbr(neighbor)
  {
    bp->s.size += p->s.ptr->s.size;
    bp->s.ptr = p->s.ptr->s.ptr;
  }
  else
    bp->s.ptr = p->s.ptr;

  // handle 'left' side of the list
  if( p + p->s.size == bp )         // join to lower nbr
  {
    p->s.size += bp->s.size;
    p->s.ptr = bp->s.ptr;
  }
  else
    p->s.ptr = bp;

  // <update-freep>, returns 'previous'
  freep = p;
}

#define NALLOC 1024 // minimum #units to request

//**
// morecore: ask system for more memory in unit
//
static Header *morecore(unsigned nu)
{
  char *cp;
  Header *up;

  // <key> since asking the system for memory is expensive operation, don't want to do that on every
  // call to malloc, so morecore requests at least NALLOC units.
  //
  // <Q> It said "this larger block will be chopped up as needed" but cannot see how in this
  // implementation. See malloc.
  //
  if( nu < NALLOC ) 
    nu = NALLOC;

  // Header is a unit and return Header array[n]
  //
  // sbrk(n) system call returns a pointer to n more bytes and returns -1 of there was no space.
  // void *sbrk(intptr_t increment);
  //
  cp = sbrk( nu*sizeof(Header) );
  if( cp == (char *) -1) // no space at all
    return NULL;

  up = (Header *)cp;
  up->s.size = nu;

  free((void*)(up+1));

  return freep;
}


//** 
// malloc: general purpose storage allocator
//
void *malloc( unsigned nbytes )
{
  Header *p, *prevp;
  unsigned nunits;

  // 1. to get #units for requested nbytes. why is this? If Header size is 10 then
  //
  // < blk#1 > < blk#2    > < blk #3 > when use nbytes/sizeof(Header)+1
  // 1 2 ... 9 10 11 ... 19 20 ...     : nbytes
  // < blk#1    > < blk #2   > <       when use (nbytes-1)/sizeof(Header)+1
  //
  // the first approach uses 'two' units when nbytes 10 although one unit is enough so waste memory.
  //
  // 2. add one more unit for every requst
  nunits = ( nbytes + sizeof(Header) -1 )/sizeof(Header) + 1;

  // 1. This is single linked list. Move [prev, p] window along the list and start from p. If found
  // a exact block(node) from the free list then remove that node by chaning prev->next. If not, get
  // the tail end which effectively chops up to the smaller blocks.
  //
  // That's why need to have prev and this is to remove a node from a linked list(unlink from the
  // list). The freep is updated with the prev of the found(removed) node which is where the last
  // block found and is the starting point for next call.
  //
  //         [ ]      [ ]      [ ]       [ ]       [ ]       [ ]       [ ]      
  // loop 0: freep
  //         prevp     p
  // loop 1:           prev     p
  //                                      X (if this is the found)
  // loop n:                    prev      p
  //                            freep       (update node link and freep)
  //
  // In any case, the free list is then searched and the search begins at the point, freep, where
  // the last block was found. This strategy helps keep the list homogeneous.
  //
  if(( prevp = freep ) == NULL )  // no free list yet
  {
    base.s.ptr = freep = prevp = &base;
    base.s.size = 0;
  }

  for( p = prevp->s.ptr; ; prevp = p, p = p->s.ptr )   // walk along list and see 'no' condition
  {
    // found a free node and 'first-fit'
    if( p->s.size >= nunits )  // big enough
    {
      if( p->s.size == nunits )   // exactly
        prevp->s.ptr = p->s.ptr;
      else
      { // node is biggger and only uses the tail(bottom) end.
        p->s.size -= nunits;  // reduce the size of the origin block(becomes previous)
        p += p->s.size;       // moves p to the tail end and set header of the new block
        p->s.size = nunits;   // set the size of new block
        // <key> This effectively chops up the block and make it out of the free list or arena.
      }

      // <update-freep>, set 'previous'
      freep = prevp;
      // return address after the header of a block
      return (void *)(p+1);
    }

    if( p == freep ) // wrapped around free list (including the first time)
      if(( p = morecore( nunits )) == NULL)
        return NULL;  // none left
  }
}


==============================================================================
Copyright: see |ktkb|  vim:tw=100:ts=3:ft=help:norl:
