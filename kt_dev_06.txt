*kt_dev_06*                                                                tw=100

kt.dev.boost

/^[#=]{
Use #{ for a group and ={ for a item

|kt_dev_boost_000| install, build and run
|kt_dev_boost_001| bind: to use member function
|kt_dev_boost_002| program_options
|kt_dev_boost_003| posix_time
|kt_dev_boost_004| typeof
|kt_dev_boost_005| is_same
|kt_dev_boost_006| lexical_cast
|kt_dev_boost_007| filesystem
|kt_dev_boost_008| boost-sync: condition 
*kt_dev_boost_009* boost-function
*kt_dev_boost_010* boost-intrusive-ptr

|kt_dev_boost_100| asio
|kt_dev_boost_101| asio: tutorial
|kt_dev_boost_102| asio: deadline_timer
|kt_dev_boost_103| asio: io_service
|kt_dev_boost_104| asio: A guide to getting started with boost::asio


# ============================================================================
#{
={============================================================================
*kt_dev_boost_000* install, build and run

http://www.boost.org/doc/libs/1_58_0/more/getting_started/unix-variants.html

1. download and untar
tar --bzip2 -xf /path/to/boost_1_58_0.tar.bz2

2. build and install
3. include in source:

#include <boost/typeof/typeof.hpp>

using namespace boost;

// don't need if installed with defaults.
// 4. specify include directory
// $ g++ -g -std=c++0x -I /usr/local/boost_1_58_0 tboost.cpp 


{build}
If you want to use any of the separately-compiled Boost libraries, you'll need to acquire library
binaries.

Issue the following commands in the shell (don't type $; that represents the shell's prompt):

$ cd path/to/boost_1_58_0
$ ./bootstrap.sh --help

Select your configuration options and invoke ./bootstrap.sh again without the --help option. Unless
you have write permission in your system's /usr/local/ directory, you'll probably want to at least
use

$ sudo ./bootstrap.sh --prefix=path/to/installation/prefix
$ sudo ./b2

to install somewhere else. Also, consider using the --show-libraries and
--with-libraries=library-name-list options to limit the long wait you'll experience if you build
everything. Finally,

$ ./b2 install


{build-error}
5.4   In Case of Build Errors

The only error messages you see when building Boost—if any—should be related to
the IOStreams library's support of zip and bzip2 formats as described here.
Install the relevant development packages for libz and libbz2 if you need those
features. Other errors when building Boost libraries are cause for concern.

Do install and run ./b2 again.

$ sudo apt-get install libbz2-dev


{link}
$ g++ -g t_asio_01.cpp

/usr/local/include/boost/asio/error.hpp:230: undefined reference to `boost::system::system_category()'
collect2: error: ld returned 1 exit status

To solve this since The boost library you are using depends on the boost_system
library. (Not all of them do.)

$ g++ -g -lboost_system t_asio_01.cpp


$ cat ./boobl.sh 
#!/bin/bash
g++ -g -std=c++0x -lboost_system $1

$ ./a.out
./a.out: error while loading shared libraries: libboost_system.so.1.58.0: cannot
open shared object file: No such file or directory

$ LD_LIBRARY_PATH=/usr/local/lib ./a.out 


={============================================================================
*kt_dev_boost_001* bind: to use member function

This is member function pointer declaration:

void (SystemClientEventRepository::*masCallback)
(boost::shared_ptr<X>, const FutureValue< std::vector<Y> > &) =
                &SystemClientEventRepository::eventsReceived;

This is the use of bind:

bar.addWithCallback(fMASEvents, boost::bind(masCallback, this, sharedCmd, _1));

However, bind uses 3 arguments but the pointer declaration uses 2 arguments.  Why?


{from-boost-doc}
Using bind with pointers to members

Pointers to member functions and pointers to data members are 'not' function objects, because they
do not support operator(). For convenience, bind accepts member pointers as its first argument, and
the behavior is as if boost::mem_fn has been used to convert the member pointer into a function
object. In other words, the expression

bind(&X::f, args)

is equivalent to

bind<R>(mem_fn(&X::f), args)

where R is the return type of X::f (for member functions) or the type of the member (for data
        members.)

Example:

struct X
{
    bool f(int a);
};

X x;

shared_ptr<X> p(new X);

int i = 5;

bind(&X::f, ref(x), _1)(i);		// x.f(i)
bind(&X::f, &x, _1)(i);			//(&x)->f(i)
bind(&X::f, x, _1)(i);			// (internal copy of x).f(i)
bind(&X::f, p, _1)(i);			// (internal copy of p)->f(i)

The last two examples are interesting in that they produce "self-contained" function objects.
bind(&X::f, x, _1) stores a copy of x. bind(&X::f, p, _1) stores a copy of p, and since p is a
boost::shared_ptr, the function object retains a reference to its instance of X and will remain
valid even when p goes out of scope or is reset(). 

note:
This doc do not have more detail but the stackoverflow said

boost::function<void (int)> f2( boost::bind( &myclass::fun2, this, _1 ) );

to use member function and this seems to be the same with 

bind(&X::f, &x, _1)(i);			//(&x)->f(i)

So this binds to a particular object.


={============================================================================
*kt_dev_boost_002* program_options

#include <boost/program_options.hpp>
#include <boost/date_time.hpp>

void parseProgramOptions(int argc, char** argv)
{
    std::string output_filename;
    unsigned long timeout_seconds = 0;
    unsigned int window_size = 20;

    boost::program_options::options_description desc("\nWaits until the system becomes idle "
                                                     "and exits.\nOptions");
    desc.add_options()
            ("help,h", "Show this help")
            ("window_size,w", boost::program_options::value(&window_size),
                             "Size of moving-average window (in number of values)")
            ("sampling_period,s", boost::program_options::value(&sampling_period_ms),
                                 "Number of milliseconds between each sample")
            ("output,o", boost::program_options::value(&output_filename),
                                  "File name to print the values to (default=stdout)")
            ("exit_threshold,e", boost::program_options::value(&exit_threshold),
                                "If specified specified (in %) - program will exit if "
                                "CPU utilisation will fall below this value (default=1)")
            ("timeout,t", boost::program_options::value(&timeout_seconds),
                         "Timeout in seconds (default=infinite)")
            ;

    boost::program_options::variables_map vm;
    boost::program_options::store(boost::program_options::parse_command_line(argc, argv, desc), vm);
    boost::program_options::notify(vm);
    if (vm.count("help"))
    {
        std::cout << desc << std::endl;
        exit(EXIT_SUCCESS);
    }

    // resize moving average window
    ma.resize(window_size);

    started_at = boost::posix_time::microsec_clock::local_time();
    if(timeout_seconds > 0)
    {
        stop_at = started_at + boost::posix_time::seconds(timeout_seconds);
    }

    if(vm.count("output"))
    {
        file.open(output_filename.c_str());
        os = &file;
    }

    *os << "started at     : " << started_at.time_of_day() << "\n";
    *os << "sampling period: " << sampling_period_ms << " ms\n";
}


={============================================================================
*kt_dev_boost_003* posix_time

#include <boost/date_time.hpp>


={============================================================================
*kt_dev_boost_004* typeof

http://www.boost.org/doc/libs/1_58_0/doc/html/typeof.html

Motivation

<object-generator>
Today many template libraries supply object generators to simplify object creation by utilizing the
C++ template argument deduction facility. Consider std::pair. In order to instantiate this class
template and create a temporary object of this instantiation, one has to supply template parameters,
as well as parameters to the constructor:

std::pair<int, double>(5, 3.14159);

To avoid this 'duplication', STL supplies the std::make_pair object generator. When it is used, the
    types of template parameters are deduced from supplied function arguments:

std::make_pair(5, 3.14159);

For the temporary objects it is enough. However, when a named object needs to be allocated, the
    problem appears again:

std::pair<int, double> p(5, 3.14159);

The object generator no longer helps:

std::pair<int, double> p = std::make_pair(5, 3.14159);

It would be nice to deduce the type of the object (on the left) from the expression it is
    initialized with (on the right), but the current C++ syntax does not allow for this.

note: l

The above example demonstrates the essence of the problem but does not demonstrate its scale. Many
libraries, especially expression template libraries, create objects of really complex types, and go
a long way to hide this complexity behind object generators. Consider a nit Boost.Lambda functor:

_1 > 15 && _2 < 20

If one wanted to allocate a named copy of such an innocently looking functor, she would have to
specify something like this:

lambda_functor<
    lambda_functor_base<
        logical_action<and_action>,
        tuple<
            lambda_functor<
                lambda_functor_base<
                    relational_action<greater_action>,
                    tuple<
                        lambda_functor<placeholder<1> >,
                        int const
                    >
                >
            >,
            lambda_functor<
                lambda_functor_base<
                    relational_action<less_action>,
                    tuple<
                        lambda_functor<placeholder<2> >,
                        int const
                    >
                >
            >
        >
    >
>
f = _1 > 15 && _2 < 20;

Not exactly elegant. To solve this problem (as well as some other problems), the C++ standard
    committee is considering a few additions to the standard language, such as typeof/decltype and
    auto (see http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1607.pdf).

The typeof operator (or decltype, which is a slightly different flavor of typeof) allows one to
determine the type of an expression at compile time. Using typeof, the above example can be
simplified drastically:

typeof(_1 > 15 && _2 < 20) f = _1 > 15 && _2 < 20;

Much better, but some duplication still exists. The auto type solves the rest of the problem:

auto f = _1 > 15 && _2 < 20;

The purpose of the Boost.Typeof library is to provide a library-based solution, which could be used
    until the language-based facility is added to the Standard and becomes widely available. 


Tutorial

The above examples are possible because the Typeof Library knows about primitive types, such as int,
    double, char, etc. The Typeof Library also knows about most types and templates defined by the
        Standard C++ Library, but the appropriate headers need to be included to take advantage of
        this:


#include <boost/typeof/std/utility.hpp>

namespace ex3
{
    BOOST_AUTO(p, make_pair(1, 2));

    BOOST_STATIC_ASSERT((is_same<BOOST_TYPEOF(p), pair<int, int> >::value));
}

Here <boost/typeof/std/utility.hpp> includes <utility> and contains knowledge about templates
defined there. This naming convention applies in general, for example to let the Typeof Library
handle std::vector, include <boost/typeof/std/vector.hpp>, etc


={============================================================================
*kt_dev_boost_005* is_same

http://www.boost.org/doc/libs/1_50_0/libs/type_traits/doc/html/boost_typetraits/reference/is_same.html

is_same

template <class T, class U>
struct is_same : public true_type-or-false_type {};

Inherits: If T and U are the same types then inherits from true_type, otherwise inherits from
              false_type.

Header: #include <boost/type_traits/is_same.hpp> or #include <boost/type_traits.hpp>

Compiler Compatibility: If the compiler does not support partial-specialization of class templates,
         then this template can not be used with abstract, incomplete or function types.

Examples:

    is_same<int, int> inherits from true_type. 

    is_same<int, int>::type is the type true_type. 

    is_same<int, int>::value is an integral constant expression that evaluates to true. 

    is_same<int const, int>::value is an integral constant expression that evaluates to false. 

    is_same<int&, int>::value is an integral constant expression that evaluates to false. 

    is_same<T, T>::value_type is the type bool. 


#include <iostream>
#include <boost/typeof/typeof.hpp>

using namespace std;
using namespace boost;

int main(int argc, char** argv)
{
    int ival = 5;

    std::cout << "is the same type? " << is_same<decltype(ival), int>::value << std::endl;
}

$ g++ -g -std=c++0x -I /usr/local/boost_1_58_0 tboost.cpp 
$ ./a.out 
is the same type? 1


={============================================================================
*kt_dev_boost_006* lexical_cast

http://www.boost.org/doc/libs/1_58_0/doc/html/boost_lexical_cast.html

Motivation

Sometimes a value must be converted to a literal text form, such as an int
represented as a std::string, or vice-versa, when a std::string is interpreted
as an int. Such examples are common when converting between data types internal
to a program and representation external to a program, such as windows and
configuration files.

The standard C and C++ libraries offer a number of facilities for performing
such conversions. However, they vary with their ease of use, extensibility, and
safety.

For instance, there are a number of limitations with the family of standard C
functions typified by 'atoi':

o Conversion is supported in one direction only: from text to internal data
type. Converting the other way using the C library requires either the
inconvenience and compromised safety of the sprintf function, or the loss of
portability associated with non-standard functions such as itoa.

o The range of types supported is only a subset of the built-in numeric types,
namely int, long, and double.

o The range of types cannot be extended in a uniform manner. For instance,
conversion from string representation to complex or rational.

The standard C functions typified by strtol have the same basic limitations, but
offer finer control over the conversion process. However, for the common case
such control is often either not required or not used. The scanf family of
functions offer even greater control, but also lack safety and ease of use.

The standard C++ library offers stringstream for the kind of in-core formatting
being discussed. It offers a great deal of control over the formatting and
conversion of I/O to and from arbitrary types through text. However, for simple
conversions direct use of stringstream can be either clumsy (with the
    introduction of extra local variables and the loss of infix-expression
    convenience) or obscure (where stringstream objects are created as temporary
      objects in an expression). Facets provide a comprehensive concept and
    facility for controlling textual representation, but their perceived
    complexity and high entry level requires an extreme degree of involvement
    for simple conversions, and excludes all but a few programmers.

The lexical_cast function template offers a convenient and consistent form for
  supporting common conversions to and from arbitrary types when they are
  represented as text. The simplification it offers is in expression-level
  convenience for such conversions. For more involved conversions, such as where
  precision or formatting need tighter control than is offered by the default
  behavior of lexical_cast, the conventional std::stringstream approach is
  recommended. Where the conversions are numeric to numeric, boost::numeric_cast
  may offer more reasonable behavior than lexical_cast.

For a good discussion of the options and issues involved in string-based
formatting, including comparison of stringstream, lexical_cast, and others, see
Herb Sutter's article, The String Formatters of Manor Farm. Also, take a look at
the Performance section. 


<ex> to string

std::map<std::string, std::string> si;

static uint64_t fake_outputs = 0;

si["POST_REPAIR_OUTPUTS"] =
  boost::lexical_cast<std::string>(fake_outputs++);

<ex> to int

int EnvironmentAppIdStrategy::getAppId() const
{
    ApplicationRuntimeInstanceId appRuntimeInstanceId = 0;

    char* appIdFromEnv = getenv(APP_RUNTIME_INSTANCE_ID_ENV_VAR_NAME);

    // note: use stringstring to convert
 
    const std::string appIdAsString(appIdFromEnv);
    std::istringstream is(appIdAsString);
    is >> appRuntimeInstanceId;

    return appRuntimeInstanceId;
}

int EnvironmentAppIdStrategy::getAppId() const
{
    ApplicationRuntimeInstanceId appRuntimeInstanceId = 0;

    char* appIdFromEnv = getenv(APP_RUNTIME_INSTANCE_ID_ENV_VAR_NAME);

    return boost::lexical_cast<int>(appIdFromEnv);
}


Synopsis

lexical_cast
bad_lexical_cast
try_lexical_convert

Library features defined in boost/lexical_cast.hpp:

namespace boost
{
    class bad_lexical_cast;

    template<typename Target, typename Source>
      Target lexical_cast(const Source& arg);

    template <typename Target>
      Target lexical_cast(const AnyCharacterType* chars, std::size_t count);

    namespace conversion
    {
        template<typename Target, typename Source>
            bool try_lexical_convert(const Source& arg, Target& result);

        template <typename AnyCharacterType, typename Target>
            bool try_lexical_convert(const AnyCharacterType* chars, std::size_t count, Target& result);

    } // namespace conversion
} // namespace boost

lexical_cast

template<typename Target, typename Source>
  Target lexical_cast(const Source& arg);

Returns the result of streaming arg into a standard library string-based stream
and then out as a Target object. Where Target is either std::string or
std::wstring, stream extraction takes the whole content of the string, including
spaces, rather than relying on the default operator>> behavior. If the
conversion is unsuccessful, a bad_lexical_cast exception is thrown.

template <typename Target>
  Target lexical_cast(const AnyCharacterType* chars, std::size_t count);

Takes an array of count characters as input parameter and streams them out as a
Target object. If the conversion is unsuccessful, a bad_lexical_cast exception
is thrown. This call may be useful for processing nonzero terminated array of
characters or processing just some part of character array.

The requirements on the argument and result types for both functions are:

o Source is OutputStreamable, meaning that an operator<< is defined that takes a
std::ostream or std::wostream object on the left hand side and an instance of
the argument type on the right.

o Target is InputStreamable, meaning that an operator>> is defined that takes a
std::istream or std::wistream object on the left hand side and an instance of
the result type on the right.

o Target is CopyConstructible [20.1.3].

o Target is DefaultConstructible, meaning that it is possible to
default-initialize an object of that type [8.5, 20.1.4].

The character type of the underlying stream is assumed to be char. 


{peformance}
While we weren't looking Boost.Lexical_cast became "in most cases
boost::lexical_cast is faster than scanf, printf, std::stringstream". Yay for
upgrades - now there's no reason to use scanf for performance reasons.

http://www.boost.org/doc/libs/1_58_0/doc/html/boost_lexical_cast/
  performance.html#boost_lexical_cast.performance.tests_description

#include "PerfCounter.h"

#include <iostream>
#include <sstream>
#include <boost/lexical_cast.hpp>

int main(int argc,char** argv)
{
    PerfCounter counter;
    
    for(int i=0;i<10000;++i)
    {
        int out;
        sscanf("42","%d",&out);
    }
    counter.snap("scanf int");

    for(int i=0;i<10000;++i)
    {
        int out;
        std::stringstream ss("42");
        ss >> out;
    }
    counter.snap("stringstream int");

    for(int i=0;i<10000;++i)
    {
        int out = boost::lexical_cast<int>("42");
    }
    counter.snap("boost::lexical_cast<int>");
    std::cout << counter.dump() << std::endl;
}

// from a run on debian

$ ./a.out 
Start -> scanf int took 2112us
scanf int -> stringstream int took 27859us
stringstream int -> boost::lexical_cast<int> took 910us
boost::lexical_cast<int> -> end took 0us


<question>
// about the above code

> you're transforming the same value on every iteration, source of which is a
> const - might this be a subject of some optimisation / cache related thing?

Yeah, I was just thinking the same thing. I wouldn't be too surprised if the
compiler replaces the lexical_cast call with a constant result. Try with a
random number converted to a string.

<result>
Start -> scanf int took 22us
scanf int -> stringstream int took 45us
stringstream int -> boost::lexical_cast<int> took 3us
boost::lexical_cast<int> -> end took 0us

on the host and

Start -> scanf int took 46us
scanf int -> stringstream int took 392us
stringstream int -> boost::lexical_cast<int> took 11us
boost::lexical_cast<int> -> end took 4us

on the device.


={============================================================================
*kt_dev_boost_007* filesystem

// from code

// read all files from the given directory and populate those in vector
vector<boost::filesystem::path> configFiles(findMediaRouterPluginConfigFiles(configDir));

// "/opt/zinc-trunk/share/platform_data/mediarouter-plugin-config"
// /opt/zinc-trunk/share/platform_data/mediarouter-plugin-config/http-application%2Fdash%2Bxml.plugin-config
// /opt/zinc-trunk/share/platform_data/mediarouter-plugin-config/https-application%2Fdash%2Bxml.plugin-config

BOOST_FOREACH(const boost::filesystem::path& fullPath, configFiles)
{
    // "http-application%2Fdash%2Bxml"
    string fileStem = fullPath.stem();

    // fullPath.string() is:
    // "/opt/zinc-trunk/share/platform_data/mediarouter-plugin-config/http-application%2Fdash%2Bxml.plugin-config"
    //
}


={============================================================================
*kt_dev_boost_008* boost-sync: condition

http://www.boost.org/doc/libs/1_58_0/doc/html/thread/synchronization.html#thread.synchronization.condvar_ref

The classes condition_variable and condition_variable_any provide a mechanism
for one thread to wait for notification from another thread that a particular
  condition has become true. 
    
The general usage pattern is that one thread locks a mutex and then calls wait
on an instance of condition_variable or condition_variable_any. When the thread
is woken from the wait, then it checks to see if the appropriate condition is
now true, and continues if so. If the condition is not true, then the thread
then calls wait again to resume waiting. In the simplest case, this condition is
just a boolean variable:


boost::condition_variable cond;
boost::mutex mut;
bool data_ready;

void process_data();

void wait_for_data_to_process()
{
    boost::unique_lock<boost::mutex> lock(mut);
    while(!data_ready)
    {
        cond.wait(lock);
    }
    process_data();
}

Notice that the 'lock' is passed to wait: wait will atomically add the thread to
the set of threads waiting on the condition variable, and unlock the mutex. When
the thread is woken, the mutex will be locked again before the call to wait
returns. This allows other threads to acquire the mutex in order to update the
shared data, and ensures that the data associated with the condition is
correctly synchronized.

In the mean time, another thread sets the condition to true, and then calls
either notify_one or notify_all on the condition variable to wake one waiting
thread or all the waiting threads respectively.

void retrieve_data();
void prepare_data();

void prepare_data_for_processing()
{
    retrieve_data();
    prepare_data();
    {
        boost::lock_guard<boost::mutex> lock(mut);
        data_ready=true;
    }
    cond.notify_one();
}

Note that the same mutex is locked before the shared data is updated, but that
the mutex does not have to be locked across the call to notify_one.

This example uses an object of type condition_variable, but would work just as
well with an object of type condition_variable_any: condition_variable_any is
more general, and will work with any kind of lock or mutex, whereas
condition_variable 'requires' that the lock passed to wait is an instance of
boost::unique_lock<boost::mutex>. This enables condition_variable to make
optimizations in some cases, based on the knowledge of the mutex type;
condition_variable_any typically has a more complex implementation than
condition_variable.

-----------------
void wait(boost::unique_lock<boost::mutex>& lock)

Precondition:
    lock is locked by the current thread, and either no other thread is
    currently waiting on *this, or the execution of the mutex() member function
    on the lock objects supplied in the calls to wait or timed_wait in all the
    threads currently waiting on *this would return the same value as
    lock->mutex() for this call to wait.  

Effects:
    Atomically call lock.unlock() and blocks the current thread. The thread will
    unblock when notified by a call to this->notify_one() or this->notify_all(),
    or spuriously. When the thread is unblocked (for whatever reason), the lock
    is reacquired by invoking lock.lock() before the call to wait returns. The
    lock is also reacquired by invoking lock.lock() if the function exits with
    an exception.  

Postcondition:
    lock is locked by the current thread. 

Throws:
    boost::thread_resource_error if an error occurs. boost::thread_interrupted
    if the wait was interrupted by a call to interrupt() on the boost::thread
    object associated with the current thread of execution. 

-----------------
void notify_one()

Effects:
    If any threads are currently blocked waiting on *this in a call to wait or
    timed_wait, unblocks one of those threads.

Throws:
    Nothing. 


={============================================================================
*kt_dev_boost_009* boost-function

http://www.boost.org/doc/libs/1_59_0/doc/html/function/tutorial.html

Boost.Function has two syntactical forms: the preferred form and the portable
form. The preferred form fits more closely with the C++ language and reduces the
number of separate template parameters that need to be considered, often
improving readability; however, the preferred form is not supported on all
platforms due to compiler bugs. The compatible form will work on all compilers
supported by Boost.Function. Consult the table below to determine which
syntactic form to use for your compiler. 


Basic Usage

A function wrapper is defined simply by instantiating the function class
template with the desired return type and argument types, formulated as a C++
function type. 

Any number of arguments may be supplied, up to some implementation-defined limit
(10 is the default maximum). The following declares a function object wrapper f
that takes two int parameters and returns a float:


Preferred syntax

boost::function<float (int x, int y)> f;


Portable syntax

boost::function2<float, int, int> f;


By default, function object wrappers are 'empty', so we can create a function
  object to assign to f:

struct int_div { 
  float operator()(int x, int y) const { return ((float)x)/y; }; 
};

f = int_div();

Now we can use f to execute the underlying function object int_div:

std::cout << f(5, 3) << std::endl;

We are free to assign any compatible function object to f. If int_div had been
declared to take two long operands, the implicit conversions would have been
applied to the arguments without any user interference. The only limit on the
types of arguments is that they be CopyConstructible, so we can even use
references and arrays: 


={============================================================================
*kt_dev_boost_010* boost-intrusive-ptr

http://baptiste-wicht.com/posts/2011/11/boost-intrusive_ptr.html

Boost intrusive_ptr : faster shared pointer

Baptiste Wicht

2011-11-14 08:40

9 Comments

Source

This post will present the Boost intrusive_ptr and its usage in C++ programming.

Recently, I took some time to optimize the parsing performances of the EDDI
Compiler. The parsing phase creates a lot of nodes to fill the Abstract Syntax
Tree.

One of the way I found was to replace some shared_ptr by some intrusive_ptr of
the Boost library.

It's a faster alternative of shared_ptr. Like its name indicates, it's
intrusive. The reference counter is 'included' directely in the managed class, in
the contrary of the shared_ptr where the reference counter has to be dynamically
allocated to live 'aside' the object. 

This leads to some performances improvement. Considering memory, the footprint
of an intrusive_ptr is the same as the footprint of a raw pointer. This is not
the case for the shared_ptr that have a pointer to the object, a pointer to the
counter and the counter itself.

For example, if you have a class X:

  class X {
    std::string name;
    int age;
  };

And you use it in your code using a shared_ptr :

  void test(){
    std::shared_ptr<X> x(new X);

    std::cout << x->name << std::endl;
  }

and you want to use an intrusive_ptr, you have first to 'add' a reference
  counter inside the X class :

  class X {
    std::string name;
    int age;

    long references;
    X() : references(0) {}
  };

And you have to indicate to the intrusive_ptr where the reference counter can be
  found for this class :

  inline void intrusive_ptr_add_ref(X* x){
    ++x->references;
  }

  inline void intrusive_ptr_release(X* x){
      if(--x->references == 0) 
          delete x;
  }

And finally you can use the intrusive_ptr to replace your shared_ptr :

  void test(){
    boost::intrusive_ptr<X> x(new X);

    std::cout << x->name << std::endl;
  }

The smart pointer itself can be used exactly the same way as a shared_ptr. If
  you have several classes that are managed using an intrusive_ptr, you can use
  a function template to tell Boost that all the reference counter are at the
  same place :

  template<typename T>
    inline void intrusive_ptr_add_ref(T* expr){
      ++expr->references;
    }

  template<typename T>
    inline void intrusive_ptr_release(T* expr){
      if(--expr->references == 0)
        delete expr;
    }

As you can see, the pointer is very intrusive and needs some boilerplate code
  added to your application, but it can leads to some interesting improvements
  for classes very often dynamically allocated.

There is another advantage in using intrusive_ptr. As the reference counter is
  stored into the object itself, you can create several intrusive_ptr to the
  same object without any problem. This is not the case when you use a
  shared_ptr. Indeed, if you create two shared_ptr to the same dynamically
  allocated object, they will both have a 'different' references counter and at
  the end, you will end up with an object being deleted twice.

Of course, there are not only advantages. First of all, you have to declare a
field in every classes that you want to manage using an intrusive_ptr and you
have to declare functions to manage the reference. Then there are some
disadvantages when using this pointer type compared to a shared_ptr :

- It's impossible to create a weak_ptr from a intrusive_ptr 

- Code redundancy, you have to copy the reference counter in every class that
you want to use an intrusive_ptr with 

- You have to provide a function for every types that has to be used with
intrusive_ptr (only two functions if you use the template versions of the two
    functions)

To conclude, the boost::intrusive_ptr can be a good replacement of
std::shared_ptr in a performance critical application, but if you have no
performances problem, do not use it because it makes your code less clear. 

If you are concerned by performances when using std::shared_ptr, consider also
using std::make_shared to create your pointers, so that the reference counter
and the object itself will be allocated at the same 'place' and at the same
time, resulting in better performances. 

note: same place?

Another case where it's interesting to use an intrusive_ptr is when dealing with
libraries using a lot of raw pointers, because you can create several
intrusive_ptr to the same raw pointer without any problem.


={============================================================================
*kt_dev_boost_100* asio

http://www.boost.org/doc/libs/1_58_0/doc/html/boost_asio.html

{overview}

<basic>
Basic Boost.Asio Anatomy

<async>

      Your Program

I/O Object        Your Completion Handler
eg. socket


      io_service

      OS

When an asynchronous operation is used, a different sequence of events occurs. 

1. Your program initiates the connect operation by calling the I/O object:

socket.async_connect(server_endpoint, your_completion_handler);

where your_completion_handler is a function or function object with the
signature:

void your_completion_handler(const boost::system::error_code& ec);

The exact signature required depends on the asynchronous operation being
performed. The reference documentation indicates the appropriate form for each
operation.

2. The I/O object forwards the request to the io_service.

3. The io_service signals to the operating system that it should start an
asynchronous connect.

Time passes. In the synchronous case this wait would have been contained
entirely within the duration of the connect operation.

4. The operating system indicates that the connect operation has completed by
placing the result on a 'queue', ready to be picked up by the io_service.

5. Your program must make a call to io_service::run() or to one of the similar
io_service member functions in order for the result to be retrieved. 

A call to io_service::run() 'blocks' while there are unfinished asynchronous
operations, so you would typically call it as soon as you have started your
first asynchronous operation.

6. While inside the call to io_service::run(), the io_service dequeues the
result of the operation, translates it into an error_code, and then passes it
to your completion handler.

This is a simplified picture of how Boost.Asio operates. You will want to
delve further into the documentation if your needs are more advanced, such as
extending Boost.Asio to perform other types of asynchronous operations. 


<threads-and-boost-asio>
Threads and Boost.Asio

Thread Safety

In general, it is safe to make concurrent use of distinct objects, but unsafe
to make concurrent use of a single object. However, types such as io_service
provide a stronger guarantee that it is safe to use a single object
concurrently.


Thread Pools note: scalable

Multiple threads may call io_service::run() to set up a pool of threads from
which completion handlers may be invoked. This approach may also be used with
io_service::post() to use a means to perform any computational tasks across a
thread pool.

Note that all threads that have joined an io_service's pool are considered
equivalent, and the io_service may distribute work across them in an arbitrary
fashion.  

Internal Threads

The implementation of this library for a particular platform may make use of
one or more internal threads to emulate asynchronicity. As far as possible,
    these threads must be invisible to the library user. In particular, the
    threads:

must not call the user's code directly; and

must block all signals.
note: this is what single dispatcher has in place.

This approach is complemented by the following guarantee:

Asynchronous completion handlers will only be called from threads that are
currently calling io_service::run(). 

Consequently, it is the library user's responsibility to create and manage all
threads to which the notifications will be delivered.

The reasons for this approach include:

By only calling io_service::run() from a single thread, the user's code can
avoid the development complexity associated with synchronisation. For example,
      a library user can implement scalable servers that are single-threaded
      (from the user's point of view).

A library user may need to perform initialisation in a thread shortly after
the thread starts and before any other application code is executed. For
example, users of Microsoft's COM must call CoInitializeEx before any other
COM operations can be called from that thread.

The library interface is decoupled from interfaces for thread creation and
management, and permits implementations on platforms where threads are not
available.


={============================================================================
*kt_dev_boost_101* asio: tutorial

<01> Timer.1 - Using a timer synchronously
#include <iostream>
#include <boost/asio.hpp>
#include <boost/date_time/posix_time/posix_time.hpp>

int main()
{
  boost::asio::io_service io;

  // Next we declare an object of type boost::asio::deadline_timer. The core
  // asio classes that provide I/O functionality (or as in this case timer
  // functionality) always take a reference to an io_service as their first
  // constructor argument. The second argument to the constructor sets the timer
  // to expire 5 seconds from now.

  boost::asio::deadline_timer t(io, boost::posix_time::seconds(5));

  // In this simple example we perform a blocking wait on the timer. That is,
  // the call to deadline_timer::wait() will not return until the timer has
  // expired, 5 seconds after it was created (i.e. not from when the wait
  // starts). 

  t.wait();

  std::cout << "Hello, world!" << std::endl;

  return 0;
}


<02> Timer.2 - Using a timer asynchronously

// This tutorial program demonstrates how to use asio's asynchronous callback
// functionality by modifying the program from tutorial Timer.1 to perform an
// asynchronous wait on the timer.

#include <iostream>
#include <boost/asio.hpp>
#include <boost/date_time/posix_time/posix_time.hpp>

// Using asio's asynchronous functionality 'means' having a callback function
// that will be called 'when' an asynchronous operation completes. In this
// program we define a function called print to be called when the asynchronous
// wait finishes.

void print(const boost::system::error_code& /*e*/)
{
  std::cout << "Hello, world!" << std::endl;
}

int main()
{
    boost::asio::io_service io;

    boost::asio::deadline_timer t(io, boost::posix_time::seconds(5));

    // Next, instead of doing a blocking wait as in tutorial Timer.1, we call
    // the deadline_timer::async_wait() function to perform an asynchronous
    // wait. When calling this function we pass the print callback handler that
    // was defined above.

    std::cout << "calls async wait..." << std::endl;

    // post a work for asio to do
    t.async_wait(&print);

    // Finally, we must call the io_service::run() member function on the
    // io_service object.

    // note: thread
    // The asio library provides a guarantee that callback handlers will only be
    // called from threads that are currently calling io_service::run().
    //
    // Therefore unless the io_service::run() function is called, the callback
    // for the asynchronous wait completion will never be invoked.

    // note: run() continue to run
    // The io_service::run() function will also continue to run while there is
    // still work to do. In this example, the 'work' is the asynchronous wait on
    // the timer, so the call will not return until the timer has expired and
    // the callback has completed.

    // It is important to remember to give the io_service some work to do before
    // calling io_service::run(). For example, if we had omitted the above call
    // to deadline_timer::async_wait(), the io_service would not have had any
    // work to do, and consequently io_service::run() would have returned
    // immediately.

    std::cout << "calls io.run..." << std::endl;

    io.run();

    std::cout << "ends..." << std::endl;

    return 0;
}

calls async wait...
calls io.run...

note: blocks on io.run() so wait for timer expired.

Hello, world!
ends...


<03> Timer.3 - Binding arguments to a handler
#include <iostream>
#include <boost/asio.hpp>
#include <boost/bind.hpp>
#include <boost/date_time/posix_time/posix_time.hpp>

// To implement a repeating timer using asio you need to change the timer's
// expiry time in your callback function, and to then start a new asynchronous
// wait. Obviously this means that the callback function will need to be able
// to access the timer object. To this end we add two new parameters to the
// print function:
//
// * A pointer to a timer object.  
// * A counter so that we can stop the program when the timer fires for the
// sixth time.
// 
// note: when to stop - no more work to do
// However you will observe that there is no explicit call to ask the
// io_service to stop. Recall that in tutorial Timer.2 we learnt that the
// io_service::run() function completes when there is no more "work" to do. By
// not starting a new asynchronous wait on the timer when count reaches 5, the
// io_service will run out of work and stop running. 

void print(const boost::system::error_code& /*e*/,
    boost::asio::deadline_timer* t, int* count)
{
  if (*count < 5)
  {
    std::cout << "callback: count: " << count << ", t: " << t << std::endl;
    std::cout << "callback: count: " << *count << std::endl;
    ++(*count);

    // Next we move the expiry time for the timer along by one second from the
    // previous expiry time. By calculating the new expiry time relative to
    // the old, we can ensure that the timer does not drift away from the
    // whole-second mark due to any delays in processing the handler.

    t->expires_at(t->expires_at() + boost::posix_time::seconds(1));

    // note: function object
    // Then we start a new asynchronous wait on the timer. As you can see, the
    // boost::bind() function is used to associate the extra parameters with
    // your callback handler. The deadline_timer::async_wait() function
    // expects a handler function (or function object) with the signature
    // void(const boost::system::error_code&). Binding the additional
    // parameters converts your print function into a function object that
    // matches the signature correctly.

    t->async_wait(boost::bind(print,
          boost::asio::placeholders::error, t, count));
  }
}

int main()
{
  boost::asio::io_service io;

  int count = 0;
  boost::asio::deadline_timer t(io, boost::posix_time::seconds(1));

  std::cout << "main: count: " << &count << ", t: " << &t << std::endl;

  // note: pass reference. is it okay when callback is called?

  t.async_wait(boost::bind(print,
        boost::asio::placeholders::error, &t, &count));

  std::cout << "main: calls run" << std::endl;
  io.run();

  std::cout << "main: final count is " << count << std::endl;

  return 0;
}

main: count: 0xbfcf0650, t: 0xbfcf062c
main: calls run
callback: count: 0xbfcf0650, t: 0xbfcf062c
callback: count: 0
callback: count: 0xbfcf0650, t: 0xbfcf062c
callback: count: 1
callback: count: 0xbfcf0650, t: 0xbfcf062c
callback: count: 2
callback: count: 0xbfcf0650, t: 0xbfcf062c
callback: count: 3
callback: count: 0xbfcf0650, t: 0xbfcf062c
callback: count: 4
main: final count is 5

note: see that &count and &t are the same between main and callback since:

Asynchronous completion handlers will only be called from threads that are
currently calling io_service::run(). 


<04> Timer.4 - Using a member function as a handler
#include <iostream>
#include <boost/asio.hpp>
#include <boost/bind.hpp>
#include <boost/date_time/posix_time/posix_time.hpp>

// The constructor of this class will take a reference to the io_service
// object and use it when initialising the timer_ member. The counter used to
// shut down the program is now also a member of the class. 

class printer
{
public:
  printer(boost::asio::io_service& io)
    : timer_(io, boost::posix_time::seconds(1)),         // note: interesting
      count_(0)
  {
    // The boost::bind() function works just as well with class member
    // functions as with free functions. Since all non-static class member
    // functions have an implicit this parameter, we need to bind this to the
    // function. As in tutorial Timer.3, boost::bind() converts our callback
    // handler (now a member function) into a function object that can be
    // invoked as though it has the signature void(const
    // boost::system::error_code&).

    // You will note that the boost::asio::placeholders::error placeholder is
    // not specified here, as the print member function does not accept an
    // error object as a parameter. 

    std::cout << "ctor: print: " << &printer::print << 
        ", this: " << this << std::endl;
    timer_.async_wait(boost::bind(&printer::print, this));
  }

  ~printer()
  {
    std::cout << "Final count is " << count_ << std::endl;
  }

  // The print member function is very similar to the print function from
  // tutorial Timer.3, except that it now operates on the class data members
  // instead of having the timer and counter passed in as parameters. 

  void print()
  {
    if (count_ < 5)
    {
      std::cout << "print: print: " << &printer::print << 
          ", this: " << this << std::endl;
      std::cout << "print: count: " << count_ << std::endl;
      ++count_;

      timer_.expires_at(timer_.expires_at() + boost::posix_time::seconds(1));
      timer_.async_wait(boost::bind(&printer::print, this));
    }
  }

private:
  boost::asio::deadline_timer timer_;
  int count_;
};

int main()
{
  boost::asio::io_service io;

  printer p1(io);
  printer p2(io);

  std::cout << "main: calls run" << std::endl;
  io.run();
  std::cout << "main: ends run" << std::endl;

  return 0;
}

ctor: print: 1, this: 0xbf956508
ctor: print: 1, this: 0xbf956530
main: calls run
print: print: 1, this: 0xbf956508
print: count: 0
print: print: 1, this: 0xbf956530
print: count: 0
print: print: 1, this: 0xbf956508
print: count: 1
print: print: 1, this: 0xbf956530
print: count: 1
print: print: 1, this: 0xbf956508
print: count: 2
print: print: 1, this: 0xbf956530
print: count: 2
print: print: 1, this: 0xbf956508
print: count: 3
print: print: 1, this: 0xbf956530
print: count: 3
print: print: 1, this: 0xbf956508
print: count: 4
print: print: 1, this: 0xbf956530
print: count: 4
main: ends run
dtor: final count is 5
dtor: final count is 5


<05> Timer.5 - Synchronising handlers in multithreaded programs

// This tutorial demonstrates the use of the boost::asio::strand class to
// synchronise callback handlers in a multithreaded program.

// The previous four tutorials avoided the issue of handler synchronisation by
// calling the io_service::run() function from one thread only. As you already
// know, the asio library provides a guarantee that callback handlers will
// only be called from threads that are currently calling io_service::run().
// Consequently, calling io_service::run() from only 'one' thread ensures that
// callback handlers cannot run concurrently.

// The single threaded approach is usually the best place to start when
// developing applications using asio. The downside is the limitations it
// places on programs, particularly servers, including:

// * Poor responsiveness when handlers can take a long time to complete.
// * An inability to scale on multiprocessor systems.

// If you find yourself running into these limitations, an alternative
// approach is to have a pool of threads 'calling' io_service::run(). However,
// as this allows handlers to execute concurrently, we need a method of
// synchronisation when handlers might be accessing a shared, thread-unsafe
// resource. 

#include <iostream>
#include <boost/asio.hpp>
#include <boost/thread/thread.hpp>
#include <boost/bind.hpp>
#include <boost/date_time/posix_time/posix_time.hpp>

// An boost::asio::strand guarantees that, for those handlers that are
// dispatched 'through' it, an executing handler will be allowed to complete
// before the next one is started. This is guaranteed irrespective of the
// number of threads that are calling io_service::run(). 
//
// Of course, the handlers may still execute concurrently with other handlers
// that were 'not' dispatched through an boost::asio::strand, or were
// dispatched through a 'different' boost::asio::strand object. 
//
// note: can use different io_service object.

class printer
{
public:
  printer(boost::asio::io_service& io)
    : strand_(io),
      timer1_(io, boost::posix_time::seconds(1)),
      timer2_(io, boost::posix_time::seconds(1)),
      count_(0)
  {

    // When initiating the asynchronous operations, each callback handler is
    // "wrapped" using the boost::asio::strand object. The strand::wrap()
    // function returns a new handler that automatically dispatches its
    // contained handler through the boost::asio::strand object. By wrapping
    // the handlers using the same boost::asio::strand, we are ensuring that
    // they cannot execute concurrently.

    timer1_.async_wait(strand_.wrap(boost::bind(&printer::print1, this)));
    timer2_.async_wait(strand_.wrap(boost::bind(&printer::print2, this)));
  }

  ~printer()
  {
    std::cout << "Final count is " << count_ << std::endl;
  }

  // In a multithreaded program, the handlers for asynchronous operations
  // should be synchronised if they access shared resources. In this tutorial,
  // the shared resources used by the handlers (print1 and print2) are
  // std::'cout' and the count_ data member. 
  //
  // In this example, use asio::strand to sync than sync primitive.

  void print1()
  {
    if (count_ < 10)
    {
      std::cout << "Timer 1: " << count_ << std::endl;
      ++count_;

      timer1_.expires_at(timer1_.expires_at() + boost::posix_time::seconds(1));
      timer1_.async_wait(strand_.wrap(boost::bind(&printer::print1, this)));
    }
  }

  void print2()
  {
    if (count_ < 10)
    {
      std::cout << "Timer 2: " << count_ << std::endl;
      ++count_;

      timer2_.expires_at(timer2_.expires_at() + boost::posix_time::seconds(1));
      timer2_.async_wait(strand_.wrap(boost::bind(&printer::print2, this)));
    }
  }

private:
  boost::asio::io_service::strand strand_;
  boost::asio::deadline_timer timer1_;
  boost::asio::deadline_timer timer2_;
  int count_;
};

// The main function now causes io_service::run() to be called from 'two'
// threads: the main thread and one additional thread. This is accomplished
// using an boost::thread object.

// Just as it would with a call from a single thread, 'concurrent' calls to
// io_service::run() will continue to execute while there is "work" left to
// do. The background thread will not exit until all asynchronous operations
// have completed. 

// note: two threads uses the same io. bind(run, &io) where &io is this since
// run() is member function but not run(io_service&).

int main()
{
  boost::asio::io_service io;
  printer p(io);
  boost::thread t(boost::bind(&boost::asio::io_service::run, &io));
  io.run();
  t.join();

  return 0;
}

$ g++ -g -std=c++0x -lboost_system -lboost_thread t_asio_04-2.cpp
$ LD_LIBRARY_PATH=/usr/local/lib ./a.out 
Timer 1: 0
Timer 2: 1
Timer 1: 2
Timer 2: 3
Timer 1: 4
Timer 2: 5
Timer 1: 6
Timer 2: 7
Timer 1: 8
Timer 2: 9
Final count is 10


={============================================================================
*kt_dev_boost_102* asio: deadline_timer

http://www.boost.org/doc/libs/1_58_0/doc/html/boost_asio/reference/basic_deadline_timer.html

basic_deadline_timer::async_wait

Start an asynchronous wait on the timer.

template<typename WaitHandler>
void-or-deduced async_wait(WaitHandler handler);

This function may be used to initiate an asynchronous wait against the timer.
It always returns immediately.

For each call to async_wait(), the supplied handler will be called exactly
once. The handler will be called when:

The timer has expired.
The timer was cancelled, in which case the handler is passed the error code
boost::asio::error::operation_aborted.

Parameters

handler

The handler to be called when the timer expires. Copies will be made of the
handler as required. The function signature of the handler must be:

void handler(
      const boost::system::error_code& error // Result of operation.
);

Regardless of whether the asynchronous operation completes immediately or not,
the handler will not be invoked from within this function.

note: 
See that 'hanlder' term means callback function and post() and aync_wait() add a
work to io_service.

Invocation of the handler will be performed in a manner equivalent to using
boost::asio::io_service::post().

// boost_1_58_0/boost/asio/detail/deadline_timer_service.hpp
//
  // Start an asynchronous wait on the timer.
  template <typename Handler>
  void async_wait(implementation_type& impl, Handler& handler)
  {
    // Allocate and construct an operation to wrap the handler.
    typedef wait_handler<Handler> op;
    typename op::ptr p = { boost::asio::detail::addressof(handler),
      boost_asio_handler_alloc_helpers::allocate(
        sizeof(op), handler), 0 };
    p.p = new (p.v) op(handler);

    impl.might_have_pending_waits = true;

    BOOST_ASIO_HANDLER_CREATION((p.p, "deadline_timer", &impl, "async_wait"));

    scheduler_.schedule_timer(timer_queue_, impl.expiry, impl.timer_data, p.p);
    p.v = p.p = 0;
  }

// boost_1_58_0/boost/asio/basic_deadline_timer.hpp
//
  template <typename WaitHandler>
  BOOST_ASIO_INITFN_RESULT_TYPE(WaitHandler,
      void (boost::system::error_code))
  async_wait(BOOST_ASIO_MOVE_ARG(WaitHandler) handler)
  {
    // If you get an error on the following line it means that your handler does
    // not meet the documented type requirements for a WaitHandler.
    BOOST_ASIO_WAIT_HANDLER_CHECK(WaitHandler, handler) type_check;

    return this->service.async_wait(this->implementation,
        BOOST_ASIO_MOVE_CAST(WaitHandler)(handler));
  }


={============================================================================
*kt_dev_boost_103* asio: io_service

http://www.boost.org/doc/libs/1_58_0/doc/html/boost_asio/reference/io_service.html

Provides core I/O functionality.

class io_service : noncopyable


* Synchronous and asynchronous operations

Synchronous operations on I/O objects implicitly run the io_service object for
an individual operation. The io_service functions run(), run_one(), poll() or
poll_one() must be called for the io_service to perform asynchronous operations
on behalf of a C++ program. 

Notification that an asynchronous operation has completed is delivered by
invocation of the associated handler. Handlers are invoked only by a thread that
is currently calling any overload of run(), run_one(), poll() or poll_one() for
the io_service. 


* Effect of exceptions thrown from handlers

If an exception is thrown from a handler, the exception is allowed to propagate
through the throwing thread's invocation of run(), run_one(), poll() or
poll_one(). No other threads that are calling any of these functions are
affected. It is then the responsibility of the application to catch the
exception.

After the exception has been caught, the run(), run_one(), poll() or poll_one()
call may be restarted without the need for an intervening call to reset(). This
allows the thread to rejoin the io_service object's thread pool 'without'
impacting any other threads in the pool.

For example:

boost::asio::io_service io_service;
...
for (;;)
{
  try
  {
    io_service.run();
    break; // run() exited normally
  }
  catch (my_exception& e)
  {
    // Deal with exception as appropriate.
  }
}


* Stopping the io_service from running out of work

note: when work is needed to keep io_service alive.

Some applications may need to prevent an io_service object's run() call from
returning when there is no more work to do. For example, the io_service may be
being run in a background thread that is launched prior to the application's
asynchronous operations. The run() call may be kept running by creating an
object of type io_service::work:

boost::asio::io_service io_service;
boost::asio::io_service::work work(io_service);
...

To effect a shutdown, the application will then need to call the io_service
object's stop() member function. This will cause the io_service run() call to
return as soon as possible, abandoning unfinished operations and without
permitting ready handlers to be dispatched.

Alternatively, if the application requires that all operations and handlers be
allowed to finish normally, the work object may be explicitly destroyed.

boost::asio::io_service io_service;
auto_ptr<boost::asio::io_service::work> work(new boost::asio::io_service::work(io_service));
...
work.reset(); // Allow run() to exit. 


* Member Functions

<post>
io_service::post

Request the io_service to invoke the given handler and return immediately.

template<typename CompletionHandler>
void-or-deduced post(CompletionHandler handler);

This function is used to ask the io_service to execute the given handler, but
    'without' allowing the io_service to call the handler from inside this
    function.

The io_service guarantees that the handler will only be called in a thread in
which the run(), run_one(), poll() or poll_one() member functions is currently
being invoked.  
        
Parameters

handler

The handler to be called. The io_service will make a 'copy' of the handler object
as required. The function signature of the handler must be:

void handler();

note: the signature of handler is different from one of deadline_timer.

Remarks

This function throws an exception only if:

the handler's asio_handler_allocate function; or the handler's copy constructor
throws an exception. 

<run>
io_service::run (1 of 2 overloads)

Run the io_service object's event processing loop.

std::size_t run();

The run() function blocks until all work has finished and there are no more
handlers to be 'dispatched', or until the io_service has been stopped.

Multiple threads may call the run() function to set up a pool of threads from
which the io_service may execute handlers. All threads that are waiting in the
pool are equivalent and the io_service may choose any one of them to invoke a
handler.

note: no order?

A normal exit from the run() function implies that the io_service object is
stopped (the stopped() function returns true). Subsequent calls to run(),
        run_one(), poll() or poll_one() will return immediately unless there is
        a prior call to reset().  
        
Return Value
The number of handlers that were executed.

Exceptions
boost::system::system_error. Thrown on failure. 

Remarks
The run() function must not be called from a thread that is currently calling
one of run(), run_one(), poll() or poll_one() on the same io_service object.

The poll() function may also be used to dispatch ready handlers, but without
blocking. 

note: here 'dispatch' means to get a handler from a io_service and calls it.
that is dispatch a user code.


* Types

<work>
io_service::work

Class to inform the io_service when it has work to do.

Member Functions

get_io_service 
Get the io_service associated with the work.

explicit work(boost::asio::io_service & io_service);
Constructor notifies the io_service that work is starting.
Copy constructor notifies the io_service that work is starting.

~work          
Destructor notifies the io_service that the work is complete.

The work class is used to 'inform' the io_service when work starts and finishes.
This ensures that the io_service object's run() function will not exit while
work is underway, and that it does exit when there is no unfinished work
remaining.

The work 'class' is copy-constructible so that it may be used as a data member
in a handler class.  It is not assignable. 

note: 'work object' and 'work'?
In other words, as long as an io_service has a work object associated with it,
   it will never run out of stuff to do.


<handler>
A free function as a completion handler:

void completion_handler()
{
  ...
}


={============================================================================
*kt_dev_boost_104* asio: A guide to getting started with boost::asio

http://www.gamedev.net/blog/950/entry-2249317-a-guide-to-getting-started-with-boostasio/?pg=1

A guide to getting started with boost::asio

Example 1f

#include <boost/asio.hpp>
#include <boost/shared_ptr.hpp>
#include <boost/thread.hpp>
#include <iostream>

boost::asio::io_service io_service;

void WorkerThread()
{
    std::cout << "Thread Start\n";
    io_service.run();
    std::cout << "Thread Finish\n";
}

int main( int argc, char * argv[] )
{
    boost::shared_ptr< boost::asio::io_service::work > work(
            new boost::asio::io_service::work( io_service )
            );

    std::cout << "Press [return] to exit." << std::endl;

    boost::thread_group worker_threads;
    for( int x = 0; x < 4; ++x )
    {
        worker_threads.create_thread( WorkerThread );
    }

    std::cin.get();

    io_service.stop();

    worker_threads.join_all();

    return 0;
}

What should really stand out is how simple and easy it is to make our threaded
programs 'scale'. By simply adding more worker threads, we can support more and
more concurrency for processing work through the io_service object. 

As mentioned before, if we had associated a work object with the io_service and
wanted to let all 'queued' work finish, we would not call stop but rather
destroy the work object. Care has to be taken though. If we want all work to
finish but keep giving the io_service more things to do, then it will never
exit! In that case, at some point, we would want to call the stop function to
ensure the system actually stops.


==============================================================================
Copyright: see |ktkb|                              vim:tw=100:ts=3:ft=help:norl:
