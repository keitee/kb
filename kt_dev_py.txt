*kt_dev_08*                                                                tw=100

kt.dev.py

/^[#=]{
Use #{ for a group and ={ for a item

|kt_dev_py_0001| py-check-version
|kt_dev_py_0001| py-base-basic
|kt_dev_py_0001| py-base-builtin-type
|kt_dev_py_0001| py-base-control
|kt_dev_py_0001| py-base-exception
|kt_dev_py_0001| py-base-loop

|kt_dev_py_0001| py-lib-sys
|kt_dev_py_0001| py-lib-subprocess
|kt_dev_py_0001| py-lib-built-in
|kt_dev_py_0001| py-lib-os
|kt_dev_py_0001| py-lib-urllib
|kt_dev_py_0001| py-lib-file
|kt_dev_py_0001| py-lib-itertools
|kt_dev_py_0001| py-lib-cvs
|kt_dev_py_0001| py-lib-re

|kt_dev_py_0001| py-data-string
|kt_dev_py_0001| py-data-tuple
|kt_dev_py_0001| py-data-list
|kt_dev_py_0001| py-data-slice
|kt_dev_py_0001| py-data-seq-function
|kt_dev_py_0001| py-data-dict
|kt_dev_py_0001| py-data-set
|kt_dev_py_0001| py-data-comprehension
|kt_dev_py_0001| py-module
|kt_dev_py_0001| py-module-namespace
|kt_dev_py_0001| py-module-package
|kt_dev_py_0001| py-module-advanced
|kt_dev_py_0001| py-module-name-test
|kt_dev_py_0001| py-function
|kt_dev_py_0001| py-class
|kt_dev_py_0001| py-


={============================================================================
|kt_dev_py_0001| py-references

LPY. Learning Python, Fifth Edition


# ============================================================================
#{
={============================================================================
|kt_dev_py_0001| py-check-version

10:27:35 ~$ python -V
Python 2.7.3

10:27:40 ~$ python --version
Python 2.7.3

>>> import sys
>>> print (sys.version)
2.7.3 (default, Mar 14 2014, 11:57:14) 
[GCC 4.7.2]

>>> sys.version_info
sys.version_info(major=2, minor=7, micro=3, releaselevel='final', serial=0)
>>> sys.hexversion
34014192

# `tuple` and `tuple` comparison?
>>> sys.version_info >= (2,5)
True


={============================================================================
|kt_dev_py_0001| py-base-basic

<indentation-not-brace>
Python uses whitespace (tabs or spaces) to structure code

for x in array:
  if x < pivot:
    less.append(x)
  else:
    greater.append(x)

A `colon` denotes the start of an `indented code block` after which all of the
code must be indented by the same amount until the end of the block.


<ex>

class Employee:
   empCount = 0

   def __init__(self, name, salary):
      self.name = name

     def setvalue(self, val):
        empCount=val

Error:
IndentationError: unindent does not match any outer indentation level

class Employee:
   empCount = 0

   def __init__(self, name, salary):
      self.name = name

   def setvalue(self, val):
      empCount=val


<everything-is-object>
An important characteristic of the Python language is the consistency of its
object model. 

Every number, string, data structure, function, class, module, and so on
exists in the Python interpreter in its own "box" which is referred to as a
`Python object` Each object has an associated `type` (for example, string or
    function) and internal `data`. In practice this makes the language very
flexible, as even functions can be treated just like any other object.


<comment>
Any text preceded by the hash mark (pound sign) # is ignored by the Python
interpreter.


<function>
Functions are called using parentheses and passing zero or more arguments,
          optionally assigning the returned value to a variable:

result = f(x, y, z)
g()

Almost every object in Python has attached functions, known as methods, that
have access to the object's internal contents. They can be called using the
syntax:

obj.some_method(x, y, z)


<pass-by-reference>
When assigning a variable (or name) in Python, you are creating a `reference` to
the object on the right hand side of the equals sign.

In some languages, this assignment would cause the data [1, 2, 3] to be
copied. In Python, a and b actually now refer to the same object, the original
list

a = [1,2,3]
b = a
a.append(4)
b
[1,2,3,4]

note:
Assignment is also referred to as `binding`, as we are binding a name to an
object. Variables names that have been assigned may occasionally be referred
to as bound variables.

When you pass objects as arguments to a function, you are only passing
references; no copying occurs.

Understanding the semantics of references in Python and when, how, and why
  data is copied is especially critical when working with larger data sets in
  Python.


<typed-language>
In contrast with many compiled languages, such as Java and C++, 
`object references` in Python `have no type` associated with them. There is no
  problem with the following:

>>> a = 5
>>> type(a)
<type 'int'>

>>> a = 'foo'
>>> type(a)
<type 'str'>

>>> a = "foo"
>>> type(a)
<type 'str'>


Variables are names for objects within a particular namespace; the type
information is stored in the `object itself` Some observers might hastily
conclude that Python `is not a typed language` This is `not true`; consider
this example:

>>> '5'+5
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
`TypeError`: cannot concatenate 'str' and 'int' objects

In some languages, such as Visual Basic, the string '5' might get implicitly
  converted (or casted) to an integer, thus yielding 10. Yet in other
  languages, such as JavaScript, the integer 5 might be casted to a string,
  yielding the concatenated string '55'. 

In this regard Python is considered a strongly-typed language, which means
that every object has a specific type (or class), and implicit conversions
will occur only in `certain obvious circumstances`, such as the following:

>>> a = 4.5
>>> b = 2
>>> print "a is %s, b is %s" % (type(a), type(b))
a is <type 'float'>, b is <type 'int'>
>>> a/b
2.25


Knowing the type of an object is important and can check that an object is an
instance of a particular type using the `isinstance` function:

>>> a = 5
>>> isinstance(a,int)
True
>>> b = 4.5
>>> isinstance(b,int)
False
>>> isinstance(b,float)
True

isinstance can accept a tuple of types if you want to check that an object's
type is among those present in the tuple:

>>> isinstance(b,(int,float))
True


<attribute-and-method>
Objects in Python typically have both `attributes`, other Python objects
stored "inside" the object, and `methods`, functions associated with an object
which can have access to the object's internal data.

Both of them are accessed via the syntax `obj.attribute_name` Attributes and
methods can also be accessed by name using the `getattr` function:

>>> a='foo'
>>> type(a)
<type 'str'>
>>> getattr(a, 'split')
<built-in method split of str object at 0xb744dc38>

While we will not extensively use the functions getattr and related functions
`hasattr` and setattr in this book, they can be used very effectively to write
generic, reusable code.


<iterable>
In a nutshell, an object is `iterable` if it is either a physically stored
sequence in memory, or an object that generates one item at a time in the
context of an iteration operation - a sort of "virtual" sequence.


Can verify that an object is iterable if it implemented the iterator protocol.

>>> def isiterable(obj):
...     try:
...             iter(obj)
...             return True
...     except TypeError:
...             return False
... 
>>> isiterable('a string')
True
>>> isiterable([1,2,3])
True
>>> isiterable(4)
False

note:
iter(object[, sentinel])

Return an iterator object. Without a second argument, object must be a
collection object which supports the `iteration protocol` (the __iter__()
    method), or it must support the sequence protocol (the __getitem__()
      method with integer arguments starting at 0). If it does not support
    either of those protocols, TypeError is raised.

A common case is writing a function that can accept any kind of sequence
(list, tuple, ndarray) or even an iterator. If it is not, convert it to be
one:

if not isinstance(x, list) and isiterable(x):
  x = list(x)


<comparison>
To check if two `references` refer to the same object, use the `is` and `is not`
keyword. Not the object itself. 

>>> a=[1,2,3]
>>> b=a
>>> c=list(a)
>>> a is b
True
>>> a is not c
True
>>> a is c
False
>>> a == c
True
>>> b == c
True

A very common use of is and is not is to check if a variable is None

>>> a = None
>>> a is None
True


={============================================================================
|kt_dev_py_0001| py-base-builtin-type

Table A-2. Standard Python Scalar Types

`None` 
The Python "null" value (only one instance of the None object exists)

`str` 
String type. ASCII-valued only in Python 2.x and Unicode in Python 3

unicode 
Unicode string type

float 
Double-precision (64-bit) floating point number. Note there is no separate
double type.

bool 
A `True` or `False` value

`int` 
Signed integer with maximum value determined by the platform.

long 
Arbitrary precision signed integer. Large int values are automatically
converted to long.


<numeric-types>
The primary Python types for numbers are `int` and `float`. 

The size of the integer which can be stored as an int is dependent on your
platform (whether 32 or 64-bit), but Python will transparently convert a very
large integer to `long`, which can store arbitrarily large integers.

Floating point numbers are represented with the Python float type. Under the
hood each one is a double-precision (64 bits) value.

In Python 3, integer division not resulting in a whole number will always
yield a floating point number:

In [284]: 3 / 2
Out[284]: 1.5

In Python 2.7 and below (which some readers will likely be using), you can
enable this behavior by default by putting the following cryptic-looking
statement at the top of your module:

from __future__ import division

Without this in place, you can always explicitly convert the denominator into
a floating point number:

In [285]: 3 / float(2)
Out[285]: 1.5

To get C-style integer division (which drops the fractional part if the result
is not a whole number), use the floor division operator //:

In [286]: 3 // 2
Out[286]: 1


={============================================================================
|kt_dev_py_0001| py-base-control

{pass}
`pass` is the "no-op" statement in Python. It can be used in blocks where no
action is to be taken; it is only required because Python uses whitespace to
delimit blocks.

It's common to use pass as a place-holder in code while working on a new piece
of functionality:

if x < 0:
  print 'negative!'
elif x == 0:
  # TODO: put something smart here
  pass
else:
  print 'positive!'


the error case:

if x < 0:
    print 'negative!'
elif x == 0:
    # TODO: put something here
else:
    print 'posivie!'

$ ./py-01.py 
  File "./py-01.py", line 17
    else:
       ^
IndentationError: expected an indented block


={============================================================================
|kt_dev_py_0001| py-base-exception

{exception}
Suppose we wanted a version of float that fails gracefully, returning the
input argument.

# catchs all

def attempt_float(x):
  try:
    return float(x)
  except:
    return x

Want to only `suppress` ValueError, since a TypeError (the input was not a
    string or numeric value) might indicate a legitimate bug in your program.
To do that, write the `exception type` after except:

def attempt_float(x):
  try:
    return float(x)
  except ValueError:
    return x

>>> float((1,2))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: float() argument must be a string or a number
>>> def attempt_float(x):
...     try:
...             return float(x)
...     except ValueError:
...             return x
... 
>>> attempt_float((1,2))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in attempt_float
TypeError: float() argument must be a string or a number
>>> 


Can catch `multiple exception types` by writing a `tuple` of exception types
instead (the parentheses are required):

def attempt_float(x):
  try:
    return float(x)
  except (TypeError, ValueError):
    return x


note:
As with C++, if exception gets raised and not catched, then returns
immediately.

In some cases, you may not want to suppress an exception, but you want some
code to be executed `regardless of` whether the code in the try block
`succeeds or not` To do this, use finally:

f = open(path, 'w')

try:
  write_to_file(f)
finally:
  f.close()

Here, the file handle f will always get closed. 

Similarly, you can have code that executes `only if` the try: block `succeeds`
using else:

f = open(path, 'w')

try:
  write_to_file(f)
except:
  print 'Failed'
else:
  print 'Succeeded'
finally:
  f.close()


={============================================================================
|kt_dev_py_0001| py-base-loop

{range}
`range` produces integers up to but not including the endpoint. 

>>> range(10)
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

A common use of range is for iterating through sequences `by index`:

seq = [1, 2, 3, 4]
for i in range(len(seq)):
  val = seq[i]

For very long ranges, it's recommended to use `xrange`, which takes the same
arguments as range but returns an iterator that generates integers one by one
rather than generating all of them up-front and storing them in a (potentially
    very large) list. This snippet sums all numbers from 0 to 9999 that are
multiples of 3 or 5:

sum = 0
for i in xrange(10000):
  # % is the modulo operator
  if x % 3 == 0 or x % 5 == 0:
    sum += i


{ternary-expression}
>>> x=5
>>> 'non-negative' if x >= 0 else 'negative'
'non-negative'
>>> 


{for}
remove an element of a list in the loop

  for script_name, priority, test_id, process in running_list:
    do something
    running_list.remove((script_name, priority, test_id, process))


={============================================================================
|kt_dev_py_0001| py-lib-sys

sys.exit([arg])

    Exit from Python. This is implemented by raising the SystemExit exception,
so cleanup actions specified by finally clauses of try statements are honored,
and it is possible to intercept the exit attempt at an outer level.

    The optional argument arg can be an integer giving the exit status
    (defaulting to zero), or another type of object. If it is an integer, zero
    is considered “successful termination” and any nonzero value is considered
    “abnormal termination” by shells and the like. Most systems require it to
    be in the range 0-127, and produce undefined results otherwise. Some
    systems have a convention for assigning specific meanings to specific exit
    codes, but these are generally underdeveloped; Unix programs generally use
    2 for command line syntax errors and 1 for all other kind of errors. If
    another type of object is passed, None is equivalent to passing zero, and
    any other object is printed to stderr and results in an exit code of 1. In
    particular, sys.exit("some error message") is a quick way to exit a
    program when an error occurs.

    Since exit() ultimately “only” raises an exception, it will only exit the
    process when called from the main thread, and the exception is not
    intercepted.


sys.argv

    The list of command line arguments passed to a Python script. argv[0] is
    the script name (it is operating system dependent whether this is a full
        pathname or not). If the command was executed using the -c command
    line option to the interpreter, argv[0] is set to the string '-c'. If no
    script name was passed to the Python interpreter, argv[0] is the empty
    string.

    To loop over the standard input, or the list of files given on the command
    line, see the fileinput module.

    note:
    argv[0] - len(argv[0]) is 1


={============================================================================
|kt_dev_py_0001| py-lib-subprocess

https://docs.python.org/2/library/subprocess.html

17.1. subprocess  Subprocess management

The subprocess module allows you to spawn new processes, connect to their
input/output/error pipes, and obtain their return codes. This module intends
to replace several older modules and functions:


The recommended way to launch subprocesses is to use the following
`convenience` functions. For more advanced use cases when these do not meet
your needs, use the underlying Popen interface.


subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False)

    Run the command described by args. Wait for command to complete, then
    return the `returncode` attribute.

    The arguments shown above are merely the most common ones, described below
    in Frequently Used Arguments (hence the slightly odd notation in the
        abbreviated signature). The full function signature is the same as
    that of the Popen constructor - this functions passes all supplied
    arguments directly through to that interface.

    Examples:

    >>> subprocess.call(["ls", "-l"])
    0

    >>> subprocess.call("exit 1", shell=True)
    1

    Warning
    Using shell=True can be a security hazard. See the warning under
    Frequently Used Arguments for details.

    Note
    Do not use stdout=PIPE or stderr=PIPE with this function as that can
    deadlock based on the child process output volume. Use Popen with the
    communicate() method when you need pipes.


17.1.1.2. Popen Constructor

The underlying process creation and management in this module is handled by
the Popen class. It offers a lot of flexibility so that developers are able to
handle the less common cases not covered by the convenience functions.

class subprocess.Popen(args, bufsize=0, executable=None, 
    stdin=None, stdout=None, stderr=None, preexec_fn=None, 
    close_fds=False, shell=False, cwd=None, env=None, 
    universal_newlines=False, startupinfo=None, creationflags=0)

`Execute a child program in a new process` On Unix, the class uses
os.execvp()-like behavior to execute the child program. 

`args` should be a sequence of program arguments or else a single string. By
default, the program to execute is the first item in args if args is a
sequence. If args is a string, the interpretation is platform-dependent and
described below. See the `shell` and executable arguments for additional
differences from the default behavior. Unless otherwise stated, it is
recommended to pass args as a sequence.

On Unix, if args is a string, the string is interpreted as the name or path of
the program to execute. However, this can only be done if not passing
arguments to the program.


<ex>
>>> print args
['/bin/vikings', '-input', 'eggs.txt', '-output', 'spam spam.txt', '-cmd', "echo '$MONEY'"]
>>> p = subprocess.Popen(args) # Success!


On Unix with `shell=True`, the shell defaults to /bin/sh. If args is a string,
the string specifies the command to execute `through the shell`  This means that
  the string must be formatted exactly as it would be when typed at the shell
  prompt. This includes, for example, quoting or backslash escaping filenames
  with spaces in them. If args is a sequence, the first item specifies the
  command string, and any additional items will be treated as additional
  arguments to the shell itself. That is to say, Popen does the equivalent of:

Popen(['/bin/sh', '-c', args[0], args[1], ...])


subprocess.PIPE

    Special value that can be used as the stdin, stdout or stderr argument to
    Popen and indicates that a pipe to the standard stream `should be opened`

stdin, stdout and stderr specify the executed program's standard input,
standard output and standard error file handles, respectively. 
  
Valid values are `PIPE`, an existing file descriptor (a positive integer), an
existing file object, and None. PIPE indicates that a new pipe to the child
should be created. With the default settings of None, no redirection will
occur; the child's file handles will be inherited from the parent.
Additionally, stderr can be STDOUT, which indicates that the stderr data from
the child process should be captured into the same file handle as for stdout.

If close_fds is true, all file descriptors except 0, 1 and 2 will be closed
before the child process is executed. (Unix only).


17.1.2. Popen Objects

Instances of the Popen class have the following methods:

Popen.wait()

    Wait for child process to terminate. Set and return returncode attribute.

    Warning

    This will deadlock when using stdout=PIPE and/or stderr=PIPE and the child
    process generates enough output to a pipe such that it blocks waiting for
    the OS pipe buffer to accept more data. `Use communicate() to avoid that.`

Popen.communicate(input=None)

    Interact with process: Send data to stdin. Read data from stdout and
    stderr, until end-of-file is reached. `Wait for process to terminate` The
    optional input argument should be a string to be sent to the child
    process, or None, if no data should be sent to the child.

    communicate() `returns` a tuple (stdoutdata, stderrdata).

    Note 
    that if you want to send data to the process's stdin, you need to create
    the Popen object with `stdin=PIPE`. Similarly, to get anything other than
    None in the result tuple, you need to give stdout=PIPE and/or stderr=PIPE
    too.

    Note
    The data read is buffered in memory, so do not use this method if the data
    size is large or unlimited.


Popen.poll()

    Check if child process has terminated. Set and return returncode
    attribute.

<ex>
        P = subprocess.Popen (cmd, stdout = subprocess.PIPE,
                stderr = subprocess.PIPE, close_fds=True, bufsize=50000000)

        stdOut, stdErr = P.communicate ()
        retVal = P.wait ()


={============================================================================
|kt_dev_py_0001| py-lib-built-in

https://docs.python.org/3/library/functions.html

2. Built-in Functions
The Python interpreter has a number of functions and types built into it that
are always available. They are listed here in alphabetical order.

print(*objects, sep=' ', end='\n', file=sys.stdout, flush=False)

    Print objects to the text stream file, separated by sep and followed by
    end. sep, end and file, if present, must be given as keyword arguments.
    All non-keyword arguments are converted to strings like str() does and
    written to the stream, separated by sep and followed by end. Both sep and
    end must be strings; they can also be None, which means to use the default
    values. If no objects are given, print() will just write end.  The file
    argument must be an object with a write(string) method; if it is not
    present or None, sys.stdout will be used. Since printed arguments are
    converted to text strings, print() cannot be used with binary mode file
    objects. For these, use file.write(...) instead.  Whether output is
    buffered is usually determined by file, but if the flush keyword argument
    is true, the stream is forcibly flushed.  Changed in version 3.3: Added
    the flush keyword argument.

<ex>
print "item in the list: %s" % item

*keyword-eval*
eval(expression, globals=None, locals=None)

    The arguments are a string and optional globals and locals. If provided,
    globals must be a dictionary. If provided, locals can be any mapping object.

    The expression argument is parsed and evaluated `as a Python expression`
    (technically speaking, a condition list) using the globals and locals
    dictionaries as global and local namespace. If the globals dictionary is
    present and lacks ‘__builtins__’, the current globals are copied into
    globals before expression is parsed. This means that expression normally
    has full access to the standard builtins module and restricted
    environments are propagated. If the locals dictionary is omitted it
    defaults to the globals dictionary. If both dictionaries are omitted, the
    expression is executed in the environment where eval() is called. The
    return value is the result of the evaluated expression. Syntax errors are
    reported as exceptions. Example:

    >>> x = 1
    >>> eval('x+1')
    2

    This function can also be used to execute arbitrary code objects (such as
        those created by compile()). In this case pass a code object instead
    of a string. If the code object has been compiled with 'exec' as the mode
    argument, eval()‘s return value will be None.

    Hints: dynamic execution of statements is supported by the exec()
    function. The globals() and locals() functions returns the current global
    and local dictionary, respectively, which may be useful to pass around for
    use by eval() or exec().

    See ast.literal_eval() for a function that can safely evaluate strings
    with expressions containing only literals.


={============================================================================
|kt_dev_py_0001| py-lib-os

https://docs.python.org/3.4/library/os.path.html

11.2. os.path  Common pathname manipulations


os.path.abspath(path)

    Return a normalized absolutized version of the pathname path. On most
    platforms, this is equivalent to calling the function normpath() as
    follows: normpath(join(os.getcwd(), path)).


os.path.dirname(path)

    Return the directory name of pathname path. This is the first element of
    the pair returned by passing path to the function split().


https://docs.python.org/3.4/library/os.html

16.1.5. Files and Directories

<ex>
    # Check the folder exists
    if os.path.isdir (dir):
        # Check if the folder is empty
        if os.listdir (dir) == []:


={============================================================================
|kt_dev_py_0001| py-lib-urllib

https://docs.python.org/2/library/urllib2.html

The urllib2 module defines functions and classes which help in opening URLs
(mostly HTTP) in a complex world  basic and digest authentication,
redirections, cookies and more.


<ex>
>>> import urllib2
>>> res = urllib2.urlopen("http://theyard.cisco.com/diagconf.txt")
>>> res
<addinfourl at 3067798252L whose fp = <socket._fileobject object at 0xb6d8266c>>
>>> content = res.read()

# the fils is:
#
# [
#       [["AMS"], ["AMS"]],
#       [["AFLPROXY"],["darwin_aflproxy_bindings_AS3"]],
#       [["DIAG_TIMESTAMP"], ["diag_svr"]],
#       [["CAPTRANS"], ["ms_captrans_src"]],
#       [["CAPTRANS_INPUT"], ["ms_captrans_src"]],
#       [["CAPTRANS_OUTPUT"], ["ms_captrans_src"]],
#       [["CAPTRANS_TTML"], ["ms_captrans_src"]],
#       [["PPCM_CF"], ["ppcm", "ppcm_core"]],
#       [["PPCM_CL"], ["ppcm", "ppcm_core"]],
#       [["PPCM_CORE"], ["ppcm", "ppcm_core"]],
#       ...
#
# returns a single long string
>>> content
'[\n      [["AMS"], ["AMS"]],\n      [["AFLPROXY"],["darwin_aflproxy_bindings_AS3"]],\n      [["DIAG_TIMESTAMP"], ["diag_svr"]],\n      [["CAPTRANS"], ["ms_captrans_src"]],\n      [["CAPTRANS_INPUT"], ["ms_captrans_src"]],\n      [["CAPTRANS_OUTPUT"], ["ms_captrans_src"]],\n      [["CAPTRANS_TTML"], ["ms_captrans_src"]],\n      [["PPCM_CF"], ["ppcm", "ppcm_core"]],\n      [["PPCM_CL"], ["ppcm", "p..'


={============================================================================
|kt_dev_py_0001| py-lib-file

Use the built-in `open` function with either a relative or absolute file path

path = 'ch13/segismundo.txt'
f = open(path)

By default, the file is opened in read-only mode 'r'. We can then treat the
file handle f like a `list` and iterate over the lines like so

for line in f:
  pass


The lines come out of the file with the end-of-line (EOL) markers intact, so
you'll often see code to get an EOL-free list of lines

lines = [x.rstrip() for x in open(path)]


To write text to a file, you can use either the file's `write` or `writelines`
methods. With no blank lines like so:

# see *with-as-context*
with open('tmp.txt', 'w') as handle:
  handle.writelines(x for x in open(path) if len(x) > 1)

open('tmp.txt').readlines()


={============================================================================
|kt_dev_py_0001| py-lib-itertools

https://docs.python.org/2/library/itertools.html#itertools.islice

 itertools.islice(iterable, stop)

<ex>
  # reads a file by section_size unit and makes it a list
  log_list = list(islice(log_file, section_size))


={============================================================================
|kt_dev_py_0001| py-lib-cvs

https://docs.python.org/2/library/csv.html

<ex>
import csv

    ret_list = list(csv.reader(open(path), delimiter="\t"))    


={============================================================================
|kt_dev_py_0001| py-lib-re

https://docs.python.org/2/library/re.html

7.2. re  Regular expression operations

7.2.2. Module Contents

The module defines several functions, constants, and an exception. 

Some of the functions are simplified versions of the `full featured methods`
for `compiled` regular expressions. Most non-trivial applications always use
  the compiled form.

re.compile(pattern, flags=0)

    Compile a regular expression `pattern into a regular expression object`,
            which can be used for matching using its match() and search()
              methods, described below.

    The expression's behaviour can be modified by specifying a flags value.
    Values can be any of the following variables, combined using bitwise OR
    (the | operator).

    The sequence

    prog = re.compile(pattern)
    result = prog.match(string)

    is equivalent to

    result = re.match(pattern, string)

    but using re.compile() and saving the resulting regular expression object
    for reuse is `more efficient` when the expression will be used several times
      in a single program.

    Note
    The compiled versions of the most recent patterns passed to re.match(),
        re.search() or re.compile() are cached, so programs that use only a
          few regular expressions at a time needn't worry about compiling
          regular expressions.


 re.split(pattern, string, maxsplit=0, flags=0)

    Split string by the occurrences of pattern. If capturing parentheses are
    used in pattern, then the text of all groups in the pattern are also
    returned as part of the resulting list. If maxsplit is nonzero, at most
    maxsplit splits occur, and the remainder of the string is returned as the
    final element of the list. (Incompatibility note: in the original Python
        1.5 release, maxsplit was ignored. This has been fixed in later
        releases.)


>>> import re
>>> match = re.match('Hello[ \t]*(.*)world', 'Hello Python world')
>>> match.group(1)
'Python '

>>> match = re.match('[/:](.*)[/:](.*)[/:](.*)', '/usr/home:lumberjack')
>>> match.groups()
('usr', 'home', 'lumberjack')

>>> re.split('[/:]', '/usr/home/lumberjack')
['', 'usr', 'home', 'lumberjack']


<ex>
# Sample line:
# NDS: ^0946684966.710878 !ERROR -SRM          < p:000000c1 t:016121b0 T:SRM_LP_THREAD M:srm_utils.c F:SRM_SystemStringToCString L:00287 > **** SRM ERR in srm_utils.c:287
#
# currently supports match = {1, 2, 3, 4, 5}
#       error type such as FATAL, ERROR, WARN, MIL and which is GROUP(1)
#       component type such as SRM and which is GROUP(2)
#       filename which is GROUP(3)
#       func which is GROUP(4)
#       free text which is GROUP(5)

# \s : any whitespace char
# \S : any not-whilespace char
# '?': causes the resulting RE to match 0 or 1 repetitions of the preceding RE. ab? will match either 'a' or 'ab'.

# NOTE. there's no support for a leading numbers of the dict line.
# NOTE. added MIL just for usefulness.
# NOTE. possibly add 'T:' group?

# extract interested groups from a dict entry. grab the whole free text.
matchDic = re.search(r'^NDS:.*!(FATAL|ERROR|WARN|MIL)\s+-(\S+).*(M:\S+)\s+(F:\S+).*>(.*)', lineDic )


={============================================================================
|kt_dev_py_0001| py-data-string
  
<immutable>
Every string operation is defined to produce a new string as its result,
because strings are `immutable` 

Can write string literal using either single quotes ' or double quotes ":

For multiline strings with line breaks, you can use `triple quotes`, either '''
or """:

c = """
This is a longer string that
spans multiple lines
"""


https://docs.python.org/2/library/string.html

7.1.6. Deprecated string functions

The following list of functions are also defined as methods of string and
Unicode objects; see section String Methods for more information on those. You
should consider these functions `as deprecated`, although they will not be
removed until Python 3. The functions defined in this module are:

<string-methods>
https://docs.python.org/2/library/stdtypes.html?highlight=endswith#str.endswith

5.6.1. String Methods

str.endswith(suffix[, start[, end]])
    Return True if the string ends with the specified suffix, otherwise return
    False. suffix can also be a tuple of suffixes to look for. With optional
    start, test beginning at that position. With optional end, stop comparing
    at that position.

    Changed in version 2.5: Accept tuples as suffix.

str.title()
    Return a titlecased version of the string where words start with an
    uppercase character and the remaining characters are lowercase.


str.split([sep[, maxsplit]])

    Return a list of the words in the string, using sep as the delimiter
    string. If maxsplit is given, at most maxsplit splits are done (thus, the
        list will have at most maxsplit+1 elements). If maxsplit is not
    specified or -1, then there is no limit on the number of splits (all
        possible splits are made).

    If sep is given, consecutive delimiters are not grouped together and are
    deemed to delimit empty strings (for example, '1,,2'.split(',') returns
        ['1', '', '2']). The sep argument may consist of multiple characters
    (for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']). Splitting an
      empty string with a specified separator returns [''].

    If sep is not specified or is None, a different splitting algorithm is
    applied: runs of consecutive whitespace are regarded as a single
    separator, and the result will contain no empty strings at the start or
    end if the string has leading or trailing whitespace. Consequently,
                        splitting an empty string or a string consisting of
                          just whitespace with a None separator returns [].

    For example, ' 1  2   3  '.split() returns ['1', '2', '3'], and '  1  2
    3  '.split(None, 1) returns ['1', '2   3  '].

<ex>
            p = re.compile (pattern)
            lines = stdOut.split ("\n")
            for line in lines:
                parts = line.split ("\t")
                if len (parts) == 2:
                    tag = parts[1].strip ()
                    if p.match (tag):
                        if not tag.endswith ("{}"):
                            tagsAux.append (tag)


str.rstrip([chars])

    Return a `copy` of the string with trailing characters removed. 
    
    The chars argument is a string specifying the `set of characters` to be
    removed. If omitted or None, the chars argument defaults to removing
    whitespace. The chars argument is not a suffix; rather, all combinations
    of its values are stripped:

    >>> '   spacious   '.rstrip()
    '   spacious'
    >>> 'mississippi'.rstrip('ipz')
    'mississ'



str.join(iterable)

    Return a string which is the concatenation of the strings in the iterable
    iterable. The separator between elements is the string providing this
    method.


{formatting}
# Formatting expression (all)
>>> '%s, eggs, and %s' % ('spam', 'SPAM!') 
'spam, eggs, and SPAM!'

# Formatting method (2.6+, 3.0+)
>>> '{0}, eggs, and {1}'.format('spam', 'SPAM!') 
'spam, eggs, and SPAM!'

# Numbers optional (2.7+, 3.1+)
>>> '{}, eggs, and {}'.format('spam', 'SPAM!') 
'spam, eggs, and SPAM!'


{raw-string}
raw string literal that turns off the backslash escape mechanism. Such
literals start with the letter r and are useful for strings like directory
paths on Windows (e.g., r'C:\text\new').


={============================================================================
|kt_dev_py_0001| py-data-tuple

A tuple is a one-dimensional, `fixed-length`, `immutable` sequence of Python
objects. 


# The easiest way to create one is with a comma-separated sequence of values

>>> tup = 4,5,6
>>> tup
(4, 5, 6)


# necessary to enclose the values in `parentheses` to create a tuple of tuples:

>>> nested_tup=(4,5,6),(7,8)
>>> nested_tup
((4, 5, 6), (7, 8))


# Any sequence or iterator can be converted to a tuple by invoking tuple:

>>> tuple([4,5,6])
(4, 5, 6)

>>> string_tup=tuple('string')
>>> string_tup
('s', 't', 'r', 'i', 'n', 'g')


# Accessed with square brackets [] as with most other sequence types.
# Sequences are 0-indexed in Python:

>>> string_tup[0]
's'


# Once created it's not possible to modify which object is stored in each slot:

>>> tup
(4, 5, 6)
>>> tup[1]=7
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'tuple' object does not support item assignment

note: WHY??

>>> tup=('foo', 'bar', 'baz')
>>> tup
('foo', 'bar', 'baz')
>>> tup=1,2,3
>>> tup
(1, 2, 3)
>>> tup=4,5,6,7
>>> tup
(4, 5, 6, 7)


# Can be concatenated using the + operator to produce longer tuples:

>>> long_tup = tup + nested_tup + string_tup
>>> long_tup
(4, 5, 6, (4, 5, 6), (7, 8), 's', 't', 'r', 'i', 'n', 'g')

note:
`tuple of tuple` so sequence can have different types.


{unpacking}
# If you try to assign to a tuple-like expression of variables, Python will
# attempt to unpack the value on the right-hand side of the equals sign:

>>> a,b,c = tup
>>> a
4
>>> b
5
>>> c
6


# Using this functionality it's easy to swap `variable names`, a task which in
# many languages might look like:
#
#   tmp = a
#   a = b
#   b = tmp

>>> a,b = b,a
>>> a
5
>>> b
4
>>> c
6


# One of the most common uses of variable unpacking when `iterating` over
# sequences of tuples or lists:

seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
for a, b, c in seq:
  pass

<ex>
seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
for a, b, c in seq:
  print a

1
4
7

<ex>
seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
for a, b, c, d in seq:
  print a

Traceback (most recent call last):
  File "./py-01.py", line 15, in <module>
    for a, b, c, d in seq:
ValueError: need more than 3 values to unpack


<method>
# Since the size and contents of a tuple cannot be modified, it is very light
# on instance methods. `count`, which counts the number of `occurrences` of a
# value:

>>> a=1,2,2,2,3,4,2
>>> a
(1, 2, 2, 2, 3, 4, 2)
>>> a.count(2)
4


<check>
>>> tup
('foo', 'bar', 'baz')
>>> 'bar' in tup
True


={============================================================================
|kt_dev_py_0001| py-data-list

In contrast with tuples, lists are `variable-length` and `mutable`. They can
be defined using `square brackets []` or using the `list` type function:

Lists and tuples are semantically similar as one-dimensional sequences of
objects and thus can be used interchangeably in many functions.

>>> b_list=list(tup)
>>> b_list
['foo', 'bar', 'baz']


<adding-removing>
# Append to the end of the list with the `append` method and `insert` an
# element at a specific location in the list:

>>> b_list.append('dwarf')
>>> b_list
['foo', 'bar', 'baz', 'dwarf']
>>> b_list.insert(1,'red')
>>> b_list
['foo', 'red', 'bar', 'baz', 'dwarf']

note: 
insert is computationally `expensive` compared with append as references to
subsequent elements have to be shifted internally to make room for the new
element.


# `pop` removes and returns an element at a particular index:

>>> b_list.pop(2)
'bar'
>>> b_list
['foo', 'red', 'baz', 'dwarf']


# `remove` locates the first such value and removes it from the last:

>>> b_list
['foo', 'red', 'red', 'red', 'baz', 'dwarf']
>>> b_list.remove('red')
>>> b_list
['foo', 'red', 'red', 'baz', 'dwarf']


<check>
As with tuple.

note:
checking whether a list contains a value is a lot `slower` than dicts and sets
as Python makes a linear scan across the values of the list, whereas the
others (based on hash tables) can make the check in constant time.


<concatenation>
# Append multiple elements to it using the `extend` method:

>>> [4, None, 'foo'] + [7,8,(2,3)]
[4, None, 'foo', 7, 8, (2, 3)]

>>> x=[4, None, 'foo']
>>> x.extend([7,8,(2,3)])
>>> x
[4, None, 'foo', 7, 8, (2, 3)]

# list concatenation is a compartively `expensive` operation since a `new
# list` must be created and the objects copied over. Using extend is usually
# preferable.

everything = []
for chunk in list_of_lists:
  everything.extend(chunk)

is faster than than the concatenative alternative

everything = []
for chunk in list_of_lists:
  everything = everything + chunk


<sorting> 
A list can be sorted in-place (without creating a new object) by calling its
`sort` function:

>>> tup = 2,4,3,5,7,6
>>> tup
(2, 4, 3, 5, 7, 6)

>>> lst = [2,4,3,5,7,8]
>>> lst
[2, 4, 3, 5, 7, 8]

>>> tup.sort()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'tuple' object has no attribute 'sort'

>>> lst.sort()
>>> lst
[2, 3, 4, 5, 7, 8]


sort has a few options that will occasionally come in handy. One is the
  ability to pass a secondary `sort key`, i.e. a `function` that produces a
  value to use to sort the objects.

>>> lst = ['saw', 'small', 'He', 'foxes', 'six']
>>> lst
['saw', 'small', 'He', 'foxes', 'six']
>>> lst.sort(key=len)
>>> lst
['He', 'saw', 'six', 'small', 'foxes']


note: *py-module-bisect*

The built-in bisect module implements binary-search and insertion into a
sorted list. bisect.bisect finds the `location` where an element should be
inserted to keep it sorted, while bisect.insort actually `inserts` the element
into that location:

>>> import bisect

>>> c = [1,2,2,2,3,4,7]
>>> bisect.bisect(c,2)
4

>>> bisect.insort(c,6)
>>> c
[1, 2, 2, 2, 3, 4, 6, 7]

The bisect module functions do not check whether the list is sorted. Thus,
using them with an unsorted list will succeed without error but may lead to
incorrect results.


<nested-list>
# [
#     [["AMS"], ["AMS"]],
#     [["PROX"], ["darwin"]]
#     ...
#     [["PPCM_CF"], ["ppcm", "ppcm_core"]],
# ]

>>> expstr = '[[["AMS"], ["AMS"]],[["PROX"], ["darwin"]]]'
>>> rlist = eval(expstr)        *keyward-eval*
>>> rlist
[[['AMS'], ['AMS']], [['PROX'], ['darwin']]]
>>> rlist[0][0]
['AMS']
>>> rlist[1]
[['PROX'], ['darwin']]
>>> rlist[0]
[['AMS'], ['AMS']]
>>> rlist[1]
[['PROX'], ['darwin']]
>>> rlist[1][0]
['PROX']
>>> rlist[1][1]
['darwin']

<ex>
# covert a nested list to a dict

  readList = eval (content)
  self._segments = {}
  for element in readList:
      self._segments [element[0][0]] = element [1]


={============================================================================
|kt_dev_py_0001| py-data-slice

You can select sections of list-like types (arrays, tuples, NumPy arrays) by
using slice notation, which in its basic form consists of `start:stop` passed
to the `indexing operator []`:

>>> seq=[7,2,3,7,5,6,0,1]
>>> seq
[7, 2, 3, 7, 5, 6, 0, 1]

# (start, end] in C++ iterator notation.

>>> seq[1:1]
[]

>>> seq[1:2]
[2]

>>> seq[1:5]
[2, 3, 7, 5]

# inserted actually

>>> seq[3:4] = [6,3]
>>> seq
[7, 2, 3, 6, 3, 5, 6, 0, 1]

Either the start or stop can be omitted in which case they default to the
start of the sequence and the end of the sequence, respectively:


A `step` can also be used after a second colon

[7, 2, 3, 6, 3, 5, 6, 0, 1]
>>> seq[::2]
[7, 3, 3, 6, 1]

Negative indices slice the sequence relative to the end:

   H  E  L  L  O  !
   0  1  2  3  4  5  6
  -6 -5 -4 -3 -2 -1

A clever use of this is to pass -1 which has the useful effect of reversing a
list or tuple:

[7, 2, 3, 6, 3, 5, 6, 0, 1]
>>> seq[::-1]
[1, 0, 6, 5, 3, 6, 3, 2, 7]


={============================================================================
|kt_dev_py_0001| py-data-seq-function

Python has a handful of useful built-in sequence functions.

<enumerate>
When iterating over a sequence to want to keep track of the index of the
current item. Since this is so common, Python has a built-in function
`enumerate` which returns a sequence of (i, value) tuples:

for i, value in enumerate(collection):
  # do something with value


Useful `pattern` that uses enumerate is computing a dict mapping the values of
a sequence (which are assumed to be unique) to their locations in the
sequence:

>>> l
['one', 'two', 'three']
>>> mapping = dict((v,i) for i,v in enumerate(l))
>>> mapping
{'three': 2, 'two': 1, 'one': 0}


<sorted>
The sorted function returns a new sorted list from the elements of any
sequence. A common `pattern` for getting a sorted list of the `unique
elements` in a sequence is to combine sorted with set.

>>> [7,1,2,6,0,3,2,3,2]
[7, 1, 2, 6, 0, 3, 2, 3, 2]
>>> sorted([7,1,2,6,0,3,2,3,2])
[0, 1, 2, 2, 2, 3, 3, 6, 7]
>>> sorted(set([7,1,2,6,0,3,2,3,2]))
[0, 1, 2, 3, 6, 7]


<zip>
zip `pairs up` the elements of a number of lists, tuples, or other sequences,
    to create a list of tuples:

>>> seq1=['foo','bar','baz']
>>> seq2=['one','two','three']
>>> zip(seq1,seq2)
[('foo', 'one'), ('bar', 'two'), ('baz', 'three')]


A very common use of zip is for simultaneously `iterating over multiple`
sequences, possibly also combined with enumerate:

>>> for i, (a,b) in enumerate(zip(seq1,seq2)):
...     print('%d: %s, %s' % (i,a,b))
... 
0: foo, one
1: bar, two
2: baz, three


Given a zipped sequence, zip can be applied in a clever way to `unzip` the
sequence.  Another way to think about this is converting a list of rows into a
list of columns. The syntax, which looks a bit magical, is:

>>> zipped=zip(seq1, seq2)
>>> zipped
[('foo', 'one'), ('bar', 'two'), ('baz', 'three')]
>>> names, numbers = zip(*zipped)
>>> names
('foo', 'bar', 'baz')
>>> numbers
('one', 'two', 'three')


<reversed>
`reversed` iterates over the elements of a sequence in reverse order:

>>> range(10)
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> reversed(range(10))
<listreverseiterator object at 0xb753a8ec>
>>> list(reversed(range(10)))
[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]


={============================================================================
|kt_dev_py_0001| py-data-dict

Dictionaries, the only mapping type in core objects set, are also `mutable`:
like lists, they may be changed in place and can grow and shrink on demand.

Unlike out-of-bounds assignments in lists, which are forbidden, assignments to
new dictionary keys create those keys:

>>> D = {}
>>> D['name'] = 'Bob'             # Create keys by assignment
>>> D['job'] = 'dev'
>>> D['age'] = 40


A more common name for it is hash map or associative array. It is a
flexibly-sized collection of key-value pairs, where key and value are Python
objects. One way to create one is by using curly `braces` {} and using
`colons` to separate keys and values:

>>> d1={'a':'some value', 'b':[1,2,3,4]}
>>> d1
{'a': 'some value', 'b': [1, 2, 3, 4]}


Elements can be accessed and inserted using the same syntax as accessing
elements of a list or tuple:

>>> d1[7]='an integer'
>>> d1
{'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}
>>> d1['b']
[1, 2, 3, 4]
>>> d1[b]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
KeyError: 'three'
>>> 


<in-test>
although we can assign to a new key to expand a dictionary, fetching a
nonexistent key is still a mistake.

The dictionary `in membership expression` allows us to query the existence of
a key and branch on the result with a Python if statement.

Can check if a dict contains a key using the same syntax as with checking
whether a list or tuple contains a value:

>>> 'b' in d1
True

>>> if not 'f' in D:          # Python's sole selection statement
  print('missing')


Values can be deleted either using the `del` keyword or the `pop` method
(which simultaneously returns the value and deletes the key):

>>> d1
{'a': 'some value', 'dummy': 'another value', 'b': [1, 2, 3, 4], 5: 'some value', 7: 'an integer'}
>>> del d1[5]
>>> d1
{'a': 'some value', 'dummy': 'another value', 'b': [1, 2, 3, 4], 7: 'an integer'}
>>> d1.pop('dummy')
'another value'
>>> d1
{'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}


The `keys() and values method` give you lists of the keys and values,
    respectively. While the key-value pairs are not in any particular order,
    these functions output the keys and values in the same order:

>>> d1.keys()
['a', 'b', 7]
>>> d1.values()
['some value', [1, 2, 3, 4], 'an integer']


One dict can be merged into another using the `update` method:

>>> d1
{'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}
>>> d1.update({'b':'foo','c':12})
>>> d1
{'a': 'some value', 'c': 12, 'b': 'foo', 7: 'an integer'}

note: 'b' is overwritten.


<dict-from-sequence> <zipping>
Common to occasionally end up with two sequences that you want to pair up
element-wise in a dict.

mapping = {}
for key, value in zip(key_list, value_list):
  mapping[key] = value

Since a dict is essentially a collection of 2-tuples, the dict type function
accepts a list of 2-tuples:

mapping = dict(zip(range(5), reversed(range(5))))
mapping
Out[454]: {0: 4, 1: 3, 2: 2, 3: 1, 4: 0}


>>> l
['one', 'two', 'three']
>>> mapping = dict((v,i) for i,v in enumerate(l))
>>> mapping
{'three': 2, 'two': 1, 'one': 0}


<default-values>
Very common to have logic like:

if key in some_dict:
  value = some_dict[key]
else:
  value = default_value

Thus, the dict methods `get` and pop can take a default value to be returned, so
that the above if-else block can be written simply as:

value = some_dict.get(key, default_value)

`get` by default will return `None` if the key is not present, while `pop`
will raise an exception.


<other-collection-as-value>

>>> di={}
>>> di['b'] = ['apple', 'atom']
>>> di
{'b': ['apple', 'atom']}

With setting values, a common case is for the values in a dict to be other
collections, like lists. For example, you could imagine categorizing a list of
words by their first letters as a dict of lists:

>>> words=['apple', 'bat', 'bar', 'atom', 'book']
>>> by_letter={}
>>> for word in words:
...     letter = word[0]
...     if letter not in by_letter:
...             by_letter[letter] = [word]
...     else:
...             by_letter[letter].append(word)
... 
>>> by_letter
{'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}


The `setdefault` dict method is for precisely this purpose.

note: HOW does all work?

>>> by_letter={}
>>> words=['apple', 'bat', 'bar', 'atom', 'book']
>>> for word in words:
...     letter = word[0]
...     by_letter.setdefault(letter,[]).append(word)
... 
>>> by_letter
{'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}


The built-in `collections` module has a useful class, `defaultdict`, which makes
  this even easier. One is created by passing a type or function for
  generating the default value for each slot in the dict: 
  
from collections import defaultdict 
by_letter = defaultdict(list) 
for word in words:
  by_letter[word[0]].append(word) 
  

The initializer to defaultdict only needs to be a callable object (e.g. any
    function), not necessarily a type. Thus, if you wanted the default value
to be 4 you could pass a function returning 4

counts = defaultdict(lambda: 4)


<key-types>
While the values of a dict can be `any` Python object, the keys have to be
`immutable` objects like scalar types (int, float, string) or tuples (all the
    objects in the tuple need to be immutable, too). The technical term here
is `hashability`. You can check whether an object is hashable (can be used as
    a key in a dict) with the hash function:

>>> hash('string')
-1542666171
>>> hash((1,2,(2,3)))
1387206534
>>> hash((1,2,[2,3]))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: unhashable type: 'list'


To use a list as a key, an easy fix is to convert it to a tuple:

>>> d = {}
>>> d[tuple([1,2,3])]=5
>>> d
{(1, 2, 3): 5}


<sorting>
dict is not `ordered` but can be done in one step with the newer `sorted`
built-in function.

>>> for key in sorted(D):
  print(key, '=>', D[key])


<dict-looping>

  # segments is a dict
  segments = D.getSegments ()
  if segments != None:

      # makes a list from keys of a dict
      keys = sorted (list (segments.keys ()))
      for key in keys:
          if args.detail:
              print key + ":",

              # looks up the value of a dict
              for build in segments [key]:
                  print build,
              print " "


={============================================================================
|kt_dev_py_0001| py-data-set

A set is an `unordered` collection of unique elements. You can think of them
like dicts, but keys only, no values.

A set can be created in two ways:

>>> set([2,2,2,1,3,3])
set([1, 2, 3])

>>> {2,2,2,1,3,3}
set([1, 2, 3])


Sets support mathematical set operations like union, intersection, difference,
and symmetric difference.

>>> a = {1,2,3,4,5}
>>> b = {3,4,5,6,7,8}

# union(or)
>>> a | b
set([1, 2, 3, 4, 5, 6, 7, 8])

# intersection(and)
>>> a & b
set([3, 4, 5])

# difference
>>> a - b
set([1, 2])

# symmetric difference
>>> a ^ b
set([1, 2, 6, 7, 8])


>>> {1,2,3}.issubset(a)
True
>>> a.issuperset({1,2,3})
True
>>> {1,2,3} == {3,2,1}
True


={============================================================================
|kt_dev_py_0001| py-data-comprehension

`List comprehensions` are one of the most-loved Python language features. They
allow you to concisely form a new list `by filtering` the elements of a
collection and transforming the elements passing the filter in one conscise
expression. They take the basic form:

[`expr` for val in collection if `condition`]

This is equivalent to the following for loop:

result = []
for val in collection:
  if condition:
    result.append(expr)

The `filter condition` can be `omitted`, leaving only the expression. For
example, we could filter out strings with length 2 or less and also convert
them to uppercase like this:

>>> strings=['a', 'as', 'bat', 'car', 'dove', 'python']
>>> [x.upper() for x in strings if len(x) > 2]
['BAT', 'CAR', 'DOVE', 'PYTHON']


>>> M
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]

>>> col2 = [row[1] for row in M]      # Collect the items in column 2
>>> col2
[2, 5, 8]
>>> M                                 # The matrix is unchanged
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]

List comprehensions derive from set notation; they are a way to build a new
  list by `running an expression on each item in a sequence`, one at a time,
       from left to right. 
List comprehensions are coded in square brackets (to tip you off to the fact
    that they make a list) and are composed of an `expression` and a `looping
construct` that share a variable name (row, here).


A `dict comprehension` looks like this:

dict_comp = { `key-expr:value-expr` for value in collection if `condition`}


A `set comprehension` looks like list comprehension except with curly braces
  instead of square brackets:

set_comp = {expr for value in collection if condition}


Comprehensions are just syntactic sugar, but they similarly can make code both
  easier to write and read.


Suppose we wanted a set containing just the lengths of the strings contained
in the collection; this could be easily computed using a set comprehension:

>>> unique_lengths = {len(x) for x in strings}
>>> unique_lengths
set([1, 2, 3, 4, 6])

Could create a lookup map of these strings to their locations in the list:

>>> loc_mapping = {val:index for index, val in enumerate(strings)}
>>> loc_mapping
{'a': 0, 'bat': 2, 'python': 5, 'car': 3, 'as': 1, 'dove': 4}

Note that this dict could be equivalently constructed by:

>>> loc_mapping2 = dict((val,index) for index, val in enumerate(strings))
>>> loc_mapping2
{'a': 0, 'bat': 2, 'python': 5, 'car': 3, 'as': 1, 'dove': 4}


={============================================================================
|kt_dev_py_0001| py-module

LPY. CHAPTER 22 Modules: The Big Picture

Python module—the highest-level program organization unit, which packages
program code and data for reuse, and provides self contained `namespaces` that
minimize variable name clashes across your programs.

All the names defined at the top level of a module file become `attributes` of
the imported module object. As we saw in the last part of this book, imports
give access to names `in a module's global scope`

The `top-level` (a.k.a. script) file contains the main flow of control of your
program—this is the file you run to launch your application. The module files
are libraries of tools used to collect components used by the top-level file.


How Imports Work

The `imports` are really runtime operations that perform three distinct steps
the first time a program imports a given file:

1. Find the module's file.

Python uses a standard `module search path` and `known file types` to locate the
module file corresponding to an import statement.

2. Compile it to byte code (if needed).

During an import operation Python checks both file modification times and the
byte code's Python version number to decide how to proceed.

In Python 3.2 and later, byte code files are segregated in a __pycache__
subdirectory and named with their Python version to avoid contention and
recompiles when multiple Pythons are installed.

note: ship byte code only
In addition, if Python finds only a byte code file on the search path and no
source, it simply loads the byte code directly; this means you can ship a
program as just byte code files and avoid sending source. 

In other words, the compile step is bypassed if possible to speed program
startup.

Notice that compilation happens when a file is being imported.

note: after all, to speed up.
If Python cannot write a file to save this on your computer for any reason,
your program still runs fine—Python simply creates and uses the byte code in
  memory and discards it on exit. To speed startups, though, it will try to
  save byte code in a file in order to skip the compile step next time around.

3. Run the module's code to build the objects it defines.

This last import step actually runs the file's code.


<module-search-path>
Python look:

1. The home directory of the program (automatic)
2. PYTHONPATH directories (if set)
3. Standard library directories (automatic)
4. The contents of any .pth files (if present)
5. The site-packages home of third-party extensions

<sys-path>
The concatenation of these four components becomes `sys.path`, a mutable list
of directory name strings. You can always inspect the path as Python knows it
by printing the built-in sys.path. The empty string at the front means current
directory


LPY. CHAPTER 23 Module Coding Basics

Module Filenames

Because module names become variable names inside a Python program, they
should also follow the `normal variable name rules`

The chief difference is that import fetches the module as a whole, so you must
qualify to fetch its names; in contrast, from fetches (or copies) specific
names out of the module.

The import Statement identifies an external file to be loaded, and it becomes
a variable in the script. Because it gives a name that refers to the whole
module object, we must go through the module name to fetch its attributes
(e.g., module1.printer).

Imports Happen Only Once

Modules are loaded and run on the first import or from, and only the first.


`import` and from Are Assignments

Just like def, import and from are executable statements, not compile-time
declarations. They may be nested in if tests, to select among options; appear
in function defs, to be loaded only on calls (subject to the preceding note);
be used in try statements, to provide defaults; and so on. They are not
  resolved or run until Python reaches them while executing your program. In
  other words, imported modules and names are not available until their
  associated import or from statements run.

Also, like def, the import and from are `implicit assignments`:
  * import assigns an entire module object to a single name.
  * from assigns one or more names to objects of the same names in another
    module.

Reassigning a copied name has no effect on the module from which it was
copied, but changing a `shared mutable object` through a copied name can also
change it in the module from which it was imported.

<ex>
# small.py
x = 1
y = [1, 2]

% python
>>> from small import x, y      # Copy two names out
>>> x = 42                      # Changes local x only
>>> y[0] = 42                   # Changes shared mutable in place

Here, x is not a shared mutable object, but y is, so changing it from one
place changes it in the other:

>>> import small # Get module name (from doesn't)
>>> small.x # Small's x is not my x
1
>>> small.y # But we share a changed mutable
[42, 2]


There is no link from a name copied with `from` back to the file it came from.
  To really change a global name in another file, you must use import:

% python
>>> from small import x, y      # Copy two names out
>>> x = 42                      # Changes my x only
>>> import small                # Get module name
>>> small.x = 42                # Changes x in other module

Note that the change to y[0] in the prior session is different; it changes an
object, not a name, and the name in both modules references the same, changed
object.

TODO: This phenomenon was introduced in Chapter 17. Scopes


import and from Equivalence

At least conceptually, a from statement like this one:

from module import name1, name2 # Copy these two names out (only)

is equivalent to this statement sequence:

import module                   # Fetch the module object
name1 = module.name1            # Copy names out by assignment
name2 = module.name2
del module                      # Get rid of the module name

Like all assignments, the from statement creates new variables in the
importer, which initially refer to objects of the same names in the imported
file. Only the names are copied out, though, `not the objects they reference`,
  and not the name of the module itself.


Potential Pitfalls of the from Statement

Some Python users recommend using import instead of from most of the time. 

It is true that the from statement has the potential to corrupt namespaces, at
least in principle—if you use it to import variables that happen to have the
same names as existing variables in your scope, your variables will be
silently overwritten. This problem doesn’t occur with the simple import
statement because you must always go through a module’s name to get to its
contents


={============================================================================
|kt_dev_py_0001| py-module-namespace

Technically, modules usually correspond to files, and Python creates a module
object to contain all the names assigned in a module file. But in simple
terms, modules are just `namespaces` (places where names are created), and the
names that live in a module are called its `attributes`.

Files Generate Namespaces

The short answer is that every name that is assigned a value at the top level
of a module file (i.e., not nested in a function or class body) becomes an
attribute of that module.

* Module statements run on the first import. The first time a module is
imported anywhere in a system, Python creates an empty module object and
executes the statements in the module file one after another, from the top of
the file to the bottom.

* Top-level assignments create module attributes. During an import, statements
at the top level of the file not nested in a def or class that assign names
(e.g., =, def) create attributes of the module object; assigned names are
stored in the module’s namespace.

* Module namespaces can be accessed via the attribute__dict__ or dir(M).
Module namespaces created by imports are dictionaries; they may be accessed
through the built-in __dict__ attribute associated with module objects and may
be inspected with the dir function. The dir function is roughly equivalent to
the sorted keys list of an object’s __dict__ attribute, but it includes
inherited names for classes, may not be complete, and is prone to changing
from release to release.

<ex>
# module2.py
print('starting to load...')

import sys
name = 42

def func(): pass
class klass: pass

print('done loading.')


Namespace Dictionaries: __dict__

module namespaces are stored as dictionary objects.

>>> list(module2.__dict__.keys())
['__loader__', 'func', 'klass', '__builtins__', '__doc__', '__file__', '__name__',
'name', '__package__', 'sys', '__initializing__', '__cached__']

Python also adds some names in the module’s namespace for us; for instance,
__file__ gives the name of the file the module was loaded from, and __name__
  gives its name as known to importers (without the .py extension and
      directory path).

>>> list(name for name in module2.__dict__.keys() if not name.startswith('__'))
['func', 'klass', 'name', 'sys']
>>> list(name for name in module2.__dict__ if not name.startswith('__'))
['func', 'sys', 'name', 'klass']

>>> module2.name, module2.__dict__['name']
(42, 42)


Imports Versus Scopes

Scopes are never influenced by function calls or module imports.

# moda.py

X = 88      # My X: global to this file only
def f():
  global X  # Change this file's X
  X = 99    # Cannot see names in other modules

# modb.py

X = 11      # My X: global to this file only
import moda # Gain access to names in moda
moda.f()    # Sets moda.X, not this file's X
print(X, moda.X)

% python modb.py
11 99


Namespace Nesting

imports do nest downward and it is possible to descend into arbitrarily nested
modules and access their attributes.

# mod3.py

X = 3

# mod2.py

X = 2
import mod3
print(X, end=' ')   # My global X
print(mod3.X)       # mod3's X

# mod1.py

X = 1
import mod2
print(X, end=' ')       # My global X
print(mod2.X, end=' ')  # mod2's X
print(mod2.mod3.X)      # Nested mod3's X

% python mod1.py
2 3
1 2 3

The reverse, however, is not true: mod3 cannot see names in mod2, and mod2
cannot see names in mod1.


={============================================================================
|kt_dev_py_0001| py-module-package

LPY. CHAPTER 24 Module Packages

In addition to a module name, an import can name a directory path. A directory
of Python code is said to be a package, so such imports are known as package
imports. In effect, a package import turns a directory on your computer into
another Python namespace, with attributes corresponding to the subdirectories
and module files that the directory contains.

Instead list a path of names separated by periods:

import dir1.dir2.mod

The same goes for from statements:

from dir1.dir2.mod import x

Furthermore, these imports imply that dir1 resides within some container
directory dir0, which is a component of the normal Python module search path.

More formally, the leftmost component in a package import path is still
relative to a directory included in the sys.path module search path list

In effect, entries on the module search path provide platform-specific
directory path prefixes, which lead to the leftmost names in import and from
statements. These import statements themselves provide the remainder of the
directory path in a platform-neutral fashion.


Package __init__.py Files

Each directory named within the path of a package import statement must
contain a file named __init__.py, or your package imports will fail.

for a directory structure such as this:
dir0\dir1\dir2\mod.py

and an import statement of the form:
import dir1.dir2.mod

the following rules apply:

* dir1 and dir2 both must contain an __init__.py file.
 
* dir0, the container, does not require an __init__.py file; this file will
  simply be ignored if present.

* dir0, not dir0\dir1, must be listed on the module search path sys.path.
 
The __init__.py files can contain Python code, just like normal module files.
Their names are special because their code is run automatically the first time
a Python program imports a directory, and thus serves primarily as a hook for
performing initialization steps required by the package. These files can also
be completely empty.

dir0\                       # Container on module search path
  dir1\
      __init__.py
      dir2\
          __init__.py
          mod.py

Once imported, the path in your import statement becomes a nested object path
in your script. Here, mod is an object nested in the object dir2, which in
turn is nested in the object dir1:

>>> dir1
<module 'dir1' from '.\\dir1\\__init__.py'>
>>> dir1.dir2
<module 'dir1.dir2' from '.\\dir1\\dir2\\__init__.py'>
>>> dir1.dir2.mod
<module 'dir1.dir2.mod' from '.\\dir1\\dir2\\mod.py'>


Why Use Package Imports?

They do serve useful roles, though, especially in larger programs: they make
imports more informative, serve as an organizational tool, simplify your
module search path, and can resolve ambiguities.


Package Relative Imports

note: TODO for Python 3.X


={============================================================================
|kt_dev_py_0001| py-module-advanced

LPY. CHAPTER 25 Advanced Module Topics

Data Hiding in Modules

There is no notion of declaring which names should and shouldn't be visible
outside the module. In fact, there's no way to prevent a client from changing
names inside a module if it wants to.  

In Python, data hiding in modules is a convention, not a syntactical
constraint.


Minimizing from * Damage: _X and __all__

a single underscore (e.g., _X) to prevent them from being copied out when a
client imports a module's names with a from * statement.

Underscores aren't "private" declarations: you can still see and change such
names with other import forms, such as the `import` statement:

When this feature is used, the from * statement will copy out only those names
listed in the __all__ list. In effect, this is the converse of the _X
convention: __all__ identifies names to be copied, while _X identifies names
not to be copied.

Python looks for an __all__ list in the module first and copies its names
irrespective of any underscores; if __all__ is not defined, from * copies all
names without a single leading underscore:

# alls.py
__all__ = ['a', '_c']                 # __all__ has precedence over _X
a, b, _c, _d = 1, 2, 3, 4

>>> from alls import *                # Load __all__ names only
>>> a, _c
(1, 3)
>>> b
NameError: name 'b' is not defined

>>> from alls import a, b, _c, _d     # But other importers get every name
>>> a, b, _c, _d
(1, 2, 3, 4)

>>> import alls
>>> alls.a, alls.b, alls._c, alls._d
(1, 2, 3, 4)


Enabling Future Language Features: __future__

Changes to the language that may potentially break existing code are usually
introduced gradually in Python. They often initially appear as optional
extensions, which are disabled by default. To turn on such extensions, use a
special import statement of this form:

from __future__ import featurename

When used in a script, this statement must appear as the first executable
statement in the file (possibly following a docstring or comment), because it
enables special compilation of code on a per-module basis. It’s also possible
to submit this statement at the interactive prompt to experiment with upcoming
language changes; the feature will then be available for the remainder of the
interactive session.


The as Extension for import and from

allow an imported name to be given a different name in your script.

import modulename as name # And use name, not modulename

This works in a from statement, too

from modulename import attrname as name # And use name, not attrname


Example: Modules Are Objects <introspection>

the module's attribute dictionary, exposed in the built-in __dict__ attribute
we met in Chapter 23. Python also exports the list of all loaded modules as
the sys.modules dictionary and provides a built-in called getattr that lets us
fetch attributes from their string names

all the following expressions reach the same attribute and object:

M.name                  # Qualify object by attribute
M.__dict__['name']      # Index namespace dictionary manually
sys.modules['M'].name   # Index loaded-modules table manually
getattr(M, 'name')      # Call built-in fetch function


Statement Order Matters in Top-Level Code

Python executes its statements one by one, from the top of the file to the
bottom.

* Code at the top level of a module file (not nested in a function) runs as
soon as Python reaches it during an import; because of that, it cannot
reference names assigned lower in the file.

* Code inside a function body doesn’t run until the function is called;
because names in a function aren’t resolved until the function actually runs,
        they can usually reference names anywhere in the file.

As a rule of thumb, if you need to mix immediate code with defs, put your defs
at the top of the file and your top-level code at the bottom. That way, your
functions are guaranteed to be defined and assigned by the time Python runs
the code that uses them.


from Copies Names but Doesn’t Link

the from statement is really an assignment to names in the importer's scope—a
name-copy operation, not a name aliasing. The implications of this are the
same as for all assignments in Python

# nested1.py
X = 99
def printer(): print(X)

# nested2.py
from nested1 import X, printer # Copy names out
X = 88 # Changes my "X" only!
printer() # nested1's X is still 99

% python nested2.py
99

If we use import to get the whole module and then assign to a qualified name,
however, we change the name in nested1.py.

# nested3.py
import nested1 # Get module as a whole
nested1.X = 88 # OK: change nested1's X
nested1.printer()

% python nested3.py
88


={============================================================================
|kt_dev_py_0001| py-module-name-test

Mixed Usage Modes: __name__ and __main__

each module has a built-in attribute called __name__, which Python creates and
assigns automatically as follows:

* If the file is being run as a top-level program file, __name__ is set to the
  string "__main__" when it starts.

* If the file is being imported instead, __name__ is set to the module’s name
  as known by its clients.

The upshot is that a module can test its own __name__ to determine whether
it's being run or imported.

In effect, a module’s __name__ variable serves as a `usage mode flag`,
allowing its code to be leveraged as both an importable library and a
  top-level script.

Coding self-test code at the bottom of a file under the __name__ test is
probably the most common and simplest unit-testing protocol in Python.

In addition, the __name__ trick is also commonly used when you’re writing
files that can be used both as command-line utilities and as tool libraries.


<reference>
29.4. __main__ — Top-level script environment

'__main__' is the name of the `scope` in which top-level code executes. A
module's __name__ is set equal to '__main__' when read from standard input, a
script, or from an interactive prompt.

A module can discover whether or not it is running in the `main-scope` by
checking its own __name__, which allows a common idiom for conditionally
executing code in a module when it is run `as-a-script` or with python -m but
not when it is imported:

if __name__ == "__main__":
    # execute only if run as a script
    main()

For a package, the same effect can be achieved by including a __main__.py
module, the contents of which will be executed when the module is run with -m.

<reference>
Python Scripts as a Replacement for Bash Utility Scripts

http://www.linuxjournal.com/content/python-scripts-replacement-bash-utility-scripts?page=0,0

Pros:

Python is a fully featured programming language. Code reuse is simple, because
Python modules easily can be imported and used in any Python script. Scripts
easily can be extended or built upon.

Python has access to an excellent standard library and thousands of third-party
libraries for all sorts of advanced utilities, such as parsers and request
libraries. For instance, Python's standard library includes datetime libraries
that allow you to parse dates into any format that you specify and compare it to
other dates easily. 

<ex>
#!/usr/bin/env python
import sys

if __name__ == "__main__":

    # initialize a names dictionary as empty to start with.
    # each key in this dictionary will be a name and the value will be
    # the number of times that names appears. name-value-pair
    names = {}

    # sys.stdin is a file object. all the same functions that can be
    # applied to a file object can be applied to sys.stdin. 
    for name in sys.stdin.readlines():

        # each line will have a newline on the end that should be
        # removed.
        name = name.strip()

        if name in names:
            names[name] += 1
        else:
            names[name] = 1

    # iterating over the dictionary. print name followed by a space and 
    # the number of times it appeared.
    for name, count in names.iteritems():
        sys.stdout.write("%d\t%s\n" % (count, name))


$ cat names.log | python namescount.py


The standard library of Python provides a CSV reader. The Python script below
completes this goal:


*py-cvs-reader*

#!/usr/bin/env python
# CSV module that comes with the Python standard library
import csv
import sys

if __name__ == "__main__":
    # The CSV module exposes a reader object that takes
    # a file object to read. In this example, sys.stdin.
    csvfile = csv.reader(sys.stdin)

    # The script should take one argument that is a column number.
    # Command-line arguments are accessed via sys.argv list.
    column_number = 0
    if len(sys.argv) > 1:
            column_number = int(sys.argv[1])

    # Each row in the CSV file is a list with each 
    # comma-separated value for that line.
    for row in csvfile:
            print row[column_number]


*py-stmplib*

#!/usr/bin/env python
import smtplib
import sys


GMAIL_SMTP_SERVER = "smtp.gmail.com"
GMAIL_SMTP_PORT = 587

GMAIL_EMAIL = "Your Gmail Email Goes Here"
GMAIL_PASSWORD = "Your Gmail Password Goes Here"


def initialize_smtp_server():
    '''
    This function initializes and greets the smtp server.
    It logs in using the provided credentials and returns 
    the smtp server object as a result.
    '''
    smtpserver = smtplib.SMTP(GMAIL_SMTP_SERVER, GMAIL_SMTP_PORT)
    smtpserver.ehlo()
    smtpserver.starttls()
    smtpserver.ehlo()
    smtpserver.login(GMAIL_EMAIL, GMAIL_PASSWORD)
    return smtpserver


def send_thank_you_mail(email):
    to_email = email
    from_email = GMAIL_EMAIL
    subj = "Thanks for being an active commenter"
    # The header consists of the To and From and Subject lines
    # separated using a newline character
    header = "To:%s\nFrom:%s\nSubject:%s \n" % (to_email,
            from_email, subj)
    # Hard-coded templates are not best practice.
    msg_body = """
    Hi %s,

    Thank you very much for your repeated comments on our service.
    The interaction is much appreciated.

    Thank You.""" % email
    content = header + "\n" + msg_body
    smtpserver = initialize_smtp_server()
    smtpserver.sendmail(from_email, to_email, content)
    smtpserver.close()


if __name__ == "__main__":
    # for every line of input.
    for email in sys.stdin.readlines():
            send_thank_you_mail(email)


*py-optionparser*

Thankfully, Python has a number of modules to deal with command-line arguments.
My personal favorite is OptionParser. OptionParser is part of the optparse
module that is provided by the standard library.

if __name__ == "__main__":
    usage = "usage: %prog [options]"
    parser = OptionParser(usage=usage)
    parser.add_option("--email", dest="email",
            help="email to login to smtp server")
    parser.add_option("--pwd", dest="pwd",
            help="password to login to smtp server")
    parser.add_option("--smtp-server", dest="smtpserver",
            help="smtp server url", default="smtp.gmail.com")
    parser.add_option("--smtp-port", dest="smtpserverport",
            help="smtp server port", default=587)
    options, args = parser.parse_args()

    if not (options.email or options.pwd):
            parser.error("Must provide both an email and a password")

    smtpserver = initialize_smtp_server(options.stmpserver,
            options.smtpserverport, options.email, options.pwd)

    # for every line of input.
    for email in sys.stdin.readlines():
            send_thank_you_mail(email, smtpserver)
    smtpserver.close()


There are a lot of aspects to Python in the shell that go beyond the scope of
  this article, such as the os module and the subprocess module. The os module
  is a standard library function that holds a lot of key operating system-level
  operations, such as listing directories and stating files, along with an
  excellent submodule os.path that deals with normalizing directories paths. The
  subprocess module allows Python programs to run system commands and other
  advanced operations, such as handling piping as described above within Python
  code between spawned processes. Both of these libraries are worth checking out
  if you intend to do any Python shell scripting. 


={============================================================================
|kt_dev_py_0001| py-function

Functions are declared using the `def` keyword and returned from using the
`return` keyword:

def my_function(x, y, z=1.5):
  if z > 1:
    return z * (x + y)
  else:
    return z / (x + y)

If the end of a function is reached without encountering a return statement,
    `None` is returned.


Each function can have some number of `positional` arguments and some number
of `keyword` arguments. Keyword arguments are most commonly used to specify
default values or optional arguments. In the above function, x and y are
positional arguments while z is a keyword argument. This means that it can be
called in either of these equivalent ways:

my_function(5, 6, z=0.7)
my_function(3.14, 7, 3.5)

The main restriction on function arguments it that the keyword arguments must
follow the positional arguments (if any).


{namespace}
Functions can access variables in two different scopes: global and local. An
alternate and more descriptive name describing a variable scope in Python is a
namespace.


{return-multiple-values}
If you think about tuple packing and unpacking from earlier in this chapter,
   you may realize that what's happening here is that the function is actually
   just returning `one` object, namely a tuple, which is then being unpacked
   into the result variables.

>>> def f():
...     a=5
...     b=6
...     c=7
...     return a,b,c
... 
>>> a
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'a' is not defined

>>> a,b,c = f()
>>> a
5
>>> b
6
>>> c
7


{functions-are-objects}
Since Python functions are objects, many constructs can be easily expressed
that are difficult to do in other languages.

Suppose we were doing some data cleaning and needed to apply a bunch of
transformations to the following list of strings:

>>> states = [' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda', \
  'south carolina##', 'West virginia?']
>>> states
[' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda', 'south carolina##',\
    'West virginia?']

>>> import re
>>> def clean_strings(strings):
...     result=[]
...     for value in strings:
                # these are `str` methods
...             value = value.strip()
...             value = re.sub('[!#?]', '', value)
...             value = value.title()
...             result.append(value)
...     return result
... 

# see address
>>> clean_strings
<function clean_strings at 0xb7509b1c>
>>> clean_strings(states)
['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia']


An alternate approach that you may find useful is to make a list of the
operations you want to apply to a particular set of strings:

>>> def remove_punctuation(value):
...     return re.sub('!?#', '', value)
... 
>>> clean_ops=[str.strip, remove_punctuation, str.title]

# see addresses
>>> clean_ops
[<method 'strip' of 'str' objects>, <function remove_punctuation at 0xb750979c>, 
  <method 'title' of 'str' objects>]

>>> def clean_strings_ops(strings, ops):
...     result=[]
...     for value in strings:
...             for function in ops:
...                     value = function(value)
...             result.append(value)
...     return result
... 

>>> states
[' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda', 'south carolina##', 
  'West virginia?']

# WTF? oops since have error in remove_punctuation function.
>>> clean_strings_ops(states, clean_ops)
['Alabama', 'Georgia!', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia?']

# going to work if define it again?
>>> def remove_punctuation(value):
...     return re.sub('[!?#]', '', value)
... 

# still not working?
>>> clean_strings_ops(states, clean_ops)
['Alabama', 'Georgia!', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia?']

# define clean_ops again and see different address for remove_punctuation
>>> clean_ops
[<method 'strip' of 'str' objects>, <function remove_punctuation at 0xb750979c>, 
  <method 'title' of 'str' objects>]

>>> clean_ops=[str.strip, remove_punctuation, str.title]
>>> clean_ops
[<method 'strip' of 'str' objects>, <function remove_punctuation at 0xb7509e9c>, 
  <method 'title' of 'str' objects>]

>>> clean_strings_ops(states, clean_ops)
['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia']


A more `functional pattern` like this enables you to easily modify how the
strings are transformed at a very high level. The clean_strings function is
also now more reusable!

Use functions as arguments to other functions like the built-in `map
function`, which applies a function to a collection of some kind:

>>> map(remove_punctuation, states)
[' Alabama ', 'Georgia', 'Georgia', 'georgia', 'FlOrIda', 
  'south carolina', 'West virginia']


{lambda}
Anonymous or lambda functions, which are really just simple functions
consisting of a single statement, the result of which is the return value.
They are defined using the `lambda keyword`

They are especially convenient in data analysis because, as you'll see, there
are many cases where data transformation functions will take functions as
arguments. It's often less typing (and clearer) to pass a lambda function as
opposed to writing a full-out function declaration or even assigning the
lambda function to a local variable. For example, consider this silly example:

>>> def apply_to_list(some_list, f):
...     return [f(x) for x in some_list]
... 

>>> ints = [4,0,1,5,6]
>>> apply_to_list(ints, lambda x: x*2)
[8, 0, 2, 10, 12]

You could also have written [x * 2 for x in ints], but here we were able to
succintly pass a custom operator to the apply_to_list function.


{closures}
In a nutshell, a closure is any `dynamically-generated function` returned by
another function. The key property is that the returned function has access to
the variables in the local namespace where it was created. Here is a very
simple example:

>>> def make_closure(a):
...     def closure():
...             print('I know the secret: %d' % a)
...     return closure
... 

>>> closure = make_closure(5)
>>> closure
<function closure at 0xb75125dc>
>>> closure()
I know the secret: 5
>>> closure()
I know the secret: 5


The difference between a closure and a regular Python function is that the
closure continues to have access to the namespace (the function) where it was
created, even though that function is done executing. So in the above case,
  the returned closure will always print "I know the secret: 5" whenever you
  call it. 

While it's common to create closures whose internal state (in this example,
    only the `value` of a) is `static`, you can just as easily have a
`mutable` object like a dict, set, or list that can be modified. For example,
  here's a function that returns a function that keeps track of arguments it
  has been called with:

def make_watcher():
  have_seen = {}

  def has_been_seen(x):
    if x in have_seen:
      return True
    else:
      have_seen[x] = True
      return False
  return has_been_seen

Using this on a sequence of integers I obtain:

In [496]: watcher = make_watcher()
In [497]: vals = [5, 6, 1, 5, 1, 6, 3, 5]
In [498]: [watcher(x) for x in vals]
Out[498]: [False, False, False, True, True, True, False, True]

one technical limitation to keep in mind is that while you can mutate any
internal state objects (like adding key-value pairs to a dict), you cannot
bind variables in the enclosing function scope. One way to work around this is
to modify a dict or list rather than binding variables:

>>> def make_counter():
...     count = [0]
...     def counter():
...             count[0] +=1
...             return count[0]
...     return counter
... 
>>> cnt = make_counter()
>>> cnt
<function counter at 0xb7512684>
>>> cnt()
1
>>> cnt()
2

>>> def make_counter_two():
...     count = 0
...     def counter():
...             count +=1
...             return count
...     return counter
... 
>>> cnt_two = make_counter_two()
>>> cnt_two
<function counter at 0xb75126f4>
>>> cnt_two()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 4, in counter
UnboundLocalError: local variable 'count' referenced before assignment


Why this is useful? In practice, you can write very `general functions` with
lots of options, then fabricate simpler, more specialized functions. Here's an
example of creating a string formatting function:


Here's an example of creating a string formatting function:

def format_and_pad(template, space):
  def formatter(x):
    return (template % x).rjust(space)
  return formatter

You could then create a floating point formatter that always returns a
length-15 string like so:

In [500]: fmt = format_and_pad('%.4f', 15)
In [501]: fmt(1.756)
Out[501]: ' 1.7560'

If you learn more about object-oriented programming in Python, you might
observe that these patterns also could be implemented (albeit more verbosely)
  using classes.


={============================================================================
|kt_dev_py_0001| py-class


<class-variable>
Class variable: A variable that is shared by all instances of a class. Class
variables are defined within a class but outside any of the class's methods.
Class variables are not used as frequently as instance variables are. 

Instance variable: A variable that is defined inside a method and belongs only
to the current instance of a class. 

class Employee:
   'Common base class for all employees'
   empCount = 0

   def __init__(self, name, salary):
      self.name = name
      self.salary = salary
      Employee.empCount += 1

empCount is a `class variable` whose value is shared among all instances of a
  this class. This can be accessed as Employee.empCount from inside the class
  or outside the class.


To create instance:

"This would create first object of Employee class"
emp1 = Employee("Zara", 2000)
"This would create second object of Employee class"
emp2 = Employee("Manni", 5000)


To access attribute:

emp1.displayEmployee()
emp2.displayEmployee()
print "Total Employee %d" % Employee.empCount


<when-create-instance-variable>
Created when used so use `__init__` to create variables used by methods. 

note: different from C++.

class HousePark:
    def setname(self, name):
        self.fullname = name

    def setlastname(self, name):
        self.lastname = name

    def printname(self):
        # @65
        print "last %s, full %s" % (self.lastname, self.fullname)

pey = HousePark()
pey.setname(" kit")
pey.printname()

Traceback (most recent call last):
  File "./class-05.py", line 70, in <module>
    pey.printname()
  File "./class-05.py", line 65, in printname
    print "last %s, full %s" % (self.lastname, self.fullname)
AttributeError: HousePark instance has no attribute 'lastname'


<scope>

class HousePark:
    lastname = "park"

    def setname(self, name):
        # has no effect
        # lastname = "LEE"
        self.fullname = self.lastname + name

    def setlastname(self, name):
        self.lastname = name

    def printname(self):
        print "last %s, full %s" % (self.lastname, self.fullname)

pey = HousePark()
pey.setlastname("LEE")
pey.setname(" kit")
pey.printname()

print HousePark.lastname

pey2 = HousePark()
pey2.setname(" kj")
pey2.printname()


last LEE, full LEE kit    # use local variable
park                      # class variable do not change
last park, full park kj   # use class variable


pey = HousePark()
pey.setlastname("LEE")
pey.setname(" kit")
pey.printname()

print HousePark.lastname

pey2 = HousePark()
pey2.setlastname("JUNG")
pey2.setname(" kj")
pey2.printname()

last LEE, full LEE kit
park
last JUNG, full JUNG kj     # shows that instance has own local


How to use `class variable`?

    def setname(self, name):
        self.fullname = HousePark.lastname + name

    def setlastname(self, name):
        HousePark.lastname = name


<built-in-attributes>
Can be accessed using dot operator like any other attribute.


{dtor}
Python's garbage collector runs during program execution and is triggered when
an object's reference count reaches zero. An object's reference count changes
as the number of aliases that point to it changes.


<ex>
Are these `local` to this method? No since these are `instance variable` 

class X:

    def getTagCode (self, branch, tag=None):

        retVal = False
        FOLDER = "Ethan"

        # ...

        return retVal, FOLDER

<global>
#!/usr/bin/env python

CL_STATUS_OK = 0
CL_STATUS_ERROR = 1

if __name__ == "__main__":
    pass

Use

import scripts.common.cmdLine as cmdLine

def func (branch, tag, dir):
    retVal = cmdLine.CL_STATUS_ERROR


<staticmethod>
https://docs.python.org/2/library/functions.html#staticmethod

staticmethod(function)

    Return a static method for function.

    A static method does not receive an `implicit first argument` 
    
    To declare a static method, use this idiom:

    class C(object):
        @staticmethod
        def f(arg1, arg2, ...):
            ...

    The @staticmethod form is a `function decorator` see the description of
      function definitions in Function definitions for details.

    It can be called either on the class (such as C.f()) or on an instance
    (such as C().f()). The instance is ignored except for its class.

    Static methods in Python are similar to those found in Java or C++. Also
    see classmethod() for a variant that is useful for creating alternate
    class constructors.

    For more information on static methods, consult the documentation on the
    standard type hierarchy in The standard type hierarchy.

    New in version 2.2.

    Changed in version 2.4: Function decorator syntax added.


{inheritance}
`overriding` when `name` is the same.

note: different from C++ where `name` and `params` should be the same.

class HousePark:
    def __init__(self, name):
        self.fullname = self.lastname + name
    def travel(self, where):
        print("%s, %s...." % (self.fullname, where))

class HouseKim(HousePark):
    def travel(self, where, day):
        print("%s, %s...." % (self.fullname, where, day))


={============================================================================
|kt_dev_py_0001| py-exception

{with-as-context}
Python 2.6 and 3.0 introduced a new exception-related statementthe with, and
its optional as clause. This statement is designed to work with context
manager objects, which support a new method-based protocol,

In short, the with/as statement is designed to be an `alternative` to a common
`try/ finally` usage idiom; like that statement, with is in large part
intended for specifying termination-time or "cleanup" activities that must run
`regardless of whether an exception occurs` during a processing step.

Unlike try/finally, the with statement is based upon an object `protocol` for
specifying actions to be run around a block of code. This makes `with` less
general, qualifies it as redundant in termination roles, and requires coding
classes for objects that do not support its protocol. 

On the other hand, `with` also handles entry actions, can reduce code size,
   and allows code contexts to be managed with full OOP.

Python enhances some built-in tools with context managers, such as files that
automatically close themselves and thread locks that automatically lock and
unlock, but programmers can code context managers of their own with classes,
  too.


with expression [as variable]:
  with-block

The `expression` here is assumed to return an object that supports the context
management protocol (more on this protocol in a moment). This object may also
return a value that will be assigned to the name `variable` if the optional as
clause is present.

Note that the variable is not necessarily assigned the result of the
expression; the result of the expression is the object that supports the
context protocol, and the variable may be assigned something else intended to
be used inside the statement. The object returned by the expression may then
run startup code before the with-block is started, as well as termination code
after the block is done, regardless of whether the block raised an exception
or not.

file objects have a context manager that automatically closes the file after
the `with block` regardless of whether an exception is raised, and regardless of
if or when the version of Python running the code may close automatically:

with open(r'C:\misc\data') as myfile:
  for line in myfile:
    print(line)
      ...more code here...

Here, the call to open returns a simple file object that is assigned to the
name myfile. We can use myfile with the usual file tools - in this case, the
file iterator reads line by line in the for loop.

Guarantees that the file object referenced by myfile is automatically closed,
           even if the for loop raised an exception while processing the file.

The with statement in this role is an alternative that allows us to be sure
that the close will occur after execution of a specific block of code.

As we saw earlier, we can achieve a similar effect with the more general and
explicit try/finally statement, but it requires three more lines of
administrative code in this case (four instead of just one):

myfile = open(r'C:\misc\data')
try:
  for line in myfile:
    print(line)
    ...more code here...
finally:
  myfile.close()


={============================================================================
|kt_dev_py_0001| py-re



==============================================================================
Copyrightobjdump see |ktkb|                        vim:tw=100:ts=3:ft=help:norl:
