*kt_dev_08*                                                                tw=100

kt.dev.py

/^[#=]{
Use #{ for a group and ={ for a item

|kt_dev_py_0001| py-book
|kt_dev_py_0001| py-version
|kt_dev_py_0001| py-indentation
|kt_dev_py_0001| py-base
|kt_dev_py_0001| py-type
|kt_dev_py_0001| py-attribute
|kt_dev_py_0001| py-none

|kt_dev_py_0001| py-gotchas
|kt_dev_py_0001| py-numeric
|kt_dev_py_0001| py-string
|kt_dev_py_0001| py-print
|kt_dev_py_0001| py-eval
|kt_dev_py_0001| py-tuple
|kt_dev_py_0001| py-list
|kt_dev_py_0001| py-slice
|kt_dev_py_0001| py-reverse
|kt_dev_py_0001| py-dict 
|kt_dev_py_0001| py-dict-ordered
|kt_dev_py_0001| py-set
|kt_dev_py_0001| py-coll
|kt_dev_py_0001| py-coll-deque
|kt_dev_py_0001| py-coll-heapq
|kt_dev_py_0001| py-reference py-copy
|kt_dev_py_0001| py-recursive
|kt_dev_py_0001| py-if py-or py-and
|kt_dev_py_0001| py-iterator py-comprehension
|kt_dev_py_0001| py-generator
|kt_dev_py_0001| py-module
|kt_dev_py_0001| py-module-namespace
|kt_dev_py_0001| py-module-package
|kt_dev_py_0001| py-module-advanced
|kt_dev_py_0001| py-module-main-name py-shell-script
|kt_dev_py_0001| py-function
|kt_dev_py_0001| py-function-namespace
|kt_dev_py_0001| py-function-lambda
|kt_dev_py_0001| py-function-arguments
|kt_dev_py_0001| py-class
|kt_dev_py_0001| py-class-overload
|kt_dev_py_0001| py-class-static py-decorator
|kt_dev_py_0001| py-property
|kt_dev_py_0001| py-class-super
|kt_dev_py_0001| py-pattern
|kt_dev_py_0001| py-namespace
|kt_dev_py_0001| py-docstring
|kt_dev_py_0001| py-exception

|kt_dev_py_0001| py-sys
|kt_dev_py_0001| py-subprocess
|kt_dev_py_0001| py-shlex
|kt_dev_py_0001| py-builtin-function
|kt_dev_py_0001| py-os
|kt_dev_py_0001| py-urllib
|kt_dev_py_0001| py-file
|kt_dev_py_0001| py-itertools
|kt_dev_py_0001| py-cvs
|kt_dev_py_0001| py-re
|kt_dev_py_0001| py-pip
|kt_dev_py_0001| py-dropbox
|kt_dev_py_0001| py-imaplib
|kt_dev_py_0001| py-time
|kt_dev_py_0001| py-time-benchmark
|kt_dev_py_0001| py-cvs
|kt_dev_py_0001| py-stmplib
|kt_dev_py_0001| py-parser-option
|kt_dev_py_0001| py-xml
|kt_dev_py_0001| py-logging
|kt_dev_py_0001| py-error-encoding
|kt_dev_py_0001| py-six

|kt_dev_py_0001| py-flask-doc
|kt_dev_py_0001| py-flask-apache
|kt_dev_py_0001| py-flask
|kt_dev_py_0001| py-flask-template
|kt_dev_py_0001| py-flask-form

|kt_dev_py_0001| py-unit


={============================================================================
|kt_dev_py_0001| py-book

LPY5. Learning Python, Fifth Edition
June 2013: Fifth Edition.

PYCB, THIRD EDITION, Python Cookbook, David Beazley and Brian K. Jones
2013-05-08: First release


={============================================================================
|kt_dev_py_0001| py-version

10:27:35 ~$ python -V
Python 2.7.3

10:27:40 ~$ python --version
Python 2.7.3

>>> import sys
>>> print (sys.version)
2.7.3 (default, Mar 14 2014, 11:57:14) 
[GCC 4.7.2]

>>> sys.version_info
sys.version_info(major=2, minor=7, micro=3, releaselevel='final', serial=0)
>>> sys.hexversion
34014192

# `tuple` and `tuple` comparison?
>>> sys.version_info >= (2,5)
True


={============================================================================
|kt_dev_py_0001| py-indentation

LYP5, Chapter 12, if Tests and Syntax Rules, Python Syntax Revisited

Block and statement boundaries are detected automatically. 

As we’ve seen, there are no braces or “begin/end” delimiters around blocks of
code in Python; instead, Python uses the indentation of statements under a
header to group the statements in a nested block. Similarly, Python statements
are not normally terminated with semicolons; rather, the end of a line usually
marks the end of the statement coded on that line. As a special case,
statements can span lines and be combined on a line with special syntax.

Block Delimiters: Indentation Rules

As introduced in Chapter 10, Python detects block boundaries automatically, by
`line indentation` - that is, the empty space to the left of your code. 

All statements indented the same distance to the right belong to the same
block of code. In other words, the statements within a block line up
vertically, as in a column. The block ends when the end of the file or a
lesser-indented line is encountered, and more deeply nested blocks are simply
indented further to the right than the statements in the enclosing block.


<indentation-not-brace>
Python uses whitespace (tabs or spaces) to structure code

for x in array:
  if x < pivot:
    less.append(x)
  else:
    greater.append(x)

A `colon` denotes the start of an `indented code block` after which all of the
code must be indented by the same amount until the end of the block.


<ex> space-and-tab does matter
class Employee:
   empCount = 0

   def __init__(self, name, salary):
      self.name = name

     def setvalue(self, val):
        empCount=val

Error:
IndentationError: unindent does not match any outer indentation level

<ex>
def okay:
    for i in range(settings.secondsToWait):
      try:
        time.sleep(1)
      except KeyboardInterrupt:
        break

      valids = devices.getValidDevices()
      if len(valids) >= settings.numSTBs:
        break

    print 'Found %d STBs in %ds' % (len(valids), i)

def error:
    for i in range(settings.secondsToWait):
      try:
        time.sleep(1)
      except KeyboardInterrupt:
        break

    valids = devices.getValidDevices()
    if len(valids) >= settings.numSTBs:
      break

    print 'Found %d STBs in %ds' % (len(valids), i)

SyntaxError: 'break' outside loop


Statement Delimiters: Lines and Continuations

A statement in Python normally ends at the end of the line on which it
appears. When a statement is too long to fit on a single line, though, a few
special rules may be used to make it span multiple lines:

Statements may span multiple lines if you're continuing an open syntactic
pair. 

Python lets you continue typing a statement on the next line if you're coding
something enclosed in a (), {}, or [] `pair.` For instance, expressions in
parentheses and dictionary and list literals can span any number of lines;
your statement doesn’t end until the Python interpreter reaches the line on
  which you type the closing part of the pair (a ), }, or ]). 
  
Continuation lines-lines 2 and beyond of the statement can start at any
indentation level you like, but you should try to make them align vertically
for readability if possible. This open pairs rule also covers set and
  dictionary comprehensions in Python 3.X and 2.7.

<py-multiple-line>
Statements may span multiple lines if they end in a backslash. 

This is a somewhat outdated feature that's `not generally recommended,` but if a
statement needs to span multiple lines, you can also add a backslash (a \ not
    embedded in a string literal or comment) at the end of the prior line to
indicate you're continuing on the next line. 

Because you can also `continue by adding parentheses around most constructs`,
backslashes are rarely used today. 

<ex>
print "  %s, %s, %s - %s -> %s, %s" % (getBoxInfo(), getBoxInfo(), getBoxInfo(), getBoxInfo(), getBoxInfo(), getBoxInfo())

print ("  %s, %s, %s - %s -> %s, %s" % 
        (getBoxInfo(), 
         getBoxInfo(), 
         getBoxInfo(), 
         getBoxInfo(), 
         getBoxInfo(), 
         getBoxInfo()))


Special rules for string literals. triple-quoted string


={============================================================================
|kt_dev_py_0001| py-base

{py-comment}
Any text preceded by the hash mark (pound sign) # is ignored by the Python
interpreter.

For multiline strings with line breaks, you can use `triple quotes`, either '''
or """:

c = """
This is a longer string that
spans multiple lines
"""

<ex> from dropbox

    def files_copy(self,
                   from_path,
                   to_path,
                   allow_shared_folder=False,
                   autorename=False,
                   allow_ownership_transfer=False):
        """
        Copy a file or folder to a different location in the user's Dropbox. If
        the source path is a folder all its contents will be copied.

        :param bool allow_shared_folder: If true, :meth:`files_copy` will copy
            contents in shared folder, otherwise
            ``RelocationError.cant_copy_shared_folder`` will be returned if
            ``from_path`` contains shared folder. This field is always true for
            :meth:`files_move`.
        :param bool autorename: If there's a conflict, have the Dropbox server
            try to autorename the file to avoid the conflict.
        :param bool allow_ownership_transfer: Allow moves by owner even if it
            would result in an ownership transfer for the content being moved.
            This does not apply to copies.
        :rtype: :class:`dropbox.files.Metadata`
        :raises: :class:`dropbox.exceptions.ApiError`

        If this raises, ApiError.reason is of type:
            :class:`dropbox.files.RelocationError`
        """


{py-pass}
`pass` is the "no-op" statement in Python. It can be used in blocks where no
action is to be taken; it is only required because Python uses whitespace to
delimit blocks.

It's common to use pass as a place-holder in code while working on a new piece
of functionality:

    def test_pass(self):
        value = 10

        if value < 0:
            result = 'negative'
        elif value == 0:
            # TODO: put something smart here
            pass
        else:
            result = 'positive'

        self.assertEqual(result, 'positive')

    # py-error compile error, when miss out `pass`
    # IndentationError: expected an indented block
    #
    # def test_pass_error(self):
    #     value = 10
    #
    #     if value < 0:
    #         result = 'negative'
    #     elif value == 0:
    #         # TODO: put something smart here
    #     else:
    #         result = 'positive'
    #
    #     self.assertEqual(result, 'positive')


{py-range}
`range` produces integers up to but not including the endpoint. A common use
of range is for iterating through sequences `by index`:

For very long ranges, it's recommended to use `xrange`, which takes the same
arguments as range but `returns an iterator` that generates integers one by
one rather than generating all of them up-front and storing them in a
(potentially very large) list. 

    def test_list_range(self):

        # py-range py-3
        coll = list(range(10))
        self.assertEqual(coll, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

        #
        coll2 = [0] * 4;
        coll3 = [5,6,7,8]

        self.assertEqual(coll2, [0, 0, 0, 0])

        for i in range(len(coll2)):
            coll2[i] = coll3[i]

        self.assertEqual(coll2, coll3)

        # xrange() is for py-2
        # # py-modulo
        # sum = 0
        # for i in list(xrange(10000)):

        #     # py-way no precedence between ops?
        #     if i % 3 == 0 or i % 5 == 0:
        #         sum += i

        # self.assertEqual(sum, 23331668)


{py-for}
remove an element of a list in the loop

  for script_name, priority, test_id, process in running_list:
    do something
    running_list.remove((script_name, priority, test_id, process))


{py-evaluate}

def total():
    return (elapsed, ret)

if __name__ == "main":
    ret = total( 1000, pow, 2, 1000)
    print 'time taken to pow is %d' % (ret.elapsed)

Why do not flag up error on ret.elapsed since there is no ret.elapsed
attribute?

Since python only cares code which runs. Even when have a totally nonsence def
in the code, there is no error since it's not used.


{py-iter}
In a nutshell, an object is `iterable` if it is either a physically stored
sequence in memory, or an object that generates one item at a time in the
context of an iteration operation - a sort of "virtual" sequence.


    def isiterable(self, object):
        try:
            iter(object)
            return True
        except TypeError:
            return False

    def test_iter(self):
        self.assertTrue(self.isiterable('string'))
        self.assertTrue(self.isiterable([1,2,3]))
        self.assertFalse(self.isiterable(4))


iter(object[, sentinel])

`Return an iterator object.` Without a second argument, object must be a
collection object which supports the `iteration protocol` (the __iter__()
    method), or it must support the sequence protocol (the __getitem__()
      method with integer arguments starting at 0). If it does not support
  either of those protocols, TypeError is `raised.`


A common case is writing a function that can accept any kind of sequence
(list, tuple, ndarray) or even an iterator. If it is not, convert it to be
one:

if not isinstance(x, list) and isiterable(x):
  x = list(x)


{py-is} {py-equal}
The first technique here, the == operator, tests whether the two referenced
objects have the `same values`; this is the method almost always used for
equality checks in Python.  

The second method, the `is operator`, instead tests for `object identity.` it
returns True only if both names point to the exact `same object`, so it is a
much `stronger form` of equality testing.


class TestReference(unittest.TestCase):

    def setUp(self):
        print("====================")
        print("[RUN] ", self._testMethodName)

    def test_reference(self):

        a = [1,2,3]
        b = a

        c = list(a)
        # *py-copy*
        cc = a[:]

        d = [1,2,3]

        # since py-reference py-is
        self.assertTrue(a is b)
        self.assertTrue(a == b)

        # c is a different list
        self.assertTrue(a is not c)

        # c and cc is a different list
        self.assertTrue(c is not cc)
        self.assertTrue(c == cc)

        # same value
        self.assertTrue(a == d)

        # but different object
        self.assertFalse(a is d)


{py-compare}

# returns 1 if greater is bigger than lesser
#        -1 is lesser  is bigger than greater
#         0 if they are equal
def compareVersions(greater, lesser):
    greater_array = [int(i) for i in greater.split('.')]
    lesser_array = [int(i) for i in lesser.split('.')]
    len_lesser = len(lesser_array)

    for i in range(len(greater_array)):
        try:
            if i >= len_lesser or greater_array[i] > lesser_array[i]:
                return 1
            elif greater_array[i] < lesser_array[i]:
                return -1
        except IndexError:
            # One of the versions strings is too short, assume they are the same
            print 'Warning unmatched version string lengths', greater, lesser                

    # if we get here they should be the same
    return 0


This is case code but is it necessary to do like this? No.

    def compare_version(self, lhs, rhs):
        # makes int list
        lhs = [int(i) for i in lhs.split('.')]
        rhs = [int(i) for i in rhs.split('.')]

        if lhs > rhs:
            return 1
        elif lhs < rhs:
            return -1
        else:
            return 0

Still necessary?

    # use string comparison itself
    def compare_version_2(self, lhs, rhs):

        if lhs > rhs:
            return 1
        elif lhs < rhs:
            return -1
        else:
            return 0

    def test_compare(self):
        version1 = '40.65.00'
        version2 = '40.66.00'
        version3 = '40.66.00'

        self.assertEqual(self.compare_version_1(version1, version2), -1)
        self.assertEqual(self.compare_version_1(version2, version1), 1)
        self.assertEqual(self.compare_version_1(version2, version3), 0)

        self.assertEqual(self.compare_version_2(version1, version2), -1)
        self.assertEqual(self.compare_version_2(version2, version1), 1)
        self.assertEqual(self.compare_version_2(version2, version3), 0)


More specifically, Python compares types as follows:

o Numbers are compared by relative magnitude, after conversion to the common
  highest type if needed.

o Strings are compared lexicographically (by the character set code point
      values returned by ord), and character by character until the end or
  first mismatch ("abc" < "ac").

o Lists and tuples are compared `by comparing each component` from left to
  right, and recursively for nested structures, until the end or first
  mismatch ([2] > [1, 2]).

o Sets are equal if both contain the same items (formally, if each is a subset
      of the other), and set relative magnitude comparisons apply subset and
  superset tests.

o Dictionaries compare as equal if their sorted (key, value) lists are equal.
  Relative magnitude comparisons `are not supported for dictionaries` in Python
  3.X, but they work in 2.X as though comparing sorted (key, value) lists.


Python 2.X and 3.X dictionary comparisons

In Python 2.X, dictionaries support magnitude comparisons, as though you were
comparing sorted key/value lists:

C:\code> c:\python27\python
>>> D1 = {'a':1, 'b':2}
>>> D2 = {'a':1, 'b':3}
>>> D1 == D2 # Dictionary equality: 2.X + 3.X
False
>>> D1 < D2 # Dictionary magnitude: 2.X only
True

comparisons for dictionaries are removed in Python 3.X because they incur too
much overhead when equality is desired (equality uses an optimized scheme in
3.X that doesn't literally compare sorted key/ value lists):

C:\code> c:\python33\python
>>> D1 = {'a':1, 'b':2}
>>> D2 = {'a':1, 'b':3}
>>> D1 == D2
False
>>> D1 < D2
TypeError: unorderable types: dict() < dict()

The alternative in 3.X is to either write loops to compare values by key, or
compare the sorted key/value lists manually—the items dictionary methods and
sorted built-in suffice:

>>> list(D1.items())
[('b', 2), ('a', 1)]

>>> sorted(D1.items())
[('a', 1), ('b', 2)]

>>> sorted(D1.items()) < sorted(D2.items()) # Magnitude test in 3.X
True

>>> sorted(D1.items()) > sorted(D2.items())
False

This takes more code, but in practice, most programs requiring this behavior
will develop more efficient ways to compare data in dictionaries than either
this workaround or the original behavior in Python 2.X.


{py-refcount}
Really, is simply compares the pointers that implement references, and it
serves as a way to detect shared references in your code if needed.

>>> import sys
>>> sys.getrefcount(1) # 647 pointers to this shared piece of memory
647


{py-membership}

checking whether a list contains a value is a lot `slower` than dicts and sets
as Python makes a linear scan across the values of the list, whereas the
others (based on hash tables) can make the check in constant time.


{py-unpack}
Unpacking actually works with any object that happens to be iterable, not just
tuples or lists.

class TestUnpack(unittest.TestCase):
    
    def setUp(self):
        print("====================")
        print("[RUN] ", self._testMethodName)

    def test_unpack(self):

        coll1 = (4,5,6)
        a, b, c = coll1

        self.assertEqual(a, 4)
        self.assertEqual(b, 5)
        self.assertEqual(c, 6)

        # py-swap, uses temporary tuple?

        # Using this functionality it's easy to swap `variable names`, a task
        # which in many languages might look like:
        # 
        # tmp = a 
        # a = b 
        # b = tmp

        a, b = b, a

        self.assertEqual(a, 5)
        self.assertEqual(b, 4)

        # py-iterator

        coll2 = (4,5,6)
        result = []
        for a in coll2:
            result.append(a)
        self.assertEqual(result, [4,5,6])

        coll3 = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
        result = []
        for a, b, c in coll3:
            result.append(a)
        self.assertEqual(result, [1,4,7])

        # PYCB3, Chapter 1: Data Structures and Algorithms
        # 1.1. Unpacking a Sequence into Separate Variables
        #
        # The only requirement is that the number of variables and structure
        # match the sequence.

        # py-error
        #    for a, b, c, d in coll3:
        # ValueError: need more than 3 values to unpack

        with self.assertRaises(ValueError):
            coll3 = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
            for a, b, c, d in coll3:
                print(a)


        # When unpacking, you may sometimes want to discard certain values.
        # Python has no special syntax for this, but you can often just pick a
        # throwaway variable name for it.               

        data = [ 'ACME', 50, 91.1, (2012, 12, 21) ]
        _, share, price, _ = data

        self.assertEqual(share, 50)
        self.assertEqual(price, 91.1)


    # PYCB3, Chapter 1: Data Structures and Algorithms
    # 1.2. Unpacking Elements from Iterables of Arbitrary Length
    #
    # Problem
    # You need to unpack N elements from an iterable, but the iterable may be
    # longer than N elements, causing a "too many values to unpack" exception.
    #
    # *py-3*
    # starred variable will always be a list, *py-list*

    @staticmethod
    def do_foo(x, y):
        print('foo', x, y)

    @staticmethod
    def do_bar(s):
        print('bar', s)

    def test_unpack_star_expression(self):

        record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212')
        name, email, *phone_numbers = record

        self.assertEqual(name, 'Dave')
        self.assertEqual(email, 'dave@example.com')
        self.assertEqual(phone_numbers, ['773-555-1212', '847-555-1212'])

        *trailing, current = [10, 8, 7, 1, 9, 5, 10, 3]
        self.assertEqual(trailing, [10, 8, 7, 1, 9, 5, 10])


        # can be especially useful when iterating over a sequence of tuples of
        # varying length.

        records = [ 
                ('foo', 1, 2), 
                ('bar', 'hello'), 
                ('foo', 3, 4) 
                ]

        for tag, *args in records:
            if tag == 'foo':
                TestUnpack.do_foo(*args)
            elif tag == 'bar':
                TestUnpack.do_bar(*args)


        # py-string processing

        line = 'nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false'
        uname, *fields, homedir, sh = line.split(':')
        self.assertEqual(uname, 'nobody')
        self.assertEqual(homedir, '/var/empty')
        self.assertEqual(sh, '/usr/bin/false')
    

        # py-ignore and py-star

        record = ('ACME', 50, 123.45, (12, 18, 2012))
        name, *_, (*_, year) = record
        self.assertEqual(name, 'ACME')
        self.assertEqual(year, 2012)


={============================================================================
|kt_dev_py_0001| py-type

<py-object> everything-is-object

An important characteristic of the Python language is the consistency of its
object model. 

Every number, string, data structure, function, class, module, and so on
exists in the Python interpreter in its own "box" which is referred to as a
`Python object` Each object has an associated `type` (for example, string or
    function) and internal `data`. In practice this makes the language very
flexible, as even functions can be treated just like any other object.


<py-reference>
When assigning a variable (or name) in Python, you are creating a `reference` to
the object on the right hand side of the equals sign.

In some languages, this assignment would cause the data [1, 2, 3] to be
copied. In Python, a and b actually now refer to the same object, the original
list

class TestType(unittest.TestCase):

    def test_reference_semantic(self):
        a = [1,2,3,4]
        b = a
        a.append(5)
        self.assertEqual(b, [1,2,3,4,5])

Assignment is also referred to as `binding`, as we are binding a name to an
object. Variables names that have been assigned may occasionally be referred
to as bound variables.

When you pass objects as arguments to a function, you are only passing
references; no copying occurs.

Understanding the semantics of references in Python and when, how, and why
data is copied is especially critical when working with larger data sets in
Python.


<py-reference-do-not-have-type>
In contrast with many compiled languages, such as Java and C++, 
`object references` in Python `have no type` associated with them. There is no
problem with the following.

Technically speaking, objects have more structure than just enough space to
represent their values. Each object also has two standard header fields: 

  o a `type designator` used to mark the type of the object

  o a `reference counter`


    # variable name, that is reference, do not have type

    def test_reference_no_type(self):
        a = 5
        self.assertEqual(type(a), type(int()))

        a = 'foo'
        self.assertEqual(type(a), type(str()))

        a = [1,2,3]
        self.assertEqual(type(a), type(list()))


Variables are names for objects within a particular namespace; object has a
type and the type information is stored in the `object itself` 

Some observers might hastily conclude that Python `is not a typed language`
This is `not true`; consider this example:

>>> '5'+5
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
`TypeError`: cannot concatenate 'str' and 'int' objects

In some languages, such as Visual Basic, the string '5' might get implicitly
  converted (or casted) to an integer, thus yielding 10. Yet in other
  languages, such as JavaScript, the integer 5 might be casted to a string,
  yielding the concatenated string '55'. 

In this regard Python is considered a strongly-typed language, which means
that every object has a specific type (or class), and implicit conversions
will occur only in `certain obvious circumstances`, such as the following:

>>> a = 4.5
>>> b = 2
>>> print "a is %s, b is %s" % (type(a), type(b))
a is <type 'float'>, b is <type 'int'>
>>> a/b
2.25


Knowing the type of an object is important and can check that an object is an
instance of a particular type using the `isinstance` function:

>>> a = 5
>>> isinstance(a,int)
True
>>> b = 4.5
>>> isinstance(b,int)
False
>>> isinstance(b,float)
True

isinstance can accept a tuple of types if you want to check that an object's
type is among those present in the tuple:

>>> isinstance(b,(int,float))
True


<py-type-dynamic>

o a dynamically typed scripting language

Variable creation *py-assign*

A variable (i.e., name), like a, is created when your code first `assigns` it a
value.

Variable types

A variable never has any type information or constraints associated with it.
The notion of type `lives with objects, not names.` Variables refer,
reference, to any type of objects and are `never declared` ahead of time.


<py-memory-garbage-collection>

Objects Are Garbage-Collected

Internally, Python accomplishes this feat by keeping a counter in every object
that keeps track of the number of references currently pointing to that
object. As soon as (and exactly when) this counter drops to zero, the object’s
memory space is automatically reclaimed.

For more details on Python's cycle detector, see the documentation for the
`gc` module in Python's library manual.

In practice, this eliminates a substantial amount of bookkeeping code required
in lower-level languages such as C and C++.

For more details on Python’s cycle detector, see the documentation for the gc
module in Python’s library manual.

Also note that this chapter’s description of Python’s garbage collector
applies to the standard Python (a.k.a. CPython) only;


<py-types> <py-coll>

More formally, there are three major type (and operation) categories in Python
that have this generic nature:

`Numbers` (integer, floating-point, decimal, fraction, others)
Support addition, multiplication, etc.

`Sequences` (strings, lists, tuples)
Support indexing, slicing, concatenation, etc.

`Mappings` (dictionaries)
Support indexing by key, etc.

`sets` are something of a category unto themselves because sets are unordered
and do not map keys to values, they are neither sequence nor mapping types

The major core types in Python break down as follows:

Immutables (numbers, strings, `tuples`, frozensets)
None of the object types in the immutable category support in-place changes,
though we can always run expressions to make new objects and assign their
  results to variables as needed.

Mutables (lists, dictionaries, sets, bytearray)
Conversely, the mutable types can always be changed in place with operations
that do not create new objects. Although such objects can be copied, in-place
changes support direct modification.


Table A-2. Standard Python Scalar Types

*py-none*
`None`    
The Python "null" value (only one instance of the None object exists)

`str` 
String type. ASCII-valued only in Python 2.x and Unicode in Python 3

unicode 
Unicode string type

float 
Double-precision (64-bit) floating point number. Note there is no separate
double type.

*py-true*
True and False are just customized 1 and 0

bool 
A `True` or `False` value

`int` 
Signed integer with maximum value determined by the platform.

long 
Arbitrary precision signed integer. Large int values are automatically
converted to long.


<py-mutable>

    def test_mutable(self):

        # no shared reference since they are immutable
        a = 3
        b = a
        a = a + 2
        self.assertEqual(a, 5)
        self.assertEqual(b, 3)

the last assignment sets a to a completely different object, which is the
result of the + expression. So does not change b as a side effect. As
introduced in Chapter 4, integers are immutable and thus can never be changed
in place. Like cxx-const cxx-temporary

        # shared reference since they are mutable
        coll1 = [2,3,4]
        coll2 = coll1
        self.assertEqual(coll1, [2,3,4])
        self.assertEqual(coll2, [2,3,4])

        # coll1 is immutable and no shared reference
        coll1 = 24
        self.assertEqual(coll1, 24)
        self.assertEqual(coll2, [2,3,4])

This behavior only occurs for mutable objects that support in-place changes,
and is usually what you want, but you should be aware of how it works, so that
it’s expected.

*py-copy*
It’s also just the default: if you don’t want such behavior, you can request
that Python copy objects instead of making references.

    def test_copy(self):
        coll1 = [2,3,4]
        coll2 = coll1[:]
        coll3 = list(coll1)
        coll1[0] = 24

        self.assertEqual(coll1, [24,3,4])
        self.assertEqual(coll2, [2,3,4])
        self.assertEqual(coll3, [2,3,4])


={============================================================================
|kt_dev_py_0001| py-attribute

Objects in Python typically have `both attributes:` 

o other Python objects stored "inside" the object

o `methods`, functions associated with an object which can have access to the
  object's internal data.

Both of them are accessed via the syntax `obj.attribute_name` 

# 944 | Chapter 31: Designing with Classes

In fact, attributes are all “public” and “virtual,” in C++ terms; they’re all
accessible everywhere and are looked up dynamically at runtime. As a scripting
language, Python is more about enabling than restricting.


Attributes and methods can also be accessed by name using the `getattr`
function:

class TestAttribute(unittest.TestCase):

    # [RUN]  test_attribute
    # <type 'str'>
    # <built-in method split of str object at 0x7fa77a489a80>

    def test_attribute(self):

        a = 'foo'
        print(type(a))
        print(getattr(a, 'split'))


While we will not extensively use the functions getattr and related functions
`hasattr` and setattr in this book, they can be used very effectively to write
generic, reusable code.


={============================================================================
|kt_dev_py_0001| py-none

LYP5, 9, Tuples, Files, and Everything Else

The Meaning of True and False in Python

In Python, as in most programming languages, an integer 0 represents false,
and an integer 1 represents true. In addition, Python recognizes any empty
  data structure as false and any nonempty data structure as true.

More generally, the notions of true and false are intrinsic properties of
every object in Python; 

each `object is either true or false`, as follows:

o Any nonzero number or `nonempty object is true.`
  o Numbers are false if zero, and true otherwise.
  o Other objects are false `if empty, and true otherwise.` *py-empty*


As one application, because objects are true or false themselves, it’s common
to see Python programmers code tests like if X:, which, assuming X is a
string, is the same as if X != '':. In other words, you can test the object
itself to see if it contains anything, instead of comparing it to an empty,
and therefore false, object of the same type


The None object

o `None are considered false`

Python also provides a special object called None, which is always considered
to be `false`. it is the only value of a special data type in Python and
typically serves as an empty placeholder (much like a NULL pointer in C).


    def test_none_empty(self):

        coll1 = ''

        if coll1:
            result = True
        else:
            result = False

        self.assertEqual(result, False)

        coll2 = None

        if coll2:
            result = True
        else:
            result = False

        self.assertEqual(result, False)

        coll1 = dict()

        if coll1:
            result = True
        else:
            result = False

        self.assertEqual(result, False)

        coll1['a'] = (1, 2)

        if coll1:
            result = True
        else:
            result = False

        self.assertEqual(result, True)


<py-way> *py-list* *py-convention*
For lists you cannot assign to an offset unless that offset already exists. To
preallocate a 100-item list such that you can add to any of the 100 offsets:

>>> L = [None] * 100
>>>
>>> L
[None, None, None, None, None, None, None, ... ]

This doesn't limit the size of the list (it can still grow and shrink later),
but simply presets an initial size to allow for future index assignments.  
  
You could initialize a list with zeros the same way, of course, but best
practice dictates using None if the type of the list’s contents is variable or
not yet known.

Keep in mind that None does not mean “undefined.” That is, None is something,
not nothing (despite its name!); it is a real object and a real piece of
memory that is created and given a built-in name by Python itself. 
  
Watch for other uses of this special object later in the book; it is also the
default return value of functions that don’t exit by running into a return
statement with a result value.

`None` 
The Python "null" value (only one instance of the None object exists)


={============================================================================
|kt_dev_py_0001| py-gotchas

<default-mutable-objects>

Defaults and Mutable Objects, Chapter 21: The Benchmarking Interlude

>>> def saver(x=[]):    # Saves away a list object
x.append(1)             # Changes same object each time!
print(x)

>>> saver([2])          # Default not used
[2, 1]

>>> saver()             # Default used
[1]
>>> saver()             # Grows on each call!
[1, 1]
>>> saver()
[1, 1, 1]


<return-none-from-function>

LPY5, 11 Expression Statements

Calling an in-place change operation such as append, sort, or reverse on a
list always changes the list in place, but these methods do not return the
list they have changed; instead, `they return the None object.`

>>> L = [1, 2]
>>> L.append(3)         # Append is an in-place change
>>> L
[1, 2, 3]

However, it’s not unusual for Python newcomers to code such an operation as an
assignment statement instead, intending to assign L to the larger list:

>>> L = L.append(4)     # But append returns None, not L
>>> print(L)            # So we lose our list!
None


A more devious example of this pops up in Python 2.X code when trying to step
through dictionary items in a sorted fashion. It’s fairly common to see code
like 

for k in D.keys().sort():
  
But because the sort method returns None, the loop fails because it is
ultimately a loop over None (a nonsequence). 
                           
This fails even sooner in Python 3.X, because dictionary keys are views, not
lists! 

To code this correctly, either use the newer sorted built-in function, which
returns the sorted list, or split the method calls out to statements: 

Ks = list(D.keys())
Ks.sort()
for k in Ks:  

This, by the way, is one case where you may still want to call the keys method
  explicitly for looping, instead of relying on the dictionary
  iterators—iterators do not sort.


={============================================================================
|kt_dev_py_0001| py-numeric

LPY5, 5 Numeric Types

integers have unlimited precision and can grow to have as many digits as your
memory space allows.

*py-to-int*
int(str, base) converts a runtime string to an integer per a given base.


{py-division}

<py-numeric>
The primary Python types for numbers are `int` and `float`. 

The size of the integer which can be stored as an int is dependent on your
platform (whether 32 or 64-bit), but Python will transparently convert a very
large integer to `long`, which can store arbitrarily large integers.

Floating point numbers are represented with the Python float type. Under the
hood each one is a double-precision (64 bits) value.

In Python 3, integer division not resulting in a whole number will always
yield a floating point number:

In Python 2.7 and below (which some readers will likely be using), you can
enable this behavior by default by putting the following cryptic-looking
statement at the top of your module:

from __future__ import division

Without this in place, you can always explicitly convert the denominator into
a floating point number:

    def test_integer_division(self):

        # fpr *py-2*
        # self.assertEqual(3 / 2, 1)
        # for *py-3*
        self.assertEqual(3 / 2, 1.5)
        self.assertEqual(3 / float(2), 1.5)

        # self.assertEqual(21600/90000, 0)
        self.assertEqual(21600/90000, 0.24)
        self.assertEqual(21600/float(90000), 0.24)

        # SyntaxError: from __future__ imports must occur at the beginning of the file
        # from __future__ import division
        # self.assertEqual(3 / 2, 1.5)

To get C-style integer division (which drops the fractional part if the result
is not a whole number), use the floor division operator //:

In [286]: 3 // 2
Out[286]: 1

The floor division is to round `down`, not strictly truncate, and this matters
for negatives.

>>> import math
>>> math.floor(2.5) # Closest number below value
2
>>> math.floor(-2.5)
-3
>>> math.trunc(2.5) # Truncate fractional part (toward zero)
2
>>> math.trunc(-2.5)
-2


{py-chained-comparison} *py-way*

Chained comparisons: range tests

    def test_chained_comparison(self):
        a = 10
        b = 11
        c = 12

        self.assertEqual(a < b < c, True)


{py-random}
The standard library random module must be imported as well. This module
provides an array of tools, for tasks such as picking a random floating-point
number between 0 and 1, and selecting a random integer between two numbers:

    # [RUN]  test_random
    # 0.146921784216
    # 5
    # 5
    # Meaning of Life
    # Meaning of Life
    # ['clubs', 'diamonds', 'spades', 'hearts']
    # ['diamonds', 'clubs', 'hearts', 'spades']

    def test_random(self):
        import random
        print(random.random())

        print(random.randint(1, 10))
        print(random.randint(1, 10))

        coll1 = ['Life of Brian', 'Holy Grail', 'Meaning of Life']
        print(random.choice(coll1))
        print(random.choice(coll1))

        coll2 = ['hearts', 'clubs', 'diamonds', 'spades']
        random.shuffle(coll2)
        print(coll2)
        random.shuffle(coll2)
        print(coll2)

<py-min> *py-list*
    def test_min(self):
        coll = ['hearts', 'clubs', 'diamonds', 'spades']
        result = min(coll)
        self.assertEqual(result, 'clubs')


={============================================================================
|kt_dev_py_0001| py-string
  
LPY5, 7, String Fundamentals

Every string operation is defined to produce a new string as its result,
because strings are `immutable` 

<py-string-conversion>
String Conversion Tools

# Python 3.X
>>> "42" + 1
TypeError: Can't convert 'int' object to str implicitly

# Python 2.X
>>> "42" + 1
TypeError: cannot concatenate 'str' and 'int' objects

*py-to-int* *py-to-str*
Convert from/to string and the `str` type name.

    def test_string_conversion(self):
        self.assertEqual(int('42'), 42)
        self.assertEqual(str(42), '42')
        self.assertEqual(repr(42), '42')

        # binary to int
        self.assertEqual(int(0b1101), 13)

        # string to binary
        self.assertEqual(int('1101', 2), 13)

        # int to binary
        self.assertEqual(bin(13), '0b1101')


The repr function (and the older backquotes expression, removed in Python 3.X)
also `converts an object to its string representation`


Character code conversions

The built-in `ord` returns the actual binary value used to represent the
corresponding character in memory. The chr function performs the inverse
operation, taking an integer code and converting it to the corresponding
character:

>>> ord('s')
115
>>> chr(115)
's'


<py-string-quote> *py-convention*
Can write string literal using either single quotes ' or double quotes ":
Most programmers prefer single quotes


https://docs.python.org/2/library/string.html

7.1.6. Deprecated string functions

The following list of functions are also defined as methods of string and
Unicode objects; see section String Methods for more information on those. 

You should consider these functions `as deprecated`, although they will not be
removed until Python 3. The functions defined in this module are:

<py-string-ops>
https://docs.python.org/2/library/stdtypes.html?highlight=endswith#str.endswith

5.6.1. String Methods

str.endswith(suffix[, start[, end]])

    Return True if the string ends with the specified suffix, otherwise return
    False. suffix can also be a tuple of suffixes to look for. With optional
    start, test beginning at that position. With optional end, stop comparing
    at that position.

    Changed in version 2.5: Accept tuples as suffix.

*py-str-title*
str.title()

    Return a titlecased version of the string where words start with an
    uppercase character and the remaining characters are lowercase.


str.split([sep[, maxsplit]])

    Return a list of the words in the string, using sep as the delimiter
    string. If maxsplit is given, at most maxsplit splits are done (thus, the
        list will have at most maxsplit+1 elements). If maxsplit is not
    specified or -1, then there is no limit on the number of splits (all
        possible splits are made).

    If sep is given, consecutive delimiters are not grouped together and are
    deemed to delimit empty strings (for example, '1,,2'.split(',') returns
        ['1', '', '2']). 
    
    The sep argument may consist of multiple characters (for example,
        '1<>2<>3'.split('<>') returns ['1', '2', '3']). 
    
    Splitting an empty string with a specified separator returns [''].

    If sep is not specified or is None, a different splitting algorithm is
    applied: runs of consecutive whitespace are regarded as a single
    separator, and the result will contain no empty strings at the start or
    end if the string has leading or trailing whitespace. Consequently,
                        splitting an empty string or a string consisting of
                          just whitespace with a None separator returns [].

    For example, ' 1  2   3  '.split() returns ['1', '2', '3'], and '  1  2
    3  '.split(None, 1) returns ['1', '2   3  '].

    p = re.compile (pattern)
    lines = stdOut.split ("\n")
    for line in lines:
        parts = line.split ("\t")
        if len (parts) == 2:
            tag = parts[1].strip ()
            if p.match (tag):
                if not tag.endswith ("{}"):
                    tagsAux.append (tag)

    def test_string_split(self):
        self.assertEqual(' 1 2  3   '.split(), ['1', '2', '3'])
        self.assertEqual(' 1 2  3   '.split(None, 1), ['1', '2  3   '])

        # Delimiters can be longer than a single character, too:

        line = "i'mSPAMaSPAMlumberjack"
        self.assertEqual(line.split("SPAM"), ["i'm", 'a', 'lumberjack'])

        # see how delimeter works
        i = str(11)
        self.assertEqual(i.split(str(1)), ['','',''])

        i = str(12)
        self.assertEqual(i.split(str(1)), ['','2'])


str.rstrip([chars])

Return a `copy` of the string with trailing characters removed. 
    
The chars argument is a string specifying the `set of characters` to be
removed. If omitted or None, the chars argument defaults to removing
whitespace. The chars argument is not a suffix; rather, all combinations of
its values are stripped:

    def test_string_rstrip(self):
        self.assertEqual('   spacious   '.rstrip(), '   spacious')

        coll = '   spacious   '
        self.assertEqual(coll[:-1], '   spacious  ')

        self.assertEqual('mississippi'.rstrip('ipz'), 'mississ')


str.join(iterable)

`join` puts the strings in a list (or other iterable) together, with the
delimiter between list items; Return a string which is the concatenation of
the strings in the iterable.  The separator between elements is the string
providing this method.

    def test_sting_join(self):
        coll = ['pay', 'job', 'name']
        self.assertEqual(','.join(coll), 'pay,job,name')
        self.assertEqual('_'.join(coll), 'pay_job_name')
        self.assertEqual('*'.join(coll), 'pay*job*name')
        self.assertEqual('_'.join('pay'), 'p_a_y')


str.find() <py-string-find>

The find method returns the `offset` where the substring appears 
(by default, searching from the front), or `−1 if it is not found.`

As we saw earlier, it's a substring search operation just like the in
expression, but find returns the position of a located substring.


str.replace()

    def test_string_replace(self):

        coll = 'xxxxSPAMxxxxSPAMxxxx'

        # replace all
        self.assertEqual(coll.replace('SPAM', 'EGGS'),
                'xxxxEGGSxxxxEGGSxxxx')

        # replace one
        self.assertEqual(coll.replace('SPAM', 'EGGS', 1),
                'xxxxEGGSxxxxSPAMxxxx')


<perfoemance>
If you have to apply many changes to a very large string, you might be able to
improve your script's performance by converting the string to an object that
does support in-place changes:

    def test_string_performance(self):

        # to list
        coll = 'spammy'
        l = list(coll)

        l[4] = l[3] = 'x'

        # to string back
        coll = ''.join(l)
        self.assertEqual(coll, 'spaxxy')


<string-method-string-module>
The Original string Module's Functions (Gone in 3.X)

The history of Python's string methods is somewhat convoluted. For roughly the
first decade of its existence, Python provided a standard library module
called `string` that contained functions that largely mirrored the current set
of string object methods. 

By popular demand, in Python 2.0 these functions were made available as
methods of string objects. Because so many people had written so much code
that relied on the original string module, however, it was retained for
backward compatibility.

Today, you should use only string methods, not the original string module. In
fact, the original module call forms of today's string methods have been
removed completely from Python 3.X, and you should not use them in new code in
either 2.X or 3.X.


{py-string-raw} *regex-basic*
raw string literal that turns off the backslash escape mechanism. Such
literals start with the letter r and are useful for strings like directory
paths on Windows (e.g., r'C:\text\new').


={============================================================================
|kt_dev_py_0001| py-print

*py-3*
print is really a function call in Python 3.X, but not in 2.X, so the
parentheses here are required in 3.X only

print(*objects, sep=' ', end='\n', file=sys.stdout, flush=False)

Print objects to the text stream file, separated by sep and followed by end.
sep, end and file, if present, `must be given as keyword arguments.` 

All non-keyword arguments are converted to strings like str() does and written
to the stream, separated by sep and followed by end. Both sep and end must be
strings; they can also be None, which means to use the default values. If no
objects are given, print() will just write end. The file argument must be an
object with a write(string) method; if it is not present or None, sys.stdout
will be used. 
  
Since printed arguments are converted to text strings, print() cannot be used
with binary mode file objects. For these, use file.write(...) instead.
Whether output is buffered is usually determined by file, but if the flush
keyword argument is true, the stream is forcibly flushed.  Changed in version
3.3: Added the flush keyword argument.


{py-print-formatting} *py-string-format*

String Formatting Expressions

string formatting allows us to perform multiple type-specific substitutions on
a string in a single step in two flavors:

o expression, '...%s...' % (values)

The original technique available since Python's inception, this form is based
upon the C language's "printf" model, and sees widespread use in much existing
code.

o method, '...{}...'.format(values)

A newer technique added in Python 2.6 and 3.0, this form is derived in part
from a same-named tool in C#/.NET, and overlaps with string formatting
expression functionality.


As every type of object can be converted to a string, every object type works
with the %s conversion code. Because of this, unless you will be doing some
special formatting, %s is often the only code you need to remember for the
formatting expression.

Again, keep in mind that formatting always makes a new string, rather than
changing the string on the left.

<ex>

    # [RUN]  test_print_function
    # item in the list: [1, 2, 3, 4]
    # [1, 2, 3, 4]
    # [1, 2, 3, 4]
    # 10000.00
    # 10000.00
    # 10000.00
    # spam, eggs, and SPAM!
    # spam, eggs, and SPAM!
    # spam, eggs, and SPAM!
    # 100, 40, 1000000
    # 42 -- 3.14159 -- [1, 2, 3]

    def test_print_function(self):
        item = [1,2,3,4]

        print 'item in the list: %s' % item
        print item
        print(item)

        pay = 10000
        print('%.2f' % pay)
        print('{0:.2f}'.format(pay))

        # numbers are optional
        print('{:.2f}'.format(pay))

        print '%s, eggs, and %s' % ('spam', 'SPAM!') 

        print '{0}, eggs, and {1}'.format('spam', 'SPAM!') 

        # Numbers optional (2.7+, 3.1+)
        print '{}, eggs, and {}'.format('spam', 'SPAM!') 

        print '{0:o}, {1:x}, {2:b}'.format(64, 64, 64)

        print '%s -- %s -- %s' % (42, 3.14159, [1, 2, 3]) 


    # [RUN]  test_print_multiple_lines
    # this is lien one
    #             this is line two
    #             this is line three
    # this is lien one
    # this is line two
    # this is line three

    def test_print_multiple_lines(self):

        print("""this is lien one
            this is line two
            this is line three""")

        print("""this is lien one
            \rthis is line two
            \rthis is line three""")


={============================================================================
|kt_dev_py_0001| py-eval

    # py-eval
    # list or string? where `eval` makes differnece

    def test_base_eval(self):
        # Q: why cannot use multiple lines?

        coll = "[[['AMS'], ['AMS']], [['PROX'], ['darwin']], [['PPCM_CF'], ['ppcm', 'ppcm_core']]]"
        self.assertEqual(type(coll), type(str()))

        coll = eval("[[['AMS'], ['AMS']], [['PROX'], ['darwin']], [['PPCM_CF'], ['ppcm', 'ppcm_core']]]")
        self.assertEqual(type(coll), type(list()))


={============================================================================
|kt_dev_py_0001| py-tuple

LYP5, 9, Tuples, Files, and Everything Else

A tuple is a one-dimensional, `fixed-length`, `immutable` sequence of Python
objects. 


Tuple syntax peculiarities: Commas and parentheses

Because parentheses can also enclose expressions, you need to do something
special to tell Python when a single object in parentheses is a tuple object
and not a simple expression.

The syntax (...) is used for tuples and expression grouping, as well as
generator expressions; a form of list comprehension that produces results on
demand, instead of building a result list. 

class TestTuple(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN] ", self._testMethodName

    def test_tuple_one_item(self):

        # one item tuple
        coll = (40,)

        # group expression, integer
        x = (40)

        self.assertEqual(type(coll), type((40,50)))
        self.assertEqual(x, 40)

    def test_tuple_create(self):

        # use comma-separated sequence to create
        coll1 = 4,5,6
        coll2 = (4,5,6)
        self.assertEqual(coll1, coll2)

        # nested tuple
        coll3 = (4,5,6),(7,8)
        self.assertEqual(coll3, ((4, 5, 6), (7, 8)))

        # py-convert
        # any sequence or iterator can be converted
        coll4 = tuple([4,5,6])
        self.assertEqual(coll4, coll1)

        coll5 = tuple('string')
        self.assertEqual(coll5, ('s', 't', 'r', 'i', 'n', 'g'))

        # py-access
        self.assertEqual(coll5[0], 's')
        self.assertEqual(coll5[1], 't')
        self.assertEqual(coll5[2], 'r')

        # operator+()
        coll6 = coll2 + coll3 + coll5
        self.assertEqual(coll6, 
                (4, 5, 6, (4, 5, 6), (7, 8), 's', 't', 'r', 'i', 'n', 'g'))


    # ======================================================================
    # ERROR: test_tuple_immutable (__main__.TestTuple)
    # ----------------------------------------------------------------------
    # Traceback (most recent call last):
    #   File "pycore.py", line 278, in test_tuple_immutable
    #     coll1[1] = 7
    # TypeError: 'tuple' object does not support item assignment

    def test_tuple_immutable(self):

        coll1 = (4,5,6)
        coll1[1] = 7
        self.assertEqual(coll1, coll2)


<py-tuple-op>

    def test_tuple_op(self):

        coll1 = 1,2,2,3,4,2
        self.assertEqual(coll1.count(2), 3) 

        # py-membership
        coll2 = ('foo', 'bar', 'baz')
        result = 'bar' in coll2
        self.assertEqual(result, True)


={============================================================================
|kt_dev_py_0001| py-list

In contrast with tuples, lists are `variable-length` and `mutable`. They can
be defined using `square brackets []` or using the `list` type function:

Lists and tuples are semantically similar as one-dimensional sequences of
objects and thus can be used interchangeably in many functions.

    # convert to list
    def test_list_ctor(self):
        coll1 = (1,2,3,4)
        coll2 = list(coll1)

        self.assertEqual(type(coll1), type((1,)))
        self.assertEqual(type(coll2), type([1]))


Because the length of the sequence being assigned does not have to match the
  length of the slice being assigned to, slice assignment can be used to
  replace (by overwriting), expand (by inserting), or shrink (by deleting) the
  subject list. 

It's a powerful operation, but frankly, one that you may not see very often in
practice. There are often `more straightforward and mnemonic ways` to replace,
  insert, and delete (concatenation, and the insert, pop, and remove list
      methods, for example), which Python programmers tend to prefer in
    practice.

    def test_slice_and_index(self):
        coll = [7,2,3,7,5,6,0,1]

        # py-list-insert since assign
        coll[3:4] = [6,3]
        self.assertEqual(coll, [7, 2, 3, 6, 3, 5, 6, 0, 1])

        # py-list-delete
        coll[3:4] = []
        self.assertEqual(coll, [7, 2, 3, 3, 5, 6, 0, 1])


<py-list-delete> *py-del*
Other common list operations

Because lists are mutable, you can use the `del` statement to delete an item or
section in place:

    def test_list_delete(self):

        coll = ['spam', 'eggs', 'ham', 'toast']

        # delete one item
        del coll[0]
        self.assertEqual(coll, ['eggs', 'ham', 'toast'])

        # delete an entire section
        del coll[1:]
        self.assertEqual(coll, ['eggs'])

        # slice can do the same
        coll2 = ['spam', 'eggs', 'ham', 'toast']

        coll2[:1] = []
        self.assertEqual(coll2, ['eggs', 'ham', 'toast'])

        coll2[1:] = []
        self.assertEqual(coll2, ['eggs'])


<py-list-insert-py-list-append>
Append to the end of the list with the `append` method and `insert` an element
at a specific location in the list:

insert is computationally `expensive` compared with append as references to
subsequent elements have to be shifted internally to make room for the new
element.

    def test_list_ops(self):

        coll = ['spam', 'eggs', 'ham', 'toast']

        coll.append('foo')
        self.assertEqual(coll, 
                ['spam', 'eggs', 'ham', 'toast', 'foo'])

        coll.insert(1, 'bean')
        self.assertEqual(coll, 
                ['spam', 'bean', 'eggs', 'ham', 'toast', 'foo'])

        # py-list-pop
        # `pop` removes and returns an element at a particular index:
        # Remove the item at the given position in the list, and return it. If
        # no index is specified, a.pop() removes and returns the last item in
        # the list.

        coll = ['spam', 'eggs', 'ham', 'toast']
        coll.pop(2)
        self.assertEqual(coll, 
                ['spam', 'eggs', 'toast'])

        coll.pop()
        self.assertEqual(coll, 
                ['spam', 'eggs'])

        # py-list-remove
        # search the first and remove it

        coll = ['foo', 'red', 'red', 'red', 'baz', 'dwarf']
        coll.remove('red')
        self.assertEqual(coll, 
                ['foo', 'red', 'red', 'baz', 'dwarf'])

        # py-list-extend
        coll = ['foo', 'red']
        coll.extend(['red', 'baz', 'dwarf'])
        self.assertEqual(coll, 
                ['foo', 'red', 'red', 'baz', 'dwarf'])


{py-list-py-membership}

checking whether a list contains a value is a lot `slower` than dicts and sets
as Python makes a linear scan across the values of the list, whereas the
others (based on hash tables) can make the check in constant time.

<py-liust-concatenation>
Append multiple elements to it using the `extend` method. List concatenation
is a compartively `expensive` operation since a `new list` must be created and
the objects copied over. Using extend is usually preferable. note that
`extend` adds many items, and `append` adds one.

    def test_list_concatenate(self):

        coll1 = [4, None, 'foo'] + [7,8,(2,3)]
        self.assertEqual(coll1, 
            [4, None, 'foo', 7, 8, (2, 3)])

        # py-list-extend
        coll2 = [4, None, 'foo']
        coll2.extend([7,8,(2,3)])
        self.assertEqual(coll2, 
            [4, None, 'foo', 7, 8, (2, 3)])


<py-list-sort> <py-list-reverse>
A list can be sorted `in-place` (without creating a new object) by calling its
`sort` function:

note that *py-tuple* do not support sort

>>> tup = 2,4,3,5,7,6
>>> tup
(2, 4, 3, 5, 7, 6)

>>> tup.sort()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'tuple' object has no attribute 'sort'

*py-keyword-argument*
Modify sort behavior by passing in `keyword arguments` - a special
"name=value" syntax in function calls that specifies passing by name and is
often used for giving configuration options.

pass a secondary `sort key`, i.e. a `function` that produces a value to use to
sort the objects.

    def test_list_sort(self):

        # case matters
        L = ['abc', 'ABD', 'aBe']
        L.sort()
        self.assertEqual(L, ['ABD', 'aBe', 'abc'])

        # normalize to lowercase
        L = ['abc', 'ABD', 'aBe']
        L.sort(key=str.lower)
        self.assertEqual(L, ['abc', 'ABD', 'aBe'])

        # py-reverse
        # both sort() and reverse() methods modify the list directly.
        # normalize to lowercase and reverse
        L = ['abc', 'ABD', 'aBe']
        L.sort(key=str.lower, reverse=True)
        self.assertEqual(L, ['aBe', 'ABD', 'abc'])

        L = ['saw', 'small', 'He', 'foxes', 'six']
        L.sort(key=len)
        self.assertEqual(L, ['He', 'saw', 'six', 'small', 'foxes'])

        # LPY5, Chapter 4: Introducing Python Object Types
        M = ['bb', 'aa', 'cc']
        M.reverse() 
        self.assertEqual(M, ['cc', 'aa', 'bb'])

        # py-sorted or py-list-sort?
        coll1 = ["flower","flow","flight"]
        coll1.sort()

        self.assertEqual(coll1, ['flight', 'flow', 'flower'])

        coll2 = sorted(coll1)

        self.assertEqual(coll1, coll2)

<py-list-nested>

    def test_list_nested(self):
        coll = [
                [["AMS"], ["AMS"]], 
                [["PROX"], ["darwin"]],
                # can have comment in the middle.  
                [["PPCM_CF"], ["ppcm", "ppcm_core"]] 
               ]

        self.assertEqual(coll[0], [["AMS"], ["AMS"]])
        self.assertEqual(coll[0][0], ["AMS"])


={============================================================================
|kt_dev_py_0001| py-slice

You can select sections of list-like types (arrays, tuples, NumPy arrays) by
using slice notation, which in its basic form consists of `start:stop` passed
to the `indexing operator []`:

Their general form, X[I:J], means "give me everything in X from offset I up to
but not including offset J." The result is returned in a `new object`

Like (start, end] in C++ iterator notation.

    def test_slice_and_index(self):
        coll = [7,2,3,7,5,6,0,1]

        # index is different from slice
        self.assertEqual(coll[2], 3)

        # `from right`, end()
        self.assertEqual(coll[-2], 0)

        # makes a single item list
        self.assertEqual(coll[1:2], [2])

        self.assertEqual(coll[1:5], [2, 3, 7, 5])

        # py-list-insert since assign
        coll[3:4] = [6,3]
        self.assertEqual(coll, [7, 2, 3, 6, 3, 5, 6, 0, 1])


<py-slice-default>
Either the start or stop can be omitted in which case they `default to` the
start of the sequence and the end of the sequence, respectively:

    def test_slice_default(self):
        coll = [7,2,3,7,5,6,0,1]

        self.assertEqual(coll[1:], [2, 3, 7, 5, 6, 0, 1])

        # coll do not change
        self.assertEqual(coll, [7, 2, 3, 7, 5, 6, 0, 1])

        self.assertEqual(coll[:3], [7, 2, 3])

        self.assertEqual(coll[:-1], [7, 2, 3, 7, 5, 6, 0])

        # all, py-copy
        self.assertEqual(coll[:], coll)

        # to get the last four chars
        message = '0123456789'
        self.assertEqual(message[-4:], '6789')


<py-slice-step>
A `step` can also be used after a second colon

    def test_slice_step(self):

        coll = [7,2,3,6,3,5,6,0,1]

        self.assertEqual(coll[::2], [7,3,3,6,1])

        # py-list-reverse py-reverse
        # A clever use of this is to pass -1 which has the useful effect of
        # reversing a list or tuple:

        self.assertEqual(coll[::-1], [1, 0, 6, 5, 3, 6, 3, 2, 7])


={============================================================================
|kt_dev_py_0001| py-reverse

    def test_reverse(self):

        # py-list sort
        coll = ['abc', 'ABD', 'aBe']
        coll.sort(key = str.lower, reverse = True)
        self.assertEqual(coll, ['aBe', 'ABD', 'abc'])

        # py-slice
        # A clever use of this is to pass -1 which has the useful effect of
        # reversing a list or tuple:

        coll = [7, 2, 3, 6, 3, 5, 6, 0, 1]
        self.assertEqual(coll[::-1], [1, 0, 6, 5, 3, 6, 3, 2, 7])

        # *py-reversed*
        # `reversed` iterates over the elements of a sequence in reverse order:
        coll = list(range(10))
        self.assertEqual(coll, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
        self.assertEqual(list(reversed(coll)), 
                [9, 8, 7, 6, 5, 4, 3, 2, 1, 0])


={============================================================================
|kt_dev_py_0001| py-dict

LPY5, 8 Lists and Dictionaries

Dictionaries are sometimes called associative arrays or hashes and are
implemented as hash tables and are unordered collections.

Dictionaries, `the only mapping type` in core objects set, are also `mutable`,
like lists, they may be changed in place and can grow and shrink on demand.

It is a flexibly-sized collection of key-value pairs, where key and value are
Python objects. 

Each key can have just one associated value, but that value can be a
collection of multiple objects if needed, and a given value can be stored
under any number of keys.


    def test_dict_ctor(self):

        # create dict by assign
        # is handy if you can spell out the entire dictionary ahead of time.

        d = {}
        d['name'] = 'Bob'
        d['age'] = 40
        self.assertEqual( d, {'name': 'Bob', 'age': 40})

        # create dict by initializers
        # The second is of use if you need to create the dictionary one field at
        # a time on the fly.

        d = {'name': 'Bob', 'age': 40}
        self.assertEqual( d, {'name': 'Bob', 'age': 40})


        # create dict by keyword argument form
        # The third involves less typing than the first, but it requires all
        # keys to be strings.

        d = dict(name='Bob', age=40)
        self.assertEqual( d, {'name': 'Bob', 'age': 40})

        # create dict by key, value tuple form
        # The last is useful if you need to build up keys and values as
        # sequences at runtime.

        d = dict([('name', 'Bob'), ('age', 40)])
        self.assertEqual( d, {'name': 'Bob', 'age': 40})


note: set vs dict
  return {'mac': result}          # returns a dict
  return {'mac', result}          # returns a set


<py-dict-sort>
How to sort dict that is unordered collection? One common solution is to grab
a list of keys with the dictionary keys method, sort that with the list sort
method, and then step through the result with a Python for loop

    # ('a', '=>', 100)
    # ('c', '=>', 300)
    # ('b', '=>', 200)
    # --------------
    # ('a', '=>', 100)
    # ('b', '=>', 200)
    # ('c', '=>', 300)

    def test_dict_sort(self):

        # in recent versions of Python it can be done in one step with the newer
        # `sorted()` built-in function.

        d = {'a':100, 'c':300, 'b':200}

        # same as 'for key in d.keys():'
        for key in d:
            print(key, '=>', d[key])

        print('--------------')

        for key in sorted(d):
            print(key, '=>', d[key])

        # use list-sort member 

        d = {'a':100, 'c':300, 'b':200}

        for key in d:
            print(key, '=>', d[key])

        key_list = list(d.keys())
        key_list.sort()

        print('--------------')

        for key in key_list:
            print(key, '=>', d[key])


{py-dict-iteration} *py-membership*

The dictionary `in membership expression` allows us to query the existence of
a key and branch on the result with a Python if statement.

    def test_dict_iterator(self):

        d = {'a':100, 'c':300, 'b':200}

        if 'a' in d:
            print('exist')
        else: 
            print('not exist')


Fetching a nonexistent key is still a mistake. Elements can be accessed and
inserted using the same syntax as accessing elements of a list or tuple:

    def test_dict_insert(self):

        # *py-dict-update* insert

        # note that b is overwritten
        # {'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}
        # {'a': 'some value', 'c': 12, 'b': 'foo', 7: 'an integer'}

        d = {'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}
        self.assertEqual(d, 
                {'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'})

        d.update({'b':'foo','c':12})
        self.assertEqual(d, 
                {'a': 'some value', 'c': 12, 'b': 'foo', 7: 'an integer'})

        # update and insert a item.
        d = {'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}
        d['b'] = 'foo'
        d['c'] = 12
        self.assertEqual(d, 
                {'a': 'some value', 'c': 12, 'b': 'foo', 7: 'an integer'})


<py-dict-default-values> *py-dict-get*
Two very common case. 

o if not found, return default value

if key in some_dict:
  value = some_dict[key]
else:
  value = default_value


o if not found, create a list and if found, append it to the list. The problem
  is that the list should be created before to append. 

# error
if handle not in handle_map:
    handle_map[handle].append(fname)

# works
if handle not in handle_map:
    handle_map[handle] = [fname]
else:
    handle_map[handle].append(fname)


        # get(key[, default])
        # Return the value for key if key is in the dictionary, else default. If
        # default is not given, it defaults to None, so that this method never
        # raises a KeyError.

        d = {'a':100, 'c':300, 'b':200}

        self.assertEqual(d.get('a', 400), 100)
        self.assertEqual(d.get('a'), 100)
        self.assertEqual(d.get('d', 400), 400)


        # group input words by the first char of a word
        # {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}

        words=['apple', 'bat', 'bar', 'atom', 'book']
 
        by_letter={}
 
        for word in words:
            letter = word[0]
            if letter not in by_letter:
                by_letter[letter] = [word]
            else:
                by_letter[letter].append(word)
 
        print(by_letter)


        # the same result

        # setdefault(key[, default])
        # If key is in the dictionary, return its value. If not, insert key with
        # a value of default and return default. default defaults to None.

        words=['apple', 'bat', 'bar', 'atom', 'book']
 
        by_letter={}
 
        for word in words:
            letter = word[0]
            by_letter.setdefault(letter, []).append(word)
 
        print(by_letter)


<py-dict-pop> *py-del*
Values can be deleted either using the `del` keyword or the `pop` method
(which simultaneously returns the value and deletes the key):

        d = {'a': 'some value', 'dummy': 'another value', 'b': [1, 2, 3, 4], 5: 'some value', 7: 'an integer'}
        self.assertEqual(d, 
                {'a': 'some value', 'dummy': 'another value', 'b': [1, 2, 3, 4], 5: 'some value', 7: 'an integer'})

        # *py-del*
        del d[5]
        self.assertEqual(d, 
                {'a': 'some value', 'dummy': 'another value', 'b': [1, 2, 3, 4], 7: 'an integer'})

        d.pop('dummy')
        self.assertEqual(d, 
                {'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'})


<py-dict-values>
The `keys() and values()` give you lists of the keys and values 

        # *py-dict-keys* 
        # use print() since the order of result varies.
        #
        # ['a', 'dummy', 'b', 5, 7]
        # ['some value', 'another value', [1, 2, 3, 4], 'some value', 'an integer']

        d = {'a': 'some value', 'dummy': 'another value', 'b': [1, 2, 3, 4], 5: 'some value', 7: 'an integer'}

        print(d.keys())
        print(d.values())


<py-dict-items>

        # items()
        # Return a copy of the dictionary's list of (key, value) pairs.
        # searching through sequences like this is generally much slower 
        # than a direct key index

        # [('The Meaning of Life', '1983'), ('Life of Brian', '1979'), ('Holy Grail', '1975')]
        # ['Holy Grail']

        # py-dict-items, Key, Value
        d = {'Holy Grail': '1975', 'Life of Brian': '1979','The Meaning of Life': '1983'}

        # *py-comprehension*
        self.assertEqual(
                [title for title, year in d.items() if year == '1975'], 
                ['Holy Grail'])


<py-dict-key-types>
While the values of a dict can be `any` Python object, the keys have to be
`immutable` objects like scalar types (int, float, string) or tuples. The
technical term here is `hashability`. 


    def test_dict_key_type(self):

        hash('string')
        # -1542666171

        hash((1,2,(2,3)))
        # 1387206534

        # TypeError: unhashable type: 'list'
        with self.assertRaises(TypeError):
            hash((1,2,[2,3]))


<py-dict-flexible>

Using dictionaries to simulate flexible lists: using integer keys

Use list

>>> L = []
>>> L[99] = 'spam'
Traceback (most recent call last):
File "<stdin>", line 1, in ?
IndexError: list assignment index out of range

Although you can use repetition to preallocate as big a list as you’ll need
(e.g., [0]*100), you can also do something that looks similar with
dictionaries that does not require such space allocations. By using integer
keys, dictionaries can emulate lists that seem to grow on offset assignment:

>>> D = {}
>>> D[99] = 'spam'
>>> D[99]
'spam'
>>> D
{99: 'spam'}

Here, it looks as if D is a 100-item list, but it's really a dictionary with a
single entry; the value of the key 99 is the string 'spam'. You can access
this structure with offsets much like a list, catching nonexistent keys with
get or in tests if required, but you don’t have to allocate space for all the
positions you might ever need to assign values to in the future. When used
like this, dictionaries are `like more flexible equivalents of lists.`


Use a list as a key, an easy fix is to convert it to a tuple:

>>> d = {}
>>> d[tuple([1,2,3])]=5
>>> d
{(1, 2, 3): 5}


In a similar way, dictionary keys are also commonly leveraged to implement
`sparse` data structures-for example, multidimensional arrays where only a few
positions have values stored in them:

>>> Matrix = {}
>>> Matrix[(2, 3, 4)] = 88
>>> Matrix[(7, 8, 9)] = 99
>>>
>>> X = 2; Y = 3; Z = 4       # separates statements: see Chapter 10
>>> Matrix[(X, Y, Z)]
88
>>> Matrix
{(2, 3, 4): 88, (7, 8, 9): 99}

Here, we’ve used a dictionary to represent a three-dimensional array that is
empty except for the two positions (2,3,4) and (7,8,9). The keys are tuples
that record the coordinates of nonempty slots. 

Rather than allocating a large and mostly empty threedimensional matrix to
hold these values, we can use a simple two-item dictionary. 

Accessing an empty slot triggers a `nonexistent key exception` slots are not
physically stored:

>>> Matrix[(2,3,6)]
Traceback (most recent call last):
File "<stdin>", line 1, in ?
KeyError: (2, 3, 6)


<ex>
783E53043FBA, SYSF40.73.00, Rack 44 Shelf 1
783E53043FA6, SYSF40.73.00, Rack 44 Shelf 2

#!/usr/bin/python
maps = {}

f = open('maclist.txt');
for line in f:
    tokens = line.rstrip().split(',')
    # maps[ tokens[0] ] = { 'version' : tokens[1], 'name' : tokens[2] }
    maps[ tokens[0] ] = tokens[1:]

print maps

if '783E53043FBA' in maps:
    print '783E53043FBA is in maps'

if '783E53043FBB' in maps:
    print '783E53043FBB is in maps'

if '783E53043FA6' in maps:
    print '783E53043FA6 is in maps'

print 'ends'


={============================================================================
|kt_dev_py_0001| py-dict-ordered

https://docs.python.org/3/library/collections.html#collections.OrderedDict

8.3.5. OrderedDict objects

Ordered dictionaries are just like regular dictionaries but they remember the
order that items were inserted. When iterating over an ordered dictionary, the
items are returned in the order their keys were first added.

<ex>
from collections import OrderedDict

    connections = OrderedDict()


={============================================================================
|kt_dev_py_0001| py-set

LPY5, 5, Numeric Types

A set is `iterable` and an `unordered` collection of `unique and immutable`
objects. You can think of them like dicts, but keys only, no values.

In 3.X and 2.7, new set literal form is supported.  This syntax makes sense,
given that sets are essentially like valueless dictionaries because a set’s
items are unordered, unique, and immutable, the items behave much like a
dictionary’s keys.

    def test_set_ctor(self):

        # use built-in function
        coll1 = set([2,2,2,1,3,3])
        self.assertEqual(coll1, {1,2,3})

        # a new set literal form, using the curly braces formerly reserved for
        # dictionaries. In 3.X and 2.7, the following are equivalent

        coll2 = {2,2,2,1,3,3}
        self.assertEqual(coll2, {1,2,3})


sets support mathematical operations like union, intersection, difference, and
symmetric difference that we can’t perform on plain sequences like strings,
lists, and tuples.

    def test_set_ops(self):

        a = {1,2,3,4,5}
        b = {3,4,5,6,7,8}

        # union(or)
        self.assertEqual(a | b, {1, 2, 3, 4, 5, 6, 7, 8})

        # intersection(and)
        self.assertEqual(a & b, {3, 4, 5})

        # difference
        self.assertEqual(a - b, {1, 2})
        # differences, filter duplicates
        self.assertEqual({1,3,5,7} - {1,2,4,5,6}, {3,7})

        # symmetric difference
        self.assertEqual(a ^ b, {1, 2, 6, 7, 8})

        # super or sub
        self.assertTrue({1,2,3}.issubset(a))
        self.assertTrue(a.issuperset({1,2,3}))

        # equal
        # the order matters in py-list but not in py-set. Can user sorted() on
        # list to have the same result.

        self.assertTrue({1,2,3} == {3,2,1})
        self.assertFalse([1,2,3] == [3,2,1])

        # sets can only contain immutable (a.k.a. “hashable”) object types as
        # keys in dict does. so tuple is okay and note that set ctor can use
        # listlist.
        #
        # TypeError: unhashable type: 'list'

        coll = set()
        coll.add(1.23)
        coll.add((1,2,3))
        self.assertEqual(coll, {1.23, (1, 2, 3)})

        z = {'b', 'd'}
        z.add('SPAM')
        self.assertEqual(z, {'b', 'd', 'SPAM'})

        # merge: in-place union
        z.update(set(['X', 'Y']))
        self.assertEqual(z, {'Y', 'X', 'b', 'd', 'SPAM'})

        z.remove('b') # Delete one item
        self.assertEqual(z, {'Y', 'X', 'd', 'SPAM'})


<py-set-iteration>
As iterable containers, sets can also be used in operations such as len, for
loops, and list comprehensions. Because they are unordered, though, they
`don’t support sequence operations like indexing and slicing`

    def test_set_iteration(self):
        
        for item in set('abc'):
            print(item * 3)

        coll = {x ** 2 for x in [1,2,3,4]}
        self.assertEqual(coll, {1,4,9,16})


={============================================================================
|kt_dev_py_0001| py-coll

https://docs.python.org/2/library/collections.html

8.3. collections — High-performance container datatypes


={============================================================================
|kt_dev_py_0001| py-coll-deque

class collections.deque([iterable[, maxlen]])

If maxlen is not specified or is None, deques may grow to an arbitrary length.
Otherwise, the deque is bounded to the specified maximum length. 

Once a bounded length deque is full, when new items are added, a corresponding
number of items are discarded from the opposite end. Bounded length deques
provide functionality `similar to the tail filter in Unix.` They are also
useful for tracking transactions and other pools of data where only the most
recent activity is of interest.

*py-performance*
Adding or popping items from either end of a queue has O(1) complexity. This
is unlike a list where inserting or removing items from the front of the list
is O(N).

<ex>
PYCB3, Chapter 1: Data Structures and Algorithms
1.3. Keeping the Last N Items

Problem

You want to keep a limited history of the last few items seen during iteration
or during some other kind of processing.


    # When new items are added and the queue is full, the oldest item is
    # automatically removed.

    def test_coll_deque(self):
        q = deque(maxlen = 3)
        q.append(1)
        q.append(2)
        q.append(3)

        # AssertionError: deque([1, 2, 3], maxlen=3) != [1, 2, 3]
        # self.assertEqual(q, [1,2,3])
        self.assertEqual(list(q), [1,2,3])

        q.append(4)
        self.assertEqual(list(q), [2,3,4])

        q.append(5)
        self.assertEqual(list(q), [3,4,5])

        q = deque()
        q.append(1)
        q.append(2)
        q.append(3)
        self.assertEqual(list(q), [1,2,3])

        q.appendleft(4)
        self.assertEqual(list(q), [4,1,2,3])

        q.pop()
        self.assertEqual(list(q), [4,1,2])

        q.popleft()
        self.assertEqual(list(q), [1,2])

    # *py-generator*
    # search() yields the matched line and five previous lines from that

    @staticmethod
    def search(lines, pattern, history = 5):
        previous_lines = deque(maxlen = history)

        for line in lines:

            if pattern in line:
                yield line, previous_lines

            previous_lines.append(line)

    def test_coll_cookbook_1_3(self):
        with open('some.txt') as f:
            for line, previous_lines in TestCollDeque.search(f, 'python', 5):
                for num, pline in enumerate(previous_lines):
                    print(num, ':', pline, end='')
                print(line, end='')
                print('-'*20)


={============================================================================
|kt_dev_py_0001| py-coll-heapq

https://docs.python.org/3.0/library/heapq.html

heapq — Heap queue algorithm

This module provides an implementation of the heap queue algorithm, also known
as the priority queue algorithm.

The interesting property of a heap is that heap[0] is always its smallest
element.

heapq.nlargest(n, iterable[, key])

Return a list with the n largest elements from the dataset defined by
iterable. key, if provided, specifies a function of one argument that is used
to extract a comparison key from each element in the iterable: key=str.lower

Equivalent to: sorted(iterable, key=key, reverse=True)[:n]

<ex>
PYCB3, Chapter 1: Data Structures and Algorithms
1.4. Finding the Largest or Smallest N Items


={============================================================================
|kt_dev_py_0001| py-reference py-copy

LPY5, 9, Tuples, Files, and Everything Else

Core Types Review and Summary, References Versus Copies

Assignments always store references to objects, not copies of those objects.
In practice, this is usually what you want. Because assignments can generate
multiple references to the same object, though, it's important to be aware
that changing a mutable object in place may affect other references to the
same object elsewhere in your program. If you don't want such behavior, you'll
need to tell Python to copy the object explicitly.

If you really do want copies, however, you can request them:

  *py-copy*
  Slice expressions with empty limits (L[:]) copy sequences.

  The dictionary, set, and list copy method (X.copy()) copies a dictionary,
  set, or list (the list’s copy is new as of 3.3).

  Some built-in functions, such as list and dict make copies (list(L),
  dict(D), set(S)).

  The copy standard library module makes full copies when needed.


class TestReference(unittest.TestCase):

    def setUp(self):
        print("====================")
        print("[RUN] ", self._testMethodName)

    def test_reference(self):

        a = [1,2,3]
        b = a

        c = list(a)
        # *py-copy*
        cc = a[:]

        d = [1,2,3]

        # since py-reference py-is
        self.assertTrue(a is b)
        self.assertTrue(a == b)

        # c is a different list
        self.assertTrue(a is not c)

        # c and cc is a different list
        self.assertTrue(c is not cc)
        self.assertTrue(c == cc)

        # same value
        self.assertTrue(a == d)

        # but different object
        self.assertFalse(a is d)


<py-copy> py-top-level-copy

One final note on copies: empty-limit slices and the dictionary copy method
only make `top-level copies`; that is, they do not copy nested data structures,
if any are present. If you need a complete, fully independent copy of a deeply
  nested data structure (like the various record structures we've coded in
      recent chapters), use the standard copy module, introduced in Chapter 6:

import copy
X = copy.copy(Y)          # top-level shallow copy
X = copy.deepcopy(Y)      # Fully copy an arbitrarily nested object Y

This call recursively traverses objects to copy all their parts. This is a
much more rare case, though, which is why you have to say more to use this
scheme. References are usually what you will want; when they are not, slices
and copy methods are usually as much copying as you'll need to do.


={============================================================================
|kt_dev_py_0001| py-recursive

PYCB3, Chapter 1: Data Structures and Algorithms
1.2. Unpacking Elements from Iterables of Arbitrary Length

However, be aware that recursion really isn’t a strong Python feature due to
the inherent recursion limit. Thus, this last example might be nothing more
than an academic curiosity in practice.


={============================================================================
|kt_dev_py_0001| py-if py-or py-and

LPY5, 12, if Tests and Syntax Rules

Like all `compound statements`, the if statement may contain other statements,
including other ifs.

<py-true> <py-and> <py-or>

On the other hand, the `and` and `or` operators always `return an object` - either
the object on the left side of the operator or the object on the right. 

One common way to use the somewhat unusual behavior of Python Boolean
operators is to select from a set of objects with an or. A statement such as
this:

X = A or B or C or None

assigns X to the first nonempty (that is, true) object among A, B, and C, or
to None if all of them are empty. This works because the or operator returns
one of its two objects, and it turns out to be a fairly common coding paradigm
in Python: `to select a nonempty object from among a fixed-size set`, simply
string them together in an or expression. 

*py-convention*
In simpler form, this is also commonly used to designate a default: the
following sets X to A if A is true (or nonempty), and to default otherwise:

X = A or default

It’s also important to understand the short-circuit evaluation of Boolean
operators and the if/else, because it may prevent actions from running.
Expressions on the right of a Boolean operator, for example, might call
functions that perform substantial or important work, or have side effects
that won’t happen if the short-circuit rule takes effect:

if f1() or f2(): ...

Here, if f1 returns a true (or nonempty) value, Python will never run f2. To
guarantee that both functions will be run, call them before the or: 

tmp1, tmp2 = f1(), f2()
if tmp1 or tmp2: ...

<ex>
// this returns '10.209.60.106' and want to have ip address not starting with
// 192, 172 or 10.

    // resp = ['10.209.60.106', '127.0.0.1']

    for ip in resp:
      if ip.find('192') != -1 or ip.find('172') != -1 or ip.find('10') != -1:
        return ip


Python `and` operations also stop as soon as the result is known; however, in
this case Python evaluates the operands from left to right and stops if the
left operand is a false object because it determines the result—false and
anything is always false:


<dictionary-based-switch> dictionary-based multiway branch.
that there is no switch or case statement in Python that selects an action
based on a variable’s value. Instead, you usually code multiway branching as a
series of if/elif tests, as in the prior example, and occasionally by indexing
dictionaries or searching lists. 

Because dictionaries and lists `can be built at runtime dynamically`, they are
sometimes more flexible than hardcoded if logic in your script:

>>> choice = 'ham'
>>> print({'spam': 1.25,  # A dictionary-based 'switch'
...        'ham': 1.99,   # Use has_key or get for default
...        'eggs': 0.99,
...        'bacon': 1.10}[choice])
1.99


<py-multiple-line>
Because any expression can be enclosed in parentheses, you can usually use the
`open pairs technique` instead if you need your code to span multiple
lines—simply wrap a part of your statement in parentheses:

if (a == b and c == d and
  d == e and e == f):
  print('new')            # But parentheses usually do too, and are obvious


{py-if-ternary}
we may want to nest such a construct in a larger statement instead of
assigning its result to a variable. For these reasons, Python 2.5 introduced a
new expression format that allows us to say the same thing in one expression:

if X:
  A = Y
else:
  A = Z

A = Y if X else Z

    def test_base_ternary(self):

        coll = 'spam'

        a = 'true' if coll else 'false'

        self.assertEqual(a, 'true')

<ex>
    print 'Found %d images, ignoring those matching \'%s\'%s' % (
        len(images),
        settings.dropBoxIgnoreRegex,
        '' if stb_regex == '.*' else ' filtering on \'' + stb_regex + '\'')


={============================================================================
|kt_dev_py_0001| py-iterator py-comprehension

LPY5, 14, Iterations and Comprehensions

Python’s two looping statements, while and for can handle most repetitive
tasks programs need to perform, the need to iterate over sequences is so
common and pervasive that Python provides additional tools to make it simpler
and more efficient.

<py-iterable> <py-iteration-protocol>
an object is considered `iterable` if it is either a physically stored
sequence, or an object that produces one result at a time in the context of an
iteration tool like a for loop.

This interface is most of what we call the iteration protocol in Python. Any
object with a __next__ method to advance to a next result, which raises
StopIteration at the end of the series of results, is considered an iterator
in Python.


Allow the for loop to automatically call __next__ to advance to the next line
on each iteration. The file object’s iterator will do the work of
automatically loading lines as you go.

    # *py-print-end*
    # Notice that the print uses end='' here `to suppress adding a \n,` because
    # line strings already have one (without this, our output would be
    # double-spaced; in 2.X, a trailing comma works the same as the end).

    def test_iterator_on_file(self):
        for line in open('trispam.txt'):
            print(line, end='')


*py-performace*
iterators run at C language speed inside Python, whereas the while loop
version runs Python byte code through the Python virtual machine.


The full iteration protocol use two objects:

o The `iterable object` you request iteration for, whose __iter__ is run by
  iter

o The `iterator object` returned by `the iterable` that actually produces
  values during the iteration, whose __next__ is run by next and raises
  StopIteration when finished producing results


    # how for loops internally process built-in sequence types such as lists:
    # py-iteration-manual

    def test_iterator_protocol(self):

        coll = [1,2,3]

        # obtain an `iterator object` from an `iterable`
        it = iter(coll)

        # call iterator's next to advance to next item
        print(it.__next__())
        print(it.__next__())
        print(it.__next__())

        with self.assertRaises(StopIteration):
            print(it.__next__())


<py-iterator-mutiple-pass> <py-iterator-protocol>

    def test_iterator_pass(self):

        # py-range do support multiple active iterators

        coll = range(3)

        it1 = iter(coll)
        it2 = iter(coll)

        self.assertEqual(next(it1), 0)
        self.assertEqual(next(it1), 1)

        self.assertEqual(next(it2), 0)

        # py-zip do not support multiple active iterators
        # By contrast, in 3.X zip, map, and filter do not support multiple
        # active iterators

        coll = zip((1,2,3), (10,11,12))

        it1 = iter(coll)
        it2 = iter(coll)

        self.assertEqual(next(it1), (1, 10))
        self.assertEqual(next(it1), (2, 11))

        self.assertEqual(next(it2), (3, 12))


{py-comprehension}
Can be used to iterate over any iterable object and is a way to build a new
list by `running an expression on each item` in a sequence, one at a time,
from left to right. 

coded in square brackets (to tip you off to the fact that they make a list)
and are composed of an `expression` and a `looping construct` that share a
variable name (row, here).

`List comprehensions` are one of the most-loved Python language features. They
allow you to concisely form a new list `by filtering` the elements of a
collection and transforming the elements passing the filter in one conscise
expression. 

The list comprehension isn’t exactly the same as the for loop statement
version because it makes a new list object


They take the basic form:

[`expr` for val in collection if `condition`]

This is equivalent to the following for loop:

result = []
for val in collection:
  if condition:
    result.append(expr)

The `filter condition` can be `omitted`, leaving only the expression. 


*py-performace*
Moreover, depending on your Python and code, list comprehensions might run
much `faster than manual for loop statements` (often roughly twice as fast)
  because their iterations are performed at C language speed inside the
  interpreter, rather than with manual Python code.


<ex>
    def test_comprehension_on_any(self):

        # use py-range to loop and it not best approach
        coll = [1,2,3,4,5]

        for i in range(len(coll)):
            coll[i] += 10

        self.assertEqual(coll, [11, 12, 13, 14, 15])

        # use for
        coll = [1,2,3,4,5]
        result = []
        for i in coll:
            result.append(i + 10)

        self.assertEqual(result, [11, 12, 13, 14, 15])

        # use py-comprehension
        coll = [1,2,3,4,5]

        coll = [x + 10 for x in coll]

        self.assertEqual(coll, [11, 12, 13, 14, 15])

        # use filter condition
        coll = ['a', 'as', 'bat', 'car', 'dove', 'python']
        result = [e.upper() for e in coll if len(e) > 2]
        self.assertEqual(result, ['BAT', 'CAR', 'DOVE', 'PYTHON'])

        # nested
        coll = [x + y for x in 'abc' for y in 'lmn']
        self.assertEqual(coll, 
                ['al', 'am', 'an', 'bl', 'bm', 'bn', 'cl', 'cm', 'cn'])

        #
        coll = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
        result = [e[1] for e in coll]
        self.assertEqual(result, [2,5,8])

        # collect a diagonal from matrix
        coll = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
        result = [coll[i][i] for i in [0, 1, 2]]
        self.assertEqual(result, [1, 5, 9])

        # repeat characters in a string
        coll = [c * 2 for c in 'spam']     
        self.assertEqual(coll, ['ss', 'pp', 'aa', 'mm'])

        # multiple values, "if" filters
        coll = [[x ** 2, x ** 3] for x in range(4)]  
        self.assertEqual(coll, [[0, 0], [1, 1], [4, 8], [9, 27]])


    # py-readlines method that loads the file into a list of line strings all at
    # once:

    def test_comprehension_on_file(self):

        f  = open('trispam.txt')
        lines = f.readlines()
        self.assertEqual(lines, ['spam\n', 'Spam\n', 'SPAM!\n'])
        f.close()

        # It would be nice if we could get rid of these newlines all at once,
        # wouldn’t it?

        f  = open('trispam.txt')
        lines = f.readlines()
        result = [line.rstrip() for line in lines]
        self.assertEqual(result, ['spam', 'Spam', 'SPAM!'])
        f.close()

        # do the same
        f = open('trispam.txt')
        result = [line.rstrip() for line in f]
        self.assertEqual(result, ['spam', 'Spam', 'SPAM!'])
        f.close()

<ex>
>>> s = '783E53043FBA, SYSF40.73.00, Rack 44 Shelf 1'
>>> s.split(',')
['783E53043FBA', ' SYSF40.73.00', ' Rack 44 Shelf 1']

f = open('maclist.txt');
for line in f:
    tokens = line.rstrip().split(',')
    maps[ tokens[0] ] = [ tokens[1].strip(), tokens[2].strip() ]

    To:
    maps[ tokens[0] ] = [ x.strip() for x in tokens[1:] ]

note:
can use dict comprehension?


<comprehension-on-other-iteration-context>

o any tool that employs the iteration protocol will automatically work on any
  built-in type or user-defined class that provides it.

  essentially everything in Python’s built-in toolset that scans an object
  from left to right is defined to use the iteration protocol on the subject
  object.

  This even includes tools such as the list and tuple built-in functions , and
  the string join method. Consequently, these will also work on an open file
  and automatically read one line at a time:

    def test_iterator_on_any(self):

        f  = open('trispam.txt')
        coll = list(f)
        self.assertEqual(coll, 
                ['spam\n', 'Spam\n', 'SPAM!\n'])

        f.close()

        f  = open('trispam.txt')
        coll = tuple(f)
        self.assertEqual(coll, 
                ('spam\n', 'Spam\n', 'SPAM!\n'))

        f.close()

        f  = open('trispam.txt')
        coll = '&&'.join(f)
        self.assertEqual(coll, 
                'spam\n&&Spam\n&&SPAM!\n')

        f.close()

        f  = open('trispam.txt')
        coll = list(f)
        f.close()

        # sequence assignment
        a, b, c = coll
        self.assertEqual(a, 'spam\n')

        # *py-3* star expression
        a, *b = coll
        self.assertEqual(b, ['Spam\n', 'SPAM!\n'])

        # *py-membership*
        self.assertTrue('spam\n' in coll)

        # slice
        result = [11, 12, 13, 44]
        result[1:3] = coll
        self.assertEqual(result, 
                [11, 'spam\n', 'Spam\n', 'SPAM!\n', 44])


o `sorted` sorts items in an iterable; `zip` combines items from iterables;
  `enumerate` pairs items in an iterable with relative positions; `filter`
  selects items for which a function is true; and `reduce` runs pairs of items
  in an iterable through a function.


*py-map*
applies a function call to each item in the passed-in iterable object.

    # *py-map*
    def test_comprehension_on_map(self):

        f  = open('trispam.txt')
        coll = [line.upper() for line in f]
        self.assertEqual(coll, 
                ['SPAM\n', 'SPAM\n', 'SPAM!\n'])
        f.close()

        f  = open('trispam.txt')
        coll = list(map(str.upper, f))
        self.assertEqual(coll, 
                ['SPAM\n', 'SPAM\n', 'SPAM!\n'])
        f.close()


*py-enumerate*
When iterating over a sequence to want to keep track of the index of the
current item. Since this is so common, Python has a built-in function
`enumerate` which returns a sequence of (i, value) tuples:

    def test_comprehension_on_enumerate(self):

        f  = open('trispam.txt')
        coll = list(enumerate(f))
        self.assertEqual(coll, 
                [(0, 'spam\n'), (1, 'Spam\n'), (2, 'SPAM!\n')])
        f.close()

        coll = ['one', 'two', 'three']
        mapping = dict((v,i) for i,v in enumerate(coll))
        self.assertEqual(mapping, {'three': 2, 'two': 1, 'one': 0})


*py-sorted*
The sorted function `returns a new sorted list` from the elements of any
sequence. A common `pattern` for getting a sorted list of the `unique
elements` in a sequence is to combine sorted with set.

    def test_sorted(self):

        # sorted do not change coll1

        coll1 = ['abc', 'ABD', 'aBe']
        result = sorted(coll1)
        self.assertEqual(result, ['ABD', 'aBe', 'abc'])

        result = sorted(coll1, key=str.lower, reverse=True)
        self.assertEqual(result, ['aBe', 'ABD', 'abc'])

        # input is not coll2 since it's lower cased before running sorted()

        coll2 = ['abc', 'ABD', 'aBe']
        result = sorted([x.lower() for x in coll2], reverse=True)
        self.assertEqual(result, ['abe', 'abd', 'abc'])

        coll3 = sorted([7,1,2,6,0,3,2,3,2])
        self.assertEqual(coll3, [0, 1, 2, 2, 2, 3, 3, 6, 7])

        coll3 = sorted(set([7,1,2,6,0,3,2,3,2]))
        self.assertEqual(coll3, [0, 1, 2, 3, 6, 7])


*py-zip*
`pairs up` the elements of a number of lists, tuples, or other sequences
*py-2* returns a list and *py-3* returns zip class instance.

    # *py-zip* *py-3*
    def test_comprehension_on_zip(self):

        coll1 = ['foo','bar','baz']
        coll2 = ['one','two','three']
        self.assertEqual(list(zip(coll1, coll2)), 
                [('foo', 'one'), ('bar', 'two'), ('baz', 'three')])

        # when one of list has less items

        coll1 = ['foo','bar','baz']
        coll2 = ['one','two']
        self.assertEqual(list(zip(coll1, coll2)), 
                [('foo', 'one'), ('bar', 'two')])

        coll1 = (1, 2)
        coll2 = (3, 4)
        self.assertEqual(list(zip(coll1, coll2)), 
                [(1,3), (2,4)])

        self.assertEqual(list(zip(*zip(coll1, coll2))), 
                [(1,2), (3,4)])

        #
        coll1 = ['foo','bar','baz']
        coll2 = ['one','two','three']
        zipped = zip(coll1, coll2)

        # *py-unpack*
        names, numbers = zip(*zipped)

        self.assertEqual(names, ('foo', 'bar', 'baz'))
        self.assertEqual(numbers, ('one', 'two', 'three'))


Given a zipped sequence, zip can be applied in a clever way to `unzip` the
sequence. Another way to think about this is converting a list of rows into a
list of columns. The syntax, which looks a bit magical, is:


*py-reversed*
`reversed` iterates over the elements of a sequence in reverse order:

    # *py-reversed*
    def test_iterator_reversed(self):

        coll = range(10)
        self.assertEqual(coll, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
        self.assertEqual(list(reversed(coll)), 
                [9, 8, 7, 6, 5, 4, 3, 2, 1, 0])


<py-iterable-py-3> *py-3*

New Iterables in Python 3.X

One of the fundamental distinctions of Python 3.X is its stronger emphasis on
iterators than 2.X. 

Specifically, in addition to the iterators associated with built-in types such
as files and dictionaries, the dictionary methods keys, values, and items
`return iterable objects in Python 3.X`, as do the built-in functions range,
  map, zip, and filter. 

All of these tools produce results on demand in Python 3.X, instead of
constructing result lists as they do in 2.X.


<dict-comporehension>
In Python 2.7 and 3.X, comprehension syntax can also be used to create `sets`
  and `dict`:

A `dict comprehension` looks like this:

dict_comp = { `key-expr:value-expr` for value in collection if `condition`}


A `set comprehension` looks like list comprehension except with curly braces
  instead of square brackets:

set_comp = {expr for value in collection if condition}


# scan the file line by line and pick out lines that begin with the letter p

>>> {line for line in open('script2.py') if line[0] == 'p'}
{'print(x ** 32)\n', 'print(sys.path)\n'}


>>> unique_lengths = {len(x) for x in strings}
>>> unique_lengths
set([1, 2, 3, 4, 6])

Could create a lookup map of these strings to their locations in the list:

>>> loc_mapping = {val:index for index, val in enumerate(strings)}
>>> loc_mapping
{'a': 0, 'bat': 2, 'python': 5, 'car': 3, 'as': 1, 'dove': 4}

Note that this dict could be equivalently constructed by:

>>> loc_mapping2 = dict((val,index) for index, val in enumerate(strings))
>>> loc_mapping2
{'a': 0, 'bat': 2, 'python': 5, 'car': 3, 'as': 1, 'dove': 4}


={============================================================================
|kt_dev_py_0001| py-generator

LPY5, Chapter 20: Comprehensions and Generations

o generator is functions that may send back a value and later be resumed,
  picking up where they left off.

o generators are their own iterator, supporting just one active iteration
  scan.

o The mere presence of the yield statement in a function turns it into a
  generator. Unlike a normal function, a generator only runs in response to
  iteration.

To support this protocol, functions containing a yield statement are compiled
specially as generators - they are not normal functions, but rather are built
to return an object with the expected iteration protocol methods. When later
called, they return a generator object that supports the iteration interface
with an `automatically created method named __next__` to start or resume
execution.


Why generator functions?

However, generators can be better in terms of both memory use and performance
in larger programs. They allow functions to avoid doing all the work up front,
which is especially useful when the result lists are large or when it takes a
lot of computation to produce each value. Generators distribute the time
required to produce the series of values among loop iterations.

<ex>
class TestGenerator(unittest.TestCase):
    
    def setUp(self):
        print("====================")
        print("[RUN] ", self._testMethodName)

    @staticmethod
    def squares(n):
        result = []
        for i in range(n):
            result.append(i ** 2)
        return result

    @staticmethod
    def gensquares(n):
        for i in range(n):
            yield i ** 2

    @staticmethod
    def ups(line):
        for sub in line.split(','):
            yield sub.upper()

    def test_generator(self):

        result = []
        for i in TestGenerator.squares(5):
            result.append(i)

        self.assertEqual(result, [0,1,4,9,16])

        result = []
        for i in TestGenerator.gensquares(5):
            result.append(i)

        self.assertEqual(result, [0,1,4,9,16])

        # iter(gen) is not required since generators are their own iterator,
        # supporting just one active iteration scan.

        gen = TestGenerator.gensquares(4)
        self.assertEqual(next(gen), 0)
        self.assertEqual(next(gen), 1)
        self.assertEqual(next(gen), 4)
        self.assertEqual(next(gen), 9)

        # 
        coll = tuple(TestGenerator.ups('aaa,bbb,ccc'))
        self.assertEqual(coll, ('AAA', 'BBB', 'CCC'))


<ex>
PYCB3, 4.3. Creating New Iteration Patterns with Generators

Problem

You want to implement a custom iteration pattern that’s different than the
usual builtin functions (e.g., range(), reversed(), etc.).


={============================================================================
|kt_dev_py_0001| py-module

LPY5, 22, Modules: The Big Picture

Python modules are easy to create; they’re just files of Python program code

the highest-level program organization unit, which packages program code and
data for reuse, and provides self contained `namespaces` that minimize
variable name clashes across your programs.

All the names defined at the top level of a module file become `attributes` of
the imported module object. As we saw in the last part of this book, imports
give access to names `in a module's global scope`


<py-module-py-top-level>
a Python program consists of text files containing Python statements, with one
main top-level file, and zero or more supplemental files known as modules.

The `top-level` (a.k.a. script) file contains the main flow of control of your
program—this is the file you run to launch your application. The module files
are libraries of tools used to collect components used by the top-level file.


How Imports Work

The `imports` are really runtime operations that perform three distinct steps
the first time a program imports a given file:

o Find the module's file.

Python uses a standard `module search path` and `known file types` to locate the
module file corresponding to an import statement.

o Compile it to byte code (if needed).

During an import operation Python checks both file modification times and the
byte code's Python version number to decide how to proceed.


<py-byte-code> ship byte code only
In Python 3.2 and later, byte code files are segregated in a __pycache__
subdirectory and named with their Python version to avoid contention and
recompiles when multiple Pythons are installed.

In addition, if Python finds only a byte code file on the search path and no
source, it simply loads the byte code directly; this means you can ship a
program as just byte code files and avoid sending source. 

In other words, the compile step is bypassed if possible to speed program
startup.

Notice that `compilation happens when a file is being imported.`

after all to speed up.

If Python cannot write a file to save this on your computer for any reason,
your program still runs fine; Python simply creates and uses the byte code in
  memory and discards it on exit. To speed startups, though, it will try to
  save byte code in a file in order to skip the compile step next time around.

o Run the module's code to build the objects it defines.

This last import step actually runs the file's code.


<py-search-path>
Python look:

1. The home directory of the program (automatic)
2. PYTHONPATH directories (if set)
3. Standard library directories (automatic)
4. The contents of any .pth files (if present)
5. The site-packages home of third-party extensions


<py-sys-path>
The concatenation of these four components `becomes sys.path`, a mutable list
of directory name strings. You can always inspect the path as Python knows it
by printing the built-in sys.path. The empty string at the front means current
directory

>>> import sys
>>> sys.path
['', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-linux2', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/pymodules/python2.7']

<ex>

/home/pi/snugupdate-v2-snugberrypi/run.sh

  cd /home/pi/snugupdate-v2-snugberrypi/snugupdate-v2-python
  ../update_log.py

    # note: 
    # do not work
    # sys.path.append('/snugupdate-v2-python/')
    # no different and shows the same problem
    # sys.path.append('snugupdate-v2-python') 
    sys.path.append('snugupdate-v2-python/')
    from libraries.settings import dropboxToken

    # >>> sys.path.append('snugupdate-v2-python/')
    # >>> sys.path
    # ['', 'snugupdate-v2-python/']

cause *py-error-import-error* 

pi@raspberrypi ~/snugupdate-v2-snugberrypi/snugupdate-v2-python $ ../upload_log.py ../www/log
pi@raspberrypi ~/snugupdate-v2-snugberrypi/snugupdate-v2-python $ python ../upload_log.py ../www/log

cause *py-error-import-error* 

pi@raspberrypi ~/snugupdate-v2-snugberrypi $ ./upload_log.py www/log
okay

these fix the problem:
export PYTHONPATH=/home/pi/snugupdate-v2-snugberrypi/snugupdate-v2-python:$PYTHONPATH
sys.path.append('/home/pi/snugupdate-v2-snugberrypi/snugupdate-v2-python')

WHY?

https://docs.python.org/3/tutorial/modules.html
6.1.2. The Module Search Path

When a module named spam is imported, the interpreter first searches for a
built-in module with that name. If not found, it then searches for a file
named spam.py in a list of directories given by the variable sys.path.

sys.path is initialized from these locations:

1. The directory containing the input script (or the current directory when no
    file is specified).

2. PYTHONPATH (a list of directory names, with the same syntax as the shell
    variable PATH).

3. The installation-dependent default.

https://docs.python.org/3/library/sys.html#sys.path

So use relative path in the list from the current directory where a script
gets run? However, libraries.settings is under snugupdate-v2-python and when
run interactive python, this works:

    from libraries.settings import dropboxToken

https://stackoverflow.com/questions/7505988/importing-from-a-relative-path-in-python
From PEP8:
Relative imports for intra-package imports are highly discouraged.

https://www.python.org/dev/peps/pep-0008/
`Absolute imports are recommended`, as they are usually more readable and tend
to be better behaved (or at least give better error messages) if the import
system is incorrectly configured (such as when a directory inside a package
    ends up on sys.path):


LPY5, 23, Module Coding Basics

Module Filenames

Because module names become variable names inside a Python program, they
should also follow the `normal variable name rules` For instance, you can
create a module file named if.py, but you cannot import it because if is a
reserved word.

The chief difference is that import fetches the module as a whole, so you must
qualify to fetch its names; in contrast, from fetches (or copies) specific
names out of the module.

The import Statement identifies an `external file to be loaded`, and it becomes
a variable in the script. Because it gives a name that refers to the whole
module object, we must go through the module name to fetch its attributes
(e.g., module1.printer).


<py-import-py-from>
Just like def, import and from are executable statements, not compile-time
declarations. They are not resolved or run until Python reaches them while
executing your program. In other words, imported modules and names are not
available until their associated import or from statements run.

Also, like `def`, the `import` and `from` are `implicit assignments`: *py-assign*

o `import` assigns an entire module object to a single name, filename

  import sys

o `from` assigns one or more names to objects of the same names in another
  module.

  from functools import partial

  copy out _all_ variables

  from module1 import * 

o Imports Happen Only Once

  Modules are loaded and run on the first import or from, and only the first.


As with function arguments, reassigning a copied name has no effect on the
module from which it was copied, but changing a `shared mutable object`
through a copied name can also change it in the module from which it was
imported. see *py-function-argument* *py-reference*


<ex>
# small.py
x = 1
y = [1, 2]

% python
>>> from small import x, y      # Copy two names out
>>> x = 42                      # Changes local x only
>>> y[0] = 42                   # Changes shared mutable in place

Here, x is not a shared mutable object, but y is, so changing it from one
place changes it in the other:

>>> import small                # Get module name (from doesn't)
>>> small.x                     # Small's x is not my x
1
>>> small.y                     # But we share a changed mutable
[42, 2]


import and from Equivalence

At least conceptually, a from statement like this one:

from module import name1, name2 # Copy these two names out (only)

is equivalent to this statement sequence:

import module                   # Fetch the module object
name1 = module.name1            # Copy names out by assignment
name2 = module.name2
del module                      # Get rid of the module name

Like all assignments, the from statement creates new variables in the
importer, which initially refer to objects of the same names in the imported
file. Only the names are copied out, though, `not the objects they reference`,
  and not the name of the module itself.

*py-convention*
Potential Pitfalls of the from Statement

Some Python users recommend using import instead of from most of the time. It
is true that the from statement has the potential to `corrupt namespaces`:

if you use it to import variables that happen to have the same names as
existing variables in your scope, then your variables will be silently
`overwritten`. This problem doesn’t occur with the simple import statement
because you must always go through a module’s name to get to its contents

>>> y = ['spam', 'value']
>>> y
['spam', 'value']
>>> from small import x, y
>>> y
[1, 2]


={============================================================================
|kt_dev_py_0001| py-module-namespace

Technically, modules usually correspond to files, and Python creates a module
object to contain all the names assigned in a module file. But in simple
terms, modules are just `namespaces` (places where names are created), and the
names that live in a module are called its `attributes`.

Files Generate Namespaces

The short answer is that every name that is assigned a value at the top level
of a module file (i.e., not nested in a function or class body) becomes an
attribute of that module.

* Module statements run on the first import. The first time a module is
  imported anywhere in a system, Python creates an empty module object and
  executes the statements in the module file one after another, from the top
  of the file to the bottom.

* Top-level assignments create module attributes. During an import, statements
  at the top level of the file not nested in a def or class that assign names
  (e.g., =, def) create attributes of the module object; assigned names are
  stored in the module’s namespace.

* Module namespaces can be accessed via the attribute __dict__ or dir(M).
  Module namespaces created by imports are dictionaries; they may be accessed
  through the built-in __dict__ attribute associated with module objects and
  may be inspected with the dir function. The dir function is roughly
  equivalent to the sorted keys list of an object’s __dict__ attribute, but it
  includes inherited names for classes, may not be complete, and is prone to
  changing from release to release.


<ex>
# module2.py
print('starting to load...')

import sys
name = 42

def func(): pass
class klass: pass

print('done loading.')

>>> import module2
starting to load...
done loading...

>>> module2.__dict__.keys()
['name', '__builtins__', '__file__', '__package__', 'sys', 'klass', 'func', '__name__', '__doc__']

>>> module2.__dict__['__file__']
'module2.py'

Namespace Dictionaries: __dict__

module namespaces are stored as dictionary objects.

>>> list(module2.__dict__.keys())
['__loader__', 'func', 'klass', '__builtins__', '__doc__', '__file__', '__name__',
'name', '__package__', 'sys', '__initializing__', '__cached__']

Python also adds some names in the module’s namespace for us; for instance,
__file__ gives the name of the file the module was loaded from, and __name__
  gives its name as known to importers (without the .py extension and
      directory path).

>>> list(name for name in module2.__dict__.keys() if not name.startswith('__'))
['func', 'klass', 'name', 'sys']
>>> list(name for name in module2.__dict__ if not name.startswith('__'))
['func', 'sys', 'name', 'klass']

>>> module2.name, module2.__dict__['name']
(42, 42)


Imports Versus Scopes

Scopes are never influenced by function calls or module imports.

# moda.py

X = 88      # My X: global to this file only
def f():
  global X  # Change this file's X
  X = 99    # Cannot see names in other modules

# modb.py

X = 11      # My X: global to this file only
import moda # Gain access to names in moda
moda.f()    # Sets moda.X, not this file's X
print(X, moda.X)

% python modb.py
11 99


Namespace Nesting

imports do nest downward and it is possible to descend into arbitrarily nested
modules and access their attributes.

# mod3.py

X = 3

# mod2.py

X = 2
import mod3
print(X, end=' ')   # My global X
print(mod3.X)       # mod3's X

# mod1.py

X = 1
import mod2
print(X, end=' ')       # My global X
print(mod2.X, end=' ')  # mod2's X
print(mod2.mod3.X)      # note: Nested mod3's X

% python mod1.py
2 3
1 2 3

The reverse, however, is not true: mod3 cannot see names in mod2, and mod2
cannot see names in mod1.


={============================================================================
|kt_dev_py_0001| py-module-package

LPY5, 24, Module Packages

In addition to a module name, an import `can name a directory path.` A
directory of code is said to be a `package`, so such imports are `package imports` 
In effect, a package import turns a directory on your computer into another
Python namespace, with attributes corresponding to the subdirectories and
module files that the directory contains.

<py-package-import>
List a path of names separated by periods:

import dir1.dir2.mod

The same goes for from statements:

from dir1.dir2.mod import x

Furthermore, these imports imply that dir1 resides within some container
directory dir0, which is a component of the normal Python module search path.

these two import statements imply a directory structure that looks something like this

dir0\dir1\dir2\mod.py

The container directory `dir0 needs to be added` to your module search path
unless it’s the home directory of the top-level file, exactly as if dir1 were
a simple module file.

`the leftmost component` in a package import path, dir1, is still relative to
a directory included in the sys.path module search path list see
*py-search-path*

entries on the module search path provide `platform-specific` directory path
prefixes and import statements themselves provide the remainder of the
directory path in a `platform-neutral` fashion.


<py-init-py>
To enable this syntax:

import dir1.dir2.mod

`Each directory named within the path of a package import statement must`
contain a file named __init__.py, or your package imports will fail.

<py-error-import> this is a general import error when cannot find it. 

Traceback (most recent call last):
  File "update.py", line 2, in <module>
    from libraries.stb import Devices              # Keeps track of STBs on the network
ImportError: No module named libraries.stb


for a directory structure such as this:
dir0\dir1\dir2\mod.py

and an import statement of the form:
import dir1.dir2.mod

the following rules apply:

o dir1 and dir2 both must contain an __init__.py file.
 
o dir0, the container, does not require an __init__.py file; this file will
  simply be ignored if present.

o dir0, not dir0\dir1, must be listed on the module search path sys.path.
 

<py-init-py-purpose>
The __init__.py files `can contain` code, just like normal module files.

Their names are special because their code is run automatically the first time
`a Python program imports a directory,` and thus serves primarily as a hook for
performing `initialization steps required by the package.` These files can
also be completely empty.

dir0\                       # Container on module search path
  dir1\
      __init__.py
      dir2\
          __init__.py
          mod.py

Once imported, the path in your import statement becomes a nested object path
in your script. Here, mod is an object nested in the object dir2, which in
turn is nested in the object dir1:

>>> dir1
<module 'dir1' from '.\\dir1\\__init__.py'>
>>> dir1.dir2
<module 'dir1.dir2' from '.\\dir1\\dir2\\__init__.py'>
>>> dir1.dir2.mod
<module 'dir1.dir2.mod' from '.\\dir1\\dir2\\mod.py'>


Why Use Package Imports?

They do serve useful roles, though, especially in larger programs: they make
imports more informative, serve as an organizational tool, simplify your
module search path, and can resolve ambiguities.


<ex> shows case where have to use sys.path for platform-dependant name

from snugupdate-v2-python.libraries.settings import dropboxToken

  File "upload_log.py", line 9
    from snugupdate-v2-python.libraries.settings import dropboxToken
                   ^
SyntaxError: invalid syntax

WHY? 

https://docs.python.org/2/reference/lexical_analysis.html
2.3. Identifiers and keywords
Identifiers (also referred to as names) are described by the following lexical
definitions:

identifier ::=  (letter|”_”) (letter | digit | “_”)*
letter     ::=  lowercase | uppercase
lowercase  ::=  “a”…”z”
uppercase  ::=  “A”…”Z”
digit      ::=  “0”…”9”

Identifiers are unlimited in length. Case is significant.

https://docs.python.org/2/reference/simple_stmts.html#import
6.12. The import statement

import_stmt     ::=  “import” module [“as” name] ( “,” module [“as” name] )*
                     | “from” relative_module “import” identifier [“as” name]
                     ( “,” identifier [“as” name] )*
                     | “from” relative_module “import” “(” identifier [“as” name]
                     ( “,” identifier [“as” name] )* [“,”] “)”
                     | “from” module “import” “*”

module          ::=  (identifier “.”)* identifier

So `module cannot have '-'` and to get it around:

sys.path.append('snugupdate-v2-python/')
from libraries import settings


<py-package-relative>
The coverage of package imports so far has focused mostly on importing package
files from outside the package. Within the package itself, imports of
same-package files can use the same full path syntax as imports from outside
the package—and as we’ll see, sometimes should. However, package files can
also make use of special intrapackage search rules to simplify import
statements. That is, rather than listing package import paths, imports within
the package can be relative to the package.

*py-3*
3.X requires explicit relative import syntax in order to import from the
package directory. This 3.X change can enhance code readability by making
same-package imports more obvious, but it’s also incompatible with 2.X and may
break some programs.

Why Relative Imports?

o The downside of using an absolute name, such as mypackage.A, is that it
  hardcodes the top-level package name into your source code. This makes your
  code more brittle and hard to work with if you ever want to reorganize it.

o this feature is designed in part to allow scripts to resolve ambiguities
  that can arise when a same-named file appears in multiple places on the
  module search path.

For example, assume that package has string module:

mypkg\
  __init__.py
  main.py
  string.py

The problem:

Within a package, it’s not clear whether an import spam statement refers to a
module within or outside the package. As one consequence, a local module or
package can hide another hanging directly off of sys.path, whether
intentionally or not.

In practice, Python users can avoid reusing the names of standard library
modules they need for modules of their own. But this doesn’t help if a package
accidentally hides a standard module; moreover, Python might add a new
standard library module in the future that has the same name as a module of
your own.

It’s better if the resolution can be made `explicit in code.`

*py-3*
make it explicit if it is either absolute or relative

import string
from string import name

find a string module outside the package, via an absolute import search of
sys.path

from . import string
from .string import name1, name2  # Imports names from mypkg.string
from .. import spam               # Imports a sibling of mypkg
from ..E import X                 # Imports A.E.X (.. means A)

relative imports are possible ONLY if you use `the dot syntax in the from`
statement since relative imports apply to the from statement only.


the difference between py-2 and py-3:

Imports with dots: always relative

Imports without dots: In 2.X, normal imports use a relative-then-absolute
search path order and in 3.x, absolute only.

note: As we’ll see later, Python 3.3 adds another flavor to modules—namespace
packages


*py-error*
This is error since relative is supposed to be used in package but used out of
package or when there is no such package

>>> from . import string
SystemError: Parent module '' not loaded, cannot perform relative import


<ex>
Example when shows difference between py-2 and py-3. py-2 works since use a
relative-then-absolute.

# code\pkg\spam.py
import eggs                 # <== Works in 2.X but not 3.X!
print(eggs.X)

# code\pkg\eggs.py
X = 99999
import string
print(string)

kyoupark@kit-debian64:~/git/kb/code-py/pybase/module/pkg$ ll
total 20
drwxr-xr-x 3 kyoupark kyoupark 4096 Feb 15 00:05 ../
-rw-r--r-- 1 kyoupark kyoupark   22 Feb 15 00:06 __init__.py
-rw-r--r-- 1 kyoupark kyoupark   43 Feb 15 00:07 spam.py
-rw-r--r-- 1 kyoupark kyoupark   56 Feb 15 00:08 egg.py

kyoupark@kit-debian64:~/git/kb/code-py/pybase/module$ python
Python 2.7.9 (default, Jun 29 2016, 13:08:31) 
[GCC 4.9.2] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import pkg.spam
pkg.__init__
<module 'string' from '/usr/lib/python2.7/string.pyc'>
99999

kyoupark@kit-debian64:~/git/kb/code-py/pybase/module$ python3
Python 3.4.2 (default, Oct  8 2014, 10:45:20) 
[GCC 4.9.1] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import pkg.spam
pkg.__init__
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/kyoupark/git/kb/code-py/pybase/module/pkg/spam.py", line 2, in <module>
    import egg
ImportError: No module named 'egg'


={============================================================================
|kt_dev_py_0001| py-module-advanced

Learning Python 5E, 25, Advanced Module Topics

Data Hiding in Modules

There is no notion of declaring which names should and shouldn't be visible
outside the module. In fact, there's no way to prevent a client from changing
names inside a module if it wants to.  

In Python, data hiding in modules is a convention, not a syntactical
constraint.


Minimizing from * Damage: _X and __all__

a single underscore (e.g., _X) to prevent them from being copied out when a
client imports a module's names with a `from *` statement to minimise
namespace pollution.

Underscores aren't "private" declarations: you can still see and change such
names with other import forms, such as the `import` statement:

# unders.py
a, _b, c, _d = 1, 2, 3, 4
>>> from unders import * # Load non _X names only
>>> a, c
(1, 3)
>>> _b
NameError: name '_b' is not defined
>>> import unders # But other importers get every name
>>> unders._b
2


Alternatively, you can achieve a hiding effect similar to the _X naming
convention by assigning a list of variable name strings to the variable
__all__ at the top level of the module.

When this feature is used, the from * statement will copy out only those names
listed in the __all__ list. In effect, this is the converse of the _X
convention: __all__ identifies names to be copied, while _X identifies names
not to be copied.

Python looks for an __all__ list in the module first and copies its names
irrespective of any underscores; if __all__ is not defined, from * copies all
names without a single leading underscore:

# alls.py
__all__ = ['a', '_c']                 # __all__ has precedence over _X
a, b, _c, _d = 1, 2, 3, 4

>>> from alls import *                # Load __all__ names only
>>> a, _c
(1, 3)
>>> b
NameError: name 'b' is not defined

>>> from alls import a, b, _c, _d     # But other importers get every name
>>> a, b, _c, _d
(1, 2, 3, 4)

>>> import alls
>>> alls.a, alls.b, alls._c, alls._d
(1, 2, 3, 4)


<py-future>
Enabling Future Language Features: __future__

Changes to the language that may potentially break existing code are usually
introduced gradually in Python. They often initially appear as optional
extensions, which are disabled by default. To turn on such extensions, use a
special import statement of this form:

from __future__ import featurename

When used in a script, this statement must appear as the first executable
statement in the file (possibly following a docstring or comment), because it
enables special compilation of code on a per-module basis. It’s also possible
to submit this statement at the interactive prompt to experiment with upcoming
language changes; the feature will then be available for the remainder of the
interactive session.


The as Extension for import and from

allow an imported name to be given a different name in your script.

import modulename as name                 # And use name, not modulename

This works in a from statement, too

from modulename import attrname as name   # And use name, not attrname


Example: Modules Are Objects <introspection>

the module's attribute dictionary, exposed in the built-in __dict__ attribute
we met in Chapter 23. Python also exports the list of all loaded modules as
the sys.modules dictionary and provides a built-in called getattr that lets us
fetch attributes from their string names

all the following expressions reach the same attribute and object:

M.name                  # Qualify object by attribute
M.__dict__['name']      # Index namespace dictionary manually
sys.modules['M'].name   # Index loaded-modules table manually

# *py-getattr* getattr(object, name[, default])

getattr(M, 'name')      # Call built-in fetch function


Statement Order Matters in Top-Level Code

Python executes its statements one by one, from the top of the file to the
bottom.

* Code at the top level of a module file (not nested in a function) runs as
soon as Python reaches it during an import; because of that, it cannot
reference names assigned lower in the file.

* Code inside a function body `doesn’t run until the function is called`;
because names in a function aren’t resolved until the function actually runs,
        they can usually reference names anywhere in the file.

As a rule of thumb, if you need to mix immediate code with defs, put your defs
at the top of the file and your top-level code at the bottom. That way, your
functions are guaranteed to be defined and assigned by the time Python runs
the code that uses them.


from Copies Names but Doesn’t Link

the from statement is really an assignment to names in the importer's scope—a
`name-copy operation`, not a name aliasing. The implications of this are the
same as for all assignments in Python see *shared-reference*

# nested1.py
X = 99
def printer(): print(X)

# nested2.py
from nested1 import X, printer    # Copy names out
X = 88                            # Changes my "X" only which is local version
printer()                         # nested1's X is still 99

% python nested2.py
99

If we use import to get the whole module and then assign to a qualified name,
however, we change the name in nested1.py.

# nested3.py
import nested1                  # Get module as a whole
nested1.X = 88                  # OK: change nested1's X
nested1.printer()

% python nested3.py
88


={============================================================================
|kt_dev_py_0001| py-module-main-name py-shell-script

Mixed Usage Modes: __name__ and __main__

each module has a built-in attribute called __name__, which Python creates and
assigns automatically as follows:

* If the file is being run as a top-level program file, __name__ is set to the
  string "__main__" when it starts.

* If the file is being imported instead, __name__ is set to the module’s name
  as known by its clients.

The upshot is that a module can test its own __name__ to determine 
`whether it's being run or imported.`

In effect, a module’s __name__ variable serves as a `usage mode flag`,
allowing its code to be leveraged as both an importable library and a
  top-level script.

Coding self-test code at the bottom of a file under the __name__ test is
probably the most common and simplest unit-testing protocol in Python.

In addition, the __name__ trick is also commonly used when you’re writing
files that can be used both as command-line utilities and as tool libraries.


<reference>
29.4. __main__ — Top-level script environment

'__main__' is the name of the `scope` in which top-level code executes. A
module's __name__ is set equal to '__main__' when read from standard input, a
script, or from an interactive prompt.

A module can discover whether or not it is running in the `main-scope` by
checking its own __name__, which allows a common idiom for conditionally
executing code in a module when it is run `as-a-script` or with python -m but
not when it is imported:

if __name__ == "__main__":
    # execute only if run as a script
    main()

For a package, the same effect can be achieved by including a __main__.py
module, the contents of which will be executed when the module is run with -m.

<reference>
Python Scripts as a Replacement for Bash Utility Scripts

http://www.linuxjournal.com/content/python-scripts-replacement-bash-utility-scripts?page=0,0

Pros:

Python is a fully featured programming language. Code reuse is simple, because
Python modules easily can be imported and used in any Python script. Scripts
easily can be extended or built upon.

Python has access to an excellent standard library and thousands of third-party
libraries for all sorts of advanced utilities, such as parsers and request
libraries. For instance, Python's standard library includes datetime libraries
that allow you to parse dates into any format that you specify and compare it to
other dates easily. 

There are a lot of aspects to Python in the shell that go beyond the scope of
  this article, such as the os module and the subprocess module. The os module
  is a standard library function that holds a lot of key operating system-level
  operations, such as listing directories and stating files, along with an
  excellent submodule os.path that deals with normalizing directories paths. The
  subprocess module allows Python programs to run system commands and other
  advanced operations, such as handling piping as described above within Python
  code between spawned processes. Both of these libraries are worth checking out
  if you intend to do any Python shell scripting. 


<ex>
#!/usr/bin/env python
import sys

if __name__ == "__main__":

    # initialize a names dictionary as empty to start with.
    # each key in this dictionary will be a name and the value will be
    # the number of times that names appears. name-value-pair
    names = {}

    # sys.stdin is a file object. all the same functions that can be
    # applied to a file object can be applied to sys.stdin. 
    for name in sys.stdin.readlines():

        # each line will have a newline on the end that should be
        # removed.
        name = name.strip()

        if name in names:
            names[name] += 1
        else:
            names[name] = 1

    # iterating over the dictionary. print name followed by a space and 
    # the number of times it appeared.
    for name, count in names.iteritems():
        sys.stdout.write("%d\t%s\n" % (count, name))


$ cat names.log | python namescount.py


={============================================================================
|kt_dev_py_0001| py-module-extension

As mentioned in the preceding chapter, it is also possible to create a Python
module by writing code in an external language such as C, C++, and others
(e.g., Java, in the Jython implementation of the language). Such modules are
called extension modules, and they are generally used to wrap up external
libraries for use in Python scripts. When imported by Python code, extension
modules look and feel the same as modules coded as Python source code
files—they are accessed with import statements, and they provide functions and
objects as module attributes. Extension modules are beyond the scope of this
book; see Python’s standard manuals or advanced texts such as Programming
Python for more details.


={============================================================================
|kt_dev_py_0001| py-function

LPY5, 16, Function Basics

Functions are declared using the `def` keyword and returned from using the
`return` keyword:

def my_function(x, y, z=1.5):
  if z > 1:
    return z * (x + y)
  else:
    return z / (x + y)

If the end of a function is reached without encountering a return statement,
`None` is returned.


{py-function-objects}

import re

# apply str functions to remove puncuations

def clean_strings(strings):

    result = []

    for e in strings:
        e = e.strip()
        e = re.sub('[!?#]', '', e)
        e = e.title()
        result.append(e)

    return result

# py-resulable it is more resuable

def clean_strings_use_ops(strings, ops):

    result = []

    for e in strings:
        for f in ops:
            e = f(e)
        result.append(e)

    return result

def remove_punctuation(value):
    return re.sub('[!?#]', '', value)


class TestFunction(unittest.TestCase):
    
    def setUp(self):
        print("====================")
        print("[RUN] ", self._testMethodName)

    def test_function_objects(self):

        states = [' Alabama ', 'Georgia!', 'FlOrIda', 
                'south carolina##', 'West virginia?']

        result = clean_strings(states)

        self.assertEqual(result, 
                ['Alabama', 'Georgia', 'Florida', 
                    'South Carolina', 'West Virginia'])

        # use list of operations
        # *py-fobj* if change remove_punctuation() then have to redefine
        # clean_ops again since clean_ops has old function address
        # 
        # defining a function with same name will create function on different
        # address

        clean_ops = [str.strip, remove_punctuation, str.title]

        result = clean_strings_use_ops(states, clean_ops)

        self.assertEqual(result, 
                ['Alabama', 'Georgia', 'Florida', 
                    'South Carolina', 'West Virginia'])


A more `functional pattern` like this enables you to easily modify how the
strings are transformed at a very high level. The clean_strings function is
also now more reusable!


<py-function-arg-type>

o Functions are `typeless`

The very meaning of the expression x * y in our simple times function depends
completely upon the kinds of `objects` that x and y are - thus, the same
function can perform multiplication in one instance and repetition in another.
Python leaves it up to the objects to do something reasonable for the syntax.

function works on arbitrary types, `as long as` they support the expected
object interface.

In _intersect(), first argument has to support iterator , and the second has
to support the in membership test.

    def _times(self, x, y):
        return x * y

    def _intersect(self, coll1, coll2):
        result = []

        for e in coll1:
            if e in coll2:
                result.append(e)

        return result

    def test_function_arg_type(self):

        result = self._times(2, 4)
        self.assertEqual(result, 8)

        result = self._times(3.14, 4)
        self.assertEqual(result, 12.56)

        result = self._times('Ni', 4)
        self.assertEqual(result, 'NiNiNiNi')

        # see that TypeError gets raised from _times()
        #
        # Traceback (most recent call last):
        #   File "/home/kyoupark/git/kb/code-py/pybase/pycore.py", line 1778, in test_function_arg_type
        #     result = self._times('Ni', 'Pi')
        #   File "/home/kyoupark/git/kb/code-py/pybase/pycore.py", line 1765, in _times
        #     return x * y
        # TypeError: can't multiply sequence by non-int of type 'str'

        with self.assertRaises(TypeError):
            result = self._times('Ni', 'Pi')

        #
        result = self._intersect([1, 2, 3], (1, 4))
        self.assertEqual(result, [1])


<py-way-on-type> *py-difference*
If the objects passed in do not support this expected interface, Python will
detect the error when the * expression is run and raise an exception
automatically. It's therefore usually pointless to code error checking
ourselves. (error checking on type) In fact, doing so would limit our
function's utility, as it would be restricted to work only on objects whose
types we test for.

This turns out to be a crucial philosophical difference between Python and
statically typed languages like C++ and Java: in Python, your code is not
supposed to care about specific data types. If it does, it will be limited to
working on just the types you anticipated when you wrote it, and it will not
support other compatible object types that may be coded in the future.
Although it is possible to test for types with tools like the type built-in
function, doing so breaks your code's flexibility. 

By and large, we code to object `interfaces` in Python, not data types.

This polymorphic model of programming means we have to test our code to detect
errors, rather than providing type declarations a compiler can use to detect
some types of errors for us ahead of time. 

In exchange for an initial bit of testing, though, we radically reduce the
`amount of code` we have to write and radically increase our code's `flexibility`.
As you'll learn, it's a net win in practice.


={============================================================================
|kt_dev_py_0001| py-function-namespace

LPY5, 17, Scopes

<py-namespace> *py-assign* *py-difference*

The term `scope` refers to a namespace: that is, the location of a name's
`assignment` in your source code determines the scope of the name's visibility
to your code. 

Functions can access variables in two different scopes: global and local. An
alternate and more descriptive name describing a variable scope in Python is a
namespace.

As names in Python spring into existence when they are first assigned values,
and Python uses the location of the assignment of a name to associate it with
  a particular namespace. In other words, the place where you assign a name in
  your source code determines the namespace it will live in, and hence its
  scope of visibility.

all names assigned inside a function are associated with that function's
namespace

o If a variable is assigned inside a def, it is `local` to that function.

o If a variable is assigned in an enclosing def, it is `non-local` to nested
  functions.

o If a variable is assigned outside all defs, it is `global` to the entire
  file.


<py-global> *py-difference*
The global scope `spans a single file only.` 

There is really no notion of a single, all-encompassing global file-based
scope in Python. 

Instead, names are partitioned into modules, and you must always import a
module explicitly if you want to be able to use the names its file defines.
`When you hear "global" in Python, think "module."`

<ex> py-global
# example of global module name
#!/usr/bin/env python

CL_STATUS_OK = 0
CL_STATUS_ERROR = 1

if __name__ == "__main__":
    pass

Use

import scripts.common.cmdLine as cmdLine

def func (branch, tag, dir):
    retVal = cmdLine.CL_STATUS_ERROR


<py-name-resolution>
Name Resolution: The LEGB Rule

Name references search at most four scopes: (L)local, then (E)enclosing
functions (if any), then (G)global, then (B)built-in.

E - the scopes of enclosing defs or lambdas - 
can technically correspond to more than one lookup level. This case only comes
into play when you nest functions within functions, and is enhanced by the
nonlocal statement in 3.X.

so E matters for lambda if not use 3.X.


<local-name-detected> *py-error-unbound*

Local Names Are Detected Statically, Chapter 21: The Benchmarking Interlude

What you may not realize is that Python detects locals statically, when it
compiles the def’s code, rather than by noticing assignments as they happen at
runtime. This leads to one of the most common oddities posted on the Python
newsgroup by beginners. 

# globals

X = 99

def selector1():
    print(X)

def selector2():
    print(X)
    X = 88

    #   File "/home/kyoupark/git/kb/code-py/pybase/pycore.py", line 1737, in selector2
    #     print(X)
    # UnboundLocalError: local variable 'X' referenced before assignment

    def test_function_local_namespace(self):
        selector1()

        with self.assertRaises(UnboundLocalError):
            selector2()

While compiling, sees the assignment to X and decides that X will be a local
name everywhere in the function. But the assignment hasn’t yet happened when
the print executes, Python says you’re using an undefined name.


<py-closures> *py-callable*
closure is any `dynamically-generated function` returned by another function.

The key property is that the returned function has access to the variables in
the local namespace where it was created. Here is a very simple example:


    def _make_closure(self, value):

        def closure():
            return 'value is ' + str(value)

        return closure

    def test_function_closure_1(self):
        clo = self._make_closure(5)

        self.assertEqual(clo(), 'value is 5')
        self.assertEqual(clo(), 'value is 5')
        self.assertEqual(clo(), 'value is 5')


The difference between a closure and a regular function is that the closure
continues to have access to the namespace (the function) where it was created,
even though that function is done executing. 

So in the above case, the returned closure will always return the same

While it's common to create closures whose internal state  is `static`, you
can just as easily have a `mutable` object like a dict, set, or list that can
be modified. For example, here's a function that returns a function that keeps
track of arguments it has been called with:


As *local-name-detected* above, one technical limitation to keep in mind is
that while you can mutate any internal state objects, you cannot bind
`variables` in the enclosing function scope. One way to work around this is to
modify a dict or list rather than binding variables:


    def _make_counter(self):
        count = [0]

        def counter():
            count[0] += 1
            return count[0]

        return counter

    def test_function_closure_2(self):
        clo = self._make_counter()

        self.assertEqual(clo(), 1)
        self.assertEqual(clo(), 2)
        self.assertEqual(clo(), 3)


>>> def make_counter_two():
...     count = 0
...     def counter():
...             count +=1
...             return count
...     return counter
... 
>>> cnt_two = make_counter_two()
>>> cnt_two
<function counter at 0xb75126f4>
>>> cnt_two()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 4, in counter
UnboundLocalError: local variable 'count' referenced before assignment


py-closure is useful? 
  
In practice, you can write very `general functions` with lots of options, then
fabricate simpler, more specialized functions. Here's an example of creating a
string formatting function:

    def _format_and_pad(self, format, space):
        def formatter(x):
            return (format % x).rjust(space)
        return formatter

    def test_function_closure_3(self):
        clo = self._format_and_pad('%.4f', 15)

        self.assertEqual(clo(1.756), '         1.7560')
        self.assertEqual(clo(1.7), '         1.7000')
        self.assertEqual(clo(1), '         1.0000')

If you learn more about object-oriented programming in Python, you might
observe that these patterns also could be implemented (albeit more verbosely)
using classes.


={============================================================================
|kt_dev_py_0001| py-function-lambda

{py-lambda}

Anonymous or lambda functions, which are really just simple functions
consisting of a single statement, the result of which is the return value.
They are defined using the `lambda keyword`

They are especially convenient in data analysis because, as you'll see, there
are many cases where data transformation functions will take functions as
arguments. It's often less typing (and clearer) to pass a lambda function as
opposed to writing a full-out function declaration or even assigning the
lambda function to a local variable. For example, consider this silly example:

    def _apply_to_list(self, coll, f):
        return [f(e) for e in coll]

    def test_function_lambda(self):

        coll = [4,0,1,5,6]
        result = self._apply_to_list(coll, lambda x: x * 2)
        self.assertEqual(result, 
                [8, 0, 2, 10, 12])

You could also have written [x * 2 for x in ints], but here we were able to
succintly pass a custom operator to the apply_to_list function.


={============================================================================
|kt_dev_py_0001| py-function-arguments

LPY5, 18, Arguments

arguments are passed by assignment. if explians in C way:

o Immutable arguments are effectively passed “by value.” Objects such as
  integers and strings are passed by object reference instead of by copying,
  but because you can’t change immutable objects in place anyhow, the effect is
  much like making a copy.

  *py-reference*
o `Mutable arguments are effectively passed “by pointer.”` Objects such as lists
  and dictionaries are also passed by object reference, which is similar to
  the way C passes arrays as pointersmutable objects can be changed in place
  in the function, much like C arrays.

  Python’s pass-by-assignment scheme isn’t quite the same as C++’s reference
  parameters option,

Of course, if you’ve never used C, Python’s argument-passing mode will seem
simpler still - it involves just the assignment of objects to names, and it
works the same "whether the objects are mutable or not."


    def _f(self, a):
        a = 99

    def _changer(self, a, b):
        a = 2
        b[0] = 'spam'

    def test_function_argument(self):

        b = 88

        self._f(b)

        # expected the change of b? no.
        self.assertEqual(b, 88)

        X = 1
        L = [1, 2]
        self._changer(X, L)

        # expected the change of L? yes.
        self.assertEqual(L, ['spam', 2])


Argument Matching Basics

By default, arguments are matched by position, from left to right, and you
must pass exactly as many arguments as there are argument names in the
function header. However, you can also specify matching by name, provide
default values, and use collectors for extra arguments.


Positionals: matched from left to right

The normal case, which we’ve mostly been using so far, is to match passed
argument values to argument names in a function header by position, from left
to right.


Keywords: matched by argument name

Alternatively, callers can specify which argument in the function is to
receive a value by using the argument’s name in the call, with the name=value
syntax.


Defaults: specify values for optional arguments that aren’t passed

Functions themselves can specify default values for arguments to receive if
the call passes too few values, again using the name=value syntax.

Syntax                Location  Interpretation

func(value)           Caller    Normal argument: matched by position

func(name=value)      Caller    Keyword argument: matched by name

def func(name)        Function  Normal argument: matches any passed value 
                                by position or name

def func(name=value)  Function  Default argument value


<py-function-arguments-order>

If you choose to use and combine the special argument-matching modes, Python
will ask you to follow these ordering rules among the modes’ optional
components:

o In a function call, arguments must appear in this order: any positional
  arguments (value); followed by a combination of any keyword arguments
  (name=value) and the *iterable form; followed by the **dict form.

o In a function header, arguments must appear in this order: any normal
  arguments (name); followed by any default arguments (name=value); followed
  by the *name (or * in 3.X) form; followed by any name or name=value
  keyword-only arguments (in 3.X); followed by the **name form.


<varargs> <py-star>
`Varargs collecting`: collect arbitrarily many positional or keyword arguments

Functions can use special arguments preceded with `one or two * characters` to
collect an arbitrary number of possibly extra arguments. This feature is often
referred to as varargs, after a variable-length argument list tool in the C
language; in Python, the arguments are collected in a normal object.

def func(*name)   Function  Matches and collects remaining positional arguments 
                            in a `tuple`

def func(**name)  Function  Matches and collects remaining keyword arguments 
                            in a `dictionary`


    def _print_variable_args(self, *arg, **karg):
        print(arg, karg)

    # [RUN]  test_function_vaarg
    # () {}
    # (1,) {}
    # (1, 2, 3) {}
    # (1, 2, 3) {'a': 1, 'b': 2}

    def test_function_vaarg(self):            
        self._print_variable_args()
        self._print_variable_args(1)
        self._print_variable_args(1,2,3)
        self._print_variable_args(1,2,3, a = 1, b = 2)


`Varargs unpacking`: pass arbitrarily many positional or keyword arguments

*py-star*
Callers can also use the * syntax to unpack argument collections into separate
arguments. This is the inverse of a * in a function header; in the header it
means collect arbitrarily many arguments, while in the call it means unpack
arbitrarily many arguments, and pass them individually as discrete values.

func(*iterable)   Caller    `pass` all objects in iterable as individual 
                            positional arguments

func(**dict)      Caller    pass all `key/value pairs in dict` as individual 
                            keyword arguments


    def _print_variable_tuple(self, a, b, c, d):
        print(a, b, c, d)

    # [RUN]  test_function_vaarg_2
    # (1, 2, 3, 4) {}
    # 1 2 3 4
    # 1 2 3 4

    def test_function_vaarg_2(self):            
        coll  = (1,2,3,4)
        self._print_variable_args(*coll)
        self._print_variable_tuple(*coll)

        coll = {'a':1, 'b':2, 'c':3, 'd':4}
        # same as func(a=1, b=2, c=3, d=4)
        self._print_variable_tuple(**coll)


={============================================================================
|kt_dev_py_0001| py-class

LPY5, 27, Class Coding Basics

o `assignments inside class` statements make `class attributes.` 

  Just like in module files, top-level assignments within a class statement
  (not nested in a def) generate attributes in a class object. Technically,
  the class statement defines a local scope that morphs into the attribute
  namespace of the class object, just like a module’s global scope. After
  running a class statement, class attributes are accessed by name
  qualification: object.name.

  *py-assign*
  As with everything else in Python, there are no declarations for instance
    attributes (sometimes called members); they spring into existence the
    first time they are assigned values, just like simple variables.

o class attributes, data and function, provide object state and behavior. 

  Attributes of a class object record state information and behavior to be
  shared by all instances created from the class; function def statements
  nested inside a class generate methods, which process instances.

o Each instance object inherits class attributes and gets its own namespace.

  Instance objects created from classes are new namespaces; they start out
  empty but inherit attributes that live in the class objects from which they
  were generated.


<py-class-inheritance>
Superclasses are listed in parentheses in a class header. To make a class
inherit attributes from another class, just list the other class in
parentheses in the new class statement’s header line. The class that inherits
is usually called a subclass, and the class that is inherited from is its
superclass.

<ex>

class FirstClass:

    def set_data(self, value):
        self.data = value

    def display(self):
        # print(self.data)
        # return self.data
        return 'superclass: data is {}'.format(self.data)

    def print_data(self):
        return 'superclass: data is {}'.format(self.data)

class SubClass(FirstClass):

    def display(self):
        return 'subclass: data is {}'.format(self.data)

# py-overload

class ThirdClass(SubClass):

    # ctor. ThirdClass(value). 
    # Q: possible to have other ctors?

    def __init__(self, value):
        print("ThirdClass: ctor: value {}".format(value))
        self.data = value

    # + operator.

    def __add__(self, other):
        print("ThirdClass: add: value {}".format(self.data + other.data))
        return ThirdClass(self.data + other.data)

    # print(instance) or instance.str()

    def __str__(self):
        print("ThirdClass: str: value {}".format(self.data))
        return "ThirdClass data {}".format(self.data)

    # this is function that intentionally wrong and not evaluated unless used.

    def xxx(self):
        print("ThirdClass: str: value {}" % (self.data))
        return xxx


class TestClass(unittest.TestCase):

    def setUp(self):
        print('====================')
        print('[RUN] ', self._testMethodName)

    # name should start with "test_" and otherwise, will not be run.
    def test_class_attribute(self):

        # create two instances which has own namespace

        o1 = FirstClass()
        o2 = FirstClass()

        o1.set_data("King Arthur")
        o2.set_data(3.1459)

        self.assertEqual(o1.display(), 
                'superclass: data is King Arthur')
        self.assertEqual(o2.display(), 
                'superclass: data is 3.1459') 

        # no type, no access control

        o1.data = "Type Checking?"
        self.assertEqual(o1.display(), 
                'superclass: data is Type Checking?')

        o2.data = "Access Control?"
        self.assertEqual(o2.display(), 
                'superclass: data is Access Control?')

    def test_class_inheritance(self):

        o1 = SubClass()

        # *py-assign* *py-error-unbound*

        # if do not call set_data(), no `data` attribute is created.
        # since __init__() is not used

        # if we were to call display on one of our instances before calling
        # setdata, we would trigger an undefined name error—the attribute
        # named data doesn’t even exist in memory until it is assigned within
        # the setdata method.

        o1.set_data("SubClass")

        self.assertEqual(o1.display(), 
                'subclass: data is SubClass')

        # use it for free
        self.assertEqual(o1.print_data(), 
                'superclass: data is SubClass')


<py-class-module> *py-import*
class name’s just a variable assigned to an object when the `class` statement
runs and become module attributes. Each module may arbitrarily mix any number
of variables, functions, and classes, and all names in a module behave the
same way.

from modulename import FirstClass     # Copy name into my scope
  class SecondClass(FirstClass): 
    def display(self): ...

import modulename                     # Access the whole module
  class SecondClass(modulename.FirstClass):
    def display(self): ...


<py-convention>
common convention in Python dictates that class names should begin with an
uppercase letter

import person         # Lowercase for modules
x = person.Person()   # Uppercase for classes


<py-class-overload> *py-overload*

o Methods named with double underscores (__X__) are special hooks. In Python
  classes we implement operator overloading by providing specially named
  methods to intercept operations. The Python language defines a `fixed` and
  unchangeable mapping from each of these operations to a specially named
  method.

o Such methods are called automatically when instances appear in built-in
  operations. 

o a user-defined object to a function that was coded to expect the operators
  available on a built-in type.
  
  
the `__init__` method, which is known as the constructor method and is used to
initialize objects’ state. You should pay special attention to this method,
      because __init__, along with the self argument, turns out to be a key
        requirement to reading and understanding most OOP code in Python.

<ex>

    # [RUN]  test_class_operator_overload
    # ThirdClass: ctor: value 100
    # ThirdClass: ctor: value 200
    # ThirdClass: add: value 300
    # ThirdClass: ctor: value 300
    # ThirdClass: str: value 300
    # ThirdClass data 300
    # ThirdClass: str: value 300
    # ThirdClass data 300

    def test_class_operator_overload(self):

        # py-error
        # TypeError: __init__() takes exactly 2 arguments (1 given)
        # o1 = ThirdClass()

        o1 = ThirdClass(100)
        o2 = ThirdClass(200)

        o3 = o1 + o2

        # both are same

        print(o3)
        print("{}".format(str(o3)))


<py-class-print-object> *py-repr*
As with C++ operator<<(), to print object, overload __repr__ or __str__.

__str__ is preferred by print and str, and __repr__ is used as a fallback for
these roles and in all other contexts. Because we’re not interested in
displaying two different formats, `so coding just __repr__ alone suffices` to
give a single display in all casesprints, nested appearances, and interactive
echoes.

Technically, the difference between default interactive echoes and print
corresponds to the difference between the built-in repr and str functions:

>>> repr('spam')  # Used by echoes: as-code form
"'spam'"
>>> str('spam')   # Used by print: user-friendly form
'spam'

Both of these convert arbitrary objects to their string representations: repr
(and the default interactive prompt) produces results that look as though they
were code; str (and the print operation) converts to a typically more
user-friendly format if available. Some objects have botha str for general
use, and a repr with extra details.


<py-class-name-resolution>
Recall that inheritance searches proceed upward from instances to subclasses
to superclasses, stopping at the first appearance of the attribute name that
it finds. In this case, since the display name in SecondClass will be found
before the one in First Class, we say that SecondClass overrides FirstClass’s
display. the inheritance search rule applied to the method’s `name`.

class Person:

    # *py-default-argument*
    # As with C++, any arguments in a function header after the first default
    # must all have defaults, too:

    def __init__(self, name, job=None, pay=0):
        self.name = name
        self.job = job
        self.pay = pay

    def lastName(self):
        return self.name.split()[-1]

    def giveRaise(self, percent):
        self.pay = int(self.pay * (1 + percent))

    def __repr__(self):
        return '[Person: %s, %s, %s]' % (self.name, self.job, self.pay)

class Manager(Person):

        # because Manager had no __init__ constructor, it inherits that
        # in Person.

    def giveRaise(self, percent, bonus=.10):

        # *py-override*
        # Same result but bad way: cut and paste
        # The problem here is a very general one: anytime you copy code with cut
        # and paste, you essentially double your maintenance effort in the
        # future.
        # self.pay = int(self.pay * (1 + percent + bonus)) 

        # *py-class-call-base-version*
        # Good: augment original
        Person.giveRaise(self, percent + bonus)

class ManagerImproved(Person):

    # redefine ctor
    def __init__(self, name, pay):
        Person.__init__(self, name, 'manager', pay)

    def giveRaise(self, percent, bonus=.10):
        # Bad: cut and paste
        # self.pay = int(self.pay * (1 + percent + bonus)) 

        # *py-class-call-base-version*
        # Good: augment original
        Person.giveRaise(self, percent + bonus)


# ====================
# [RUN]  test_manager_class
# [Person: Tom Jones, None, 0]
# [Person: Ian King, 1000, 0]
# [Person: Pat King, 1000, manager]
# [Person: Susan King, manager, 1000]
#
# .====================
# [RUN]  test_preson_class
# [Person: Bob Smith, None, 0]
# [Person: Sue Jones, dev, 100000]
# Smith Jones
# [Person: Sue Jones, dev, 110000]
# == overrides ==
# Jones
# [Person: Tom Jones, mgr, 60000]
# == all three ==
# [Person: Bob Smith, None, 0]
# [Person: Sue Jones, dev, 121000]
# [Person: Tom Jones, mgr, 72000]

class TestPerson(unittest.TestCase):

    def setUp(self):
        print('====================')
        print('[RUN] ', self._testMethodName)
    
    def test_preson_class(self):
        bob = Person('Bob Smith')
        sue = Person('Sue Jones', job='dev', pay=100000)
        print(bob)
        print(sue)
        print(bob.lastName(), sue.lastName())
        sue.giveRaise(.10)
        print(sue)

        #
        print("== overrides ==")
        tom = Manager('Tom Jones', 'mgr', 50000)
        tom.giveRaise(.10)
        print(tom.lastName())
        print(tom)

        # py-class-polymorphism
        print("== all three ==")
        for obj in (bob, sue, tom):
            obj.giveRaise(.10)
            print(obj)

    def test_manager_class(self):
        tom = Manager('Tom Jones')
        print(tom)

        ian = Manager('Ian King', 1000)
        print(ian)

        pat = Manager('Pat King', 1000, 'manager')
        print(pat)

        sus = ManagerImproved('Susan King', 1000)
        print(sus)


<py-class-nested>
From py-descriptor example:

class Person:
  def __init__(self, name):
    self._name = name

    class Name: # Using a nested class
      "name descriptor docs"
      def __get__(self, instance, owner):
        print('fetch...')
        return instance._name

      def __set__(self, instance, value):
        print('change...')
        instance._name = value

      def __delete__(self, instance):
        print('remove...')
        del instance._name

    name = Name()


When coded this way, Name becomes a local variable in the scope of the Person
class statement, such that it won’t clash with any names outside the class.


<py-class-composition>

Chapter 28: A More Realistic Example

class CompositeManager:

    # has a person
    def __init__(self, name, pay):
        self.person = Person(name, 'manager', pay)

    # forwards instead
    def giveRaise(self, percent, bonus=.10):
        # Person.giveRaise(self, percent + bonus)
        self.person.giveRaise(percent + bonus)

    # delegate all other attrs
    # *py-getattr* *py-overload*
    # since this class do not use inheritance, all attribute fetch request comes
    # to this and forward them to the composite.

    def __getattr__(self, attr):
        return getattr(self.person, attr)

    # must overload in 3.x and 2.x is okay with/without this
    # (in 3.X, at least, as noted in the upcoming sidebar "Catching Built-in
    # Attributes in 3.X" on page 839);

    def __repr__(self):
        return str(self.person)

class TestComposite_1(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName
    
    def test_composite_manager_class(self):
        tom = Manager('Tom Jones')
        print(tom)

        ian = Manager('Ian King', 1000)
        print(ian)

        pat = Manager('Pat King', 1000, 'manager')
        print(pat)

        sus = ManagerImproved('Susan King', 1000)
        print(sus)


class Department:
    def __int__(self, *args):
        self.members = list(args)

    def addMember(self, person):
        self.members.append(person)

    def giveRaises(self, percent):
        for person in self.members:
            person.giveRaise(percent)

    def showAll(self):
        for person in self.members:
            print(person)

class TestComposite_2(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName
    
    def test_department_class(self):
        bob = Person('Bob Smith')
        sus = Person('Sue Jones', job='dev', pay=10000)
        tom = Manager('Tom Jones', 50000)

        development = Department(bob, sus)
        development.addMember(tom)
        development.giveRaises(.10)
        development.showAll()


<py-class-extend-builtin>

# LPY5, Chapter 32: Advanced Class Topics
# Extending Types by Embedding

class Set:
    def __init__(self, value = []):
        self.data = []
        # *py-class-call-member*
        self.concat(value)

    # common(self + other)
    def intersect(self, other):
        res = []
        for e in self.data:
            if e in other:
                res.append(e)
        return Set(res)

    # self + other
    # res is list so cannot use concat()
    def union(self, other):
        res = self.data[:]
        for e in other:
            if not e in res:
                res.append(e)
        return Set(res)

    # value can be T. remove duplicates by adding items which are in in data.
    def concat(self, value):
        for e in value:
            if not e in self.data:
                self.data.append(e)

    # len(self)
    def __len__(self):
        # print('__len__')
        return len(self.data)

    # self[i], self[i:j]
    def __getitem__(self, key):
        # print('__getitem__')
        return self.data[key]

    # self & other
    def __and__(self, other):
        # print('__and__')
        return self.intersect(other)

    # self | other
    def __or__(self, other):
        # print('__or__')
        return self.union(other)

    def __repr__(self):
        # print('__repr__')
        return 'Set: ' + repr(self.data)

    # when not defines __iter__(), calls __getitem__() instead and more times
    def __iter__(self):
        # print('__iter__')
        return iter(self.data)


class TestMySet(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN] ", self._testMethodName


    def test_extend_by_composite(self):
        x = Set([1,3,5,7])
        y = Set([1,2,3,4,5,6])
        print(x, y, len(x))
        print(x.intersect(y))
        print(x & y)
        print(x.union(y))
        print(x | y)

        # x.reverse()
        # print(x)


# Extending Types by Subclassing

class MyList(list):
    def __getitem__(self, offset):
        print('(indexing %s at %s)' % (self, offset))
        return list.__getitem__(self, offset-1)

class TestMyList(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN] ", self._testMethodName

    # [RUN]  test_mylist
    # ['a', 'b', 'c']
    # ['a', 'b', 'c']
    # (indexing ['a', 'b', 'c'] at 1)
    # a
    # (indexing ['a', 'b', 'c'] at 3)
    # c
    # ['a', 'b', 'c', 'spam']

    def test_extend_by_subclass_01(self):
        print(list('abc'))
        x = MyList('abc')
        print(x)

        print(x[1])
        print(x[3])

        x.append('spam')
        print(x)


# Extending Types by Subclassing

class SubSet(list):
    def __init__(self, value = []):

        # *py-error* cause infinite recursion
        # self.__init__([])

        list.__init__([])
        self.concat(value)

    # common(self + other)
    def intersect(self, other):
        res = []
        for e in self:
            if e in other:
                res.append(e)
        return SubSet(res)

    # self + other
    # since res is SubSet and can call concat() on it. 
    def union(self, other):
        res = SubSet(self)
        res.concat(other)
        return res

    # value can be T. remove duplicates by adding items which are in in data.
    def concat(self, value):
        for e in value:
            if not e in self:
                self.append(e)

    # self & other
    def __and__(self, other):
        # print('__and__')
        return self.intersect(other)

    # self | other
    def __or__(self, other):
        # print('__or__')
        return self.union(other)

    def __repr__(self):
        # print('__repr__')
        return 'Set: ' + list.__repr__(self)

class TestSubSet(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN] ", self._testMethodName

    # .====================
    # [RUN]  test_extend_by_composite
    # (Set: [1, 3, 5, 7], Set: [1, 2, 3, 4, 5, 6], 4)
    # Set: [1, 3, 5]
    # Set: [1, 3, 5]
    # Set: [1, 3, 5, 7, 2, 4, 6]
    # Set: [1, 3, 5, 7, 2, 4, 6]
    # .====================
    # [RUN]  test_extend_by_subclass_02
    # (Set: [1, 3, 5, 7], Set: [1, 2, 3, 4, 5, 6], 4)
    # Set: [1, 3, 5]
    # Set: [1, 3, 5]
    # Set: [1, 3, 5, 7, 2, 4, 6]
    # Set: [1, 3, 5, 7, 2, 4, 6]
    # Set: [7, 5, 3, 1]

    def test_extend_by_subclass_02(self):
        x = SubSet([1,3,5,7])
        y = SubSet([1,2,3,4,5,6])
        print(x, y, len(x))
        print(x.intersect(y))
        print(x & y)
        print(x.union(y))
        print(x | y)

        x.reverse()
        print(x)


<py-class-internal> <py-class-introspection>

The World’s Simplest Python Class

>>> rec.__bases__         # Class to superclasses link, () in 2.X
(<class 'object'>,)

>>> bob = Person('Bob Sminth')
>>> bob
[Person: Bob Sminth, 0]

>>> bob.__class__
<class person.Person at 0x7fdf1ecbd530>

*py-class-name*

>>> bob.__class__.__name__
'Person'

>>> bob.__dict__.keys()   # *py-instance-dictionary* instance attrs only
['pay', 'job', 'name']

>>> dir(bob)              # Plus inherited attrs in classes
['__doc__', '__init__', '__module__', '__repr__', 'giveRaise', 'job', 'lastName',
'name', 'pay']


<py-convention-for-internal-name>
To minimize the chances of name collisions like this, Python programmers often
prefix methods not meant for external use with a single underscore:
_gatherAttrs in our case. 

This isn’t foolproof (what if another class defines _gatherAttrs, too?), but
it’s usually sufficient, and it’s a common Python naming convention for
methods internal to a class. not for override.

*py-convention-double-underscores* *py-mangle-names*
A better and less commonly used solution would be to use two underscores at
the front of the method name only: __gatherAttrs for us. Python automatically
expands such names to include the enclosing class’s name, which makes them
truly unique when looked up by the inheritance search. This is a feature
usually called pseudoprivate class attributes.

The fact that there are two different conventions for “private” attributes
leads to the obvious question of which style you should use. 

For most code, you should probably just make your nonpublic names start with a
single underscore. If, however, you know that your code will involve
subclassing, and there are internal attributes that should be hidden from
subclasses, use the double underscore instead.


{py-class-attribute-and-instance-attribute}

## "Assorted class utilities and tools"

class AttrDisplay:
    """
    Provides an inheritable display overload method that shows
    instances with their class names and a name=value pair for
    each attribute stored on the instance itself (but not attrs
    inherited from its classes). Can be mixed into any class,
    and will work on any instance.
    """
    def gatherAttrs(self):
        # sort attrs and make a string from these
        attrs = []
        for key in sorted(self.__dict__):
            attrs.append('%s = %s ' % (key, getattr(self, key)))
        return ','.join(attrs)

    def __repr__(self):
        return '[%s: %s]' % (self.__class__.__name__, self.gatherAttrs())

class TopTest(AttrDisplay):

    # *py-class-variable*
    count = 0

    # *py-error* on __int__ typo
    # no error message from python and simply wrong result. spend time to figure
    # out and the thing is no ctor is called; not overrided. 
    #
    # def __int__(self):

    def __init__(self):
        self.attr1 = TopTest.count
        self.attr2 = TopTest.count+1
        TopTest.count += 2

class SubTest(TopTest):
    pass

class TestAttrDisplay(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName
    
    # [RUN] test_attr_display
    # [TopTest: attr1 = 0,attr2 = 1]
    # [SubTest: attr1 = 2,attr2 = 3]

    def test_attr_display(self):
        X, Y = TopTest(), SubTest()
        print(X)
        print(Y)


<py-class-abc> abstract-superclass

# py-class-abc, CHAPTER 29 Class Coding Details
# Class Interface Techniques

class Super:
    def method(self):
        print('in Super.method')

    def delegate(self):

        # expected to be defined
        self.action()

# Implements the action method expected by Super’s delegate method.

class Provider(Super):
    def action(self):
        print('in Provider.action')

# [RUN] test_abstract_method
# in Provider.action

class TestAbstract(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName
    
    def test_abstract_method(self):
        x = Provider()
        x.delegate()


If an expected method is not defined in a subclass, Python raises an undefined
name exception when the inheritance search fails.

# Implements the action method expected by Super's delegate method.
class Provider(Super):
    pass
    # def action(self):
    #     print('in Provider.action')

Traceback (most recent call last):
  File "pyclass.py", line 446, in test_abstract_method
    x.delegate()
  File "pyclass.py", line 427, in delegate
    self.action()
AttributeError: Provider instance has no attribute 'action'

*py-override-force*
Class coders sometimes make such subclass requirements `more obvious` with
assert statements, or by raising the built-in NotImplementedError exception

class Super:

    def method(self):
        print('in Super.method')

    def delegate(self):
        self.action()

    def action(self):
        raise NotImplementedError('action must be defined!')
        or
        assert False, 'action must be defined!'

class Provider(Super):
    pass

if __name__ == '__main__':
    x = Provider()
    x.delegate()


Traceback (most recent call last):
  File "./specialize.py", line 20, in <module>
    x.delegate()
  File "./specialize.py", line 9, in delegate
    self.action()
  File "./specialize.py", line 11, in action
    assert False, 'action must be defined!'
AssertionError: action must be defined!

Traceback (most recent call last):
  File "./specialize.py", line 21, in <module>
    x.delegate()
  File "./specialize.py", line 9, in delegate
    self.action()
  File "./specialize.py", line 11, in action
    raise NotImplementedError('action must be defined!')
NotImplementedError: action must be defined!


<syntax-difference-to-make-abc>

Abstract superclasses in Python 3.X and 2.6+: Preview

As of Python 2.6 and 3.0, the prior section’s abstract superclasses (a.k.a.
    “abstract base classes”), which require methods to be filled in by
subclasses, may also be implemented `with special class syntax.`

Since the effect is the same; we `can’t make an instance` unless the method is
defined lower in the class tree.

the potential advantage of this approach is that errors for missing methods
are issued `when we attempt to make an instance of the class`, not later when we
try to call a missing method.


# *py-2* in Python 2.6 and 2.7, we use a class attribute instead:

from abc import ABCMeta, abstractmethod

class ABCSuper:
    __metaclass__ = ABCMeta
    @abstractmethod
    def method(self):
        pass

class ABCSub(ABCSuper):
    pass

class TestAbstractCreation(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName
    
    def test_abstract_super_creation(self):
        x = ABCSuper()

    def test_abstract_sub_creation(self):
        x = ABCSub()


Traceback (most recent call last):
  File "pyclass.py", line 469, in test_abstract_sub_creation
    x = ABCSub()
TypeError: Can't instantiate abstract class ABCSub with abstract methods method


Traceback (most recent call last):
  File "pyclass.py", line 466, in test_abstract_super_creation
    x = ABCSuper()
TypeError: Can't instantiate abstract class ABCSuper with abstract methods method


={============================================================================
|kt_dev_py_0001| py-class-overload py-overload

LPY5, Chapter 30: Operator Overloading

{py-getattr} *py-attribute* *py-getattr*

LPY5, 25: Advanced Module Topics, Example: Modules Are Objects

`To get to an attribute called name in a module called M`, all the following
expressions reach the same attribute and object:

M.name                    # Qualify object by attribute
M.__dict__['name']        # Index namespace dictionary manually
sys.modules['M'].name     # Index loaded-modules table manually
getattr(M, 'name')        # Call built-in fetch function


Attribute Access: __getattr__ and __setattr__

classes can also intercept basic `attribute access` (a.k.a. `qualification`) when
needed or useful. Specifically, for an object created from a class, 
`dot operator` expression object.attribute can be implemented by your code too.


Attribute Reference

The __getattr__ method intercepts attribute references. It’s called with the
attribute name as a string whenever you try to qualify an instance with an
`undefined (nonexistent) attribute name. It is not called` if Python can find
the attribute using its inheritance tree search procedure. 

The __setattr__ intercepts all attribute assignments.

class Empty:

    # if has this, __getattr__() will be called
    # def __init__(self, value):
    #     self.age = value
    #     self.attrname = value

    # Here, the Empty class and its instance X have no real attributes of their
    # own, so the access to X.age gets routed to the __getattr__ method; self is
    # assigned the instance (X), and attrname is assigned the undefined
    # attribute name string ('age'). The class makes age look like a real
    # attribute by returning a real value as the result of the X.age
    # qualification expression (40). In effect, age becomes a dynamically
    # computed attribute

    def __getattr__(self, attrname):
        print('__getattr__ is called')
        if attrname == 'age':
            return 40
        else:
            raise AttributeError(attrname)

    # to avoid infinite recursion loop, use __dict__{} instead then dot
    # notation and its setattr built-in function equivalent

    def __setattr__(self, attr, value):
        print('__setattr__ is called')
        if attr == 'age':
            self.__dict__[attr] = value + 10
        else:
            raise AttributeError(attr + ' not allowed')


class TestOverload(unittest.TestCase):

    def test_overload_getattr_op(self):

        # X = Empty(10)
        X = Empty()
        X.age
        X.age = 100
        with self.assertRaises(AttributeError):
            X.attrname


{py-call} <py-callable>

Call Expressions: __call__

o callable also retain state information for use during calls.

# py-overload 
# Chapter 30: Operator Overloading

# py-callable
class Callee:

    # py-keyward-argument
    def __call__(self, *pargs, **kargs):
        # accept arbitrary arguments
        print('Called:', pargs, kargs)

class Prod:
    def __init__(self, value):
        self.value = value

    def __call__(self, other):
        return self.value * other

class TestOverload(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    # [RUN] test_call_overload
    # ('Called:', (1, 2, 3), {})
    # ('Called:', (1, 2, 3), {'y': 5, 'x': 4})

    def test_call_overload(self):
        # C is callable
        C = Callee()
        C(1,2,3)
        C(1,2,3, x=4, y=5)

    def test_callable(self):
        x = Prod(2)
        self.assertEqual(x(3), 6)
        self.assertEqual(x(4), 8)


As an example, the tkinter GUI toolkit allows you to register functions as
  event handlers (callbacks) - when events occur, tkinter calls the registered
  objects. If you want an event handler to retain state between events, you
  can register either a class’s bound method, or an instance that conforms to
  the expected interface with __call__.


<py-bound-method>

Chapter 31: Designing with Classes, Methods Are Objects: Bound or Unbound

class’s methods can be accessed from an instance or a class, though, they
actually come in two flavors in Python:

o Unbound (class) method objects: no self

o Bound (instance) method objects: self + function pairs

class Spam:
    def doit(self, message):
        return message

class Number:
    def __init__(self, base):
        self.base = base

    def double(self):
        return self.base * 2

    def triple(self):
        return self.base * 3

class TestBoundMethod(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    def test_callable_1(self):

        object1 = Spam()
        self.assertEqual(object1.doit('hello world'), 'hello world')

        # bound
        object2 = Spam()
        # x is bound method object
        x = object2.doit
        self.assertEqual(x('hello world'), 'hello world')

        # py-class-unbound 
        # *py-2x* since requires instance to call
        # *py-3x* In Python 3.X, the language has dropped the notion of
        # unbound methods. What we describe as an unbound method here is
        # treated as a simple function in 3.X.

        object3 = Spam()
        t = Spam.doit
        self.assertEqual(t(object3, 'howdy'), 'howdy')
        
    # [RUN] test_callable_2
    # 4
    # 6
    # 9
    # 8

    def test_callable_2(self):
        x = Number(2)
        y = Number(3)
        z = Number(4)

        # list of bound objects
        acts = [x.double, y.double, y.triple, z.double]

        for act in acts:
            print(act())


{py-iterator}

Technically, iteration contexts work by passing an iterable object to the iter
built-in function to invoke an __iter__ method, which is expected to return an
iterator object.


={============================================================================
|kt_dev_py_0001| py-class-static py-decorator

LYP5, 32, Advanced Class Topics

Three kinds of methods within a class that can be called without an instance:

o static methods work roughly like simple instance-less functions inside a
  class

o class methods are passed a class instead of an instance.

o Normal methods, now known in formal circles as instance methods, still
  receive a subject instance when called; static and class methods do not.

To enable these method modes, you must call special built-in functions named
staticmethod and classmethod within the class, or invoke them with the special
@name decoration syntax


Why the Special Methods?

o One solution. Simple functions coded outside a class can access class
  attributes through the class name, they have access to class data and never
  require access to an instance. 

# use simple method and works for both version

def show_id():
    print 'id: %d' % StaticClass.track_id

class StaticClass:
    track_id = 0

    def __init__(self):
        StaticClass.track_id += 1

class TestStaticClass_2(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    def test_static_class_use_simple_method(self):

        sc = StaticClass()
        show_id()
        print(StaticClass.track_id)


o Use *py-class-attribute-instance-attribute* and *py-class-unbound* 

# tries to mimic c++ cookbook, 8.4 Automatically Adding New Class Instances to a
# Container

class StaticClass:
    track_id = 0

    def __init__(self):
        StaticClass.track_id += 1

    # selfless method
    def show_id():
        print 'id: %d' % StaticClass.track_id


class TestStaticClass(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    def test_static_class_in_py2x(self):

        # TypeError: unbound method show_id() must be called with StaticClass
        # instance as first argument (got nothing instead)

        # this is okay in *py-3x*
        # StaticClass.show_id()

        with self.assertRaises(TypeError):
            StaticClass.show_id()

        # TypeError: show_id() takes no arguments (1 given)

        sc = StaticClass()
        with self.assertRaises(TypeError):
            sc.show_id()


If you’re able to use 3.X and stick with calling self-less methods through
classes only, you already have a static method feature. 
  
However, to allow self-less methods to be called through classes in 2.X and
through instances in both 2.X and 3.X, you need to either adopt other designs
or be able to somehow mark such methods as special.


<py-staticmethod>
The better is to associate such code with a class, and to allow such
processing to be customized with inheritance as usual, it would be better to
code these types of functions inside the class itself.

advantages over using simple global function:

o it also localizes the function name in the class scope (so it won’t clash
    with other names in the module)

o moves the function code closer to where it is used (inside the class
    statement) 

o allows subclasses to customize the static method with inheritance


Call the built-in functions staticmethod and classmethod, as hinted in the
earlier discussion of new-style classes. Both mark a function object as
special to make `neither of which requires` an instance argument to be passed
in when invoked.


class Methods:
    # normal instance method
    def imeth(self, x):
        print([self, x])

    # static method
    def smeth(x):
        print([x])

    # class method
    def cmeth(cls, x):
        print([cls, x])

    # Notice how the last two assignments in this code simply reassign
    # (a.k.a. rebind) the method names smeth and cmeth.

    smeth = staticmethod(smeth)
    cmeth = classmethod(cmeth)


class TestStaticClass_3(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    # [RUN] test_static_class_use_staticmethod
    # [<pyclass.Methods instance at 0x7efd73c7d1b8>, 1]
    # [<pyclass.Methods instance at 0x7efd73c7d1b8>, 2]
    # [3]
    # [4]
    # [<class pyclass.Methods at 0x7efd73c67f58>, 5]
    # [<class pyclass.Methods at 0x7efd73c67f58>, 6]

    def test_static_class_use_staticmethod(self):

        m = Methods()
        m.imeth(1)
        Methods.imeth(m, 2)

        # now worlks for *py-2x*
        Methods.smeth(3)
        m.smeth(4)

        # Class methods are similar, but Python automatically passes the class
        # (not an instance) in to a class method’s first (leftmost) argument,
        # whether it is called through a class or an instance:

        # Class method: call through class
        # Becomes cmeth(Methods, 5)

        Methods.cmeth(5)

        # Class method: call through instance
        # Becomes cmeth(Methods, 5)

        m.cmeth(6)


class Spam:

    numInstances = 0

    def __init__(self):
        Spam.numInstances += 1

    def printNumInstances():
        print('number of instances: %s' % Spam.numInstances)

    printNumInstances = staticmethod(printNumInstances)

class TestStaticClass_4(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    # [RUN] test_static_class_use_staticmethod_2
    # number of instances: 2
    # number of instances: 2

    def test_static_class_use_staticmethod_2(self):
        a = Spam()
        b = Spam()
        Spam.printNumInstances()
        a.printNumInstances()

class Sub(Spam):

    def printNumInstances():
        print('extra stuff...')
        Spam.printNumInstances()

    printNumInstances = staticmethod(printNumInstances)

class TestStaticClass_5(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    # [RUN] test_static_class_use_staticmethod_2
    # extra stuff...
    # number of instances: 2
    # number of instances: 2
    # extra stuff...
    # number of instances: 2

    def test_static_class_use_staticmethod_2(self):
        a = Sub()
        b = Sub()
        Sub.printNumInstances()
        Spam.printNumInstances()
        a.printNumInstances()


# https://docs.python.org/2/library/functions.html#staticmethod
# 
# staticmethod(function)
# 
#     Return a static method for function.
# 
#     A static method does not receive an `implicit first argument` 
#     
#     To declare a static method, use this idiom:
# 
#     class C(object):
#         @staticmethod
#         def f(arg1, arg2, ...):
#             ...
# 
#     The @staticmethod form is a `function decorator` see the description of
#       function definitions in Function definitions for details.
# 
#     It can be called either on the class (such as C.f()) or on an instance
#     (such as C().f()). The instance is ignored except for its class.
# 
#     Static methods in Python are similar to those found in Java or C++. Also
#     see classmethod() for a variant that is useful for creating alternate
#     class constructors.
# 
#     For more information on static methods, consult the documentation on the
#     standard type hierarchy in The standard type hierarchy.
# 
#     New in version 2.2.
# 
#     Changed in version 2.4: Function decorator syntax added.


{py-decorator}
Python decorators addressed this specific need and provided a general tool for
adding `logic` that manages both functions and classes, or later `calls` to them.

`Function decorators` turn out to be very general tools: they are useful for
adding many types of logic to functions besides the static and class method
use cases. For instance, they may be used to augment functions with code that
logs calls made to them, checks the types of passed arguments during
debugging, and so on. Function decorators can be used to manage either
functions themselves or later calls to them.

Function decorators - the initial entry in this set, added in Python 2.4 -
augment function definitions. They specify special operation modes for both
simple functions and classes’ methods by `wrapping` them in an extra layer of
logic implemented as another function, usually called a `metafunction`


class DecoratedSpam:

    numInstances = 0

    def __init__(self):
        Spam.numInstances += 1

    @staticmethod
    def printNumInstances():
        print('number of instances: %s' % Spam.numInstances)


class TestStaticClass_6(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    # [RUN] test_static_class_use_staticmethod_2
    # number of instances: 2
    # number of instances: 2

    def test_static_class_use_staticmethod_2(self):
        a = DecoratedSpam()
        b = DecoratedSpam()
        DecoratedSpam.printNumInstances()
        a.printNumInstances()


this syntax has the same effect as the followingpassing the function through
the decorator and assigning the result back to the original name:


<py-decorator-do>
Decoration rebinds the method name to the decorator’s result. The net effect
is that calling the method function’s name later actually triggers the result
of its staticme thod decorator first. Because a decorator can return any sort
of object, this allows the decorator to insert a layer of logic to be run on
every call. The decorator function is free to return either the original
function itself, or a new proxy object that saves the original function passed
to the decorator to be invoked indirectly after the extra logic layer runs.


# LPY5, Decorators and Metaclasses: Part 1
# A First Look at User-Defined Function Decorators

class tracer:
    def __init__(self, func):
        self.calls = 0
        self.func = func

    # add logic and run original

    def __call__(self, *args):
        self.calls += 1
        print('call %s to %s' % (self.calls, self.func.__name__))
        return self.func(*args)

@tracer
def spam(a, b, c):
    return a + b + c

class TestDecorator_1(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    # [RUN] test_decorator_user_defined
    # call 1 to spam
    # 6
    # call 2 to spam
    # abc

    def test_decorator_user_defined(self):
        print(spam(1, 2, 3))
        print(spam('a', 'b', 'c'))


So the function decorator syntax:

@decorator
def func(args): ...

is automatically translated to this equivalent `to rebind` the function name
to the result of the decorator callable:

def func(args): ...
func = decorator(func)


TODO: A First Look at Class Decorators and Metaclasses


Although they are a general mechanism whose usage may be required by some
packages, coding new user-defined decorators and metaclasses is an advanced
topic of interest primarily to `tool writers`, not application programmers.

Chapter 38 shows how to code properties using function decorator syntax in
more depth.

Chapter 39 has much more on decorators, including more comprehensive examples.

Chapter 40 covers metaclasses, and more on the class and instance management
story.


={============================================================================
|kt_dev_py_0001| py-property

LPY5, 38: Managed Attributes

A better solution would allow you to run code automatically on attribute
access, if needed. That’s one of the main roles of managed attributesthey
provide ways to add attribute accessor logic after the fact.

four accessor techniques:

o The __getattr__ and __setattr__ methods, for routing undefined attribute
  fetches and all attribute assignments to generic handler methods.

o The __getattribute__ method, for routing all attribute fetches to a generic
  handler method.

o The property built-in, for routing specific attribute access to get and set
  handler functions.

o The descriptor protocol, for routing specific attribute accesses to
  instances of classes with arbitrary get and set handler methods, and the
  basis for other tools such as properties and slots.

*py-3* *py-2*
The tools in the first of these bullets are available in all Pythons. The last
three bullets’ tools are available in Python 3.X and new-style classes in 2.X

the last two techniques listed here apply to specific attributes, whereas the
first two are generic enough to be used by delegation-based proxy classes that
must route arbitrary attributes to wrapped objects.


<py-property>

Properties

The property protocol allows us to route a specific attribute’s get, set, and
delete operations to functions or methods we provide, enabling us to insert
code to be run automatically on attribute access, intercept attribute
deletions, and provide documentation for the attributes if desired.

A property is created by assigning the result of a built-in function to a
class attribute:

attribute = property(fget, fset, fdel, doc)

None of this built-in’s arguments are required, and all default to None if not
passed. For the first three, this None means that the corresponding operation
is not supported, and attempting it will raise an AttributeError exception
automatically.

This built-in property call `returns a property object`, which we assign to
the name of the attribute to be managed in the class scope, where it will be
inherited by every instance.

the following class uses a property to trace access to an attribute named
name; the actual stored data is named _name so it does not clash with the
property

class PersonProperty:
    def __init__(self, name):
        self._name = name

    def getName(self):
        print('fetch...')
        return self._name

    def setName(self, value):
        print('change...')
        self._name = value

    def delName(self):
        print('remove...')
        del self._name

    name = property(getName, setName, delName, 'name property docs')

class TestDecoratorProperty(unittest.TestCase):

    def setUp(self):
        print('====================')
        print('[RUN] ', self._testMethodName)

    # [RUN]  test_decorator_property
    # fetch...
    # Bob Smith
    # change...
    # fetch...
    # Robert Smith
    # remove...
    # fetch...
    # Sue Jones
    # name property docs

    def test_decorator_property(self):
        bob = PersonProperty('Bob Smith')
        print(bob.name)

        bob.name = 'Robert Smith'
        print(bob.name)

        del bob.name

        # AttributeError: 'PersonProperty' object has no attribute '_name'
        # print(bob.name)

        sue = PersonProperty('Sue Jones')
        print(sue.name)
        print(PersonProperty.name.__doc__)


o Like all class attributes, properties are inherited by both instances and
  lower subclasses.


Coding Properties with Decorators

Again, the function decorator syntax:

@decorator
def func(args): ...

is automatically translated to this equivalent `to rebind` the function name
to the result of the decorator callable:

def func(args): ...
func = decorator(func)

Because of this mapping, it turns out that the property built-in can serve as
a decorator

As of Python 2.6 and 3.0, property objects also have getter, setter, and
deleter methods that assign the corresponding property accessor methods and
return a copy of the property itself.

class PersonPropertyDecorator:
    def __init__(self, name):
        self._name = name

    # name = property(name)
    @property
    def name(self):
        "name property docs"
        print('fetch...')
        return self._name

    # name = name.setter(name)
    @name.setter
    def name(self, value):
        print('change...')
        self._name = value

    # name = name.deleter(name)
    @name.deleter
    def name(self):
        print('remove...')
        del self._name

    # name = property(getName, setName, delName, 'name property docs')

Compared to manual assignment of property results, in this case using
decorators to code properties requires just three extra lines of code—a
seemingly negligible difference.  As is so often the case with alternative
tools, though, the choice between the two techniques is largely subjective.


o what if do not define setter and user tries to use? *py-read-only*

  AttributeError: can't set attribute


# PYCB3, 8.6. Creating Managed Attributes

Properties `should only be used in cases` where you actually need to perform
extra processing on attribute access.


class PersonCookbook_8_6:

    def __init__(self, first_name):
        self.first_name = first_name

    @property
    def first_name(self):
        return self._first_name

    @first_name.setter
    def first_name(self, value):
        if not isinstance(value, str):
            raise TypeError('Expected a string')
        self._first_name = value

    @first_name.deleter
    def first_name(self):
        raise AttributeError("can't delete attribute")


    def test_decorator_cookbook_8_3(self):
        a = PersonCookbook_8_6('Guido')
        print(a.first_name)

        with self.assertRaises(TypeError):
            a.first_name = 42

        with self.assertRaises(AttributeError):
            del a.first_name 


you may ask why the __init__() method sets self.first_name instead of
self._first_name. Thus, chances are you would also want such checking to take
place during initialization. By setting self.first_name, the set operation
uses the setter method (as opposed to bypassing it by accessing
    self._first_name).


PYCB, 8.8. Extending a Property in a Subclass

Problem

Within a subclass, you want to extend the functionality of a property defined
in a parent class.

TODO:


<py-descriptor>

the property built-in is just a simplified way to create a specific type of
descriptor that runs method functions on attribute accesses.

o use their `instance argument` to access state information in the subject
  instance

o To use a descriptor, instances of the descriptor are placed into a class
  definition as class variables.

o descriptors can only be defined at the class level, not on a per-instance
  basis.

class Name:
    "name descriptor docs"
    def __get__(self, instance, owner):
        print('fetch...')
        return instance._name

    def __set__(self, instance, value):
        print('change...')
        instance._name = value
    
    def __delete__(self, instance):
        print('remove...')
        del instance._name

class PersonDescriptor:
    def __init__(self, name):
        self._name = name

    # assign descriptor to attr
    name = Name()


# PYCB3, 8.9. Creating a New Kind of Class or Instance Attribute

class Integer:
    def __init__(self, name):
        self.name = name

    def __get__(self, instance, cls):
        if instance is None:
            return self
        else:
            # return instance.x or return instance.y?
            # use Integer(str) and str is attribute name.
            return instance.__dict__[self.name]

    def __set__(self, instance, value):
        if not isinstance(value, int):
            raise TypeError('Expected an int')
        instance.__dict__[self.name] = value

    def __delete__(self, instance):
        del instance.__dict__[self.name]

class Point:

    # py-class-variable
    x = Integer('x')
    y = Integer('y')

    def __init__(self, x, y):
        self.x = x
        self.y = y

class TestDescriptor(unittest.TestCase):

    def setUp(self):
        print('====================')
        print('[RUN] ', self._testMethodName)

    # [RUN]  test_descriptor
    # fetch...
    # Bob Smith
    # change...
    # fetch...
    # Robert Smith
    # remove...
    # fetch...
    # Sue Jones
    # name property docs

    def test_descriptor(self):

        # as `int type`
        xxx = PersonProperty(100)
        self.assertEqual(type(xxx.name), type(int()))

        # as `str type`
        bob = PersonProperty('Bob Smith')
        self.assertEqual(type(bob.name), type(str()))
        print(bob.name)

        bob.name = 'Robert Smith'
        print(bob.name)

        del bob.name

        sue = PersonProperty('Sue Jones')
        print(sue.name)
        print(PersonProperty.name.__doc__)

    def test_cookbook_8_9(self):

        p = Point(2, 3)
        self.assertEqual(p.x, 2)
        p.y = 5

        with self.assertRaises(TypeError):
            p.x = 2.3


TODO:

Descriptors are more useful in situations where there will be a lot of code
reuse (i.e., you want to use the functionality provided by the descriptor in
    hundreds of places in your code or provide it as a library feature).


={============================================================================
|kt_dev_py_0001| py-class-super

LPY5, 28: A More Realistic Example

See how to call super class's version:

class Person:
    def __init__(self, name, job=None, pay=0):
        self.name = name
        self.job = job
        self.pay = pay

    def giveRaise(self, percent):
        self.pay = int(self.pay * (1+percent))

    def __repr__(self):
        return '[Person: %s, %s]' % (self.name, self.pay)

class Manager(Person):
    def giveRaise(self, percent, bonus=.10):
        `Person.giveRaise(self, percent+bonus)`

What About super?

Because of these downsides, this book prefers to call superclasses by explicit
name instead of super, recommends the same policy for newcomers, and defers
presenting super until Chapter 32. It’s usually best judged after you learn
the simpler, and generally more traditional and “Pythonic” ways of achieving
the same goals, especially if you’re new to OOP. Topics like MROs and
cooperative multiple inheritance dispatch seem a lot to ask of beginnersand
others.


PYCB, 8.7. Calling a Method on a Parent Class

Support the use of super()

TODO: 


={============================================================================
|kt_dev_py_0001| py-pattern

<py-pattern-factory>
Factories can be a major undertaking in a strongly typed language such as C++
but are almost trivial to implement in Python.

o classes are also “first class” objects, it’s easy to pass them around a
  program, store them in data structures, and so on.

o works for any class and any constructor arguments.

# py-pattern-facory 
# Chapter 31: Designing with Classes
# Classes Are Objects: Generic Object Factories

# The function uses special "varargs" call syntax to call the function and
# return an instance.

def factory(aClass, *pargs, **kargs):
    return aClass(*pargs, **kargs)

class TestPatternFactory(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN]", self._testMethodName

    def test_factory(self):
        object1 = factory(Spam)
        object2 = factory(Person, 'Arthur', 'King')
        object3 = factory(Person, name='Brian')

        self.assertEqual(object1.doit(99), 99)

        self.assertEqual(object2.name, 'Arthur')
        self.assertEqual(object2.job, 'King')

        self.assertEqual(object3.name, 'Brian')
        self.assertEqual(object3.job, None)


={============================================================================
|kt_dev_py_0001| py-namespace

# CHAPTER 29 Class Coding Details
# The “Zen” of Namespaces: Assignments Classify Names

*py-assign*
In Python, the place where you assign a name is crucialit fully determines the
scope or object in which a name will reside. are never influenced by what
imports what or who imports whom.


<ex>
# File manynames.py
# All five different Xs

X = 11              # Global (module) name/attribute (X, or manynames.X)

def f():
  print(X)          # Access global X (11)

def g():
  X = 22            # Local (function) variable (X, hides module X)
  print(X)

class C:
  X = 33            # Class attribute (C.X)

  def m(self):
    X = 44          # Local variable in method (X)
    self.X = 55     # Instance attribute (instance.X)

if __name__ == '__main__':

  print(X)      # 11: module (a.k.a. manynames.X outside file)
  f()           # 11: global
  g()           # 22: local
  print(X)      # 11: module name unchanged

  obj = C()     # Make instance
  print(`obj.X`)  # 33: class name inherited by instance

  obj.m()       # Attach attribute name X to instance now

  # that the instance’s own X is not created until we call I.m()attributes,
  # like all variables, spring into existence when assigned, and not before.

  print(`obj.X`)  # 55: instance
  print(C.X)    # 33: class (a.k.a. obj.X if no X in instance)

  #print(C.m.X) # FAILS: only visible in method
  #print(g.X)   # FAILS: only visible in function


In Chapter 23, we learned that module namespaces have a concrete
implementation as dictionaries, exposed with the built-in __dict__ attribute.
In Chapter 27 and Chapter 28, we learned that the same holds true for class
and instance objectsattribute qualification is mostly a dictionary indexing
operation internally, and attribute inheritance is largely a matter of
searching linked dictionaries.

# this is interesting and different from C++

Again, `each instance has an independent namespace dictionary`, which starts out
empty and can record completely different attributes than those recorded by
the namespace dictionaries of other instances of the same class.


={============================================================================
|kt_dev_py_0001| py-docstring

LPY5, 29 Class Coding Details
Documentation Strings Revisited

# >>> import pyclassdoc
# >>> pyclassdoc.__doc__
# 'I am: docstr.__doc__'
# >>> pyclassdoc.func.__doc__
# 'I am: docstr.func.__doc__'
# >>> pyclassdoc.spam.__doc__
# 'I am: spam.__doc__ or docstr.spam.__doc__ or self.__doc__'
# >>> pyclassdoc.spam.method.__doc__
# 'I am: spam.method.__doc__ or self.method.__doc__'
# "I am: docstr.__doc__"

# >>> help(pyclassdoc)
#
# Help on module pyclassdoc:
# 
# NAME
#     pyclassdoc - I am: docstr.__doc__
# 
# FILE
#     /home/kyoupark/git/kb/code-py/pyclass/pyclassdoc.py
# 
# CLASSES
#     spam
# 
#     class spam
#      |  I am: spam.__doc__ or docstr.spam.__doc__ or self.__doc__
#      |
#      |  Methods defined here:
#      |
#      |  method(self)
#      |      I am: spam.method.__doc__ or self.method.__doc__
# 
# FUNCTIONS
#     func(args)
#         I am: docstr.func.__doc__

def func(args):
    "I am: docstr.func.__doc__"
    pass

class spam:

    "I am: spam.__doc__ or docstr.spam.__doc__ or self.__doc__"

    def method(self):
        "I am: spam.method.__doc__ or self.method.__doc__"
        print(self.__doc__)
        print(self.method.__doc__)


={============================================================================
|kt_dev_py_0001| py-exception

LPY5, 33 Exception Basics

<py-exception-default>

Exception Roles

If an exception is ignored, Python’s default exception-handling behavior kicks
in; it stops the program and prints an error message.

    def _fetcher(self, obj, index):
        return obj[index]

    def test_exception_default_handler(self):

        self.assertEqual(self._fetcher('spam', 3), 'm')

        # py-exception-default-handler
        #
        # >>> fetcher(x, 4) 
        # Traceback (most recent call last):
        # File "<stdin>", line 1, in <module>
        # File "<stdin>", line 2, in fetcher
        # IndexError: string index out of range

        # default handler of unittest
        #
        # ======================================================================
        # ERROR: test_exception_default_handler (pycore.TestException)
        # ----------------------------------------------------------------------
        # Traceback (most recent call last):
        #   File "/home/kyoupark/git/kb/code-py/pybase/pycore.py", line 1935, in test_exception_default_handler
        #     self.assertEqual(self._fetcher('spam', 4), 'm')
        #   File "/home/kyoupark/git/kb/code-py/pybase/pycore.py", line 1929, in _fetcher
        #     return obj[index]
        # IndexError: string index out of range

        # self.assertEqual(self._fetcher('spam', 4), 'm')

        # now handles exception

        try:
            # trigger manually
            # raise IndexError
            self.assertEqual(self._fetcher('spam', 4), 'm')
        except IndexError:
            print('got exception')

        print('continuing')


<py-exception-user-defined>
User-defined exceptions are coded with classes, which inherit from a built-in
exception class: usually the class named Exception.

class AlreadyGotOne(Exception):
    pass

class TestException(unittest.TestCase):

    def _grail(self):
        raise AlreadyGotOne()

    def test_exception_user_defined(self):

        try:
            self._grail()
        except AlreadyGotOne:
            print('got exception')


<py-exception-termination>
Not seeing "after try?" on output and default exception handler runs for
IndexError instead since "finally" do not catch and it 'propagates' further
up.

    def _after(self):

        try:
            self._fetcher('spam', 4)
        finally:
            print('after fetch')
        print('after try?')

    def test_exception_termination(self):
        
        self._after()


<py-exception-why>
Chapter 33: Exception Basics, Why You Will Care: Error Checks

One way to see how exceptions are useful is to compare coding styles in Python
and languages without exceptions.

In fact, realistic C programs often have as much code devoted to error
detection as to doing actual work. But in Python, you don’t have to be so
methodical

generally have to test return values or status codes after every operation
that could possibly go astray, and propagate the results of the tests as your
programs run:

# Detect errors everywhere even if not handled in this function

doStuff()
{ 
  if (doFirstThing() == ERROR)  
    return ERROR;               

  if (doNextThing() == ERROR)
    return ERROR;
  ...
  return doLastThing();
}

main()
{
  if (doStuff() == ERROR)
    badEnding();
  else
    goodEnding();
}

You can instead wrap arbitrarily vast pieces of a program in exception
handlers and simply write the parts that do the actual work, assuming all is
normally well:

# We don't care about exceptions here, so don't need to detect them

def doStuff():
  doFirstThing()
  doNextThing()
  ...
  doLastThing()

# This is where we care about results,

if __name__ == '__main__':
  try:
    doStuff() 

  # so it's the only place we must check
  except: 
    badEnding()

  else:
    goodEnding()


<py-try-statement-clause>

LPY5, 34, Exception Coding Details

try:
  statements    # Run this main action first
except name1:
  statements    # Run if name1 is raised during try block
except (name2, name3):
  statements    # Run if any of these exceptions occur
except name4 as var:
  statements    # Run if name4 is raised, assign instance raised to var
except:
  statements    # `Run for all` other exceptions raised
else:
  statements    # Run if no exception was raised during try block
finally:
  statements    # `Always perform this block on exit`

unlike an except, the finally does not terminate the exceptionit continues
being raised after the finally block runs


<raise-statement>

raise IndexError    # Class (instance created)
raise IndexError()  # Instance (created in statement)
raise               # Reraise the most recent exception

The `as` is optional in a try handler (if it’s omitted, the instance is simply
    not assigned to a name), but including it allows the handler to access
both data in the instance and methods in the exception class.

class MyExc(Exception): pass
...
raise MyExc('spam')     # Exception class with constructor args
...
try:
  ...
except MyExc as X:      # Instance attributes available in handler
  print(X.args)


<assert-statement>
Assertions are typically used to verify program `conditions` or user-defined
constraints during development.

When displayed, their error message text automatically includes source code
line information and the value listed in the assert statement.

def f(x):
  assert x < 0, 'x must be negative'
  return x ** 2

% python
>>> import asserter
>>> asserter.f(1)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File ".\asserter.py", line 2, in f
    assert x < 0, 'x must be negative'
AssertionError: x must be negative


Use a command line like python O main.py to run in optimized mode and disable
(and hence skip) asserts.


{py-with} {with-as-context}

Termination actions

As you’ll see, the try/finally statement allows you to guarantee that required
closing-time operations will be performed, regardless of the presence or
absence of exceptions in your programs. The newer with statement offers an
alternative in this department for objects that support it.

Python 2.6 and 3.0 introduced a new exception-related statementthe with, and
its optional as clause. This statement is designed to work with context
manager objects, which support a new method-based protocol

In short, the with/as statement is designed to be an `alternative` to a common
`try/ finally` usage idiom; like that statement, with is in large part
intended for specifying termination-time or "cleanup" activities that must run
`regardless of whether an exception occurs` during a processing step.

Unlike try/finally, the with statement is based upon an object `protocol` for
specifying actions to be run around a block of code. This makes `with` less
general

Although this option requires fewer lines of code, it’s applicable only when
processing certain object types, so try/finally is a more general termination
structure.

with expression [as variable]:
  with-block

The `expression` here is assumed to return an object that supports the context
management protocol. This object may also return a value that will be assigned
to the name `variable` if the optional as clause is present.

the result of the expression is the object that supports the `context protocol`, 
and the variable may be assigned something else intended to be used inside the
statement. The object returned by the expression may then run `startup code`
before the with-block is started, as well as `termination code` after the
block is done, regardless of whether the block raised an exception or not.

For simpler purposes, the try/finally statement provides sufficient support
for terminationtime activities without coding classes.

    def test_exception_context_manager(self):

        # there is warning if not call close()

        f  = open('trispam.txt')
        coll = list(f)
        self.assertEqual(coll, 
                ['spam\n', 'Spam\n', 'SPAM!\n'])
        f.close()

        # general and explicit try/finally statement, but it requires three more
        # lines of administrative code

        f  = open('trispam.txt')
        try:
            coll = list(f)
            self.assertEqual(coll, 
                    ['spam\n', 'Spam\n', 'SPAM!\n'])
        finally:
            f.close()

        # file objects have a context manager that automatically closes the file
        # after the with block regardless of whether an exception is raised,
        
        with open('trispam.txt') as f:
            cpll = list(f)
            self.assertEqual(coll, 
                    ['spam\n', 'Spam\n', 'SPAM!\n'])


<context-management-protocol>

Here’s how the with statement actually works:

o The expression is evaluated, resulting in an object known as a context
  manager that must have __enter__ and __exit__ methods.

o The context manager’s __enter__ method is called. The value it returns is
  assigned to the variable in the as clause if present, or simply discarded
  otherwise.

o The code in the nested with block is executed.

o If the with block raises an exception, the __exit__(type, value, traceback)
  method is called with the exception details. These are the same three values
  returned by sys.exc_info, described in the Python manuals and later in this
  part of the book.  If this method returns a false value, the exception is
  reraised; otherwise, the exception is terminated. The exception should
  normally be reraised so that it is propagated outside the with statement.

o If the with block does not raise an exception, the __exit__ method is still
  called, but its type, value, and traceback arguments are all passed in as
  None.

The __exit__() method can choose to use the exception information in some way
or to ignore it by doing nothing and returning None as a result. If __exit__()
returns True, the exception is cleared as if nothing happened and the
program continues executing statements immediately after the with block.


# Notice that this class’s __exit__ method returns False to propagate the
# exception; deleting the return statement would have the same effect, as the
# default None return value of functions is False by definition. Also notice
# that the __enter__ method returns self as the object to assign to the as
# variable; in other use cases, this might return a completely different object
# instead.

class TraceBlock:
    def message(self, arg):
        print('running ' + arg)

    def __enter__(self):
        print('starting with block')
        return self

    def __exit__(self, exc_type, exc_value, exc_tb):
        if exc_type is None:
            print('exited normally\n')
        else:
            print('raise an exception!' + str(exc_type))
            # propagate
            return False

    # [RUN]  test_exception_context_manager_user
    # starting with block
    # running test 1
    # reached
    # exited normally
    # 
    # starting with block
    # running test 2
    # raise an exception!<class 'TypeError'>

    def test_exception_context_manager_user(self):

        with TraceBlock() as action:
            action.message('test 1')
            print('reached')

        with TraceBlock() as action:
            action.message('test 2')
            raise TypeError
            print('not reached')


={============================================================================
|kt_dev_py_0001| py-sorted

sorting is also available in recent Pythons as a builtin function, which sorts
any collection (not just lists) and `returns a new list` for the result
(instead of in-place changes):

class TestSorted(unittest.TestCase):

    def setUp(self):
        print "===================="
        print "[RUN] ", self._testMethodName

    def test_sorted(self):

        # sorted do not change coll1

        coll1 = ['abc', 'ABD', 'aBe']
        result = sorted(coll1)
        self.assertEqual(result, ['ABD', 'aBe', 'abc'])

        result = sorted(coll1, key=str.lower, reverse=True)
        self.assertEqual(result, ['aBe', 'ABD', 'abc'])

        # input is not coll2 since it's lower cased before running sorted()

        coll2 = ['abc', 'ABD', 'aBe']
        result = sorted([x.lower() for x in coll2], reverse=True)
        self.assertEqual(result, ['abe', 'abd', 'abc'])


={============================================================================
|kt_dev_py_0001| py-bisect

The built-in bisect module implements binary-search and insertion into a
sorted list. bisect.bisect finds the `location` where an element should be
inserted to keep it sorted, while bisect.insort actually `inserts` the element
into that location:


The bisect module functions do not check whether the list is sorted. Thus,
using them with an unsorted list will succeed without error but may lead to
incorrect results.

    def test_bisect(self):

        import bisect

        coll = [1,2,2,2,3,4,7]
        result = bisect.bisect(coll, 2)
        self.assertEqual(result, 4)

        coll = [1,2,2,2,3,4,7]
        bisect.insort(coll, 6)
        self.assertEqual(coll, 
                [1, 2, 2, 2, 3, 4, 6, 7])


={============================================================================
|kt_dev_py_0001| py-sys

https://docs.python.org/2/library/sys.html?highlight=sys#module-sys

sys.exit([arg])

    Exit from Python. This is implemented by raising the SystemExit exception,
so cleanup actions specified by finally clauses of try statements are honored,
and it is possible to intercept the exit attempt at an outer level.

    The optional argument arg can be an integer giving the exit status
    (defaulting to zero), or another type of object. If it is an integer, zero
    is considered “successful termination” and any nonzero value is considered
    “abnormal termination” by shells and the like. Most systems require it to
    be in the range 0-127, and produce undefined results otherwise. Some
    systems have a convention for assigning specific meanings to specific exit
    codes, but these are generally underdeveloped; Unix programs generally use
    2 for command line syntax errors and 1 for all other kind of errors. If
    another type of object is passed, None is equivalent to passing zero, and
    any other object is printed to stderr and results in an exit code of 1. In
    particular, sys.exit("some error message") is a quick way to exit a
    program when an error occurs.

    Since exit() ultimately “only” raises an exception, it will only exit the
    process when called from the main thread, and the exception is not
    intercepted.


<py-argv>
sys.argv

    The list of command line arguments passed to a Python script. argv[0] is
    the script name (it is operating system dependent whether this is a full
        pathname or not). If the command was executed using the -c command
    line option to the interpreter, argv[0] is set to the string '-c'. If no
    script name was passed to the Python interpreter, argv[0] is the empty
    string.

    note: when access argv[x] in case no argv is provided

    IndexError: list index out of range

    so cannot test argv[x] to see if args are provided or not.


    To loop over the standard input, or the list of files given on the command
    line, see the fileinput module.

    note:
    argv[0] - len(argv[0]) is 1


sys.stdin
sys.stdout
sys.stderr

File objects corresponding to the interpreter’s standard input, output and
error streams. stdin is used for all interpreter input except for scripts but
including calls to input() and raw_input(). stdout is used for the output of
print and expression statements and for the prompts of input() and
raw_input(). The interpreter’s own prompts and (almost all of) its error
messages go to stderr. 

stdout and stderr needn’t be built-in file objects: any object is acceptable
as long as it has a write() method that takes a string argument. (Changing
    these objects doesn’t affect the standard I/O streams of processes
    executed by os.popen(), os.system() or the exec*() family of functions in
    the os module.)

<faq>
https://stackoverflow.com/questions/3263672/python-the-difference-between-sys-stdout-write-and-print


={============================================================================
|kt_dev_py_0001| py-subprocess

https://docs.python.org/2/library/subprocess.html

17.1. subprocess  Subprocess management

The subprocess module allows you to spawn new processes, connect to their
input/output/error pipes, and obtain their return codes. This module intends
to replace several older modules and functions:


The recommended way to launch subprocesses is to use the following
`convenience` functions. For more advanced use cases when these do not meet
your needs, use the underlying Popen interface.


subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False)

    Run the command described by args. Wait for command to complete, then
    return the `returncode` attribute.

    The arguments shown above are merely the most common ones, described below
    in Frequently Used Arguments (hence the slightly odd notation in the
        abbreviated signature). The full function signature is the same as
    that of the Popen constructor - this functions passes all supplied
    arguments directly through to that interface.

    Examples:

    >>> subprocess.call(["ls", "-l"])
    0

    >>> subprocess.call("exit 1", shell=True)
    1

    Warning
    Using shell=True can be a security hazard. See the warning under
    Frequently Used Arguments for details.

    Note
    Do not use stdout=PIPE or stderr=PIPE with this function as that can
    deadlock based on the child process output volume. Use Popen with the
    communicate() method when you need pipes.


17.1.1.1. Frequently Used Arguments

The arguments that are most commonly needed are:

`args` 
is required for all calls and should be a string, or a `sequence` of program
arguments. `Providing a sequence of arguments is generally preferred,` as it
allows the module to take care of any required escaping and quoting of
arguments (e.g. to permit spaces in file names). If passing a single string,
either shell must be True (see below) or else the string must simply name the
  program to be executed without specifying any arguments.

`stdin, stdout and stderr` 
specify the executed program’s standard input, standard output and standard
error file handles, respectively. 

Valid values are PIPE, an existing file descriptor (a positive integer), an
existing file object, and None. 

PIPE indicates that a new pipe to the child should be created. With the
default settings of None, no redirection will occur; the child’s file handles
will be inherited from the parent. Additionally, stderr can be STDOUT, which
indicates that the stderr data from the child process `should be captured` into
the same file handle as for stdout.

When stdout or stderr are pipes and universal_newlines is True then all line
endings will be converted to '\n' as described for the universal newlines 'U'
mode argument to open().

`shell` 
If shell is True, the specified command will be executed `through the shell.`
This can be useful if you are using Python primarily for the enhanced control
flow it offers over most system shells and still want convenient access to
other shell features such as shell pipes, filename wildcards, environment
variable expansion, and expansion of ~ to a user’s home directory. 

However, note that Python itself offers implementations of many shell-like
features (in particular, glob, fnmatch, os.walk(), os.path.expandvars(),
    os.path.expanduser(), and shutil).


<ex>
# often times, run grep on logs but forget the pattern used later. so want to
# keep the pattern used to make greped output.
# usually, run "egrep -an PATTERN LOGlastrun_realtime_1c75 > 1c75.nds"

#!/usr/bin/env python
import sys
import subprocess

if __name__ == "__main__":
    # execute only if run as a script

    if len(sys.argv) > 3:
        # print error and exit
        # e.g., file is LOGlastrun_realtime_1c75
        sys.stdout.write("mgrep {pattern} {file} \n")
        sys.exit(1)

    # note: on pattern string      
    # when pattern is $ cmd "SS|DD", pattern var gets SS|DD and subproces call
    # works okay.
    pattern = sys.argv[1]
    log_filename = sys.argv[2]
    out_filename = log_filename.split('_')[-1] + '.nds'

    sys.stdout.write('grep -an "%s" %s > %s\n' % (pattern, log_filename, out_filename))

    o = open(out_filename, 'w+')
    o.write('%s\n' % ('='*60))
    o.write('grep -an "%s" %s > %s\n' % (pattern, log_filename, out_filename))
    o.write('%s\n' % ('='*60))

    # note: without this, output file don't have the header above irrespective
    # of mode used.
    # https://stackoverflow.com/questions/10722752/python-subprocess-is-overwriting-file-used-for-stdout-i-need-it-to-append-to-t
    # os.SEEK_END or 2 (seek relative to the file’s end).
    o.seek(0, 2)

    # note: see how link to stdout of a command
    # https://stackoverflow.com/questions/3679974/run-shell-command-with-input-redirections-from-python-2-4
    # egrep -an pattern logfile > out_filename
    subprocess.call(["egrep", "-an", pattern, log_filename], stdout=o)

    o.close()


<ex>
#!/usr/bin/env python
import sys
import subprocess

if __name__ == "__main__":
    # execute only if run as a script

    # cleanup files
    subprocess.call(["rm", "-f", "G* tags flist.out"])

    dirs = [
        './CMS_PLATFORM_SERVICES', 
        './CMS_SYSTEM_INFRASTRUCTURE',
        './DARWIN_PLATFORM', './CMS_MEDIA_SERVICES', './CMS_INFORMATION_SERVICES',
        './THIRD_PARTY_LIBRARIES/BSKYB_JTH/build/applications/Picasso/picasso/Picasso/src/java/picasso',
        './THIRD_PARTY_LIBRARIES/CRAFTWORK_LAE/lae',
        './FUSIONOS_2/UTILITIES_HELPER',
        './XTV_High_Level_VOB',
        './FUSIONOS'
        ]

    listfile = 'flist.out'
    logfile = open(listfile, 'w+')

    # *TN* have to use a list for every single arguments to find rather than
    # trying to find a way to quote argument string
    #
    # find . -type d \( -path '*/build' -o -path '*/mock' \) -prune -o -print
    # 
    # this is do not work
    # subprocess.call(["find", ".", "-type d \( -path '*/build' -o -path '*/mock' \)", "-prune", "-o", "-print"])

    command = ["find", ".", "-type", "d", 
        "(", 
        "-path",  "*/build", "-o", 
        "-path", "*/mock",  "-o",
        "-path", "*/lib",  "-o",
        "-path", "*/tools",  "-o",
        "-path", "*/VQE_SRC",  "-o",
        "-path", "*/AVCU",  "-o",
        "-path", "*/test",  "-o",
        "-path", "*/test2",
        ")", "-prune", "-o", "-type", "f", "-print"]

    for e in dirs:
      command[1] = e
      subprocess.call(command, stdout=logfile)

    logfile.close()

    sys.stdout.write("building ctags for %s ...\n" % listfile)
    subprocess.call(["ctags", "-L", listfile])

    sys.stdout.write("building gtags for %s ...\n" % listfile)
    subprocess.call(["gtags", "-f", listfile])

    sys.stdout.write("done\n")


<ex>
    text = "1i" + filename
    subprocess.call(["sed", "-i", text, newlogfile])


17.1.1.2. Popen Constructor

The underlying process creation and management in this module is handled by
the Popen class. It offers a lot of flexibility so that developers are able to
handle the less common cases not covered by the convenience functions.

class subprocess.Popen(args, bufsize=0, executable=None, 
    stdin=None, stdout=None, stderr=None, preexec_fn=None, 
    close_fds=False, shell=False, cwd=None, env=None, 
    universal_newlines=False, startupinfo=None, creationflags=0)

`Execute a child program in a new process` On Unix, the class uses
os.execvp()-like behavior to execute the child program. 

`args` should be a `sequence` of program arguments or else a `single string.` By
default, the program to execute is the first item in args if args is a
sequence. If args is a string, the interpretation is platform-dependent and
described below. See the `shell` and executable arguments for additional
differences from the default behavior. Unless otherwise stated, it is
recommended to pass args as a sequence.

On Unix, if args is a string, the string is interpreted as the name or path of
the program to execute. However, this can only be done if not passing
arguments to the program.


<ex>
>>> print args
['/bin/vikings', '-input', 'eggs.txt', '-output', 'spam spam.txt', '-cmd', "echo '$MONEY'"]
>>> p = subprocess.Popen(args) # Success!


On Unix with `shell=True`, the shell defaults to /bin/sh. If args is a string,
the string specifies the command to execute `through the shell`  This means that
  the string must be formatted exactly as it would be when typed at the shell
  prompt. This includes, for example, quoting or backslash escaping filenames
  with spaces in them. If args is a sequence, the first item specifies the
  command string, and any additional items will be treated as additional
  arguments to the shell itself. That is to say, Popen does the equivalent of:

Popen(['/bin/sh', '-c', args[0], args[1], ...])


subprocess.PIPE

    Special value that can be used as the stdin, stdout or stderr argument to
    Popen and indicates that a pipe to the standard stream `should be opened`

stdin, stdout and stderr specify the executed program's standard input,
standard output and standard error file handles, respectively. 
  
Valid values are `PIPE`, an existing file descriptor (a positive integer), an
existing file object, and None. PIPE indicates that a new pipe to the child
should be created. With the default settings of None, no redirection will
occur; the child's file handles will be inherited from the parent.
Additionally, stderr can be STDOUT, which indicates that the stderr data from
the child process should be captured into the same file handle as for stdout.

If close_fds is true, all file descriptors except 0, 1 and 2 will be closed
before the child process is executed. (Unix only).


17.1.2. Popen Objects

Instances of the Popen class have the following methods:

Popen.wait()

    Wait for child process to terminate. Set and return returncode attribute.

    Warning

    This will deadlock when using stdout=PIPE and/or stderr=PIPE and the child
    process generates enough output to a pipe such that it blocks waiting for
    the OS pipe buffer to accept more data. `Use communicate() to avoid that.`

Popen.communicate(input=None)

    Interact with process: Send data to stdin. Read data from stdout and
    stderr, until end-of-file is reached. `Wait for process to terminate` The
    optional input argument should be a string to be sent to the child
    process, or None, if no data should be sent to the child.

    communicate() `returns` a tuple (stdoutdata, stderrdata).

    Note 
    that if you want to send data to the process's stdin, you need to create
    the Popen object with `stdin=PIPE`. Similarly, to get anything other than
    None in the result tuple, you need to give stdout=PIPE and/or stderr=PIPE
    too.

    Note
    The data read is buffered in memory, so do not use this method if the data
    size is large or unlimited.


Popen.poll()

    Check if child process has terminated. Set and return returncode
    attribute.

<ex>
        P = subprocess.Popen (cmd, stdout = subprocess.PIPE,
                stderr = subprocess.PIPE, close_fds=True, bufsize=50000000)

        stdOut, stdErr = P.communicate ()
        retVal = P.wait ()

<ex> py-ex-get-ip-address

pi@raspberrypi ~ $ /sbin/ifconfig
eth0      Link encap:Ethernet  HWaddr b8:27:eb:11:5f:d6
          inet addr:10.209.60.87  Bcast:10.209.60.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:294459 errors:0 dropped:12617 overruns:0 frame:0
          TX packets:71643 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000
          RX bytes:191387746 (182.5 MiB)  TX bytes:41340485 (39.4 MiB)

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:1755 errors:0 dropped:0 overruns:0 frame:0
          TX packets:1755 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:138052 (134.8 KiB)  TX bytes:138052 (134.8 KiB)



def get_ipv4_address():
    import socket, subprocess, re
    """
    Returns IP address of current machine.
    """
    try:
        p = subprocess.Popen(["/sbin/ifconfig"], stdout=subprocess.PIPE)
    except OSError:
        print 'ifconfig not found, please set your ip address manually'
        return None

    ifc_resp = p.communicate()
    // returns tuple which has one element.
    // ('eth0      Link encap:Ethernet  HWaddr b8:27:eb:11:5f:d6  \n          inet addr:10.209.60.87  Bcast:10.209.60.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:294333 errors:0 dropped:12611 overruns:0 frame:0\n          TX packets:71573 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:191380039 (182.5 MiB)  TX bytes:41333421 (39.4 MiB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:1755 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:1755 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:138052 (134.8 KiB)  TX bytes:138052 (134.8 KiB)\n\n', None)
 
    patt = re.compile(r'inet\s*(?:\w*\S*:\s*)?(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')

    // *py-re-findall*
    >>> patt = re.compile(r'inet\s*(?:\w*\S*:\s*)?(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    >>> patt.findall(ifc_resp[0])
    // ['10.209.60.106', '127.0.0.1']

    resp = patt.findall(ifc_resp[0])
    for ip in resp:
      if ip.find('192') != -1 or ip.find('172') != -1 or ip.find('10') != -1:
        return ip

// to solve the issue when use docker

IP address detection was picking an IP address associated with the
Docker system, which could not be accessed from the STB. Updated
the IP address detection code using a Stack Overflow snippet. This
attempts to connect to Google's public DNS server (8.8.8.8) and
returns the local IP address used for that connection.

def get_ipv4_address():
    import socket, subprocess, re
    """
    Returns IP address of current machine.
    """
    try:
        # From https://stackoverflow.com/a/166589
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
        s.close()
        print("Local IP is {}".format(ip))
        return ip
    except socket.error:
        print 'Problem determining IP address, please set your ip address manually'
        return None


={============================================================================
|kt_dev_py_0001| py-shlex

https://docs.python.org/2/library/shlex.html


={============================================================================
|kt_dev_py_0001| py-builtin-function

https://docs.python.org/3/library/functions.html

2. Built-in Functions
The Python interpreter has a number of functions and types built into it that
are always available. They are listed here in alphabetical order.

*eval-keyword-eval*
eval(expression, globals=None, locals=None)

    The arguments are a string and optional globals and locals. If provided,
    globals must be a dictionary. If provided, locals can be any mapping object.

    The expression argument is parsed and evaluated `as a Python expression`
    (technically speaking, a condition list) using the globals and locals
    dictionaries as global and local namespace. If the globals dictionary is
    present and lacks ‘__builtins__’, the current globals are copied into
    globals before expression is parsed. This means that expression normally
    has full access to the standard builtins module and restricted
    environments are propagated. If the locals dictionary is omitted it
    defaults to the globals dictionary. If both dictionaries are omitted, the
    expression is executed in the environment where eval() is called. The
    return value is the result of the evaluated expression. Syntax errors are
    reported as exceptions. Example:

    >>> x = 1
    >>> eval('x+1')
    2

    This function can also be used to execute arbitrary code objects (such as
        those created by compile()). In this case pass a code object instead
    of a string. If the code object has been compiled with 'exec' as the mode
    argument, eval()‘s return value will be None.

    Hints: dynamic execution of statements is supported by the exec()
    function. The globals() and locals() functions returns the current global
    and local dictionary, respectively, which may be useful to pass around for
    use by eval() or exec().

    See ast.literal_eval() for a function that can safely evaluate strings
    with expressions containing only literals.

<py-raw-input>
raw_input([prompt])

If the prompt argument is present, it is written to standard output without a
trailing newline. The function then reads a line from input, converts it to a
string (stripping a trailing newline), and returns that. When EOF is read,
EOFError is raised. Example:

>>> s = raw_input('--> ')
--> Monty Python's Flying Circus
>>> s
"Monty Python's Flying Circus"

If the readline module was loaded, then raw_input() will use it to provide
elaborate line editing and history features.

Version skew note: If you are working in Python 2.X, use raw_input() instead
of input() in this code. The former was renamed to the latter in Python 3.X.
Technically, 2.X has an input function too, but it also evaluates strings as
though they are program code typed into a script, and so will not work in this
context (an empty string is an error). Python 3.X’s input (and 2.X’s
    raw_input) simply returns the entered text as a character string,
unevaluated. To simulate 2.X’s input in 3.X, use eval(input()).

<ex>

// Do the actions look OK? (yes/no/confirm): xx
// Invalid answer!
// Do the actions look OK? (yes/no/confirm): yes
// yes

answer = getAnswer('Do the actions look OK?', ['yes', 'no', 'confirm'])

def getAnser(question, answers):
  repr_answers = ' (%s): ' % '/'.join(answers)
  answer = raw_input(question + repr_answers)
  while answer not in answers:
    print 'Invalid answer!'
    answer = raw_input(question + repr_answers)
  return answer


={============================================================================
|kt_dev_py_0001| py-os

https://docs.python.org/3.4/library/os.path.html

11.2. os.path  Common pathname manipulations


os.path.abspath(path)

    Return a normalized absolutized version of the pathname path. On most
    platforms, this is equivalent to calling the function normpath() as
    follows: normpath(join(os.getcwd(), path)).


os.path.dirname(path)

    Return the directory name of pathname path. This is the first element of
    the pair returned by passing path to the function split().


https://docs.python.org/3.4/library/os.html

16.1.5. Files and Directories


os.listdir(path='.')

    Return a list containing the names of the entries in the directory given
    by path. The list is in arbitrary order, and does not include the special
    entries '.' and '..' even if they are present in the directory.

    path may be either of type str or of type bytes. If path is of type bytes,
    the filenames returned will also be of type bytes; in all other circumstances,
    they will be of type str.

    This function can also support specifying a file descriptor; the file
    descriptor must refer to a directory.

    Note
    To encode str filenames to bytes, use fsencode().

    Availability: Unix, Windows.

    Changed in version 3.2: The path parameter became optional.

    New in version 3.3: Added support for specifying an open file descriptor
    for path.

<ex>
    # Check the folder exists
    if os.path.isdir (dir):
        # Check if the folder is empty
        if os.listdir (dir) == []:


={============================================================================
|kt_dev_py_0001| py-urllib

https://docs.python.org/2/library/urllib2.html

The urllib2 module defines functions and classes which help in opening URLs
(mostly HTTP) in a complex world  basic and digest authentication,
redirections, cookies and more.


<ex>
>>> import urllib2
>>> res = urllib2.urlopen("http://theyard.cisco.com/diagconf.txt")
>>> res
<addinfourl at 3067798252L whose fp = <socket._fileobject object at 0xb6d8266c>>
>>> content = res.read()

# the fils is:
#
# [
#       [["AMS"], ["AMS"]],
#       [["AFLPROXY"],["darwin_aflproxy_bindings_AS3"]],
#       [["DIAG_TIMESTAMP"], ["diag_svr"]],
#       [["CAPTRANS"], ["ms_captrans_src"]],
#       [["CAPTRANS_INPUT"], ["ms_captrans_src"]],
#       [["CAPTRANS_OUTPUT"], ["ms_captrans_src"]],
#       [["CAPTRANS_TTML"], ["ms_captrans_src"]],
#       [["PPCM_CF"], ["ppcm", "ppcm_core"]],
#       [["PPCM_CL"], ["ppcm", "ppcm_core"]],
#       [["PPCM_CORE"], ["ppcm", "ppcm_core"]],
#       ...
#
# returns a single long string
>>> content
'[\n      [["AMS"], ["AMS"]],\n      [["AFLPROXY"],["darwin_aflproxy_bindings_AS3"]],\n      [["DIAG_TIMESTAMP"], ["diag_svr"]],\n      [["CAPTRANS"], ["ms_captrans_src"]],\n      [["CAPTRANS_INPUT"], ["ms_captrans_src"]],\n      [["CAPTRANS_OUTPUT"], ["ms_captrans_src"]],\n      [["CAPTRANS_TTML"], ["ms_captrans_src"]],\n      [["PPCM_CF"], ["ppcm", "ppcm_core"]],\n      [["PPCM_CL"], ["ppcm", "p..'


={============================================================================
|kt_dev_py_0001| py-file

Chapter 9: Tuples, Files, and Everything Else

the built-in `open` function creates a Python `file object`, which serves as a
link to a file residing on your machine. After calling open, you can transfer
strings of data to and from the associated external file by calling the
returned file object's methods.

afile = open(filename, mode)
afile.method()

Without a directory path, the file is assumed to exist in the current working
directory. Use either a relative or absolute file path

path = 'ch13/segismundo.txt'
f = open(path)

By default, the file is opened in read-only mode 'r'. 

<py-open>

https://docs.python.org/2/library/functions.html#open

2. Built-in Functions

open(name[, mode[, buffering]])

Open a file, returning an object of the file type described in section File
Objects. If the file cannot be opened, IOError is raised. When opening a file,
  it’s preferable to use open() instead of invoking the file constructor
    directly.

The first two arguments are the same as for stdio‘s fopen(): 
name is the file name to be opened, and mode is a string indicating how the
  file is to be opened.

The most commonly-used values of mode are 'r' for reading, 'w' for writing
  (truncating the file if it already exists), and 'a' for appending (which on
      some Unix systems means that all writes append to the end of the file
      regardless of the current seek position). If mode is omitted, it
  defaults to 'r'. The default is to use text mode, which may convert '\n'
  characters to a platform-specific representation on writing and back on
  reading. Thus, when opening a binary file, you should append 'b' to the mode
  value to open the file in binary mode, which will improve portability.
  (Appending 'b' is useful even on systems that don’t treat binary and text
   files differently, where it serves as documentation.) See below for more
  possible values of mode.

The optional buffering argument specifies the file’s desired buffer size: 0
means unbuffered, 1 means line buffered, any other positive value means use a
buffer of (approximately) that size (in bytes). A negative buffering means to
use the system default, which is usually line buffered for tty devices and
fully buffered for other files. If omitted, the system default is used. [2]

Modes 'r+', 'w+' and 'a+' open the file for updating (reading and writing);
note that 'w+' truncates the file. Append 'b' to the mode to open the file in
  binary mode, on systems that differentiate between binary and text files; on
  systems that don’t have this distinction, adding the 'b' has no effect.

# from fopen
DESCRIPTION
       The fopen() function opens the file whose name is the string pointed to
       by path and associates a stream with it.

       The argument mode points to a string beginning with one of the
       following sequences (possibly followed by additional characters, as
           described below):

       r      Open text file for reading.  The stream is positioned at the
         beginning of the file.

       r+     Open for reading and writing.  The stream is positioned at the
       beginning of the file.

       w      Truncate file to zero length or create text file for writing.
       The stream is positioned at the beginning of the file.

       w+     Open for reading and writing.  The file is created if it does
       not exist, otherwise it is truncated.  The stream is positioned at the
       beginning of the file.

       a      Open for appending (writing at end of file).  The file is
       created if it does not exist.  The stream is positioned at the end of
       the file.

       a+     Open for reading and appending (writing at end of file).  The
       file is created if it does not exist.  The initial file position for
       reading is at the beginning of the file, but output is always appended
       to the end of the file.


<for-vs-readline>
https://docs.python.org/2/tutorial/inputoutput.html

7.2.1. Methods of File Objects

f.readline() reads a single line from the file; a newline character (\n) is
left at the end of the string, and is only omitted on the last line of the
file if the file doesn't end in a newline. This makes the return value
unambiguous; if f.readline() returns an empty string, the end of the file has
been reached, while a blank line is represented by '\n', a string containing
only a single newline.

>>> f.readline()
'This is the first line of the file.\n'
>>> f.readline()
'Second line of the file\n'
>>> f.readline()
''

*iteration-protocol*
For reading lines from a file, you can loop over the file object. This is
memory efficient, fast, and leads to simple code:

>>> for line in f:
        print line,

This is the first line of the file.
Second line of the file


# Or this way. File iterators read line by line
for line in open('data'): 
  use line 

The lines come out of the file with the end-of-line (EOL) markers intact, so
you'll often see code to get an EOL-free list of lines

lines = [x.rstrip() for x in open(path)]

If you want to read `all the lines` of a file in a list you can also use list(f)
or f.readlines().


To write text to a file, you can use either the file's `write` or `writelines`
methods. With no blank lines like so:

<py-file-operations>
https://docs.python.org/2/library/stdtypes.html

5. Built-in Types

5.9. File Objects

file.write(str)
Write a string to the file. There is no return value. Due to buffering, the
string may not actually show up in the file until the flush() or close()
method is called.

file.writelines(sequence) 
Write a sequence of strings to the file. The sequence can be any iterable
object producing strings, typically a list of strings. There is no return
value. (The name is intended to match readlines(); writelines() `does not add`
line separators.)

file.read([size])
Read at most size bytes from the file (less if the read hits EOF before
obtaining size bytes). If the size argument is negative or omitted, read all
data `until EOF is reached.` The bytes are returned as a string object. An
empty string is returned when EOF is encountered immediately

file.next()
A file object is its own iterator, for example iter(f) returns f (unless f is
    closed). When a file is used as an iterator, typically in a for loop (for
      example, for line in f: print line.strip()), the next() method is called
    repeatedly. This method returns the next input line, or raises
    StopIteration when EOF is hit when the file is open for reading (behavior
        is undefined when the file is open for writing). In order to make a
    for loop the most efficient way of looping over the lines of a file (a
        very common operation), the next() method uses a hidden read-ahead
      buffer. As a consequence of using a read-ahead buffer, combining next()
        with other file methods (like readline()) does not work right.
        However, using seek() to reposition the file to an absolute position
        will flush the read-ahead buffer.

New in version 2.3.


# see *with-as-context*
with open('tmp.txt', 'w') as handle:
  handle.writelines(x for x in open(path) if len(x) > 1)

open('tmp.txt').readlines()


As discussed, in Python an object's memory space is automatically reclaimed as
soon as the object is no longer referenced anywhere in the program. When file
objects are reclaimed, Python also automatically closes the files if they are
still open (this also happens when a program shuts down).

`write` methods don't add the end-of-line character for us, so we must include
it to properly terminate our lines

>>> myfile.write('hello text file\n') # Write a line of text: string
>>>
>>> myfile.readline()                 # Read the lines back
'hello text file\n'


Storing Python Objects in Files: Conversions

Have to use other conversion tools to translate from the strings in the text
file to real Python objects.

>>> X, Y, Z = 43, 44, 45 # Native Python objects
>>> S = 'Spam' # Must be strings to store in file
>>> D = {'a': 1, 'b': 2}
>>> L = [1, 2, 3]
>>>
>>> F = open('datafile.txt', 'w') # Create output text file
>>> F.write(S + '\n') # Terminate lines with \n
>>> F.write('%s,%s,%s\n' % (X, Y, Z)) # Convert numbers to strings
>>> F.write(str(L) + '$' + str(D) + '\n') # Convert and separate with $
>>> F.close()

>>> line = F.readline() # Next line from file
>>> line # It's a string here
'43,44,45\n'
>>> parts = line.split(',') # Split (parse) on commas
>>> parts
['43', '44', '45\n']

>>> int(parts[1]) # Convert from string to int
44
>>> numbers = [int(P) for P in parts] # Convert all in list at once
>>> numbers
[43, 44, 45]

*eval-keyword-eval*

>>> line = F.readline()
>>> line
"[1, 2, 3]${'a': 1, 'b': 2}\n"
>>> parts = line.split('$') # Split (parse) on $
>>> parts
['[1, 2, 3]', "{'a': 1, 'b': 2}\n"]
>>> eval(parts[0]) # Convert to any object type
[1, 2, 3]
>>> objects = [eval(P) for P in parts] # Do same for all in list
>>> objects
[[1, 2, 3], {'a': 1, 'b': 2}]


={============================================================================
|kt_dev_py_0001| py-itertools

https://docs.python.org/2/library/itertools.html#itertools.islice

 itertools.islice(iterable, stop)

<ex>
  # reads a file by section_size unit and makes it a list
  log_list = list(islice(log_file, section_size))


={============================================================================
|kt_dev_py_0001| py-cvs

https://docs.python.org/2/library/csv.html

<ex>
import csv

    ret_list = list(csv.reader(open(path), delimiter="\t"))    


={============================================================================
|kt_dev_py_0001| py-re

https://docs.python.org/2/library/re.html

*TN*
Since POSIX is not supported by Python re module, you have to emulate it with
the help of character class. 

DO not support character class such as [[:alnum::]]


Q:

# to support:
# http://theyard.cisco.com/si_logs/translation/darwin_783e53fe4a60_81b952e11b7e50199c8d07a4649310c7/index.html
# darwin_783e53ffaa6d_9276a4c871ae42a6a41f729def322c3f.tgz

# why do not cover both?
# match = re.match('(darwin_[0-9A-Za-z]{12}_[0-9A-Za-z]{32})', sys.argv[1])
match = re.match('.*(darwin_[0-9A-Za-z]{12}_[0-9A-Za-z]{32})', sys.argv[1])


7.2. re  Regular expression operations

This module provides regular expression matching operations similar to those
found in Perl


7.2.1. Regular Expression Syntax

\d
    When the UNICODE flag is not specified, matches any decimal digit; this is
    equivalent to the set [0-9]. With UNICODE, it will match whatever is
    classified as a decimal digit in the Unicode character properties
    database.


7.2.2. Module Contents

The module defines several functions, constants, and an exception. 

Some of the functions are simplified versions of the `full featured methods`
for `compiled` regular expressions. Most non-trivial applications always use
  the compiled form.

re.compile(pattern, flags=0)

    Compile a regular expression `pattern into a regular expression object`,
            which can be used for matching using its match() and search()
              methods, described below.

    The expression's behaviour can be modified by specifying a flags value.
    Values can be any of the following variables, combined using bitwise OR
    (the | operator).

    The sequence

    prog = re.compile(pattern)
    result = prog.match(string)

    is equivalent to

    result = re.match(pattern, string)

    but using re.compile() and saving the resulting regular expression object
    for reuse is `more efficient` when the expression will be used several times
      in a single program.

    Note
    The compiled versions of the most recent patterns passed to re.match(),
        re.search() or re.compile() are cached, so programs that use only a
          few regular expressions at a time needn't worry about compiling
          regular expressions.


re.search(pattern, string, flags=0)

    Scan through string looking for `the first location` where the regular
    expression pattern produces a match, and return a corresponding
    MatchObject instance. 
    
    Return None if no position in the string matches the pattern; note that
    this is different from finding a zero-length match at some point in the
    string.


re.match(pattern, string, flags=0)

    If zero or more characters at the beginning of string match the regular
    expression pattern, return a corresponding MatchObject instance. 
    
    Return None if the string does not match the pattern; note that this is
    different from a zero-length match.

    Note that even in MULTILINE mode, re.match() will only match at the
    beginning of the string and not at the beginning of each line.

    If you want to locate a match anywhere in string, use search() instead
    (see also search() vs. match()).


// *py-re-findall*
re.findall(pattern, string, flags=0)

Return all non-overlapping matches of pattern in string, `as a list of strings.`
The string is scanned left-to-right, and matches are returned in the order
found. If one or more groups are present in the pattern, return a list of
groups; this will be a list of tuples if the pattern has more than one group.
Empty matches are included in the result unless they touch the beginning of
another match.


7.2.5.3. search() vs. match()

Python offers two different primitive operations based on regular expressions:
re.match() checks for a match only at the beginning of the string, while
re.search() checks for a match anywhere in the string (this is what Perl does
    by default).

For example:

>>> re.match("c", "abcdef")    # No match
>>> re.search("c", "abcdef")   # Match
<_sre.SRE_Match object at ...>

Regular expressions beginning with '^' can be used with search() to restrict
the match at the beginning of the string:

>>> re.match("c", "abcdef")    # No match
>>> re.search("^c", "abcdef")  # No match
>>> re.search("^a", "abcdef")  # Match
<_sre.SRE_Match object at ...>

Note however that in MULTILINE mode match() only matches at the beginning of
the string, whereas using search() with a regular expression beginning with
'^' will match at the beginning of each line.

>>> re.match('X', 'A\nB\nX', re.MULTILINE)    # No match
>>> re.search('^X', 'A\nB\nX', re.MULTILINE)  # Match
<_sre.SRE_Match object at ...>


re.split(pattern, string, maxsplit=0, flags=0)

    Split string by the occurrences of pattern. 

    If capturing parentheses are used in pattern, then the text of all groups
    in the pattern are also returned as part of the resulting list. 
    
    If maxsplit is nonzero, at most maxsplit splits occur, and the remainder
    of the string is returned as the final element of the list.
    (Incompatibility note: in the original Python 1.5 release, maxsplit was
     ignored. This has been fixed in later releases.)

>>> re.split('[/:]', '/usr/home/lumberjack')
['', 'usr', 'home', 'lumberjack']

>>> re.split('\W+', 'Words, words, words.')
['Words', 'words', 'words', '']



7.2.4. Match Objects

group([group1, ...])

    Returns one or more subgroups of the match.

    Without arguments, group1 defaults to zero (the whole match is returned).

    // group[0]
    If a groupN argument is zero, the corresponding return value is the entire
    matching string; if it is in the inclusive range [1..99], it is the string
    matching the corresponding parenthesized group.

    If the regular expression uses the (?P<name>...) syntax, the groupN
    arguments may `also be strings identifying groups by their group name` If a
    string argument is not used as a group name in the pattern, an IndexError
    exception is raised.

groups([default])

    Return a tuple containing all the subgroups of the match, from 1 up to
    however many groups are in the pattern.

>>> match = re.match('Hello[ \t]*(.*)world', 'Hello Python world')
>>> match.group(0)
'Hello Python world'
>>> match.group(1)
'Python '

>>> match = re.match('[/:](.*)[/:](.*)[/:](.*)', '/usr/home:lumberjack')
>>> match.groups()
('usr', 'home', 'lumberjack')

>>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
>>> m.group('first_name')
'Malcolm'
>>> m.group('last_name')
'Reynolds'


*py-raw-string*
import re
f='drx890.SYSF40.73.00.enc.snugupdate'
m=re.match(r'^(?P<type>.+)\.SYSF(?P<version>[\d.]+)', f)
print 'DEBUG: f: %s, match.group(type): %s, m.group(version): %s' % (f, m.group('type'), m.group('version'))
DEBUG: f: drx890.SYSF40.73.00.enc.snugupdate, match.group(type): drx890, m.group(version): 40.73.00.


groupdict([default])

    Return a dictionary containing all the named subgroups of the match, keyed
    by the subgroup name. The default argument is used for groups that did not
    participate in the match; it defaults to None. For example:

    >>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
    >>> m.groupdict()
    {'first_name': 'Malcolm', 'last_name': 'Reynolds'}


<ex>
  # see multiple regex
  def _getVersionNumber(self, value):
      regexes = (r'(?P<model_release>R\d+)\.(?P<version>\d+\.\d+\.\d+)',
                 r'(?P<version>\d+\.\d+\.\d+)_\d+_(?P<model_release>WALRUS-ENG-\d+)' )
      for r in regexes:
        result = re.match(r, value)
        if result is not None:
          return result.groupdict()
      raise Exception('Could not parse model number %s' % value)

<ex>
# Sample line:
# NDS: ^0946684966.710878 !ERROR -SRM          < p:000000c1 t:016121b0 T:SRM_LP_THREAD M:srm_utils.c F:SRM_SystemStringToCString L:00287 > **** SRM ERR in srm_utils.c:287
#
# currently supports match = {1, 2, 3, 4, 5}
#       error type such as FATAL, ERROR, WARN, MIL and which is GROUP(1)
#       component type such as SRM and which is GROUP(2)
#       filename which is GROUP(3)
#       func which is GROUP(4)
#       free text which is GROUP(5)

# \s : any whitespace char
# \S : any not-whilespace char
# '?': causes the resulting RE to match 0 or 1 repetitions of the preceding RE. ab? will match either 'a' or 'ab'.

# NOTE. there's no support for a leading numbers of the dict line.
# NOTE. added MIL just for usefulness.
# NOTE. possibly add 'T:' group?

# extract interested groups from a dict entry. grab the whole free text.
matchDic = re.search(r'^NDS:.*!(FATAL|ERROR|WARN|MIL)\s+-(\S+).*(M:\S+)\s+(F:\S+).*>(.*)', lineDic )


={============================================================================
|kt_dev_py_0001| py-pip

https://pip.pypa.io/en/stable/

<install-pip>
$ sudo python get-pip.py

Quickstart

Install a package from PyPI:

$ pip install SomePackage
  [...]
  Successfully installed SomePackage

https://packaging.python.org/glossary/#term-python-package-index-pypi
Python Package Index (PyPI)
    PyPI is the default Package Index for the Python community. It is open to
    all Python developers to consume and distribute their distributions.

To search package:
https://pypi.python.org/pypi/

<to-list>
https://pip.pypa.io/en/stable/reference/pip_freeze/

pi@raspberrypi ~/snugupdate-v2-snugberrypi $ pip freeze
Warning: cannot find svn location for distribute==0.6.24dev-r0
PAM==0.4.2
RPi.GPIO==0.5.11
Twisted==12.0.0
Twisted-Conch==12.0.0
Twisted-Core==12.0.0
Twisted-Lore==12.0.0
Twisted-Mail==12.0.0
Twisted-Names==12.0.0
Twisted-News==12.0.0
Twisted-Runner==12.0.0
Twisted-Web==12.0.0
Twisted-Words==12.0.0
argparse==1.2.1
cffi==1.1.2
cryptography==0.9.1
## FIXME: could not find svn URL in dependency_links for this package:
distribute==0.6.24dev-r0
dropbox==2.2.0

<to-upgrade>
https://pip.pypa.io/en/stable/reference/pip_install/

-U, --upgrade
Upgrade all specified packages to the newest available version. The handling
of dependencies depends on the upgrade-strategy used.

3. Upgrade an already installed SomePackage to the latest from PyPI.

$ pip install --upgrade SomePackage


={============================================================================
|kt_dev_py_0001| py-dropbox

https://www.dropbox.com/developers/documentation/python#install
Install Dropbox for Python

To get started with Dropbox for Python, we recommend you add the SDK to your
project using pip.

Download and install the SDK.

pip install dropbox

Now you can do "import dropbox" in your Python app, or in a Python interpreter.

import dropbox

That's it! Now you're ready to get started with the tutorial.


https://www.dropbox.com/developers/documentation/python#tutorial
Link an account

In order to make calls to the API, you'll need an instance of the Dropbox
object. To instantiate, pass in the access token for the account you want to
link. (Tip: You can generate an access token for your own account through the
    App Console).

dbx = dropbox.Dropbox('YOUR_ACCESS_TOKEN')

Test it out to make sure you've linked the right account:

dbx.users_get_current_account()


<core-api>
https://www.dropbox.com/developers-v1/core/start/python
Warning: API v1 has been deprecated. Learn more.

Using the Core API in Python

The Core API is based on HTTP and OAuth and provides low-level calls to access
and manipulate a user's Dropbox account.

If you want to follow along, first register a new app on the App Console.
You'll need the app key to access the Core API. Then install the Python SDK
and you'll be ready to go.


Downloading files

Some time has passed and you're ready to start editing that magnum opus of
yours again. We'll need the get_file_and_metadata method to download the file.

f, metadata = client.get_file_and_metadata('/magnum-opus.txt')
out = open('magnum-opus.txt', 'wb')
out.write(f.read())
out.close()
print metadata

get_file_and_metadata, like other calls that return file data, returns an
httplib.HTTPResponse that you should .read() from to get the full response.
https://www.dropbox.com/developers-v1/core/docs/python#DropboxClient.get_file_and_metadata

https://github.com/andreafabrizi/Dropbox-Uploader
# creates si-pi-prepare-deploy-roll under db:snugupdate-v2-snugberrypi-roll/
/home/kyoupark/si/si-pi-prepare-deploy-roll$ /home/kyoupark/Dropbox-Uploader/dropbox_uploader.sh upload . /snugberrypi/snugupdate-v2-snugberrypi-roll

# works
kyoupark@kit-debian64:~/si/snugupdate-v2-snugberrypi-roll$ /home/kyoupark/Dropbox-Uploader/dropbox_uploader.sh upload . /snugberrypi/


={============================================================================
|kt_dev_py_0001| py-imaplib


={============================================================================
|kt_dev_py_0001| py-time

https://docs.python.org/2/library/time.html

This module provides various time-related functions. For related
functionality, see also the datetime and calendar modules.

Although this module is always available, not all functions are available on
all platforms. Most of the functions defined in this module call platform C
library functions with the same name. It may sometimes be helpful to consult
the platform documentation, because the semantics of these functions varies
among platforms.

An explanation of some terminology and conventions is in order.

time.time()

    Return the time in seconds since the epoch as a floating point number.
    Note that even though the time is always returned as a floating point
    number, not all systems provide time with a better precision than 1
    second. While this function normally returns non-decreasing values, it can
    return a lower value than a previous call if the system clock has been set
    back between the two calls.


={============================================================================
|kt_dev_py_0001| py-time-benchmark

Learning Python 5E, 21, The Benchmarking Interlude

The range call is hoisted out of the timing loop in the total function, so its
construction cost is not charged to the timed function in Python 2.X. In 3.X
range is an iterable, so this step is neither required nor harmful, but we
still run the result through list so its traversal cost is the same in both
2.X and 3.X. This doesn’t apply to the bestof function, since no range factors
are charged to the test’s time.


<ex>
#!/usr/bin/env python
"""
homegrown timing tools for function calls.
does total time, best-of time, and best-of-totals time
"""

import time, sys

# >>> sys.platform
# 'win32'

timer = time.clock if sys.platform[:3] == 'win' else time.time

def total( reps, func, *pargs, **kargs):
    """
    total time to run func() reps times.
    returns( total time, last result )
    """
    repslist = list(range(reps))
    start = timer()
    for i in repslist:
        ret = func(*pargs, **kargs)

    elapsed = timer() - start
    return (elapsed, ret)


def bestof( reps, func, *pargs, **kargs):
    """
    quickest func() among reps runs.
    returns( best time, last result )
    """
    best = 2**32

    # range usuage not timed here
    for i in range(reps):
        start = timer()
        ret = func(*pargs, **kargs)
        elapsed = timer()-start
        if elapsed < best: best = elapsed
    return (best, ret)


def bestoftotal( rep1, rep2, func, *pargs, **kargs):
    """
    best of totals:
    (best of rep1 runs of (total of rep2 runs of func))
    """
    return bestof( rep1, total, rep2, func, *pargs, **kargs)


if __name__ == "__main__":
    ret = total( 1000, pow, 2, 1000)
    print 'time taken to pow is %f' % (ret[0])
    ret = bestof( 1000, pow, 2, 1000)
    print 'time taken to best of pow is %f' % (ret[0])
    ret = bestoftotal( 50, 1000, pow, 2, 1000)
    print 'time taken to bestoftotal of pow is %f' % (ret[0])


See the way we use these and the both do the same and return the best-of
tuple, which embeds the last total call’s result tuple.

>>> timer.bestof(50, timer.total, 1000, str.upper, 'spam')
(0.0005468751145372153, (0.0005004469323637295, 'SPAM'))

>>> timer.bestoftotal(50, 1000, str.upper, 'spam')
(0.000566912540591602, (0.0005195069228989269, 'SPAM'))

note: that is, bestoftotal limits itself to use total. 


#!/usr/bin/env python
"Test the relative speed of iteration tool alternatives."

import sys, timer

reps = 10000

replist = list(range(reps))

# for loop
def forLoop():
    res = []
    for x in replist:
        res.append(abs(x))
    return res

# list comprehension
def listComp():
    return [abs(x) for x in replist]

# map call
def mapCall():
    return map(abs, replist)

# generator expression
def genExpr():
    return list(abs(x) for x in replist)

# generator function
def genFunc():
    def gen():
        for x in replist:
            yield abs(x)
    return list(gen())


print(sys.version)
for test in (forLoop, listComp, mapCall, genExpr, genFunc):
    (bestof, (total, result)) = timer.bestoftotal(5, 1000, test)
    print('%-9s: %.5f => [%s...%s]' %
            (test.__name__, bestof, result[0], result[-1]))


kit-debian64:~/works$ ./timeseqs.py 
2.7.9 (default, Jun 29 2016, 13:08:31) 
[GCC 4.9.2]
forLoop  : 0.85904 => [0...9999]
listComp : 0.53057 => [0...9999]
mapCall  : 0.32763 => [0...9999]
genExpr  : 0.71238 => [0...9999]
genFunc  : 0.72132 => [0...9999]

note: see that list comprehension and map is better than for loop.


<py-timeit>
the standard library also ships with a module named timeit that can be used in
similar ways, but offers added flexibility and may better insulate clients
from some platform differences.

With timeit, tests are specified by either callable objects or statement
strings; the latter can hold multiple statements if they use ; separators or
\n characters for line breaks, and spaces or tabs to indent statements in
nested blocks (e.g., \n\t).

# timeit.repeat(stmt=’pass’, setup=’pass’, timer=<default timer>, repeat=3, number=1000000)
# 
# Create a Timer instance with the given statement, setup code and timer
# function and run its repeat() method with the given repeat count and number
# executions.
# 
# New in version 2.6.

# use karg version
>>> timer.bestoftotal(pow, 2, 1000, _reps1=50, _reps=1000)[0]
0.0015938282012939453


>>> import timeit
>>> min(timeit.repeat(stmt="pow(2, 1000)", number=1000, repeat=50))
0.0016210079193115234


={============================================================================
|kt_dev_py_0001| py-time-datetime

https://docs.python.org/2/library/datetime.html

https://docs.python.org/2/library/datetime.html#strftime-strptime-behavior
8.1.7. strftime() and strptime() Behavior

date, datetime, and time objects all support a strftime(format) method, to
create a string representing the time under the control of an explicit format
string. Broadly speaking, d.strftime(fmt) acts like the time module’s
time.strftime(fmt, d.timetuple()) although not all objects support a
timetuple() method.

<ex>
time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')


={============================================================================
|kt_dev_py_0001| py-cvs

The standard library of Python provides a CSV reader. The Python script below
completes this goal:

#!/usr/bin/env python
# CSV module that comes with the Python standard library
import csv
import sys

if __name__ == "__main__":
    # The CSV module exposes a reader object that takes
    # a file object to read. In this example, sys.stdin.
    csvfile = csv.reader(sys.stdin)

    # The script should take one argument that is a column number.
    # Command-line arguments are accessed via sys.argv list.
    column_number = 0
    if len(sys.argv) > 1:
            column_number = int(sys.argv[1])

    # Each row in the CSV file is a list with each 
    # comma-separated value for that line.
    for row in csvfile:
            print row[column_number]


={============================================================================
|kt_dev_py_0001| py-stmplib

#!/usr/bin/env python
import smtplib
import sys


GMAIL_SMTP_SERVER = "smtp.gmail.com"
GMAIL_SMTP_PORT = 587

GMAIL_EMAIL = "Your Gmail Email Goes Here"
GMAIL_PASSWORD = "Your Gmail Password Goes Here"


def initialize_smtp_server():
    '''
    This function initializes and greets the smtp server.
    It logs in using the provided credentials and returns 
    the smtp server object as a result.
    '''
    smtpserver = smtplib.SMTP(GMAIL_SMTP_SERVER, GMAIL_SMTP_PORT)
    smtpserver.ehlo()
    smtpserver.starttls()
    smtpserver.ehlo()
    smtpserver.login(GMAIL_EMAIL, GMAIL_PASSWORD)
    return smtpserver


def send_thank_you_mail(email):
    to_email = email
    from_email = GMAIL_EMAIL
    subj = "Thanks for being an active commenter"
    # The header consists of the To and From and Subject lines
    # separated using a newline character
    header = "To:%s\nFrom:%s\nSubject:%s \n" % (to_email,
            from_email, subj)
    # Hard-coded templates are not best practice.
    msg_body = """
    Hi %s,

    Thank you very much for your repeated comments on our service.
    The interaction is much appreciated.

    Thank You.""" % email
    content = header + "\n" + msg_body

    smtpserver = initialize_smtp_server()
    smtpserver.sendmail(from_email, to_email, content)
    smtpserver.close()


if __name__ == "__main__":
    # for every line of input.
    for email in sys.stdin.readlines():
            send_thank_you_mail(email)


={============================================================================
|kt_dev_py_0001| py-parser-option py-arg

https://docs.python.org/2/howto/argparse.html#id1

Note There are two other modules that fulfill the same task, namely getopt (an
    equivalent for getopt() from the C language) and the deprecated optparse.
  Note also that argparse is based on optparse, and therefore very similar in
  terms of usage.

The basics

Let us start with a very simple example which does (almost) nothing:

import argparse
parser = argparse.ArgumentParser()
parser.parse_args()


Following is a result of running the code:

$ python prog.py
$ python prog.py --help
usage: prog.py [-h]

optional arguments:
  -h, --help  show this help message and exit
$ python prog.py --verbose
usage: prog.py [-h]
prog.py: error: unrecognized arguments: --verbose
$ python prog.py foo
usage: prog.py [-h]
prog.py: error: unrecognized arguments: foo
Here is what is happening:

Running the script without any options results in nothing displayed to stdout.
Not so useful.  The second one starts to display the usefulness of the
argparse module. We have done almost nothing, but already we get a nice help
message.  The --help option, which can also be shortened to -h, is the only
option we get for free (i.e. no need to specify it). Specifying anything else
results in an error. But even then, we do get a useful usage message, also for
free.

Introducing Positional arguments

An example:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("echo")
args = parser.parse_args()
print args.echo
And running the code:


$ python tut_01.py
usage: tut_01.py [-h] echo
tut_01.py: error: too few arguments

$ python tut_01.py echo
echo

$ python tut_01.py -h
usage: tut_01.py [-h] echo

`positional arguments`:
  echo

optional arguments:
  -h, --help  show this help message and exit

$ python tut_01.py foo
foo


Here is what’s happening:

We’ve added the add_argument() method, which is what we use to specify which
command-line options the program is willing to accept. In this case, I’ve
named it echo so that it’s in line with its function.

Calling our program now requires us to specify an option.

The parse_args() method actually returns some data from the options specified,
in this case, echo.

The variable is some form of ‘magic’ that argparse performs for free 
(i.e. `no need to specify which variable that value is stored in`). You will also
notice that its name matches the string argument given to the method, echo.

Note however that, although the help display looks nice and all, it currently
is not as helpful as it can be. For example we see that we got echo as a
positional argument, but we don’t know what it does, other than by guessing or
by reading the source code. So, let’s make it a bit more useful:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("echo", help="echo the string you use here")
args = parser.parse_args()
print args.echo


And we get:

$ python prog.py -h
usage: prog.py [-h] echo

positional arguments:
  echo        echo the string you use here

optional arguments:
  -h, --help  show this help message and exit


Now, how about doing something even more useful:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", help="display a square of a given number")
args = parser.parse_args()
print args.square**2


Following is a result of running the code:

$ python prog.py 4
Traceback (most recent call last):
  File "prog.py", line 5, in <module>
    print args.square**2
TypeError: unsupported operand type(s) for ** or pow(): 'str' and 'int'

That didn’t go so well. That’s because argparse treats the options we give it
  as strings, unless we tell it otherwise. So, let’s tell argparse to treat
  that input as an integer:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", help="display a square of a given number", type=int)
args = parser.parse_args()
print args.square**2


Following is a result of running the code:

$ python prog.py 4
16
$ python prog.py four
usage: prog.py [-h] square
prog.py: error: argument square: invalid int value: 'four'

That went well. The program now even helpfully quits on bad illegal input
before proceeding.


// import argparse
// 
// parser = argparse.ArgumentParser()
// parser.add_argument("echo", help="echo the string you use here")
// parser.add_argument("square", help="display a square of a given number", type=int)
// args = parser.parse_args()
// print args.echo
// print args.square**2
// 
// $ python tut_01.py xxx 20
// xxx
// 400


Introducing Optional arguments

So far we have been playing with positional arguments. Let us have a look on
how to add optional ones:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("--verbosity", help="increase output verbosity")
args = parser.parse_args()
if args.verbosity:
    print "verbosity turned on"

And the output:

$ python prog.py --verbosity 1
verbosity turned on
$ python prog.py

$ python prog.py --help
usage: prog.py [-h] [--verbosity VERBOSITY]

`optional arguments:`
  -h, --help            show this help message and exit
  `--verbosity VERBOSITY`
                        increase output verbosity

$ python prog.py --verbosity
usage: prog.py [-h] [--verbosity VERBOSITY]
prog.py: error: argument --verbosity: expected one argument

Here is what is happening:

The program is written so as to display something when --verbosity is
specified and display nothing when not.

To show that the option is actually optional, there is no error when running
the program without it. Note that by default, if an optional argument isn’t
used, the relevant variable, in this case args.verbosity, is given None as a
value, which is the reason it fails the truth test of the if statement.

The help message is a bit different.

When using the --verbosity option, one must also specify some value, any
value.

The above example accepts arbitrary integer values for --verbosity, but for
our simple program, only two values are actually useful, True or False. Let’s
modify the code accordingly:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("--verbose", help="increase output verbosity",
                    action="store_true")
args = parser.parse_args()
if args.verbose:
   print "verbosity turned on"

And the output:

$ python prog.py --verbose
verbosity turned on
$ python prog.py --verbose 1
usage: prog.py [-h] [--verbose]
prog.py: error: unrecognized arguments: 1
$ python prog.py --help
usage: prog.py [-h] [--verbose]

optional arguments:
  -h, --help  show this help message and exit
  `--verbose   increase output verbosity`

Here is what is happening:

The option is now more of a flag than something that requires a value. We even
changed the name of the option to match that idea. Note that we now specify a
new keyword, action, and give it the value "store_true". This means that, if
the option is specified, assign the value True to args.verbose. Not specifying
it implies False.

It complains when you specify a value, in true spirit of what flags actually
are.

Notice the different help text.

<ex>
import argparse

parser = argparse.ArgumentParser()
parser.add_argument("--host", help="build for host", action="store_true")
parser.add_argument("--target", help="build for target", action="store_true")
parser.add_argument("--clang", help="build for clang", action="store_true")
args = parser.parse_args()
if args.host:
    print "host turned on"

if args.target:
    print "target turned on"

if args.clang:
    print "clang turned on"


={============================================================================
|kt_dev_py_0001| py-xml

import xml.dom.minidom


={============================================================================
|kt_dev_py_0001| py-logging

https://docs.python.org/2/library/logging.html?highlight=logging

logging.getLogger([name])

Return a logger with the specified name or, if no name is specified, return a
logger which is the `root logger` of the hierarchy. If specified, the name is
typically a dot-separated hierarchical name like “a”, “a.b” or “a.b.c.d”.
Choice of these names is entirely up to the developer who is using logging.

All calls to this function with a given name return the same logger instance.
This means that logger instances never need to be passed between different
parts of an application.

note: if set settings such as handler or formatter to root logger then all
children logger will use the same setting. However, settings in a chind take
priority over root logger.


<basic-config>

logging.basicConfig([**kwargs])

Does basic configuration for the logging system by creating a StreamHandler
with a default Formatter and adding it to the root logger. The functions
debug(), info(), warning(), error() and critical() will call basicConfig()
automatically if no handlers are defined for the root logger.

This function does nothing if the root logger already has handlers configured
for it.

Note This function should be called from the main thread before other threads
  are started. In versions of Python prior to 2.7.1 and 3.2, if this function
  is called from multiple threads, it is possible (in rare circumstances) that
  a handler will be added to the root logger more than once, leading to
  unexpected results such as messages being duplicated in the log.  The
  following keyword arguments are supported.

Format	Description

filename	
Specifies that a FileHandler be created, using the specified filename, rather
than a StreamHandler.

filemode	
Specifies the mode to open the file, if filename is specified (if filemode is
    unspecified, it defaults to ‘a’).

format	
Use the specified format string for the handler.

datefmt	
Use the specified date/time format.

level	
Set the root logger level to the specified level.

stream	
Use the specified stream to initialize the StreamHandler. Note that this
argument is incompatible with ‘filename’ - if both are present, ‘stream’ is
ignored.

    logging.basicConfig (filename="test.log", level = logging.DEBUG, \
            format = '%(asctime)s-%(levelname)s-%(message)s')

logging.disable(lvl)

Provides an overriding level lvl for all loggers which takes precedence over
the logger’s own level. When the need arises to temporarily throttle logging
output down across the whole application, this function can be useful. Its
effect is to disable all logging calls of severity lvl `and below,` so that if
you call it with a value of INFO, then all INFO and DEBUG events would be
discarded, whereas those of severity WARNING and above would be processed
according to the logger’s effective level. If logging.disable(logging.NOTSET)
is called, it effectively removes this overriding level, so that logging
output again depends on the effective levels of individual loggers.


<ex>
    logging.basicConfig(level=logging.DEBUG, format='[%(levelname)-7s] (%(threadName)-10s) %(message)s')
    # Disable this level and all above, i.e. logging.INFO disables INFO & DEBUG
    # Use logging.NOTSET to get all as per level set during initialisation.
    # logging.disable(logging.INFO)
    logging.info('logging info')
    logging.debug('logging debug')
    logging.warn('logging warn)')

# when use logging.disable(logging.INFO)
kyoupark@kit-debian64:~/works$ ./py-log.py
[WARNING] (MainThread) logging warn)

kyoupark@kit-debian64:~/works$ ./py-log.py
[INFO   ] (MainThread) logging info
[DEBUG  ] (MainThread) logging debug
[WARNING] (MainThread) logging warn)


<ex>
#!/usr/bin/env python

import logging

if __name__ == '__main__':

    # create own logger
    ml = logging.getLogger("ml")
    ml.setLevel(logging.INFO)

    # create formatter
    # 2017-08-07 20:41:44,288 - ml - INFO - server started.
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # add handler to console
    stream_handler = logging.StreamHandler()
    # set formatter
    stream_handler.setFormatter(formatter)

    ml.addHandler(stream_handler)

    # add handler to file
    file_handler = logging.FileHandler('ml.log')
    ml.addHandler(file_handler)

    ml.info("server started.")


<set-logger-from-file>

# logging.json
{
  "version": 1,
  "formatters": {
    "simple": {
      "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    }
  },

  "handlers": {
    "console": {
      "class": "logging.StreamHandler",
      "level": "INFO",
      "formatter": "simple",
      "stream": "ext://sys.stdout"
    },

    "info_file_handler": {
      "class": "logging.FileHandler",
      "level": "DEBUG",
      "formatter": "simple",
      "filename": "info.log"
    }
  },

  # for specific logger
  "loggers": {
    "my_module": {
      "level": "ERROR",
      "handlers": ["console"],
      "propagate": "no"
    }
  },

  "root": {
    "level": "DEBUG",
    "handlers": ["console", "info_file_handler"]
  }
}


#!/usr/bin/env python

import logging
import logging.config
import json

if __name__ == '__main__':

    with open('logging.json', 'rt') as f:
        config = json.load(f)

    logging.config.dictConfig(config)

    # get root logger
    ml = logging.getLogger()

    ml.info("info, server started.")
    ml.debug("debug, server started.")


$ ./py-log.py 
2017-08-07 21:01:52,990 - root - INFO - info, server started.

$ cat info.log 
2017-08-07 21:01:52,990 - root - INFO - info, server started.
2017-08-07 21:01:52,998 - root - DEBUG - debug, server started.


<set-adapter>
To add context in the logging.

#!/usr/bin/env python

import logging
import logging.config
import json

class LoggerAdapter(logging.LoggerAdapter):
    def __init__(self, prefix, logger):
        super(LoggerAdapter, self).__init__(logger, {})
        self.prefix = prefix

    def process(self, msg, kwargs):
        return '[%s] %s' % (self.prefix, msg), kwargs

if __name__ == '__main__':

    with open('logging.json', 'rt') as f:
        config = json.load(f)

    logging.config.dictConfig(config)

    # get root logger
    ml = logging.getLogger()

    # set adapter
    ml = LoggerAdapter("SAS", ml)

    ml.info("info, server started.")
    ml.debug("debug, server started.")


$ ./py-log.py 
2017-08-07 21:11:25,549 - root - INFO - [SAS] info, server started.


<custom-logging-level>

15.7.2. Logging Levels

The numeric values of logging levels are given in the following table. These
are primarily of interest if you want to define your own levels, and need them
to have specific values relative to the predefined levels. If you define a
level with the same numeric value, it overwrites the predefined value; the
predefined name is lost.

CRITICAL  50
ERROR     40
WARNING   30
INFO      20
DEBUG     10
NOTSET    0

logging.addLevelName(15, "DATA")
logging.DATA = 15

logger.log(logging.DATA, "message")


<use-q-with-logging>

http://hamait.tistory.com/880


={============================================================================
|kt_dev_py_0001| py-error-encoding

  File "./mgrep-latin.py", line 27
SyntaxError: Non-ASCII character '\xbf' in file ./mgrep-latin.py on line 27, but no encoding declared; see http://www.python.org/peps/pep-0263.html for details

what's the problem since I cannot see that char in the file? In vim, cannot
see that char since vim encoding mode is utf-8. see odd char when change
encoding to latin1.

The new python syntax introduced in the above link works as said or can use
encoding.


={============================================================================
|kt_dev_py_0001| py-six

https://pythonhosted.org/six/#

Six: Python 2 and 3 Compatibility Library

Six provides simple utilities for wrapping over differences between Python 2
and Python 3. It is intended to support codebases that work on both Python 2
and 3 without modification. six consists of only one Python file, so it is
painless to copy into a project.

Six can be downloaded on PyPi. Its bug tracker and code hosting is on
BitBucket.

The name, “six”, comes from the fact that 2*3 equals 6. Why not addition?
Multiplication is more powerful, and, anyway, “five” has already been snatched
away by the (admittedly now moribund) Zope Five project.

Renamed modules and attributes compatibility

Python 3 reorganized the standard library and moved several functions to
different modules. Six provides a consistent interface to them through the
fake six.moves module. For example, to load the module for parsing HTML on
Python 2 or 3, write:

The urllib, urllib2, and urlparse modules have been combined in the urllib
package in Python 3. The six.moves.urllib package is a version-independent
location for this functionality; its structure mimics the structure of the
Python 3 urllib package.


// before, 2.7 code
def getAnswer(question, answers):
  repr_answers = ' (%s): ' % '/'.join(answers)
  answer = raw_input(question + repr_answers)
  while answer not in answers:
    print 'Invalid answer!'
    answer = raw_input(question + repr_answers)
  return answer
    

// after, 2.7 code
import six

def get_answer(question, answers):
    repr_answers = ' (%s): ' % '/'.join(answers)
    answer = six.moves.input(question + repr_answers)
    while answer not in answers:
        print('Invalid answer!')
        answer = six.moves.input(question + repr_answers)
    return answer


={============================================================================
|kt_dev_py_0001| py-telnet

https://docs.python.org/2/library/telnetlib.html

Telnet.read_until(expected[, timeout])

Read until a given string, expected, is encountered or until timeout seconds
have passed.

When no match is found, return whatever is available instead, possibly the
empty string. Raise EOFError if the connection is closed and no cooked data is
available.

note: `expected` can be a substring to search.

<ex>
    def openTelnetConnection(self):
        tn = telnetlib.Telnet(self.ip, 23, 30)
        regexs = [r'login: ', r'sh-\d\.\d# ']
        result = tn.expect(regexs, 30)

        if result[0] == -1:
            raise Exception('Could not log into the STB %s', self.ip)
        elif result[0] == 0:
            tn.write('root\n')
            tn.read_until('# ')
            return tn
        else:
            return tn

tn = telnetlib.Telnet('10.209.60.98', 23, 30)
regexs = [r'login: ', r'sh-\d\.\d# ']
result = tn.expect(regexs, 30)
tn.write('root\n')
tn.read_until('# ')

note:
1. if there is no '\n' in write() such as tn.write('ls -al'), it blocks
forever.

2. read_until() returns all up to the match.


tn.write('ls -al\n')
output = tn.read_until('# ')
print output

// -sh-3.2# ls -al
// drwxrwxrwx    2 root     root            0 Jan  1 02:22 .
// drwxr-xr-x   19 root     root            0 Jan  1 00:00 ..
// -rw-------    1 root     root           11 Jan  1 02:22 .bash_history
// -sh-3.2#
// 
// >>> print output
// ls -al
// drwxrwxrwx    2 root     root            0 Jan  1 02:22 .
// drwxr-xr-x   19 root     root            0 Jan  1 00:00 ..
// -rw-------    1 root     root           11 Jan  1 02:22 .bash_history
// -sh-3.2#
// >>>

tn.write('pwd\n')
output = tn.read_until('# ')
print output

// -sh-3.2# pwd
// /root
// -sh-3.2#
// 
// >>> print output
// pwd
// /root
// -sh-3.2#
// >>>


={============================================================================
|kt_dev_py_0001| py-flask-doc

http://flask-docs-kr.readthedocs.io/ko/latest/index.html
http://flask.pocoo.org/docs/0.12/
https://www.fullstackpython.com/flask.html


={============================================================================
|kt_dev_py_0001| py-flask-apache

https://code.google.com/archive/p/modwsgi/

What Is mod_wsgi?

The aim of mod_wsgi is to implement a simple to use Apache module which can
host any Python application which supports the Python WSGI interface. The
module would be suitable for use in hosting high performance production web
sites, as well as your average self managed personal sites running on web
hosting services.

http://wsgi.readthedocs.io/en/latest/what.html
What is WSGI?

WSGI is the Web Server Gateway Interface. It is a specification that describes
how a web server communicates with web applications, and how web applications
can be chained together to process one request.

WSGI is a Python standard described in detail in PEP 3333.

For more, see Learn about WSGI.



Configuring apache to use with Flask[edit]

This procedure is described in the following page: mod_wsgi(Apache).

# http://flask.pocoo.org/docs/0.11/deploying/mod_wsgi/
# 
# mod_wsgi (Apache)
# 
# If you are using the Apache webserver, consider using mod_wsgi.
# 
# Watch Out
# 
# Please make sure in advance that any app.run() calls you might have in your
# application file are inside an if __name__ == '__main__': block or moved to a
# separate file. Just make sure it’s not called because this will always start a
# local WSGI server which we do not want if we deploy that application to
# mod_wsgi.

After we have installed apache2 we also need to install mod_wsgi:

apt-get install libapache2-mod-wsgi

Create a wsgi file. If we wanted to install our application in
/var/www/html/manatee the file will look something like (file saved in
    repository):

/ETHAN_SI_SCRIPTS/manatee/manatee.wsgi

import sys
sys.path.insert(0, '/var/www/html/ESS/manatee')

print sys.path

from manatee import app as application


Create an Apache configuration file. I added one sample in the repository at
manatee/conf/manatee.conf.

/ETHAN_SI_SCRIPTS/manatee/conf/manatee.conf

$ more manatee.conf
<VirtualHost *:80>

    LoadModule wsgi_module /usr/lib/apache2/modules/mod_wsgi.so

#ServerName manatee.com

    DocumentRoot /var/www/html/
    WSGIDaemonProcess manatee user=www-data group=www-data threads=5
    WSGIScriptAlias / /var/www/html/manatee/manatee.wsgi
    Alias /static /var/www/html/manatee/static

    <Directory /var/www/html/manatee>
        WSGIProcessGroup manatee
        WSGIApplicationGroup %{GLOBAL}
        # Allow bigger files to upload
        LimitRequestBody 41943040
        Order deny,allow
        Allow from all
    </Directory>
</VirtualHost>

Copy the configuration file to /etc/apache2/sites-available. Then go to
/etc/apache2/sites-enables and replace the configuration:

 ln -s ../sites-available/manatee.conf
 rm 000-default.conf


/etc/apache2/sites-enabled$ ls -al
lrwxrwxrwx 1 root root   31 Aug  9 09:57 manatee.conf -> ../sites-available/manatee.conf

Finally restart the apache server:

service apache2 restart


kyoupark@kit-debian64:~/si/ETHAN_SI_SCRIPTS$ WORKSPACE=/home/kyoupark/si/ETHAN_SI_SCRIPTS/WS python manatee/manatee.py
 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)


={============================================================================
|kt_dev_py_0001| py-flask

Part I: Hello, World!
https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world

<create-virtualenv>
create a virtual environment where everything gets installed so that your main
Python installation is not affected. As an added benefit, you won't need root
access to do the installation in this way.

https://pypi.python.org/pypi/virtualenv

sudo pip install virtualenv

the command that creates a virtual environment is the following:

$ virtualenv flask

# kyoupark@kit-debian64:~$ virtualenv flask
# New python executable in /home/kyoupark/flask/bin/python
# Installing setuptools, pip, wheel...done.

Virtual environments can be activated and deactivated, if desired. An
activated environment adds the location of its bin folder to the system path,
so that for example, when you type python you get the environment's version
  and not the system's one. But activating a virtual environment is not
  necessary, `it is equally effective to invoke the interpreter by` specifying
  its pathname.

install flask and extensions by entering the following commands, one after
another:

flask/bin/pip install flask
flask/bin/pip install flask-login
flask/bin/pip install flask-openid
flask/bin/pip install flask-mail
flask/bin/pip install flask-sqlalchemy
flask/bin/pip install sqlalchemy-migrate
flask/bin/pip install flask-whooshalchemy
flask/bin/pip install flask-wtf
flask/bin/pip install flask-babel
flask/bin/pip install guess_language
flask/bin/pip install flipflop
flask/bin/pip install coverage


"Hello, World" in Flask

You now have a flask sub-folder inside your microblog folder that is populated
with a Python interpreter and the Flask framework and extensions that we will
use for this application. Now it's time to write our first web application!

After you cd to the microblog folder, let's create the basic folder structure
for our application:

mkdir app
mkdir app/static
mkdir app/templates
mkdir tmp

The app folder will be where we will put our application package. The static
sub-folder is where we will store static files like images, javascripts, and
cascading style sheets. The templates sub-folder is obviously where our
templates will go.

Let's start by creating a simple init script for our app package (file
    app/__init__.py):

from flask import Flask

# app variable
app = Flask(__name__)

# app module
from app import views

The script above simply creates the application object (of class Flask) and
then imports the views module, which we haven't written yet. Do not confuse
app the variable (which gets assigned the Flask instance) with app the package
(from which we import the views module).

If you are wondering why the import statement is at the end and not at the
beginning of the script as it is always done, the reason is to avoid circular
references, because you are going to see that the views module needs to import
the `app variable` defined in this script. Putting the import at the end avoids
the circular import error.

<handlers>
The views are the handlers that respond to requests from web browsers or other
clients. In Flask handlers are written as Python functions. Each view function
is mapped to one or more request URLs.

Let's write our first view function (file app/views.py):

from app import app

@app.route('/')
@app.route('/index')
def index():
    return "Hello, World!"

This view is actually pretty simple, it just returns a string, to be displayed
  on the client's web browser. The two route decorators above the function
  create the mappings from URLs / and /index to this function.


The final step to have a fully working web application is to create a script
that starts up the development web server with our application. Let's call
this script run.py, and put it in the root folder:

#!flask/bin/python
from app import app
app.run(debug=True)

The script simply imports the app variable from our app package and invokes
its run method to start the server. Remember that the app variable holds the
Flask instance that we created it above.

To start the app you just run this script. On OS X, Linux and Cygwin you have
to indicate that this is an executable file before you can run it:

$ chmod a+x run.py

Then the script can simply be executed as follows:

./run.py

kyoupark@kit-debian64:~/mblog$ ./run.py 
 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 204-100-668

127.0.0.1 - - [08/Aug/2017 20:36:55] "GET / HTTP/1.1" 200 -
127.0.0.1 - - [08/Aug/2017 20:36:55] "GET /favicon.ico HTTP/1.1" 404 -
127.0.0.1 - - [08/Aug/2017 20:36:55] "GET /favicon.ico HTTP/1.1" 404 -


After the server initializes it will listen on port 5000 waiting for
connections. Now open up your web browser and enter the following URL in the
address field:

http://localhost:5000

Alternatively you can use the following URL:

http://localhost:5000/index

Do you see the route mappings in action? The first URL maps to /, while the
second maps to /index. Both routes are associated with our view function, so
they produce the same result. If you enter any other URL you will get an
error, since only these two have been defined.

When you are done playing with the server you can just hit Ctrl-C to stop it.


={============================================================================
|kt_dev_py_0001| py-flask-template

Part II: Templates (this article)
https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-ii-templates

yet very simple web application that has the following file structure:

    microblog\
      flask\
        <virtual environment files>
      app\
        static\
        templates\
        __init__.py
        views.py
      tmp\
      run.py


If not use template:

from app import app

@app.route('/')
@app.route('/index')
def index():
    user = {'nickname': 'Miguel'}  # fake user
    return '''
<html>
  <head>
    <title>Home Page</title>
  </head>
  <body>
    <h1>Hello, ''' + user['nickname'] + '''</h1>
  </body>
</html>
'''

Templates to the rescue

If you could keep the logic of your application separate from the layout or
presentation of your web pages things would be much better organized, don't
you think? You could even hire a web designer to create a killer web site
while you code the site's behaviors in Python. Templates help implement this
  separation.

Let's write our first template 

(file app/templates/index.html):

<html>
  <head>
    <title>{{ title }} - microblog</title>
  </head>
  <body>
      <h1>Hello, {{ user.nickname }}!</h1>
  </body>
</html>

As you see above, we just wrote a mostly standard HTML page, with the only
difference that there are some placeholders for the `dynamic content` enclosed
in {{ ... }} sections.

Now let's see how we use this template from our view function 

(file app/views.py):

from flask import render_template
from app import app

@app.route('/')
@app.route('/index')
def index():
    user = {'nickname': 'Miguel'}  # fake user
    return render_template('index.html',
                           title='Home',
                           user=user)


note: so view has data and stitch up with template. `renders` the template.


Try the application at this point to see how the template works. Once you have
the rendered page in your browser you may want to `view the source HTML` and
compare it against the original template.

This function takes a template filename and a variable list of template
arguments and returns the rendered template, with all the arguments replaced.


<jinja2-templating-engine>
Under the covers, the render_template function invokes the Jinja2 templating
engine that is part of the Flask framework. Jinja2 substitutes {{...}} blocks
with the corresponding values provided as template arguments.


Loops in templates

The logged in user in our microblog application will probably want to see
recent posts from followed users in the home page, so let's see how we can do
that.

To begin, we use our handy fake object trick to create some users and some
posts to show 

(file app/views.py):

def index():
    user = {'nickname': 'Miguel'}  # fake user
    posts = [  # fake array of posts
        { 
            'author': {'nickname': 'John'}, 
            'body': 'Beautiful day in Portland!' 
        },
        { 
            'author': {'nickname': 'Susan'}, 
            'body': 'The Avengers movie was so cool!' 
        }
    ]
    return render_template("index.html",
                           title='Home',
                           user=user,
                           posts=posts)

To represent user posts we are using a list, where each element has author and
body fields. When we get to implement a real database we will preserve these
field names, so we can design and test our template using the fake objects
without having to worry about updating it when we move to a database.

On the template side we have to solve a new problem. The list can have any
number of elements, it will be up to the view function to decide how many
posts need to be presented. The template cannot make any assumptions about the
number of posts, so it needs to be prepared to render as many posts as the
view sends.

So let's see how we do this using a for control structure (file
    app/templates/index.html):


Template inheritance

Our microblog web application will need to have a navigation bar at the top of
the page with a few links. Here you will get the link to edit your profile, to
login, logout, etc.

We can add a navigation bar to our index.html template, but as our application
grows we will be needing to implement more pages, and this navigation bar will
have to be copied to all of them. Then you will have to keep all these
identical copies of the navigation bar in sync, and that could become a lot of
work if you have a lot of pages and templates.

Instead, we can use Jinja2's template inheritance feature, which allows us to
move the parts of the page layout that are common to all templates and put
them in a base template from which all other templates are derived.

So let's define a base template that includes the navigation bar and also the
bit of title logic we implemented earlier 

(file app/templates/base.html):

<html>
  <head>
    {% if title %}
    <title>{{ title }} - microblog</title>
    {% else %}
    <title>Welcome to microblog</title>
    {% endif %}
  </head>
  <body>
    <div>Microblog: <a href="/index">Home</a></div>
    <hr>
    {% block content %}{% endblock %}
  </body>
</html>

In this template we use the `block` control statement to define the place where
the derived templates can insert themselves. Blocks are given a unique name,
    and their content can be replaced or enhanced in derived templates.

And now what's left is to modify our index.html template to inherit from
base.html (file app/templates/index.html):

{% extends "base.html" %}
{% block content %}
    <h1>Hi, {{ user.nickname }}!</h1>
    {% for post in posts %}
    <div><p>{{ post.author.nickname }} says: <b>{{ post.body }}</b></p></div>
    {% endfor %}
{% endblock %}

Since the base.html template will now take care of the general page structure
we have removed those elements from this one and left only the content part.
The extends block establishes the inheritance link between the two templates,
    so that Jinja2 knows that when it needs to render index.html it needs to
    include it inside base.html. The two templates have matching block
    statements with name content, and this is how Jinja2 knows how to combine
    the two into one. When we get to write new templates we will also create
    them as extensions to base.html.


={============================================================================
|kt_dev_py_0001| py-flask-form

Part III: Web Forms (this article)
https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-iii-web-forms

Configuration

To handle our web forms we are going to use the Flask-WTF extension, which in
turn wraps the WTForms project in a way that integrates nicely with Flask
apps.

Many Flask extensions require some amount of configuration, so we are going to
setup a configuration file inside our root microblog folder so that it is
easily accessible if it needs to be edited. Here is what we will start with
(file config.py):

WTF_CSRF_ENABLED = True
SECRET_KEY = 'you-will-never-guess'

Pretty simple, it's just two settings that our Flask-WTF extension needs. The
WTF_CSRF_ENABLED setting activates the cross-site request forgery prevention
(note that this setting is enabled by default in current versions of
 Flask-WTF). In most cases you want to have this option enabled as it makes
your app more secure.

The SECRET_KEY setting is only needed when CSRF is enabled, and is used to
create a cryptographic token that is used to validate a form. When you write
your own apps make sure to set the secret key to something that is difficult
to guess.

Now that we have our config file we need to tell Flask to read it and use it.
We can do this right after the Flask app object is created, as follows 
(file app/__init__.py):

from flask import Flask

app = Flask(__name__)
app.config.from_object('config')      # added

from app import views


The user login form

Web forms are represented in Flask-WTF as classes, subclassed from base class
Form. A form subclass simply defines the fields of the form as class
variables.

Now we will create a login form that users will use to identify with the
system. The login mechanism that we will support in our app is not the
standard username/password type, we will have our users login using their
OpenID. OpenIDs have the benefit that the authentication is done by the
provider of the OpenID, so we don't have to validate passwords, which makes
our site more secure to our users.

The OpenID login only requires one string, the so called OpenID. We will also
throw a 'remember me' checkbox in the form, so that users can choose to have a
cookie installed in their browsers that remembers their login when they come
back.

Let's write our first form (file app/forms.py):

from flask_wtf import Form
from wtforms import StringField, BooleanField
from wtforms.validators import DataRequired

class LoginForm(Form):
    openid = StringField('openid', validators=[DataRequired()])
    remember_me = BooleanField('remember_me', default=False)

I believe the class is pretty much self-explanatory. We imported the Form
  class, and the two form field classes that we need, StringField and
  BooleanField.

The DataRequired import is a validator, a function that can be attached to a
field to perform validation on the data submitted by the user. The
DataRequired validator simply checks that the field is not submitted empty.
There are many more validators included with Flask-WTF, we will use some more
in the future.


Form templates

We will also need a template that contains the HTML that produces the form.

The good news is that the LoginForm class that we just created knows how to
render form fields as HTML, so we just need to concentrate on the layout. Here
is our login template 

(file app/templates/login.html):

<!-- extend from base layout -->
{% extends "base.html" %}

{% block content %}
  <h1>Sign In</h1>
  <form action="" method="post" name="login">
      {{ form.hidden_tag() }}
      <p>
          Please enter your OpenID:<br>
          {{ form.openid(size=80) }}<br>
      </p>
      <p>{{ form.remember_me }} Remember Me</p>
      <p><input type="submit" value="Sign In"></p>
  </form>
{% endblock %}

Note that in this template we are reusing the base.html template through the
extends template inheritance statement. We will actually do this with all our
templates, to ensure a consistent layout across all pages.


There are a few interesting differences between a regular HTML form and our
template. This template expects a form object instantiated from the form class
we just defined stored in a template argument named form. We will take care of
sending this template argument to the template next, when we write the view
function that renders this template.

The form.hidden_tag() template argument will get replaced with a hidden field
that implements the CSRF prevention that we enabled in the configuration. This
field needs to be in all your forms if you have CSRF enabled. The good news is
that Flask-WTF handles it for us, we just need to make sure it is included in
the form.

The actual fields of our form are rendered by the field objects, we just need
to refer to a {{form.field_name}} template argument in the place where each
field should be inserted. Some fields can take arguments. In our case, we are
asking the text field to generate our openid field with a width of 80
characters.

Since we have not defined the submit button in the form class we have to
define it as a regular field. The submit field does not carry any data so it
doesn't need to be defined in the form class.


Form views

The final step before we can see our form is to code a view function that
renders the template.

This is actually quite simple since we just need to pass a form object to the
template. Here is our new view function 

(file app/views.py):

from flask import render_template, flash, redirect
from app import app
from .forms import LoginForm

# index view function suppressed for brevity

@app.route('/login', methods=['GET', 'POST'])
def login():
    form = LoginForm()
    return render_template('login.html', 
                           title='Sign In',
                           form=form)


So basically, we have imported our LoginForm class, instantiated an object
from it, and sent it down to the template. This is all that is required to get
form fields rendered.

Let's ignore for now the flash and redirect imports. We'll use them a bit
later.

The only other thing that is new here is the methods argument in the route
decorator. This tells Flask that this view function accepts GET and POST
requests. Without this the view will only accept GET requests. We will want to
receive the POST requests, these are the ones that will bring in the form data
entered by the user.

At this point you can try the app and see the form in your web browser. After
you start the application you will want to open http://localhost:5000/login in
your web browser, as this is the route we have associated with the login view
function.

We have not coded the part that accepts data yet, so pressing the submit
button will not have any effect at this time.


http://localhost:5000/login

/home/kyoupark/mblog/app/views.py:7: FlaskWTFDeprecationWarning: "flask_wtf.Form" has been renamed to "FlaskForm" and will be removed in 1.0.
  form = LoginForm()

// rendered source

<!-- extend from base layout -->
<html>
  <head>
    
    <title> Sign In - microblog </title>
    
  </head>
  <body>
    <div> microblog: <a href="/index"> home </a></div>
    <hr>
    
  <h1> Sign In </h1>
  <form action="" method="post" name="login">
    <input id="csrf_token" name="csrf_token" type="hidden" value="IjE0NmFlZTNhZDQyMzBlMzliNDdjYjk2NWNlZGZmYzNiNzUyYmU4ZTgi.DG95ww.Wx8mq0hmKtPqh1EsmCfXABOy-8w">
    <p>
      Please enter your OpenID: <br>
      <input id="openid" name="openid" size="80" type="text" value=""> <br>
    </p>
    <p> <input id="remember_me" name="remember_me" type="checkbox" value="y"> Remember Me </p>
    <p><input type="submit" value="Sign In"></p>
  </form>

  </body>
</html>


Receiving form data


={============================================================================
|kt_dev_py_0001| py-unit

https://docs.python.org/2/library/unittest.html

25.3. unittest — Unit testing framework

The Python unit testing framework, sometimes referred to as “PyUnit,” is a
Python language version of JUnit, by Kent Beck and Erich Gamma. JUnit is, in
turn, a Java version of Kent’s Smalltalk testing framework. Each is the de
facto standard unit testing framework for its respective language.


25.3.1. Basic example

<ex>
import unittest

class TestStringMethods(unittest.TestCase):

    def test_upper(self):
        self.assertEqual('foo'.upper(), 'FOO')

    def test_isupper(self):
        self.assertTrue('FOO'.isupper())
        self.assertFalse('Foo'.isupper())

    def test_split(self):
        s = 'hello world'
        self.assertEqual(s.split(), ['hello', 'world'])
        # check that s.split fails when the separator is not a string
        with self.assertRaises(TypeError):
            s.split(2)

if __name__ == '__main__':
    unittest.main()


A testcase `is created by subclassing unittest.TestCase.` The three individual
tests are defined with methods whose names `start with the letters test.` This
`naming convention` informs the test runner about which methods represent tests.

The crux of each test is a call to assertEqual() to check for an expected
result; assertTrue() or assertFalse() to verify a condition; or assertRaises()
to verify that a specific exception gets raised. These methods are used
instead of the assert statement so the test runner can accumulate all test
results and produce a report.

The setUp() and tearDown() methods allow you to define instructions that will
be executed before and after each test method. They are covered in more detail
in the section Organizing test code.

The final block shows a simple way to run the tests. unittest.main() provides
a command-line interface to the test script. When run from the command line,
  the above script produces an output that looks like this:

...
----------------------------------------------------------------------
Ran 3 tests in 0.000s

OK


When changes it to fail:

    def test_isupper(self):
        self.assertTrue('FOO'.isupper())
        # self.assertFalse('Foo'.isupper())
        self.assertTrue('Foo'.isupper())


 F..
 ======================================================================
 FAIL: test_isupper (__main__.TestStringMethods)
 ----------------------------------------------------------------------
 Traceback (most recent call last):
   File "pyunit_test.py", line 11, in test_isupper
     self.assertTrue('Foo'.isupper())
 AssertionError: False is not true
 
 ----------------------------------------------------------------------
 Ran 3 tests in 0.002s
 
 FAILED (failures=1)


==============================================================================
Copyrightobjdump see |ktkb|                        vim:tw=100:ts=3:ft=help:norl:
