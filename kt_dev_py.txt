*kt_dev_08*                                                                tw=100

kt.dev.py

/^[#=]{
Use #{ for a group and ={ for a item

|kt_dev_py_0001| py-book
|kt_dev_py_0001| py-check-version
|kt_dev_py_0001| py-base-basic
|kt_dev_py_0001| py-base-builtin-type
|kt_dev_py_0001| py-base-control
|kt_dev_py_0001| py-base-exception
|kt_dev_py_0001| py-base-loop

|kt_dev_py_0001| py-sys
|kt_dev_py_0001| py-subprocess
|kt_dev_py_0001| py-shlex
|kt_dev_py_0001| py-built-in
|kt_dev_py_0001| py-os
|kt_dev_py_0001| py-urllib
|kt_dev_py_0001| py-file
|kt_dev_py_0001| py-itertools
|kt_dev_py_0001| py-cvs
|kt_dev_py_0001| py-re
|kt_dev_py_0001| py-pip
|kt_dev_py_0001| py-dropbox
|kt_dev_py_0001| py-imaplib
|kt_dev_py_0001| py-time

|kt_dev_py_0001| py-types
|kt_dev_py_0001| py-string
|kt_dev_py_0001| py-tuple
|kt_dev_py_0001| py-list
|kt_dev_py_0001| py-slice
|kt_dev_py_0001| py-data-seq-function
|kt_dev_py_0001| py-dict in-membership
|kt_dev_py_0001| py-set
|kt_dev_py_0001| py-reference
|kt_dev_py_0001| py-comparison
|kt_dev_py_0001| py-comprehension
|kt_dev_py_0001| py-if
|kt_dev_py_0001| py-module
|kt_dev_py_0001| py-module-namespace
|kt_dev_py_0001| py-module-package
|kt_dev_py_0001| py-module-advanced
|kt_dev_py_0001| py-module-name-test
|kt_dev_py_0001| py-function
|kt_dev_py_0001| py-function-polymorphism
|kt_dev_py_0001| py-function-scope
|kt_dev_py_0001| py-function-arguments
|kt_dev_py_0001| py-function-
|kt_dev_py_0001| py-class
|kt_dev_py_0001| py-exception
|kt_dev_py_0001| py-


={============================================================================
|kt_dev_py_0001| py-book

LPY. Learning Python, Fifth Edition


# ============================================================================
#{
={============================================================================
|kt_dev_py_0001| py-check-version

10:27:35 ~$ python -V
Python 2.7.3

10:27:40 ~$ python --version
Python 2.7.3

>>> import sys
>>> print (sys.version)
2.7.3 (default, Mar 14 2014, 11:57:14) 
[GCC 4.7.2]

>>> sys.version_info
sys.version_info(major=2, minor=7, micro=3, releaselevel='final', serial=0)
>>> sys.hexversion
34014192

# `tuple` and `tuple` comparison?
>>> sys.version_info >= (2,5)
True


={============================================================================
|kt_dev_py_0001| py-base-basic

<indentation-not-brace>
Python uses whitespace (tabs or spaces) to structure code

for x in array:
  if x < pivot:
    less.append(x)
  else:
    greater.append(x)

A `colon` denotes the start of an `indented code block` after which all of the
code must be indented by the same amount until the end of the block.


<ex>

class Employee:
   empCount = 0

   def __init__(self, name, salary):
      self.name = name

     def setvalue(self, val):
        empCount=val

Error:
IndentationError: unindent does not match any outer indentation level

class Employee:
   empCount = 0

   def __init__(self, name, salary):
      self.name = name

   def setvalue(self, val):
      empCount=val


<everything-is-object>
An important characteristic of the Python language is the consistency of its
object model. 

Every number, string, data structure, function, class, module, and so on
exists in the Python interpreter in its own "box" which is referred to as a
`Python object` Each object has an associated `type` (for example, string or
    function) and internal `data`. In practice this makes the language very
flexible, as even functions can be treated just like any other object.


<comment>
Any text preceded by the hash mark (pound sign) # is ignored by the Python
interpreter.


<function>
Functions are called using parentheses and passing zero or more arguments,
          optionally assigning the returned value to a variable:

result = f(x, y, z)
g()

Almost every object in Python has attached functions, known as methods, that
have access to the object's internal contents. They can be called using the
syntax:

obj.some_method(x, y, z)


<pass-by-reference>
When assigning a variable (or name) in Python, you are creating a `reference` to
the object on the right hand side of the equals sign.

In some languages, this assignment would cause the data [1, 2, 3] to be
copied. In Python, a and b actually now refer to the same object, the original
list

a = [1,2,3]
b = a
a.append(4)
b
[1,2,3,4]

note:
Assignment is also referred to as `binding`, as we are binding a name to an
object. Variables names that have been assigned may occasionally be referred
to as bound variables.

When you pass objects as arguments to a function, you are only passing
references; no copying occurs.

Understanding the semantics of references in Python and when, how, and why
  data is copied is especially critical when working with larger data sets in
  Python.


<typed-language>
In contrast with many compiled languages, such as Java and C++, 
`object references` in Python `have no type` associated with them. There is no
  problem with the following:

>>> a = 5
>>> type(a)
<type 'int'>

>>> a = 'foo'
>>> type(a)
<type 'str'>

>>> a = "foo"
>>> type(a)
<type 'str'>


Variables are names for objects within a particular namespace; the type
information is stored in the `object itself` Some observers might hastily
conclude that Python `is not a typed language` This is `not true`; consider
this example:

>>> '5'+5
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
`TypeError`: cannot concatenate 'str' and 'int' objects

In some languages, such as Visual Basic, the string '5' might get implicitly
  converted (or casted) to an integer, thus yielding 10. Yet in other
  languages, such as JavaScript, the integer 5 might be casted to a string,
  yielding the concatenated string '55'. 

In this regard Python is considered a strongly-typed language, which means
that every object has a specific type (or class), and implicit conversions
will occur only in `certain obvious circumstances`, such as the following:

>>> a = 4.5
>>> b = 2
>>> print "a is %s, b is %s" % (type(a), type(b))
a is <type 'float'>, b is <type 'int'>
>>> a/b
2.25


Knowing the type of an object is important and can check that an object is an
instance of a particular type using the `isinstance` function:

>>> a = 5
>>> isinstance(a,int)
True
>>> b = 4.5
>>> isinstance(b,int)
False
>>> isinstance(b,float)
True

isinstance can accept a tuple of types if you want to check that an object's
type is among those present in the tuple:

>>> isinstance(b,(int,float))
True


<attribute-and-method>
Objects in Python typically have both `attributes`, other Python objects
stored "inside" the object, and `methods`, functions associated with an object
which can have access to the object's internal data.

Both of them are accessed via the syntax `obj.attribute_name` Attributes and
methods can also be accessed by name using the `getattr` function:

>>> a='foo'
>>> type(a)
<type 'str'>
>>> getattr(a, 'split')
<built-in method split of str object at 0xb744dc38>

While we will not extensively use the functions getattr and related functions
`hasattr` and setattr in this book, they can be used very effectively to write
generic, reusable code.


<iterable>
In a nutshell, an object is `iterable` if it is either a physically stored
sequence in memory, or an object that generates one item at a time in the
context of an iteration operation - a sort of "virtual" sequence.


Can verify that an object is iterable if it implemented the iterator protocol.

>>> def isiterable(obj):
...     try:
...             iter(obj)
...             return True
...     except TypeError:
...             return False
... 
>>> isiterable('a string')
True
>>> isiterable([1,2,3])
True
>>> isiterable(4)
False

note:
iter(object[, sentinel])

Return an iterator object. Without a second argument, object must be a
collection object which supports the `iteration protocol` (the __iter__()
    method), or it must support the sequence protocol (the __getitem__()
      method with integer arguments starting at 0). If it does not support
    either of those protocols, TypeError is raised.

A common case is writing a function that can accept any kind of sequence
(list, tuple, ndarray) or even an iterator. If it is not, convert it to be
one:

if not isinstance(x, list) and isiterable(x):
  x = list(x)


<comparison>
To check if two `references` refer to the same object, use the `is` and `is not`
keyword. Not the object itself. 

>>> a=[1,2,3]
>>> b=a
>>> c=list(a)
>>> a is b
True
>>> a is not c
True
>>> a is c
False
>>> a == c
True
>>> b == c
True

A very common use of is and is not is to check if a variable is None

>>> a = None
>>> a is None
True


<check-equility>
>>> L = [1, 2, 3]
>>> M = L         # M and L reference the same object
>>> L == M        # Same values
True
>>> L is M        # Same objects
True

The first technique here, the == operator, tests whether the two referenced
objects have the `same values`; this is the method almost always used for
equality checks in Python.  

The second method, the `is operator`, instead tests for object identityit
returns True only if both names point to the exact `same object`, so it is a
much stronger form of equality testing.

Really, is simply compares the pointers that implement references, and it
serves as a way to detect shared references in your code if needed.

>>> import sys
>>> sys.getrefcount(1) # 647 pointers to this shared piece of memory
647


<variable-object>
Names have no types; as stated earlier, types live with objects, not names.

Objects that can be changed in place (that is, mutable objects) are lists,
dictionaries, sets, and some objects defined with class statements.


<garbage-collection>
Internally, Python accomplishes this feat by keeping a counter in every object
that keeps track of the number of references currently pointing to that
object. As soon as (and exactly when) this counter drops to zero, the object’s
memory space is automatically reclaimed.

For more details on Python's cycle detector, see the documentation for the
`gc` module in Python's library manual.


={============================================================================
|kt_dev_py_0001| py-base-builtin-type

Table A-2. Standard Python Scalar Types

`None` 
The Python "null" value (only one instance of the None object exists)

`str` 
String type. ASCII-valued only in Python 2.x and Unicode in Python 3

unicode 
Unicode string type

float 
Double-precision (64-bit) floating point number. Note there is no separate
double type.

bool 
A `True` or `False` value

`int` 
Signed integer with maximum value determined by the platform.

long 
Arbitrary precision signed integer. Large int values are automatically
converted to long.


<numeric-types>
The primary Python types for numbers are `int` and `float`. 

The size of the integer which can be stored as an int is dependent on your
platform (whether 32 or 64-bit), but Python will transparently convert a very
large integer to `long`, which can store arbitrarily large integers.

Floating point numbers are represented with the Python float type. Under the
hood each one is a double-precision (64 bits) value.

In Python 3, integer division not resulting in a whole number will always
yield a floating point number:

In [284]: 3 / 2
Out[284]: 1.5

In Python 2.7 and below (which some readers will likely be using), you can
enable this behavior by default by putting the following cryptic-looking
statement at the top of your module:

from __future__ import division

Without this in place, you can always explicitly convert the denominator into
a floating point number:

In [285]: 3 / float(2)
Out[285]: 1.5

To get C-style integer division (which drops the fractional part if the result
is not a whole number), use the floor division operator //:

In [286]: 3 // 2
Out[286]: 1


={============================================================================
|kt_dev_py_0001| py-base-control

{pass}
`pass` is the "no-op" statement in Python. It can be used in blocks where no
action is to be taken; it is only required because Python uses whitespace to
delimit blocks.

It's common to use pass as a place-holder in code while working on a new piece
of functionality:

if x < 0:
  print 'negative!'
elif x == 0:
  # TODO: put something smart here
  pass
else:
  print 'positive!'


the error case:

if x < 0:
    print 'negative!'
elif x == 0:
    # TODO: put something here
else:
    print 'posivie!'

$ ./py-01.py 
  File "./py-01.py", line 17
    else:
       ^
IndentationError: expected an indented block


={============================================================================
|kt_dev_py_0001| py-base-exception

{exception}
Suppose we wanted a version of float that fails gracefully, returning the
input argument.

# catchs all

def attempt_float(x):
  try:
    return float(x)
  except:
    return x

Want to only `suppress` ValueError, since a TypeError (the input was not a
    string or numeric value) might indicate a legitimate bug in your program.
To do that, write the `exception type` after except:

def attempt_float(x):
  try:
    return float(x)
  except ValueError:
    return x

>>> float((1,2))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: float() argument must be a string or a number
>>> def attempt_float(x):
...     try:
...             return float(x)
...     except ValueError:
...             return x
... 
>>> attempt_float((1,2))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in attempt_float
TypeError: float() argument must be a string or a number
>>> 


Can catch `multiple exception types` by writing a `tuple` of exception types
instead (the parentheses are required):

def attempt_float(x):
  try:
    return float(x)
  except (TypeError, ValueError):
    return x


note:
As with C++, if exception gets raised and not catched, then returns
immediately.

In some cases, you may not want to suppress an exception, but you want some
code to be executed `regardless of` whether the code in the try block
`succeeds or not` To do this, use finally:

f = open(path, 'w')

try:
  write_to_file(f)
finally:
  f.close()

Here, the file handle f will always get closed. 

Similarly, you can have code that executes `only if` the try: block `succeeds`
using else:

f = open(path, 'w')

try:
  write_to_file(f)
except:
  print 'Failed'
else:
  print 'Succeeded'
finally:
  f.close()


={============================================================================
|kt_dev_py_0001| py-base-loop

{range}
`range` produces integers up to but not including the endpoint. 

>>> range(10)
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

A common use of range is for iterating through sequences `by index`:

seq = [1, 2, 3, 4]
for i in range(len(seq)):
  val = seq[i]

For very long ranges, it's recommended to use `xrange`, which takes the same
arguments as range but returns an iterator that generates integers one by one
rather than generating all of them up-front and storing them in a (potentially
    very large) list. This snippet sums all numbers from 0 to 9999 that are
multiples of 3 or 5:

sum = 0
for i in xrange(10000):
  # % is the modulo operator
  if x % 3 == 0 or x % 5 == 0:
    sum += i


{ternary-expression}
>>> x=5
>>> 'non-negative' if x >= 0 else 'negative'
'non-negative'
>>> 


{for}
remove an element of a list in the loop

  for script_name, priority, test_id, process in running_list:
    do something
    running_list.remove((script_name, priority, test_id, process))


={============================================================================
|kt_dev_py_0001| py-sys

sys.exit([arg])

    Exit from Python. This is implemented by raising the SystemExit exception,
so cleanup actions specified by finally clauses of try statements are honored,
and it is possible to intercept the exit attempt at an outer level.

    The optional argument arg can be an integer giving the exit status
    (defaulting to zero), or another type of object. If it is an integer, zero
    is considered “successful termination” and any nonzero value is considered
    “abnormal termination” by shells and the like. Most systems require it to
    be in the range 0-127, and produce undefined results otherwise. Some
    systems have a convention for assigning specific meanings to specific exit
    codes, but these are generally underdeveloped; Unix programs generally use
    2 for command line syntax errors and 1 for all other kind of errors. If
    another type of object is passed, None is equivalent to passing zero, and
    any other object is printed to stderr and results in an exit code of 1. In
    particular, sys.exit("some error message") is a quick way to exit a
    program when an error occurs.

    Since exit() ultimately “only” raises an exception, it will only exit the
    process when called from the main thread, and the exception is not
    intercepted.


sys.argv

    The list of command line arguments passed to a Python script. argv[0] is
    the script name (it is operating system dependent whether this is a full
        pathname or not). If the command was executed using the -c command
    line option to the interpreter, argv[0] is set to the string '-c'. If no
    script name was passed to the Python interpreter, argv[0] is the empty
    string.

    To loop over the standard input, or the list of files given on the command
    line, see the fileinput module.

    note:
    argv[0] - len(argv[0]) is 1


={============================================================================
|kt_dev_py_0001| py-subprocess

https://docs.python.org/2/library/subprocess.html

17.1. subprocess  Subprocess management

The subprocess module allows you to spawn new processes, connect to their
input/output/error pipes, and obtain their return codes. This module intends
to replace several older modules and functions:


The recommended way to launch subprocesses is to use the following
`convenience` functions. For more advanced use cases when these do not meet
your needs, use the underlying Popen interface.


subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False)

    Run the command described by args. Wait for command to complete, then
    return the `returncode` attribute.

    The arguments shown above are merely the most common ones, described below
    in Frequently Used Arguments (hence the slightly odd notation in the
        abbreviated signature). The full function signature is the same as
    that of the Popen constructor - this functions passes all supplied
    arguments directly through to that interface.

    Examples:

    >>> subprocess.call(["ls", "-l"])
    0

    >>> subprocess.call("exit 1", shell=True)
    1

    Warning
    Using shell=True can be a security hazard. See the warning under
    Frequently Used Arguments for details.

    Note
    Do not use stdout=PIPE or stderr=PIPE with this function as that can
    deadlock based on the child process output volume. Use Popen with the
    communicate() method when you need pipes.


17.1.1.2. Popen Constructor

The underlying process creation and management in this module is handled by
the Popen class. It offers a lot of flexibility so that developers are able to
handle the less common cases not covered by the convenience functions.

class subprocess.Popen(args, bufsize=0, executable=None, 
    stdin=None, stdout=None, stderr=None, preexec_fn=None, 
    close_fds=False, shell=False, cwd=None, env=None, 
    universal_newlines=False, startupinfo=None, creationflags=0)

`Execute a child program in a new process` On Unix, the class uses
os.execvp()-like behavior to execute the child program. 

`args` should be a sequence of program arguments or else a single string. By
default, the program to execute is the first item in args if args is a
sequence. If args is a string, the interpretation is platform-dependent and
described below. See the `shell` and executable arguments for additional
differences from the default behavior. Unless otherwise stated, it is
recommended to pass args as a sequence.

On Unix, if args is a string, the string is interpreted as the name or path of
the program to execute. However, this can only be done if not passing
arguments to the program.


<ex>
>>> print args
['/bin/vikings', '-input', 'eggs.txt', '-output', 'spam spam.txt', '-cmd', "echo '$MONEY'"]
>>> p = subprocess.Popen(args) # Success!


On Unix with `shell=True`, the shell defaults to /bin/sh. If args is a string,
the string specifies the command to execute `through the shell`  This means that
  the string must be formatted exactly as it would be when typed at the shell
  prompt. This includes, for example, quoting or backslash escaping filenames
  with spaces in them. If args is a sequence, the first item specifies the
  command string, and any additional items will be treated as additional
  arguments to the shell itself. That is to say, Popen does the equivalent of:

Popen(['/bin/sh', '-c', args[0], args[1], ...])


subprocess.PIPE

    Special value that can be used as the stdin, stdout or stderr argument to
    Popen and indicates that a pipe to the standard stream `should be opened`

stdin, stdout and stderr specify the executed program's standard input,
standard output and standard error file handles, respectively. 
  
Valid values are `PIPE`, an existing file descriptor (a positive integer), an
existing file object, and None. PIPE indicates that a new pipe to the child
should be created. With the default settings of None, no redirection will
occur; the child's file handles will be inherited from the parent.
Additionally, stderr can be STDOUT, which indicates that the stderr data from
the child process should be captured into the same file handle as for stdout.

If close_fds is true, all file descriptors except 0, 1 and 2 will be closed
before the child process is executed. (Unix only).


17.1.2. Popen Objects

Instances of the Popen class have the following methods:

Popen.wait()

    Wait for child process to terminate. Set and return returncode attribute.

    Warning

    This will deadlock when using stdout=PIPE and/or stderr=PIPE and the child
    process generates enough output to a pipe such that it blocks waiting for
    the OS pipe buffer to accept more data. `Use communicate() to avoid that.`

Popen.communicate(input=None)

    Interact with process: Send data to stdin. Read data from stdout and
    stderr, until end-of-file is reached. `Wait for process to terminate` The
    optional input argument should be a string to be sent to the child
    process, or None, if no data should be sent to the child.

    communicate() `returns` a tuple (stdoutdata, stderrdata).

    Note 
    that if you want to send data to the process's stdin, you need to create
    the Popen object with `stdin=PIPE`. Similarly, to get anything other than
    None in the result tuple, you need to give stdout=PIPE and/or stderr=PIPE
    too.

    Note
    The data read is buffered in memory, so do not use this method if the data
    size is large or unlimited.


Popen.poll()

    Check if child process has terminated. Set and return returncode
    attribute.

<ex>
        P = subprocess.Popen (cmd, stdout = subprocess.PIPE,
                stderr = subprocess.PIPE, close_fds=True, bufsize=50000000)

        stdOut, stdErr = P.communicate ()
        retVal = P.wait ()


={============================================================================
|kt_dev_py_0001| py-shlex

https://docs.python.org/2/library/shlex.html


={============================================================================
|kt_dev_py_0001| py-builtin

https://docs.python.org/3/library/functions.html

2. Built-in Functions
The Python interpreter has a number of functions and types built into it that
are always available. They are listed here in alphabetical order.

print(*objects, sep=' ', end='\n', file=sys.stdout, flush=False)

    Print objects to the text stream file, separated by sep and followed by
    end. sep, end and file, if present, must be given as keyword arguments.
    All non-keyword arguments are converted to strings like str() does and
    written to the stream, separated by sep and followed by end. Both sep and
    end must be strings; they can also be None, which means to use the default
    values. If no objects are given, print() will just write end.  The file
    argument must be an object with a write(string) method; if it is not
    present or None, sys.stdout will be used. Since printed arguments are
    converted to text strings, print() cannot be used with binary mode file
    objects. For these, use file.write(...) instead.  Whether output is
    buffered is usually determined by file, but if the flush keyword argument
    is true, the stream is forcibly flushed.  Changed in version 3.3: Added
    the flush keyword argument.

<ex>
print "item in the list: %s" % item

*eval-keyword-eval*
eval(expression, globals=None, locals=None)

    The arguments are a string and optional globals and locals. If provided,
    globals must be a dictionary. If provided, locals can be any mapping object.

    The expression argument is parsed and evaluated `as a Python expression`
    (technically speaking, a condition list) using the globals and locals
    dictionaries as global and local namespace. If the globals dictionary is
    present and lacks ‘__builtins__’, the current globals are copied into
    globals before expression is parsed. This means that expression normally
    has full access to the standard builtins module and restricted
    environments are propagated. If the locals dictionary is omitted it
    defaults to the globals dictionary. If both dictionaries are omitted, the
    expression is executed in the environment where eval() is called. The
    return value is the result of the evaluated expression. Syntax errors are
    reported as exceptions. Example:

    >>> x = 1
    >>> eval('x+1')
    2

    This function can also be used to execute arbitrary code objects (such as
        those created by compile()). In this case pass a code object instead
    of a string. If the code object has been compiled with 'exec' as the mode
    argument, eval()‘s return value will be None.

    Hints: dynamic execution of statements is supported by the exec()
    function. The globals() and locals() functions returns the current global
    and local dictionary, respectively, which may be useful to pass around for
    use by eval() or exec().

    See ast.literal_eval() for a function that can safely evaluate strings
    with expressions containing only literals.


={============================================================================
|kt_dev_py_0001| py-os

https://docs.python.org/3.4/library/os.path.html

11.2. os.path  Common pathname manipulations


os.path.abspath(path)

    Return a normalized absolutized version of the pathname path. On most
    platforms, this is equivalent to calling the function normpath() as
    follows: normpath(join(os.getcwd(), path)).


os.path.dirname(path)

    Return the directory name of pathname path. This is the first element of
    the pair returned by passing path to the function split().


https://docs.python.org/3.4/library/os.html

16.1.5. Files and Directories


os.listdir(path='.')

    Return a list containing the names of the entries in the directory given
    by path. The list is in arbitrary order, and does not include the special
    entries '.' and '..' even if they are present in the directory.

    path may be either of type str or of type bytes. If path is of type bytes,
    the filenames returned will also be of type bytes; in all other circumstances,
    they will be of type str.

    This function can also support specifying a file descriptor; the file
    descriptor must refer to a directory.

    Note
    To encode str filenames to bytes, use fsencode().

    Availability: Unix, Windows.

    Changed in version 3.2: The path parameter became optional.

    New in version 3.3: Added support for specifying an open file descriptor
    for path.

<ex>
    # Check the folder exists
    if os.path.isdir (dir):
        # Check if the folder is empty
        if os.listdir (dir) == []:


={============================================================================
|kt_dev_py_0001| py-urllib

https://docs.python.org/2/library/urllib2.html

The urllib2 module defines functions and classes which help in opening URLs
(mostly HTTP) in a complex world  basic and digest authentication,
redirections, cookies and more.


<ex>
>>> import urllib2
>>> res = urllib2.urlopen("http://theyard.cisco.com/diagconf.txt")
>>> res
<addinfourl at 3067798252L whose fp = <socket._fileobject object at 0xb6d8266c>>
>>> content = res.read()

# the fils is:
#
# [
#       [["AMS"], ["AMS"]],
#       [["AFLPROXY"],["darwin_aflproxy_bindings_AS3"]],
#       [["DIAG_TIMESTAMP"], ["diag_svr"]],
#       [["CAPTRANS"], ["ms_captrans_src"]],
#       [["CAPTRANS_INPUT"], ["ms_captrans_src"]],
#       [["CAPTRANS_OUTPUT"], ["ms_captrans_src"]],
#       [["CAPTRANS_TTML"], ["ms_captrans_src"]],
#       [["PPCM_CF"], ["ppcm", "ppcm_core"]],
#       [["PPCM_CL"], ["ppcm", "ppcm_core"]],
#       [["PPCM_CORE"], ["ppcm", "ppcm_core"]],
#       ...
#
# returns a single long string
>>> content
'[\n      [["AMS"], ["AMS"]],\n      [["AFLPROXY"],["darwin_aflproxy_bindings_AS3"]],\n      [["DIAG_TIMESTAMP"], ["diag_svr"]],\n      [["CAPTRANS"], ["ms_captrans_src"]],\n      [["CAPTRANS_INPUT"], ["ms_captrans_src"]],\n      [["CAPTRANS_OUTPUT"], ["ms_captrans_src"]],\n      [["CAPTRANS_TTML"], ["ms_captrans_src"]],\n      [["PPCM_CF"], ["ppcm", "ppcm_core"]],\n      [["PPCM_CL"], ["ppcm", "p..'


={============================================================================
|kt_dev_py_0001| py-file

Chapter 9: Tuples, Files, and Everything Else

the built-in `open` function creates a Python `file object`, which serves as a
link to a file residing on your machine. After calling open, you can transfer
strings of data to and from the associated external file by calling the
returned file object's methods.

afile = open(filename, mode)
afile.method()

Without a directory path, the file is assumed to exist in the current working
directory. Use either a relative or absolute file path

path = 'ch13/segismundo.txt'
f = open(path)

By default, the file is opened in read-only mode 'r'. We can then treat the
file handle f like a `list` and iterate over the lines like so

for line in f:
  pass

# Or this way. File iterators read line by line
for line in open('data'): 
  use line 

The lines come out of the file with the end-of-line (EOL) markers intact, so
you'll often see code to get an EOL-free list of lines

lines = [x.rstrip() for x in open(path)]

<for-vs-readline>
https://docs.python.org/2/tutorial/inputoutput.html

7.2.1. Methods of File Objects

f.readline() reads a single line from the file; a newline character (\n) is
left at the end of the string, and is only omitted on the last line of the
file if the file doesn't end in a newline. This makes the return value
unambiguous; if f.readline() returns an empty string, the end of the file has
been reached, while a blank line is represented by '\n', a string containing
only a single newline.

>>> f.readline()
'This is the first line of the file.\n'
>>> f.readline()
'Second line of the file\n'
>>> f.readline()
''

For reading lines from a file, you can loop over the file object. This is
memory efficient, fast, and leads to simple code:

>>> for line in f:
        print line,

This is the first line of the file.
Second line of the file

If you want to read all the lines of a file in a list you can also use list(f)
or f.readlines().


To write text to a file, you can use either the file's `write` or `writelines`
methods. With no blank lines like so:

# see *with-as-context*
with open('tmp.txt', 'w') as handle:
  handle.writelines(x for x in open(path) if len(x) > 1)

open('tmp.txt').readlines()


As discussed, in Python an object's memory space is automatically reclaimed as
soon as the object is no longer referenced anywhere in the program. When file
objects are reclaimed, Python also automatically closes the files if they are
still open (this also happens when a program shuts down).

`write` methods don't add the end-of-line character for us, so we must include
it to properly terminate our lines

>>> myfile.write('hello text file\n') # Write a line of text: string
>>>
>>> myfile.readline()                 # Read the lines back
'hello text file\n'


Storing Python Objects in Files: Conversions

Have to use other conversion tools to translate from the strings in the text
file to real Python objects.

>>> X, Y, Z = 43, 44, 45 # Native Python objects
>>> S = 'Spam' # Must be strings to store in file
>>> D = {'a': 1, 'b': 2}
>>> L = [1, 2, 3]
>>>
>>> F = open('datafile.txt', 'w') # Create output text file
>>> F.write(S + '\n') # Terminate lines with \n
>>> F.write('%s,%s,%s\n' % (X, Y, Z)) # Convert numbers to strings
>>> F.write(str(L) + '$' + str(D) + '\n') # Convert and separate with $
>>> F.close()

>>> line = F.readline() # Next line from file
>>> line # It's a string here
'43,44,45\n'
>>> parts = line.split(',') # Split (parse) on commas
>>> parts
['43', '44', '45\n']

>>> int(parts[1]) # Convert from string to int
44
>>> numbers = [int(P) for P in parts] # Convert all in list at once
>>> numbers
[43, 44, 45]

*eval-keyword-eval*

>>> line = F.readline()
>>> line
"[1, 2, 3]${'a': 1, 'b': 2}\n"
>>> parts = line.split('$') # Split (parse) on $
>>> parts
['[1, 2, 3]', "{'a': 1, 'b': 2}\n"]
>>> eval(parts[0]) # Convert to any object type
[1, 2, 3]
>>> objects = [eval(P) for P in parts] # Do same for all in list
>>> objects
[[1, 2, 3], {'a': 1, 'b': 2}]


={============================================================================
|kt_dev_py_0001| py-itertools

https://docs.python.org/2/library/itertools.html#itertools.islice

 itertools.islice(iterable, stop)

<ex>
  # reads a file by section_size unit and makes it a list
  log_list = list(islice(log_file, section_size))


={============================================================================
|kt_dev_py_0001| py-cvs

https://docs.python.org/2/library/csv.html

<ex>
import csv

    ret_list = list(csv.reader(open(path), delimiter="\t"))    


={============================================================================
|kt_dev_py_0001| py-re

https://docs.python.org/2/library/re.html

7.2. re  Regular expression operations

This module provides regular expression matching operations similar to those
found in Perl


7.2.1. Regular Expression Syntax

A brief explanation of the format of regular expressions follows. For further
information and a gentler presentation, consult the Regular Expression HOWTO.

https://docs.python.org/2/howto/regex.html#regex-howto

(?...)
    This is an `extension` notation (a '?' following a '(' is not meaningful
        otherwise). The first character after the '?' determines what the
    meaning and further syntax of the construct is. 

    Extensions usually do not create a new group; (?P<name>...) is the only
    `exception to this rule` 
    
    Following are the currently supported extensions.

(?P<name>...)

    Similar to regular parentheses, but the substring matched by the group is
    accessible via `the symbolic group name` 
    
    Group names must be valid Python identifiers, and each group name must be
    defined only once `within a regular expression` A symbolic group is also a
    numbered group, just as if the group were not named.

    Named groups can be referenced in three contexts. If the pattern is
    (?P<quote>['"]).*?(?P=quote) (i.e. matching a string quoted with either
    single or double quotes):

(?P=name)

    A backreference to a named group; it matches whatever text was matched by
    the earlier group named name.

\d
    When the UNICODE flag is not specified, matches any decimal digit; this is
    equivalent to the set [0-9]. With UNICODE, it will match whatever is
    classified as a decimal digit in the Unicode character properties
    database.


7.2.2. Module Contents

The module defines several functions, constants, and an exception. 

Some of the functions are simplified versions of the `full featured methods`
for `compiled` regular expressions. Most non-trivial applications always use
  the compiled form.

re.compile(pattern, flags=0)

    Compile a regular expression `pattern into a regular expression object`,
            which can be used for matching using its match() and search()
              methods, described below.

    The expression's behaviour can be modified by specifying a flags value.
    Values can be any of the following variables, combined using bitwise OR
    (the | operator).

    The sequence

    prog = re.compile(pattern)
    result = prog.match(string)

    is equivalent to

    result = re.match(pattern, string)

    but using re.compile() and saving the resulting regular expression object
    for reuse is `more efficient` when the expression will be used several times
      in a single program.

    Note
    The compiled versions of the most recent patterns passed to re.match(),
        re.search() or re.compile() are cached, so programs that use only a
          few regular expressions at a time needn't worry about compiling
          regular expressions.


re.search(pattern, string, flags=0)

    Scan through string looking for `the first location` where the regular
    expression pattern produces a match, and return a corresponding
    MatchObject instance. 
    
    Return None if no position in the string matches the pattern; note that
    this is different from finding a zero-length match at some point in the
    string.


re.match(pattern, string, flags=0)

    If zero or more characters at the beginning of string match the regular
    expression pattern, return a corresponding MatchObject instance. 
    
    Return None if the string does not match the pattern; note that this is
    different from a zero-length match.

    Note that even in MULTILINE mode, re.match() will only match at the
    beginning of the string and not at the beginning of each line.

    If you want to locate a match anywhere in string, use search() instead
    (see also search() vs. match()).


7.2.5.3. search() vs. match()

Python offers two different primitive operations based on regular expressions:
re.match() checks for a match only at the beginning of the string, while
re.search() checks for a match anywhere in the string (this is what Perl does
    by default).

For example:

>>> re.match("c", "abcdef")    # No match
>>> re.search("c", "abcdef")   # Match
<_sre.SRE_Match object at ...>

Regular expressions beginning with '^' can be used with search() to restrict
the match at the beginning of the string:

>>> re.match("c", "abcdef")    # No match
>>> re.search("^c", "abcdef")  # No match
>>> re.search("^a", "abcdef")  # Match
<_sre.SRE_Match object at ...>

Note however that in MULTILINE mode match() only matches at the beginning of
the string, whereas using search() with a regular expression beginning with
'^' will match at the beginning of each line.

>>> re.match('X', 'A\nB\nX', re.MULTILINE)    # No match
>>> re.search('^X', 'A\nB\nX', re.MULTILINE)  # Match
<_sre.SRE_Match object at ...>


re.split(pattern, string, maxsplit=0, flags=0)

    Split string by the occurrences of pattern. 

    If capturing parentheses are used in pattern, then the text of all groups
    in the pattern are also returned as part of the resulting list. 
    
    If maxsplit is nonzero, at most maxsplit splits occur, and the remainder
    of the string is returned as the final element of the list.
    (Incompatibility note: in the original Python 1.5 release, maxsplit was
     ignored. This has been fixed in later releases.)

>>> re.split('[/:]', '/usr/home/lumberjack')
['', 'usr', 'home', 'lumberjack']

>>> re.split('\W+', 'Words, words, words.')
['Words', 'words', 'words', '']



7.2.4. Match Objects

group([group1, ...])

    Returns one or more subgroups of the match.

    Without arguments, group1 defaults to zero (the whole match is returned).
    If a groupN argument is zero, the corresponding return value is the entire
    matching string; if it is in the inclusive range [1..99], it is the string
    matching the corresponding parenthesized group.

    If the regular expression uses the (?P<name>...) syntax, the groupN
    arguments may `also be strings identifying groups by their group name` If a
    string argument is not used as a group name in the pattern, an IndexError
    exception is raised.

groups([default])

    Return a tuple containing all the subgroups of the match, from 1 up to
    however many groups are in the pattern.

>>> match = re.match('Hello[ \t]*(.*)world', 'Hello Python world')
>>> match.group(0)
'Hello Python world'
>>> match.group(1)
'Python '

>>> match = re.match('[/:](.*)[/:](.*)[/:](.*)', '/usr/home:lumberjack')
>>> match.groups()
('usr', 'home', 'lumberjack')

>>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
>>> m.group('first_name')
'Malcolm'
>>> m.group('last_name')
'Reynolds'

import re
f='drx890.SYSF40.73.00.enc.snugupdate'
m=re.match(r'^(?P<type>.+)\.SYSF(?P<version>[\d.]+)', f)
print 'DEBUG: f: %s, match.group(type): %s, m.group(version): %s' % (f, m.group('type'), m.group('version'))
DEBUG: f: drx890.SYSF40.73.00.enc.snugupdate, match.group(type): drx890, m.group(version): 40.73.00.


groupdict([default])

    Return a dictionary containing all the named subgroups of the match, keyed
    by the subgroup name. The default argument is used for groups that did not
    participate in the match; it defaults to None. For example:

    >>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
    >>> m.groupdict()
    {'first_name': 'Malcolm', 'last_name': 'Reynolds'}


<ex>
# Sample line:
# NDS: ^0946684966.710878 !ERROR -SRM          < p:000000c1 t:016121b0 T:SRM_LP_THREAD M:srm_utils.c F:SRM_SystemStringToCString L:00287 > **** SRM ERR in srm_utils.c:287
#
# currently supports match = {1, 2, 3, 4, 5}
#       error type such as FATAL, ERROR, WARN, MIL and which is GROUP(1)
#       component type such as SRM and which is GROUP(2)
#       filename which is GROUP(3)
#       func which is GROUP(4)
#       free text which is GROUP(5)

# \s : any whitespace char
# \S : any not-whilespace char
# '?': causes the resulting RE to match 0 or 1 repetitions of the preceding RE. ab? will match either 'a' or 'ab'.

# NOTE. there's no support for a leading numbers of the dict line.
# NOTE. added MIL just for usefulness.
# NOTE. possibly add 'T:' group?

# extract interested groups from a dict entry. grab the whole free text.
matchDic = re.search(r'^NDS:.*!(FATAL|ERROR|WARN|MIL)\s+-(\S+).*(M:\S+)\s+(F:\S+).*>(.*)', lineDic )


={============================================================================
|kt_dev_py_0001| py-pip

https://pip.pypa.io/en/stable/

Quickstart

Install a package from PyPI:

$ pip install SomePackage
  [...]
  Successfully installed SomePackage

https://packaging.python.org/glossary/#term-python-package-index-pypi
Python Package Index (PyPI)
    PyPI is the default Package Index for the Python community. It is open to
    all Python developers to consume and distribute their distributions.

To search package:
https://pypi.python.org/pypi/


={============================================================================
|kt_dev_py_0001| py-dropbox

https://www.dropbox.com/developers/documentation/python#install
Install Dropbox for Python

To get started with Dropbox for Python, we recommend you add the SDK to your
project using pip.

Download and install the SDK.

pip install dropbox

Now you can do "import dropbox" in your Python app, or in a Python interpreter.

import dropbox

That's it! Now you're ready to get started with the tutorial.


https://www.dropbox.com/developers/documentation/python#tutorial
Link an account

In order to make calls to the API, you'll need an instance of the Dropbox
object. To instantiate, pass in the access token for the account you want to
link. (Tip: You can generate an access token for your own account through the
    App Console).

dbx = dropbox.Dropbox('YOUR_ACCESS_TOKEN')

Test it out to make sure you've linked the right account:

dbx.users_get_current_account()


<core-api>
https://www.dropbox.com/developers-v1/core/start/python
Warning: API v1 has been deprecated. Learn more.

Using the Core API in Python

The Core API is based on HTTP and OAuth and provides low-level calls to access
and manipulate a user's Dropbox account.

If you want to follow along, first register a new app on the App Console.
You'll need the app key to access the Core API. Then install the Python SDK
and you'll be ready to go.


Downloading files

Some time has passed and you're ready to start editing that magnum opus of
yours again. We'll need the get_file_and_metadata method to download the file.

f, metadata = client.get_file_and_metadata('/magnum-opus.txt')
out = open('magnum-opus.txt', 'wb')
out.write(f.read())
out.close()
print metadata

get_file_and_metadata, like other calls that return file data, returns an
httplib.HTTPResponse that you should .read() from to get the full response.
https://www.dropbox.com/developers-v1/core/docs/python#DropboxClient.get_file_and_metadata


={============================================================================
|kt_dev_py_0001| py-imaplib


={============================================================================
|kt_dev_py_0001| py-time

https://docs.python.org/2/library/time.html

This module provides various time-related functions. For related
functionality, see also the datetime and calendar modules.

Although this module is always available, not all functions are available on
all platforms. Most of the functions defined in this module call platform C
library functions with the same name. It may sometimes be helpful to consult
the platform documentation, because the semantics of these functions varies
among platforms.

An explanation of some terminology and conventions is in order.

time.time()

    Return the time in seconds since the epoch as a floating point number.
    Note that even though the time is always returned as a floating point
    number, not all systems provide time with a better precision than 1
    second. While this function normally returns non-decreasing values, it can
    return a lower value than a previous call if the system clock has been set
    back between the two calls.


={============================================================================
|kt_dev_py_0001| py-types

More formally, there are three major type (and operation) categories in Python
that have this generic nature:

Numbers (integer, floating-point, decimal, fraction, others)
Support addition, multiplication, etc.

Sequences (strings, lists, tuples)
Support indexing, slicing, concatenation, etc.

Mappings (dictionaries)
Support indexing by key, etc.

Sets are something of a category unto themselves (they don’t map keys to
    values and are not positionally ordered sequences)


The major core types in Python break down as follows:

Immutables (numbers, strings, tuples, frozensets)
None of the object types in the immutable category support in-place changes,
though we can always run expressions to make new objects and assign their
  results to variables as needed.

Mutables (lists, dictionaries, sets, bytearray)
Conversely, the mutable types can always be changed in place with operations
that do not create new objects. Although such objects can be copied, in-place
changes support direct modification.


={============================================================================
|kt_dev_py_0001| py-number


={============================================================================
|kt_dev_py_0001| py-string
  
Every string operation is defined to produce a new string as its result,
because strings are `immutable` 

Chapter 7: String Fundamentals

String Conversion Tools

# Python 3.X
>>> "42" + 1
TypeError: Can't convert 'int' object to str implicitly

# Python 2.X
>>> "42" + 1
TypeError: cannot concatenate 'str' and 'int' objects

>>> int("42"), str(42)  # Convert from/to string
(42, '42')

>>> repr(42)            # Convert to as-code string
'42'

note: 
The `str` type name.

The repr function (and the older backquotes expression, removed in Python 3.X)
also converts an object to its string representation


Character code conversions

The built-in `ord` returns the actual binary value used to represent the
corresponding character in memory. The chr function performs the inverse
operation, taking an integer code and converting it to the corresponding
character:

>>> ord('s')
115
>>> chr(115)
's'

#!/usr/bin/python

B = '1101'
I = 0

while B != '':
    I = I*2 + (ord(B[0]) - ord('0'))
    B = B[1:]

print(I)


>>> int(0b1101)
13
>>> int('1101', 2)
13
>>> bin(13)
'0b1101'


<string-quote>
Can write string literal using either single quotes ' or double quotes ":

For multiline strings with line breaks, you can use `triple quotes`, either '''
or """:

c = """
This is a longer string that
spans multiple lines
"""


https://docs.python.org/2/library/string.html

7.1.6. Deprecated string functions

The following list of functions are also defined as methods of string and
Unicode objects; see section String Methods for more information on those. 

You should consider these functions `as deprecated`, although they will not be
removed until Python 3. The functions defined in this module are:

<string-methods>
https://docs.python.org/2/library/stdtypes.html?highlight=endswith#str.endswith

5.6.1. String Methods

str.endswith(suffix[, start[, end]])

    Return True if the string ends with the specified suffix, otherwise return
    False. suffix can also be a tuple of suffixes to look for. With optional
    start, test beginning at that position. With optional end, stop comparing
    at that position.

    Changed in version 2.5: Accept tuples as suffix.


str.title()

    Return a titlecased version of the string where words start with an
    uppercase character and the remaining characters are lowercase.


str.split([sep[, maxsplit]])

    Return a list of the words in the string, using sep as the delimiter
    string. If maxsplit is given, at most maxsplit splits are done (thus, the
        list will have at most maxsplit+1 elements). If maxsplit is not
    specified or -1, then there is no limit on the number of splits (all
        possible splits are made).

    If sep is given, consecutive delimiters are not grouped together and are
    deemed to delimit empty strings (for example, '1,,2'.split(',') returns
        ['1', '', '2']). The sep argument may consist of multiple characters
    (for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']). Splitting an
      empty string with a specified separator returns [''].

    If sep is not specified or is None, a different splitting algorithm is
    applied: runs of consecutive whitespace are regarded as a single
    separator, and the result will contain no empty strings at the start or
    end if the string has leading or trailing whitespace. Consequently,
                        splitting an empty string or a string consisting of
                          just whitespace with a None separator returns [].

    For example, ' 1  2   3  '.split() returns ['1', '2', '3'], and '  1  2
    3  '.split(None, 1) returns ['1', '2   3  '].

<ex>
            p = re.compile (pattern)
            lines = stdOut.split ("\n")
            for line in lines:
                parts = line.split ("\t")
                if len (parts) == 2:
                    tag = parts[1].strip ()
                    if p.match (tag):
                        if not tag.endswith ("{}"):
                            tagsAux.append (tag)

<ex>
Delimiters can be longer than a single character, too:

>>> line = "i'mSPAMaSPAMlumberjack"
>>> line.split("SPAM")
["i'm", 'a', 'lumberjack']


str.rstrip([chars])

    Return a `copy` of the string with trailing characters removed. 
    
    The chars argument is a string specifying the `set of characters` to be
    removed. If omitted or None, the chars argument defaults to removing
    whitespace. The chars argument is not a suffix; rather, all combinations
    of its values are stripped:

    >>> '   spacious   '.rstrip()
    '   spacious'
    >>> 'mississippi'.rstrip('ipz')
    'mississ'

    note: Compared with [:-1]

    Chapter 7: String Fundamentals
    A line[:−1] slice would work, too. Having said that, calling the
    line.rstrip method is often preferred for stripping newline characters
    because this call leaves the line intact if it has no newline character at
    the end - a common case for files created with some text-editing tools.
    Slicing works if you're sure the line is properly terminated.


str.join(iterable)

    Return a string which is the concatenation of the strings in the iterable
    iterable. The separator between elements is the string providing this
    method.


str.find()

The find method returns the offset where the substring appears (by default,
    searching from the front), or −1 if it is not found. 
As we saw earlier, it's a substring search operation just like the in
expression, but find returns the position of a located substring.


str.replace()

>>> S = 'xxxxSPAMxxxxSPAMxxxx'
>>> S.replace('SPAM', 'EGGS')     # Replace all
'xxxxEGGSxxxxEGGSxxxx'
>>> S.replace('SPAM', 'EGGS', 1)  # Replace one
'xxxxEGGSxxxxSPAMxxxx'


<perfoemance>
If you have to apply many changes to a very large string, you might be able to
improve your script's performance by converting the string to an object that
does support in-place changes:

>>> S = 'spammy'
>>> L = list(S)
>>> L
['s', 'p', 'a', 'm', 'm', 'y']

>>> L[3] = 'x' # Works for lists, not strings
>>> L[4] = 'x'

>>> L
['s', 'p', 'a', 'x', 'x', 'y']

If, after your changes, you need to convert back to a string, use the string
  join method to "implode" the list back into a string:

>>> S = ''.join(L)
>>> S
'spaxxy'

str.join()

`join` puts the strings in a list (or other iterable) together, with the
delimiter between list items; in this case, it uses an empty string delimiter
to convert from a list back to a string. More generally, any string delimiter
and iterable of strings will do:

>>> 'SPAM'.join(['eggs', 'sausage', 'ham', 'toast'])
'eggsSPAMsausageSPAMhamSPAMtoast'

>>> '|'.join("one")     # o| n|e
'o|n|e'
>>> '|'.join(['one'])
'one'


<string-module>
The Original string Module's Functions (Gone in 3.X)

The history of Python's string methods is somewhat convoluted. For roughly the
first decade of its existence, Python provided a standard library module
called `string` that contained functions that largely mirrored the current set
of string object methods. 

By popular demand, in Python 2.0 these functions were made available as
methods of string objects. Because so many people had written so much code
that relied on the original string module, however, it was retained for
backward compatibility.

Today, you should use only string methods, not the original string module. In
fact, the original module call forms of today's string methods have been
removed completely from Python 3.X, and you should not use them in new code in
either 2.X or 3.X.


{string-formatting} *py-print*

String Formatting Expressions

string formatting allows us to perform multiple type-specific substitutions on
a string in a single step.

string formatting is available in two flavors

String formatting expressions: '...%s...' % (values)

The original technique available since Python's inception, this form is based
upon the C language's "printf" model, and sees widespread use in much existing
code.

String formatting method calls: '...{}...'.format(values)

A newer technique added in Python 2.6 and 3.0, this form is derived in part
from a same-named tool in C#/.NET, and overlaps with string formatting
expression functionality.

# Formatting expression (all)
>>> '%s, eggs, and %s' % ('spam', 'SPAM!') 
'spam, eggs, and SPAM!'

# Formatting method (2.6+, 3.0+)
>>> '{0}, eggs, and {1}'.format('spam', 'SPAM!') 
'spam, eggs, and SPAM!'

# Numbers optional (2.7+, 3.1+)
>>> '{}, eggs, and {}'.format('spam', 'SPAM!') 
'spam, eggs, and SPAM!'


>>> '%s -- %s -- %s' % (42, 3.14159, [1, 2, 3]) # All types match a %s target
'42 -- 3.14159 -- [1, 2, 3]'

As every type of object can be converted to a string, every object type works
with the %s conversion code. Because of this, unless you will be doing some
special formatting, %s is often the only code you need to remember for the
formatting expression.

Again, keep in mind that formatting always makes a new string, rather than changing
the string on the left.

<ex>
>>> L = [1,2,3]
>>> print 'print list: %s' % (L)
print list: [1, 2, 3]


{raw-string}
raw string literal that turns off the backslash escape mechanism. Such
literals start with the letter r and are useful for strings like directory
paths on Windows (e.g., r'C:\text\new').


={============================================================================
|kt_dev_py_0001| py-tuple

A tuple is a one-dimensional, `fixed-length`, `immutable` sequence of Python
objects. 

Because parentheses can also enclose expressions (see Chapter 5), you need to
do something special to tell Python when a single object in parentheses is a
  tuple object and not a simple expression.

T = (0,) A one-item tuple (not an expression)

>>> x = (40)      # An integer!
>>> x
40
>>> y = (40,)     # A tuple containing an integer
>>> y
(40,)


# The easiest way to create one is with a comma-separated sequence of values

>>> tup = 4,5,6   # >>> tup = (4,5,6)
>>> tup
(4, 5, 6)


# necessary to enclose the values in `parentheses` to create a tuple of tuples:

>>> nested_tup=(4,5,6),(7,8)
>>> nested_tup
((4, 5, 6), (7, 8))


# Any sequence or iterator can be converted to a tuple by invoking tuple:

>>> tuple([4,5,6])
(4, 5, 6)

>>> string_tup=tuple('string')
>>> string_tup
('s', 't', 'r', 'i', 'n', 'g')


# Accessed with square brackets [] as with most other sequence types.
# Sequences are 0-indexed in Python:

>>> string_tup[0]
's'


# Once created it's not possible to modify which object is stored in each slot:

>>> tup
(4, 5, 6)
>>> tup[1]=7
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'tuple' object does not support item assignment


# Can be concatenated using the + operator to produce longer tuples:

>>> long_tup = tup + nested_tup + string_tup
>>> long_tup
(4, 5, 6, (4, 5, 6), (7, 8), 's', 't', 'r', 'i', 'n', 'g')

note:
`tuple of tuple` so sequence can have different types.


{unpacking}
# If you try to assign to a tuple-like expression of variables, Python will
# attempt to unpack the value on the right-hand side of the equals sign:

>>> a,b,c = tup
>>> a
4
>>> b
5
>>> c
6


# Using this functionality it's easy to swap `variable names`, a task which in
# many languages might look like:
#
#   tmp = a
#   a = b
#   b = tmp

>>> a,b = b,a
>>> a
5
>>> b
4
>>> c
6


# One of the most common uses of variable unpacking when `iterating` over
# sequences of tuples or lists:

seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
for a, b, c in seq:
  pass

<ex>
seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
for a, b, c in seq:
  print a

1
4
7

<ex>
seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
for a, b, c, d in seq:
  print a

Traceback (most recent call last):
  File "./py-01.py", line 15, in <module>
    for a, b, c, d in seq:
ValueError: need more than 3 values to unpack


<method>
# Since the size and contents of a tuple cannot be modified, it is very light
# on instance methods. `count`, which counts the number of `occurrences` of a
# value:

>>> a=1,2,2,2,3,4,2
>>> a
(1, 2, 2, 2, 3, 4, 2)
>>> a.count(2)
4


<check>
>>> tup
('foo', 'bar', 'baz')
>>> 'bar' in tup
True


={============================================================================
|kt_dev_py_0001| py-list

In contrast with tuples, lists are `variable-length` and `mutable`. They can
be defined using `square brackets []` or using the `list` type function:

Lists and tuples are semantically similar as one-dimensional sequences of
objects and thus can be used interchangeably in many functions.

>>> b_list=list(tup)
>>> b_list
['foo', 'bar', 'baz']


<indexing>
Chapter 8: Lists and Dictionaries

Indexing, Slicing, and Matrixes

Because lists are sequences, indexing and slicing work the same way for lists
as they do for strings. However, the result of indexing a list is whatever
type of object lives at the offset you specify, while slicing a list always
returns a new list:

>>> L = ['spam', 'Spam', 'SPAM!']
>>> L[2]    # Offsets start at zero
'SPAM!'
>>> L[−2]   # Negative: count from the right
'Spam'
>>> L[1:]   # Slicing fetches sections
['Spam', 'SPAM!']


Index and slice assignments

When using a list, you can change its contents by assigning to either a
particular item (offset) or an entire section (slice):

>>> L = ['spam', 'Spam', 'SPAM!']
>>> L[1] = 'eggs'               # Index assignment
>>> L
['spam', 'eggs', 'SPAM!']
>>> L[0:2] = ['eat', 'more']    # Slice assignment: delete+insert
>>> L # Replaces items 0,1
['eat', 'more', 'SPAM!']

>>> L = [1, 2, 3]
>>> L[1:2] = [4, 5]       # Replacement/insertion
>>> L
[1, 4, 5, 3]
>>> L[1:1] = [6, 7]       # Insertion (replace nothing)
>>> L
[1, 6, 7, 4, 5, 3]
>>> L[1:2] = []           # Deletion (insert nothing)
>>> L
[1, 7, 4, 5, 3]

Because the length of the sequence being assigned does not have to match the
  length of the slice being assigned to, slice assignment can be used to
  replace (by overwriting), expand (by inserting), or shrink (by deleting) the
  subject list. 

It's a powerful operation, but frankly, one that you may not see very often in
practice. There are often `more straightforward and mnemonic ways` to replace,
  insert, and delete (concatenation, and the insert, pop, and remove list
      methods, for example), which Python programmers tend to prefer in
    practice.


Other common list operations

Because lists are mutable, you can use the del statement to delete an item or
section in place:

>>> L = ['spam', 'eggs', 'ham', 'toast']
>>> del L[0]          # Delete one item
>>> L
['eggs', 'ham', 'toast']
>>> del L[1:]         # Delete an entire section
>>> L # Same as L[1:] = []
['eggs']


<adding-removing>
# Append to the end of the list with the `append` method and `insert` an
# element at a specific location in the list:

>>> b_list.append('dwarf')
>>> b_list
['foo', 'bar', 'baz', 'dwarf']
>>> b_list.insert(1,'red')
>>> b_list
['foo', 'red', 'bar', 'baz', 'dwarf']

note: 
insert is computationally `expensive` compared with append as references to
subsequent elements have to be shifted internally to make room for the new
element.


# `pop` removes and returns an element at a particular index:

>>> b_list.pop(2)
'bar'
>>> b_list
['foo', 'red', 'baz', 'dwarf']

>>> L
[1, 2]
>>> L.pop() # Pop off stack
2


# `remove` locates the first such value and removes it from the last:

>>> b_list
['foo', 'red', 'red', 'red', 'baz', 'dwarf']
>>> b_list.remove('red')
>>> b_list
['foo', 'red', 'red', 'baz', 'dwarf']


<check>
As with tuple.

note:
checking whether a list contains a value is a lot `slower` than dicts and sets
as Python makes a linear scan across the values of the list, whereas the
others (based on hash tables) can make the check in constant time.


<concatenation>
# Append multiple elements to it using the `extend` method:

>>> [4, None, 'foo'] + [7,8,(2,3)]
[4, None, 'foo', 7, 8, (2, 3)]

>>> x=[4, None, 'foo']
>>> x.extend([7,8,(2,3)])
>>> x
[4, None, 'foo', 7, 8, (2, 3)]

# list concatenation is a compartively `expensive` operation since a `new
# list` must be created and the objects copied over. Using extend is usually
# preferable.

everything = []
for chunk in list_of_lists:
  everything.extend(chunk)

is faster than than the concatenative alternative

everything = []
for chunk in list_of_lists:
  everything = everything + chunk

note:
Know that extend adds many items, and append adds one.


<sorting> 
A list can be sorted in-place (without creating a new object) by calling its
`sort` function:

>>> tup = 2,4,3,5,7,6
>>> tup
(2, 4, 3, 5, 7, 6)

>>> lst = [2,4,3,5,7,8]
>>> lst
[2, 4, 3, 5, 7, 8]

>>> tup.sort()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'tuple' object has no attribute 'sort'

>>> lst.sort()
>>> lst
[2, 3, 4, 5, 7, 8]


Can modify sort behavior by passing in `keyword arguments` - a special
  "name=value" syntax in function calls that specifies passing by name and is
  often used for giving configuration options.

One is the ability to pass a secondary `sort key`, i.e. a `function` that
produces a value to use to sort the objects.

>>> lst = ['saw', 'small', 'He', 'foxes', 'six']
>>> lst
['saw', 'small', 'He', 'foxes', 'six']
>>> lst.sort(key=len)
>>> lst
['He', 'saw', 'six', 'small', 'foxes']


>>> L = ['abc', 'ABD', 'aBe']
>>> L.sort()                              # Sort with mixed case
>>> L
['ABD', 'aBe', 'abc']
>>> L = ['abc', 'ABD', 'aBe']
>>> L.sort(key=str.lower)                 # Normalize to lowercase
>>> L
['abc', 'ABD', 'aBe']
>>>
>>> L = ['abc', 'ABD', 'aBe']
>>> L.sort(key=str.lower, reverse=True)   # Change sort order
>>> L
['aBe', 'ABD', 'abc']


<sorted-function>

Partly because of such constraints, sorting is also available in recent
  Pythons as a builtin function, which sorts any collection (not just lists)
  and `returns a new list` for the result (instead of in-place changes):

>>> L = ['abc', 'ABD', 'aBe']
>>> sorted(L, key=str.lower, reverse=True) # Sorting built-in
['aBe', 'ABD', 'abc']

>>> L = ['abc', 'ABD', 'aBe']
>>> sorted([x.lower() for x in L], reverse=True) # Pretransform items: differs!
['abe', 'abd', 'abc']

Notice the last example here - we can convert to lowercase prior to the sort
  with a list comprehension, but the result `does not contain` the original
  list's values as it does with the key argument. 

The latter is applied temporarily during the sort, instead of changing the
values to be sorted altogether.


note: *py-module-bisect*

The built-in bisect module implements binary-search and insertion into a
sorted list. bisect.bisect finds the `location` where an element should be
inserted to keep it sorted, while bisect.insort actually `inserts` the element
into that location:

>>> import bisect

>>> c = [1,2,2,2,3,4,7]
>>> bisect.bisect(c,2)
4

>>> bisect.insort(c,6)
>>> c
[1, 2, 2, 2, 3, 4, 6, 7]

The bisect module functions do not check whether the list is sorted. Thus,
using them with an unsorted list will succeed without error but may lead to
incorrect results.


<nested-list>
# [
#     [["AMS"], ["AMS"]],
#     [["PROX"], ["darwin"]]
#     ...
#     [["PPCM_CF"], ["ppcm", "ppcm_core"]],
# ]

>>> expstr = '[[["AMS"], ["AMS"]],[["PROX"], ["darwin"]]]'
>>> rlist = eval(expstr)        *keyward-eval*
>>> rlist
[[['AMS'], ['AMS']], [['PROX'], ['darwin']]]
>>> rlist[0][0]
['AMS']
>>> rlist[1]
[['PROX'], ['darwin']]
>>> rlist[0]
[['AMS'], ['AMS']]
>>> rlist[1]
[['PROX'], ['darwin']]
>>> rlist[1][0]
['PROX']
>>> rlist[1][1]
['darwin']

<ex>
# covert a nested list to a dict

  readList = eval (content)
  self._segments = {}
  for element in readList:
      self._segments [element[0][0]] = element [1]


<list-string>

>>> A=["spam"]
>>> A
['spam']
>>> len(A)
1


>>> L="spam"
>>> L
'spam'
>>> list(L)
['s', 'p', 'a', 'm']
>>> B=list(L)
>>> len(B)
4


={============================================================================
|kt_dev_py_0001| py-slice

You can select sections of list-like types (arrays, tuples, NumPy arrays) by
using slice notation, which in its basic form consists of `start:stop` passed
to the `indexing operator []`:

>>> seq=[7,2,3,7,5,6,0,1]
>>> seq
[7, 2, 3, 7, 5, 6, 0, 1]

Their general form, X[I:J], means "give me everything in X from offset I up to
  but not including offset J." The result is returned in a `new object`

# (start, end] in C++ iterator notation.

>>> seq[1:1]
[]

>>> seq[1:2]
[2]

>>> seq[1:5]
[2, 3, 7, 5]

# inserted actually

>>> seq[3:4] = [6,3]
>>> seq
[7, 2, 3, 6, 3, 5, 6, 0, 1]


<default-to>
Either the start or stop can be omitted in which case they `default to` the
start of the sequence and the end of the sequence, respectively:

>>> S[1:]   # Everything past the first (1:len(S))
'pam'
>>> S       # S itself hasn't changed
'Spam'
>>> S[0:3]  # Everything but the last
'Spa'
>>> S[:3]   # Same as S[0:3]
'Spa'
>>> S[:-1]  # Everything but the last again, but simpler (0:-1)
'Spa'
>>> S[:]    # All of S as a top-level copy (0:len(S))
'Spam'

note: in how the last operation effectively copies the entire string.


<step>
A `step` can also be used after a second colon

[7, 2, 3, 6, 3, 5, 6, 0, 1]
>>> seq[::2]
[7, 3, 3, 6, 1]

Negative indices slice the sequence relative to the end:

   H  E  L  L  O  !
   0  1  2  3  4  5  6
  -6 -5 -4 -3 -2 -1

A clever use of this is to pass -1 which has the useful effect of reversing a
list or tuple:

[7, 2, 3, 6, 3, 5, 6, 0, 1]
>>> seq[::-1]
[1, 0, 6, 5, 3, 6, 3, 2, 7]


<copy>
>>> L1 = [2, 3, 4]
>>> L2 = L1[:]      # Make a copy of L1 (or list(L1), copy.copy(L1), etc.)
>>> L1[0] = 24

>>> L1
[24, 3, 4]
>>> L2              # L2 is not changed
[2, 3, 4]


={============================================================================
|kt_dev_py_0001| py-data-seq-function

Python has a handful of useful built-in sequence functions.

<enumerate>
When iterating over a sequence to want to keep track of the index of the
current item. Since this is so common, Python has a built-in function
`enumerate` which returns a sequence of (i, value) tuples:

for i, value in enumerate(collection):
  # do something with value


Useful `pattern` that uses enumerate is computing a dict mapping the values of
a sequence (which are assumed to be unique) to their locations in the
sequence:

>>> l
['one', 'two', 'three']
>>> mapping = dict((v,i) for i,v in enumerate(l))
>>> mapping
{'three': 2, 'two': 1, 'one': 0}


<sorted>
The sorted function returns a new sorted list from the elements of any
sequence. A common `pattern` for getting a sorted list of the `unique
elements` in a sequence is to combine sorted with set.

>>> [7,1,2,6,0,3,2,3,2]
[7, 1, 2, 6, 0, 3, 2, 3, 2]
>>> sorted([7,1,2,6,0,3,2,3,2])
[0, 1, 2, 2, 2, 3, 3, 6, 7]
>>> sorted(set([7,1,2,6,0,3,2,3,2]))
[0, 1, 2, 3, 6, 7]


<zip>
zip `pairs up` the elements of a number of lists, tuples, or other sequences,
    to create a list of tuples:

>>> seq1=['foo','bar','baz']
>>> seq2=['one','two','three']
>>> zip(seq1,seq2)
[('foo', 'one'), ('bar', 'two'), ('baz', 'three')]


A very common use of zip is for simultaneously `iterating over multiple`
sequences, possibly also combined with enumerate:

>>> for i, (a,b) in enumerate(zip(seq1,seq2)):
...     print('%d: %s, %s' % (i,a,b))
... 
0: foo, one
1: bar, two
2: baz, three


Given a zipped sequence, zip can be applied in a clever way to `unzip` the
sequence.  Another way to think about this is converting a list of rows into a
list of columns. The syntax, which looks a bit magical, is:

>>> zipped=zip(seq1, seq2)
>>> zipped
[('foo', 'one'), ('bar', 'two'), ('baz', 'three')]
>>> names, numbers = zip(*zipped)
>>> names
('foo', 'bar', 'baz')
>>> numbers
('one', 'two', 'three')


<reversed>
`reversed` iterates over the elements of a sequence in reverse order:

>>> range(10)
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> reversed(range(10))
<listreverseiterator object at 0xb753a8ec>
>>> list(reversed(range(10)))
[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]


={============================================================================
|kt_dev_py_0001| py-dict in-membership

Chapter 8: Lists and Dictionaries

Dictionaries are sometimes called associative arrays or hashes. Internally,
dictionaries are implemented as hash tables.

Dictionaries, the only mapping type in core objects set, are also `mutable`:
like lists, they may be changed in place and can grow and shrink on demand.

Unlike out-of-bounds assignments in lists, which are forbidden, assignments to
new dictionary keys create those keys:

>>> D = {}
>>> D['name'] = 'Bob'             # Create keys by assignment
>>> D['age'] = 40


A more common name for it is hash map or associative array. It is a
flexibly-sized collection of key-value pairs, where key and value are Python
objects. 

One way to create one is by using curly `braces` {} and using `colons` to
separate keys and values:

{'name': 'Bob', 'age': 40}        # Traditional literal expression

dict(name='Bob', age=40)          # dict keyword argument form


note: set vs dict
  return {'mac': result}          # returns a dict
  return {'mac', result}          # returns a set


<order>
Notice how the left-to-right order of dictionary keys is scrambled. Mappings
are not positionally ordered, they'll come back in a different order than you
typed them.

What do we do, though, if we do need to impose an ordering on a dictionary's
items?  One common solution is to grab a list of keys with the dictionary keys
method, sort that with the list sort method, and then step through the result
with a Python for loop

>>> Ks = list(D.keys())         # Unordered keys list
>>> Ks                          # A list in 2.X, "view" in 3.X: use list()
['a', 'c', 'b']

>>> Ks.sort()                   # Sorted keys list
>>> Ks
['a', 'b', 'c']

>>> for key in Ks:              # Iterate though sorted keys
      print(key, '=>', D[key])  # <== press Enter twice here (3.X print)
a => 1
b => 2
c => 3

This is a three-step process, and in recent versions of Python it can be done
in one step with the newer `sorted` built-in function.

>>> D
{'a': 1, 'c': 3, 'b': 2}
>>> for key in sorted(D):
      print(key, '=>', D[key])
a => 1
b => 2
c => 3


<in-membership>
although we can assign to a new key to expand a dictionary, fetching a
nonexistent key is still a mistake.

The dictionary `in membership expression` allows us to query the existence of
a key and branch on the result with a Python if statement.

Can check `if a dict contains a key` using the same syntax as with checking
whether a list or tuple contains a value:

>>> 'b' in d1
True

>>> if not 'f' in D:          # Python's sole selection statement
  print('missing')

# see comprehension:
#
# >>> strings=['a', 'as', 'bat', 'car', 'dove', 'python']
# >>> [x.upper() for x in strings if len(x) > 2]
# ['BAT', 'CAR', 'DOVE', 'PYTHON']


<dict-looping>
  # segments is a dict
  segments = D.getSegments ()
  if segments != None:

      # makes a list from keys of a dict
      keys = sorted (list (segments.keys ()))
      for key in keys:
          if args.detail:
              print key + ":",

              # looks up the value of a dict
              for build in segments [key]:
                  print build,
              print " "

In fact, Python also lets you step through a dictionary's keys list without
actually calling the keys method in most for loops. 
For any dictionary D, saying `for key in D` works the same as saying the
complete `for key in D.keys()`

>>> table = {'1975': 'Holy Grail',    # Key: Value
... '1979': 'Life of Brian',
... '1983': 'The Meaning of Life'}

>>> for year in table:                # Same as: for year in table.keys()
... print(year + '\t' + table[year])
...
1979 Life of Brian
1975 Holy Grail
1983 The Meaning of Life


Values can be deleted either using the `del` keyword or the `pop` method
(which simultaneously returns the value and deletes the key):

>>> d1
{'a': 'some value', 'dummy': 'another value', 'b': [1, 2, 3, 4], 5: 'some value', 7: 'an integer'}
>>> del d1[5]
>>> d1
{'a': 'some value', 'dummy': 'another value', 'b': [1, 2, 3, 4], 7: 'an integer'}
>>> d1.pop('dummy')
'another value'
>>> d1
{'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}


The `keys() and values method` give you lists of the keys and values,
    respectively. While the key-value pairs are not in any particular order,
    these functions output the keys and values in the same order:

>>> d1.keys()
['a', 'b', 7]
>>> d1.values()
['some value', [1, 2, 3, 4], 'an integer']


<dict-update>
One dict can be merged into another using the `update` method:

>>> d1
{'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}
>>> d1.update({'b':'foo','c':12})
>>> d1
{'a': 'some value', 'c': 12, 'b': 'foo', 7: 'an integer'}

note: 'b' is overwritten.


Preview: Mapping values to keys

Notice how the prior table maps year to titles, but not vice versa. If you
want to map the other way-titles to years-you can either code the dictionary
differently, or use methods like items that give searchable sequences,

>>> table = {'Holy Grail': '1975',  # Key=>Value (title=>year)
... 'Life of Brian': '1979',
... 'The Meaning of Life': '1983'}
>>>
>>> table['Holy Grail']
'1975'

>>> list(table.items())             # Value=>Key (year=>title)
[('The Meaning of Life', '1983'), ('Holy Grail', '1975'), ('Life of Brian', '1979')]

>>> [title for (title, year) in table.items() if year == '1975']
['Holy Grail']

searching through sequences like this is generally much slower than a direct
key index


<dict-from-sequence> <zipping>
Common to occasionally end up with two sequences that you want to pair up
element-wise in a dict.

mapping = {}
for key, value in zip(key_list, value_list):
  mapping[key] = value

Since a dict is essentially a collection of 2-tuples, the dict type function
accepts a list of 2-tuples:

mapping = dict(zip(range(5), reversed(range(5))))
mapping
Out[454]: {0: 4, 1: 3, 2: 2, 3: 1, 4: 0}

>>> bob2 = dict(zip(['name', 'job', 'age'], ['Bob', 'dev', 40])) # Zipping
>>> bob2
{'job': 'dev', 'name': 'Bob', 'age': 40}

>>> l
['one', 'two', 'three']
>>> mapping = dict((v,i) for i,v in enumerate(l))
>>> mapping
{'three': 2, 'two': 1, 'one': 0}


<dict-nonexistent-key-exception>
Elements can be accessed and inserted using the same syntax as accessing
elements of a list or tuple:

>>> d1={'a':'some value', 'b':[1,2,3,4]}
>>> d1
{'a': 'some value', 'b': [1, 2, 3, 4]}
>>> d1[7]='an integer'
>>> d1
{'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}
>>> d1['b']
[1, 2, 3, 4]
>>> d1[b]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
KeyError: 'three'
>>> 


<dict-default-values>
Very common to have logic like:

if key in some_dict:
  value = some_dict[key]
else:
  value = default_value

Thus, the dict methods `get` and pop can take a default value to be returned, so
that the above if-else block can be written simply as:

value = some_dict.get(key, default_value)

`get` by default will return `None` if the key is not present, while `pop`
will raise an exception.

Fetching a nonexistent key is normally an error, but the get method returns a
default value-None, or a passed-in default-if the key doesn’t exist.

>>> D.get('spam') # A key that is there
2
>>> print(D.get('toast')) # A key that is missing
None
>>> D.get('toast', 88)
88


<other-collection-as-value>

>>> di={}
>>> di['b'] = ['apple', 'atom']
>>> di
{'b': ['apple', 'atom']}

With setting values, a common case is for the values in a dict to be other
collections, like lists. For example, you could imagine categorizing a list of
words by their first letters as a dict of lists:

>>> words=['apple', 'bat', 'bar', 'atom', 'book']
>>> by_letter={}
>>> for word in words:
...     letter = word[0]
...     if letter not in by_letter:
...             by_letter[letter] = [word]
...     else:
...             by_letter[letter].append(word)
... 
>>> by_letter
{'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}


The `setdefault` dict method is for precisely this purpose.

note: HOW does all work?

>>> by_letter={}
>>> words=['apple', 'bat', 'bar', 'atom', 'book']
>>> for word in words:
...     letter = word[0]
...     by_letter.setdefault(letter,[]).append(word)
... 
>>> by_letter
{'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}


The built-in `collections` module has a useful class, `defaultdict`, which makes
  this even easier. One is created by passing a type or function for
  generating the default value for each slot in the dict: 
  
from collections import defaultdict 
by_letter = defaultdict(list) 
for word in words:
  by_letter[word[0]].append(word) 
  

The initializer to defaultdict only needs to be a callable object (e.g. any
    function), not necessarily a type. Thus, if you wanted the default value
to be 4 you could pass a function returning 4

counts = defaultdict(lambda: 4)


<key-types>
While the values of a dict can be `any` Python object, the keys have to be
`immutable` objects like scalar types (int, float, string) or tuples (all the
    objects in the tuple need to be immutable, too). The technical term here
is `hashability`. You can check whether an object is hashable (can be used as
    a key in a dict) with the hash function:

>>> hash('string')
-1542666171
>>> hash((1,2,(2,3)))
1387206534
>>> hash((1,2,[2,3]))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: unhashable type: 'list'


in dictionaries, there's just one value per key, but there may be many keys
per value.


Using dictionaries to simulate flexible lists: Integer keys

>>> L = []
>>> L[99] = 'spam'
Traceback (most recent call last):
File "<stdin>", line 1, in ?
IndexError: list assignment index out of range

Although you can use repetition to preallocate as big a list as you’ll need
(e.g., [0]*100), you can also do something that looks similar with
dictionaries that does not require such space allocations. By using integer
keys, dictionaries can emulate lists that seem to grow on offset assignment:

>>> D = {}
>>> D[99] = 'spam'
>>> D[99]
'spam'
>>> D
{99: 'spam'}

Here, it looks as if D is a 100-item list, but it's really a dictionary with a
single entry; the value of the key 99 is the string 'spam'. You can access
this structure with offsets much like a list, catching nonexistent keys with
get or in tests if required, but you don’t have to allocate space for all the
positions you might ever need to assign values to in the future. When used
like this, dictionaries are like more flexible equivalents of lists.


To use a list as a key, an easy fix is to convert it to a tuple:

>>> d = {}
>>> d[tuple([1,2,3])]=5
>>> d
{(1, 2, 3): 5}


Turple as a key?

Using dictionaries for sparse data structures: Tuple keys

In a similar way, dictionary keys are also commonly leveraged to implement
`sparse` data structures-for example, multidimensional arrays where only a few
positions have values stored in them:

>>> Matrix = {}
>>> Matrix[(2, 3, 4)] = 88
>>> Matrix[(7, 8, 9)] = 99
>>>
>>> X = 2; Y = 3; Z = 4 # ; separates statements: see Chapter 10
>>> Matrix[(X, Y, Z)]
88
>>> Matrix
{(2, 3, 4): 88, (7, 8, 9): 99}

Here, we’ve used a dictionary to represent a three-dimensional array that is
empty except for the two positions (2,3,4) and (7,8,9). The keys are tuples
that record the coordinates of nonempty slots. 

Rather than allocating a large and mostly empty threedimensional matrix to
hold these values, we can use a simple two-item dictionary. 

Accessing an empty slot triggers a `nonexistent key exception` slots are not
physically stored:

>>> Matrix[(2,3,6)]
Traceback (most recent call last):
File "<stdin>", line 1, in ?
KeyError: (2, 3, 6)


<sorting>
dict is not `ordered` but can be done in one step with the newer `sorted`
built-in function.

>>> for key in sorted(D):
  print(key, '=>', D[key])


<ex>
783E53043FBA, SYSF40.73.00, Rack 44 Shelf 1
783E53043FA6, SYSF40.73.00, Rack 44 Shelf 2

#!/usr/bin/python
maps = {}

f = open('maclist.txt');
for line in f:
    tokens = line.rstrip().split(',')
    # maps[ tokens[0] ] = { 'version' : tokens[1], 'name' : tokens[2] }
    maps[ tokens[0] ] = tokens[1:]

print maps

if '783E53043FBA' in maps:
    print '783E53043FBA is in maps'

if '783E53043FBB' in maps:
    print '783E53043FBB is in maps'

if '783E53043FA6' in maps:
    print '783E53043FA6 is in maps'

print 'ends'


={============================================================================
|kt_dev_py_0001| py-set

A set is an `unordered` collection of unique elements. You can think of them
like dicts, but keys only, no values.

A set can be created in two ways:

>>> set([2,2,2,1,3,3])
set([1, 2, 3])

>>> {2,2,2,1,3,3}
set([1, 2, 3])


Sets support mathematical set operations like union, intersection, difference,
and symmetric difference.

>>> a = {1,2,3,4,5}
>>> b = {3,4,5,6,7,8}

# union(or)
>>> a | b
set([1, 2, 3, 4, 5, 6, 7, 8])

# intersection(and)
>>> a & b
set([3, 4, 5])

# difference
>>> a - b
set([1, 2])

# symmetric difference
>>> a ^ b
set([1, 2, 6, 7, 8])


>>> {1,2,3}.issubset(a)
True
>>> a.issuperset({1,2,3})
True
>>> {1,2,3} == {3,2,1}
True


={============================================================================
|kt_dev_py_0001| py-reference

Chapter 9: Tuples, Files, and Everything Else

Core Types Review and Summary, References Versus Copies

Assignments always store references to objects, not copies of those objects.
In practice, this is usually what you want. Because assignments can generate
multiple references to the same object, though, it's important to be aware
that changing a mutable object in place may affect other references to the
same object elsewhere in your program. If you don't want such behavior, you'll
need to tell Python to copy the object explicitly.

If you really do want copies, however, you can request them:

  Slice expressions with empty limits (L[:]) copy sequences.

  The dictionary, set, and list copy method (X.copy()) copies a dictionary,
  set, or list (the list’s copy is new as of 3.3).

  Some built-in functions, such as list and dict make copies (list(L),
  dict(D), set(S)).

  The copy standard library module makes full copies when needed.

One final note on copies: empty-limit slices and the dictionary copy method
only make top-level copies; that is, they do not copy nested data structures,
if any are present. If you need a complete, fully independent copy of a deeply
  nested data structure (like the various record structures we've coded in
      recent chapters), use the standard copy module, introduced in Chapter 6:

import copy
X = copy.deepcopy(Y)      # Fully copy an arbitrarily nested object Y

This call recursively traverses objects to copy all their parts. This is a
much more rare case, though, which is why you have to say more to use this
scheme. References are usually what you will want; when they are not, slices
and copy methods are usually as much copying as you'll need to do.


={============================================================================
|kt_dev_py_0001| py-comparison

Chapter 9: Tuples, Files, and Everything Else

Core Types Review and Summary, Comparisons, Equality, and Truth

All Python objects also respond to comparisons: tests for equality, relative
magnitude, and so on. Python comparisons always inspect all parts of compound
objects until a result can be determined. 

When nested objects are present, Python automatically traverses data
structures to apply comparisons from left to right, and as deeply as needed.
The first difference found along the way determines the comparison result.
This is sometimes called a `recursive comparison`

*is-keyword-is*
>>> L1 = [1, ('a', 3)]  # Same value, unique objects
>>> L2 = [1, ('a', 3)]
>>> L1 == L2, L1 is L2  # Equivalent? Same object?
(True, False)

L1 and L2 are assigned lists that are equivalent but distinct objects.

  The == operator tests `value equivalence` Python performs an equivalence
  test, comparing all nested objects recursively.

  The is operator tests `object identity` Python tests whether the two are
  really the same object (i.e., live at the same address in memory).


Relative magnitude comparisons are also applied recursively to nested data
structures:

>>> L1 = [1, ('a', 3)]
>>> L2 = [1, ('a', 2)]
>>> L1 < L2, L1 == L2, L1 > L2    # Less, equal, greater: tuple of results
(False, False, True)

<ex>
#!/usr/bin/python

# returns 1 if greater is bigger than lesser
#        -1 is lesser  is bigger than greater
#         0 if they are equal
def compareVersions(greater, lesser):
    greater_array = [int(i) for i in greater.split('.')]
    lesser_array = [int(i) for i in lesser.split('.')]
    len_lesser = len(lesser_array)

    for i in range(len(greater_array)):
        try:
            if i >= len_lesser or greater_array[i] > lesser_array[i]:
                return 1
            elif greater_array[i] < lesser_array[i]:
                return -1
        except IndexError:
            # One of the versions strings is too short, assume they are the same
            print 'Warning unmatched version string lengths', greater, lesser                

    # if we get here they should be the same
    return 0

# returns 1 if greater is bigger than lesser
#        -1 is lesser  is bigger than greater
#         0 if they are equal
def compareVersions2(greater, lesser):
    greater_array = [int(i) for i in greater.split('.')]
    lesser_array = [int(i) for i in lesser.split('.')]

    return 1 if greater_array > lesser_array else -1

version1 = "40.65.00"
version2 = '40.66.00'

print 'version 1 is :', version1
print 'version 2 is :', version1

print 'compare result :', compareVersions( version1, version2 )
print 'compare result :', compareVersions2( version1, version2 )

print 'compare result :', compareVersions( version2, version1 )
print 'compare result :', compareVersions2( version2, version1 )

$ ./py-03.py
version 1 is : 40.65.00
version 2 is : 40.65.00
compare result : -1
compare result : -1
compare result : 1
compare result : 1


More specifically, Python compares types as follows:

  Numbers are compared by relative magnitude, after conversion to the common
  highest type if needed.

  Strings are compared lexicographically (by the character set code point
      values returned by ord), and character by character until the end or
  first mismatch ("abc" < "ac").

  Lists and tuples are compared by comparing each component from left to
  right, and recursively for nested structures, until the end or first
  mismatch ([2] > [1, 2]).

  Sets are equal if both contain the same items (formally, if each is a subset
      of the other), and set relative magnitude comparisons apply subset and
  superset tests.

  Dictionaries compare as equal if their sorted (key, value) lists are equal.
  Relative magnitude comparisons are not supported for dictionaries in Python
  3.X, but they work in 2.X as though comparing sorted (key, value) lists.


Python 2.X and 3.X dictionary comparisons

In Python 2.X, dictionaries support magnitude comparisons, as though you were
comparing sorted key/value lists:

C:\code> c:\python27\python
>>> D1 = {'a':1, 'b':2}
>>> D2 = {'a':1, 'b':3}
>>> D1 == D2 # Dictionary equality: 2.X + 3.X
False
>>> D1 < D2 # Dictionary magnitude: 2.X only
True

magnitude comparisons for dictionaries are removed in Python 3.X because they
incur too much overhead when equality is desired (equality uses an optimized
    scheme in 3.X that doesn't literally compare sorted key/ value lists):

C:\code> c:\python33\python
>>> D1 = {'a':1, 'b':2}
>>> D2 = {'a':1, 'b':3}
>>> D1 == D2
False
>>> D1 < D2
TypeError: unorderable types: dict() < dict()

The alternative in 3.X is to either write loops to compare values by key, or
compare the sorted key/value lists manually—the items dictionary methods and
sorted built-in suffice:

>>> list(D1.items())
[('b', 2), ('a', 1)]
>>> sorted(D1.items())
[('a', 1), ('b', 2)]
>>>
>>> sorted(D1.items()) < sorted(D2.items()) # Magnitude test in 3.X
True
>>> sorted(D1.items()) > sorted(D2.items())
False

This takes more code, but in practice, most programs requiring this behavior
will develop more efficient ways to compare data in dictionaries than either
this workaround or the original behavior in Python 2.X.


<true-flase>
The Meaning of True and False in Python

The notions of true and false are intrinsic properties of every object in
Python-each object is either true or false, as follows:

  Numbers are false if zero, and true otherwise.
  Other objects are false if empty, and true otherwise.


The None object

Python also provides a special object called None, which is always considered
to be false. It is the only value of a special data type in Python and
typically serves as an empty placeholder (much like a NULL pointer in C).

For lists you cannot assign to an offset unless that offset already exists. To
preallocate a 100-item list such that you can add to any of the 100 offsets:

>>> L = [None] * 100
>>>
>>> L
[None, None, None, None, None, None, None, ... ]

This doesn't limit the size of the list (it can still grow and shrink later),
     but simply presets an initial size to allow for future index assignments.
       You could initialize a list with zeros the same way, of course, but
       best practice dictates using None if the type of the list’s contents is
       variable or not yet known.

Keep in mind that None does not mean "undefined." That is, None is something,
not nothing (despite its name!)-it is a real object and a real piece of memory
  that is created and given a built-in name by Python itself.


={============================================================================
|kt_dev_py_0001| py-comprehension

`List comprehensions` are one of the most-loved Python language features. They
allow you to concisely form a new list `by filtering` the elements of a
collection and transforming the elements passing the filter in one conscise
expression. They take the basic form:

[`expr` for val in collection if `condition`]

This is equivalent to the following for loop:

result = []
for val in collection:
  if condition:
    result.append(expr)

The `filter condition` can be `omitted`, leaving only the expression. For
example, we could filter out strings with length 2 or less and also convert
them to uppercase like this:

>>> strings=['a', 'as', 'bat', 'car', 'dove', 'python']
>>> [x.upper() for x in strings if len(x) > 2]
['BAT', 'CAR', 'DOVE', 'PYTHON']


>>> M
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]

>>> col2 = [row[1] for row in M]      # Collect the items in column 2
>>> col2
[2, 5, 8]
>>> M                                 # The matrix is unchanged
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]

List comprehensions derive from set notation; they are a way to build a new
  list by `running an expression on each item in a sequence`, one at a time,
       from left to right. 
List comprehensions are coded in square brackets (to tip you off to the fact
    that they make a list) and are composed of an `expression` and a `looping
construct` that share a variable name (row, here).

<ex>
>>> s = '783E53043FBA, SYSF40.73.00, Rack 44 Shelf 1'
>>> s.split(',')
['783E53043FBA', ' SYSF40.73.00', ' Rack 44 Shelf 1']

f = open('maclist.txt');
for line in f:
    tokens = line.rstrip().split(',')
    maps[ tokens[0] ] = [ tokens[1].strip(), tokens[2].strip() ]

    To:
    maps[ tokens[0] ] = [ x.strip() for x in tokens[1:] ]


<any-iterable-object>
Can be used to iterate over any iterable object

>>> diag = [M[i][i] for i in [0, 1, 2]]   # Collect a diagonal from matrix
>>> diag
[1, 5, 9]

>>> doubles = [c * 2 for c in 'spam']     # Repeat characters in a string
>>> doubles
['ss', 'pp', 'aa', 'mm']

>>> [[x ** 2, x ** 3] for x in range(4)]  # Multiple values, "if" filters
[[0, 0], [1, 1], [4, 8], [9, 27]]

>>> [[x, x / 2, x * 2] for x in range(−6, 7, 2) if x > 0]
[[2, 1, 4], [4, 2, 8], [6, 3, 12]]


In Python 2.7 and 3.X, comprehension syntax can also be used to create sets
  and dictionaries:

A `dict comprehension` looks like this:

dict_comp = { `key-expr:value-expr` for value in collection if `condition`}


A `set comprehension` looks like list comprehension except with curly braces
  instead of square brackets:

set_comp = {expr for value in collection if condition}


Comprehensions are just syntactic sugar, but they similarly can make code both
  easier to write and read.


Suppose we wanted a set containing just the lengths of the strings contained
in the collection; this could be easily computed using a set comprehension:

>>> unique_lengths = {len(x) for x in strings}
>>> unique_lengths
set([1, 2, 3, 4, 6])

Could create a lookup map of these strings to their locations in the list:

>>> loc_mapping = {val:index for index, val in enumerate(strings)}
>>> loc_mapping
{'a': 0, 'bat': 2, 'python': 5, 'car': 3, 'as': 1, 'dove': 4}

Note that this dict could be equivalently constructed by:

>>> loc_mapping2 = dict((val,index) for index, val in enumerate(strings))
>>> loc_mapping2
{'a': 0, 'bat': 2, 'python': 5, 'car': 3, 'as': 1, 'dove': 4}


={============================================================================
|kt_dev_py_0001| py-if

Chapter 12: if Tests and Syntax Rules

Like all `compound statements`, the if statement may contain other statements,
including other ifs.

<python-true>
Remember that 1 is Boolean true (the word `True` is its equivalent), so this
statement’s test always succeeds. To handle a false result, code the else:

>>> if not 1:
... print('true')
... else:
... print('false')
...
false

* All objects have an inherent Boolean true or false value.
* Any nonzero number or nonempty object is true.
* Zero numbers, empty objects, and the special object `None` are considered false.
* Comparisons and equality tests return `True` or `False` (custom versions of 1 and 0).
* Boolean and and or operators return a true or false operand object.
* Boolean operators stop evaluating (“short circuit”) as soon as a result is known.


On the other hand, the `and` and `or` operators always `return an object` - either
the object on the left side of the operator or the object on the right. If we
test their results in if or other statements, they will be as expected
(remember, every object is inherently true or false), but we won't get back a
simple True or False.

>>> 2 or 3, 3 or 2    # Return left operand if true
(2, 3)                # Else, return right operand (true or false)
>>> [] or 3
3
>>> [] or {}
{}


Python `and` operations also stop as soon as the result is known; however, in
this case Python evaluates the operands from left to right and stops if the
left operand is a false object because it determines the result—false and
anything is always false:

>>> 2 and 3, 3 and 2  # Return left operand if false
(3, 2)                # Else, return right operand (true or false)
>>> [] and {}
[]
>>> 3 and []
[]


<alternative-to-switch> dictionary-based multiway branch.
that there is no switch or case statement in Python that selects an action
based on a variable’s value. Instead, you usually code multiway branching as a
series of if/elif tests, as in the prior example, and occasionally by indexing
dictionaries or searching lists. 

Because dictionaries and lists `can be built at runtime dynamically`, they are
sometimes more flexible than hardcoded if logic in your script:

>>> choice = 'ham'
>>> print({'spam': 1.25,  # A dictionary-based 'switch'
...        'ham': 1.99,   # Use has_key or get for default
...        'eggs': 0.99,
...        'bacon': 1.10}[choice])
1.99


Because any expression can be enclosed in parentheses, you can usually use the
`open pairs technique` instead if you need your code to span multiple
lines—simply wrap a part of your statement in parentheses:

if (a == b and c == d and
  d == e and e == f):
  print('new')            # But parentheses usually do too, and are obvious


The if/else Ternary Expression

if X:
  A = Y
else:
  A = Z

At other times, we may want to nest such a construct in a larger statement
instead of assigning its result to a variable. For these reasons, Python 2.5
introduced a new expression format that allows us to say the same thing in one
expression:

A = Y if X else Z

>>> A = 't' if 'spam' else 'f'  # For strings, `nonempty means true`
>>> A
't'
>>> A = 't' if '' else 'f'
>>> A
'f'

<ex>
    print 'Found %d images, ignoring those matching \'%s\'%s' % (
        len(images),
        settings.dropBoxIgnoreRegex,
        '' if stb_regex == '.*' else ' filtering on \'' + stb_regex + '\'')


={============================================================================
|kt_dev_py_0001| py-module

LPY. CHAPTER 22 Modules: The Big Picture

Python module—the highest-level program organization unit, which packages
program code and data for reuse, and provides self contained `namespaces` that
minimize variable name clashes across your programs.

All the names defined at the top level of a module file become `attributes` of
the imported module object. As we saw in the last part of this book, imports
give access to names `in a module's global scope`

The `top-level` (a.k.a. script) file contains the main flow of control of your
program—this is the file you run to launch your application. The module files
are libraries of tools used to collect components used by the top-level file.


How Imports Work

The `imports` are really runtime operations that perform three distinct steps
the first time a program imports a given file:

1. Find the module's file.

Python uses a standard `module search path` and `known file types` to locate the
module file corresponding to an import statement.

2. Compile it to byte code (if needed).

During an import operation Python checks both file modification times and the
byte code's Python version number to decide how to proceed.

In Python 3.2 and later, byte code files are segregated in a __pycache__
subdirectory and named with their Python version to avoid contention and
recompiles when multiple Pythons are installed.

note: ship byte code only
In addition, if Python finds only a byte code file on the search path and no
source, it simply loads the byte code directly; this means you can ship a
program as just byte code files and avoid sending source. 

In other words, the compile step is bypassed if possible to speed program
startup.

Notice that compilation happens when a file is being imported.

note: after all, to speed up.
If Python cannot write a file to save this on your computer for any reason,
your program still runs fine—Python simply creates and uses the byte code in
  memory and discards it on exit. To speed startups, though, it will try to
  save byte code in a file in order to skip the compile step next time around.

3. Run the module's code to build the objects it defines.

This last import step actually runs the file's code.


<module-search-path>
Python look:

1. The home directory of the program (automatic)
2. PYTHONPATH directories (if set)
3. Standard library directories (automatic)
4. The contents of any .pth files (if present)
5. The site-packages home of third-party extensions

<sys-path>
The concatenation of these four components becomes `sys.path`, a mutable list
of directory name strings. You can always inspect the path as Python knows it
by printing the built-in sys.path. The empty string at the front means current
directory

>>> import sys
>>> sys.path
['', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-linux2', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/pymodules/python2.7']


LPY. CHAPTER 23 Module Coding Basics

Module Filenames

Because module names become variable names inside a Python program, they
should also follow the `normal variable name rules`

The chief difference is that import fetches the module as a whole, so you must
qualify to fetch its names; in contrast, from fetches (or copies) specific
names out of the module.

The import Statement identifies an external file to be loaded, and it becomes
a variable in the script. Because it gives a name that refers to the whole
module object, we must go through the module name to fetch its attributes
(e.g., module1.printer).

Imports Happen Only Once

Modules are loaded and run on the first import or from, and only the first.


`import` and from Are Assignments

Just like def, import and from are executable statements, not compile-time
declarations. They may be nested in if tests, to select among options; appear
in function defs, to be loaded only on calls (subject to the preceding note);
be used in try statements, to provide defaults; and so on. They are not
  resolved or run until Python reaches them while executing your program. In
  other words, imported modules and names are not available until their
  associated import or from statements run.

Also, like def, the import and from are `implicit assignments`:
  * import assigns an entire module object to a single name.
  * from assigns one or more names to objects of the same names in another
    module.

Reassigning a copied name has no effect on the module from which it was
copied, but changing a `shared mutable object` through a copied name can also
change it in the module from which it was imported.

<ex>
# small.py
x = 1
y = [1, 2]

% python
>>> from small import x, y      # Copy two names out
>>> x = 42                      # Changes local x only
>>> y[0] = 42                   # Changes shared mutable in place

Here, x is not a shared mutable object, but y is, so changing it from one
place changes it in the other:

>>> import small # Get module name (from doesn't)
>>> small.x # Small's x is not my x
1
>>> small.y # But we share a changed mutable
[42, 2]


There is no link from a name copied with `from` back to the file it came from.
  To really change a global name in another file, you must use import:

% python
>>> from small import x, y      # Copy two names out
>>> x = 42                      # Changes my x only
>>> import small                # Get module name
>>> small.x = 42                # Changes x in other module

Note that the change to y[0] in the prior session is different; it changes an
object, not a name, and the name in both modules references the same, changed
object.

TODO: This phenomenon was introduced in Chapter 17. Scopes


import and from Equivalence

At least conceptually, a from statement like this one:

from module import name1, name2 # Copy these two names out (only)

is equivalent to this statement sequence:

import module                   # Fetch the module object
name1 = module.name1            # Copy names out by assignment
name2 = module.name2
del module                      # Get rid of the module name

Like all assignments, the from statement creates new variables in the
importer, which initially refer to objects of the same names in the imported
file. Only the names are copied out, though, `not the objects they reference`,
  and not the name of the module itself.


Potential Pitfalls of the from Statement

Some Python users recommend using import instead of from most of the time. 

It is true that the from statement has the potential to corrupt namespaces, at
least in principle—if you use it to import variables that happen to have the
same names as existing variables in your scope, your variables will be
silently overwritten. This problem doesn’t occur with the simple import
statement because you must always go through a module’s name to get to its
contents


={============================================================================
|kt_dev_py_0001| py-module-namespace

Technically, modules usually correspond to files, and Python creates a module
object to contain all the names assigned in a module file. But in simple
terms, modules are just `namespaces` (places where names are created), and the
names that live in a module are called its `attributes`.

Files Generate Namespaces

The short answer is that every name that is assigned a value at the top level
of a module file (i.e., not nested in a function or class body) becomes an
attribute of that module.

* Module statements run on the first import. The first time a module is
imported anywhere in a system, Python creates an empty module object and
executes the statements in the module file one after another, from the top of
the file to the bottom.

* Top-level assignments create module attributes. During an import, statements
at the top level of the file not nested in a def or class that assign names
(e.g., =, def) create attributes of the module object; assigned names are
stored in the module’s namespace.

* Module namespaces can be accessed via the attribute__dict__ or dir(M).
Module namespaces created by imports are dictionaries; they may be accessed
through the built-in __dict__ attribute associated with module objects and may
be inspected with the dir function. The dir function is roughly equivalent to
the sorted keys list of an object’s __dict__ attribute, but it includes
inherited names for classes, may not be complete, and is prone to changing
from release to release.

<ex>
# module2.py
print('starting to load...')

import sys
name = 42

def func(): pass
class klass: pass

print('done loading.')


Namespace Dictionaries: __dict__

module namespaces are stored as dictionary objects.

>>> list(module2.__dict__.keys())
['__loader__', 'func', 'klass', '__builtins__', '__doc__', '__file__', '__name__',
'name', '__package__', 'sys', '__initializing__', '__cached__']

Python also adds some names in the module’s namespace for us; for instance,
__file__ gives the name of the file the module was loaded from, and __name__
  gives its name as known to importers (without the .py extension and
      directory path).

>>> list(name for name in module2.__dict__.keys() if not name.startswith('__'))
['func', 'klass', 'name', 'sys']
>>> list(name for name in module2.__dict__ if not name.startswith('__'))
['func', 'sys', 'name', 'klass']

>>> module2.name, module2.__dict__['name']
(42, 42)


Imports Versus Scopes

Scopes are never influenced by function calls or module imports.

# moda.py

X = 88      # My X: global to this file only
def f():
  global X  # Change this file's X
  X = 99    # Cannot see names in other modules

# modb.py

X = 11      # My X: global to this file only
import moda # Gain access to names in moda
moda.f()    # Sets moda.X, not this file's X
print(X, moda.X)

% python modb.py
11 99


Namespace Nesting

imports do nest downward and it is possible to descend into arbitrarily nested
modules and access their attributes.

# mod3.py

X = 3

# mod2.py

X = 2
import mod3
print(X, end=' ')   # My global X
print(mod3.X)       # mod3's X

# mod1.py

X = 1
import mod2
print(X, end=' ')       # My global X
print(mod2.X, end=' ')  # mod2's X
print(mod2.mod3.X)      # Nested mod3's X

% python mod1.py
2 3
1 2 3

The reverse, however, is not true: mod3 cannot see names in mod2, and mod2
cannot see names in mod1.


={============================================================================
|kt_dev_py_0001| py-module-package

LPY. CHAPTER 24 Module Packages

In addition to a module name, an import can name a directory path. A directory
of Python code is said to be a package, so such imports are known as package
imports. In effect, a package import turns a directory on your computer into
another Python namespace, with attributes corresponding to the subdirectories
and module files that the directory contains.

Instead list a path of names separated by periods:

import dir1.dir2.mod

The same goes for from statements:

from dir1.dir2.mod import x

Furthermore, these imports imply that dir1 resides within some container
directory dir0, which is a component of the normal Python module search path.

More formally, the leftmost component in a package import path is still
relative to a directory included in the sys.path module search path list

In effect, entries on the module search path provide platform-specific
directory path prefixes, which lead to the leftmost names in import and from
statements. These import statements themselves provide the remainder of the
directory path in a platform-neutral fashion.


Package __init__.py Files

Each directory named within the path of a package import statement must
contain a file named __init__.py, or your package imports will fail.

for a directory structure such as this:
dir0\dir1\dir2\mod.py

and an import statement of the form:
import dir1.dir2.mod

the following rules apply:

* dir1 and dir2 both must contain an __init__.py file.
 
* dir0, the container, does not require an __init__.py file; this file will
  simply be ignored if present.

* dir0, not dir0\dir1, must be listed on the module search path sys.path.
 
The __init__.py files can contain Python code, just like normal module files.
Their names are special because their code is run automatically the first time
a Python program imports a directory, and thus serves primarily as a hook for
performing initialization steps required by the package. These files can also
be completely empty.

dir0\                       # Container on module search path
  dir1\
      __init__.py
      dir2\
          __init__.py
          mod.py

Once imported, the path in your import statement becomes a nested object path
in your script. Here, mod is an object nested in the object dir2, which in
turn is nested in the object dir1:

>>> dir1
<module 'dir1' from '.\\dir1\\__init__.py'>
>>> dir1.dir2
<module 'dir1.dir2' from '.\\dir1\\dir2\\__init__.py'>
>>> dir1.dir2.mod
<module 'dir1.dir2.mod' from '.\\dir1\\dir2\\mod.py'>


Why Use Package Imports?

They do serve useful roles, though, especially in larger programs: they make
imports more informative, serve as an organizational tool, simplify your
module search path, and can resolve ambiguities.


Package Relative Imports

note: TODO for Python 3.X


={============================================================================
|kt_dev_py_0001| py-module-advanced

LPY. CHAPTER 25 Advanced Module Topics

Data Hiding in Modules

There is no notion of declaring which names should and shouldn't be visible
outside the module. In fact, there's no way to prevent a client from changing
names inside a module if it wants to.  

In Python, data hiding in modules is a convention, not a syntactical
constraint.


Minimizing from * Damage: _X and __all__

a single underscore (e.g., _X) to prevent them from being copied out when a
client imports a module's names with a from * statement.

Underscores aren't "private" declarations: you can still see and change such
names with other import forms, such as the `import` statement:

When this feature is used, the from * statement will copy out only those names
listed in the __all__ list. In effect, this is the converse of the _X
convention: __all__ identifies names to be copied, while _X identifies names
not to be copied.

Python looks for an __all__ list in the module first and copies its names
irrespective of any underscores; if __all__ is not defined, from * copies all
names without a single leading underscore:

# alls.py
__all__ = ['a', '_c']                 # __all__ has precedence over _X
a, b, _c, _d = 1, 2, 3, 4

>>> from alls import *                # Load __all__ names only
>>> a, _c
(1, 3)
>>> b
NameError: name 'b' is not defined

>>> from alls import a, b, _c, _d     # But other importers get every name
>>> a, b, _c, _d
(1, 2, 3, 4)

>>> import alls
>>> alls.a, alls.b, alls._c, alls._d
(1, 2, 3, 4)


Enabling Future Language Features: __future__

Changes to the language that may potentially break existing code are usually
introduced gradually in Python. They often initially appear as optional
extensions, which are disabled by default. To turn on such extensions, use a
special import statement of this form:

from __future__ import featurename

When used in a script, this statement must appear as the first executable
statement in the file (possibly following a docstring or comment), because it
enables special compilation of code on a per-module basis. It’s also possible
to submit this statement at the interactive prompt to experiment with upcoming
language changes; the feature will then be available for the remainder of the
interactive session.


The as Extension for import and from

allow an imported name to be given a different name in your script.

import modulename as name # And use name, not modulename

This works in a from statement, too

from modulename import attrname as name # And use name, not attrname


Example: Modules Are Objects <introspection>

the module's attribute dictionary, exposed in the built-in __dict__ attribute
we met in Chapter 23. Python also exports the list of all loaded modules as
the sys.modules dictionary and provides a built-in called getattr that lets us
fetch attributes from their string names

all the following expressions reach the same attribute and object:

M.name                  # Qualify object by attribute
M.__dict__['name']      # Index namespace dictionary manually
sys.modules['M'].name   # Index loaded-modules table manually
getattr(M, 'name')      # Call built-in fetch function


Statement Order Matters in Top-Level Code

Python executes its statements one by one, from the top of the file to the
bottom.

* Code at the top level of a module file (not nested in a function) runs as
soon as Python reaches it during an import; because of that, it cannot
reference names assigned lower in the file.

* Code inside a function body doesn’t run until the function is called;
because names in a function aren’t resolved until the function actually runs,
        they can usually reference names anywhere in the file.

As a rule of thumb, if you need to mix immediate code with defs, put your defs
at the top of the file and your top-level code at the bottom. That way, your
functions are guaranteed to be defined and assigned by the time Python runs
the code that uses them.


from Copies Names but Doesn’t Link

the from statement is really an assignment to names in the importer's scope—a
name-copy operation, not a name aliasing. The implications of this are the
same as for all assignments in Python

# nested1.py
X = 99
def printer(): print(X)

# nested2.py
from nested1 import X, printer # Copy names out
X = 88 # Changes my "X" only!
printer() # nested1's X is still 99

% python nested2.py
99

If we use import to get the whole module and then assign to a qualified name,
however, we change the name in nested1.py.

# nested3.py
import nested1 # Get module as a whole
nested1.X = 88 # OK: change nested1's X
nested1.printer()

% python nested3.py
88


={============================================================================
|kt_dev_py_0001| py-module-name-test

Mixed Usage Modes: __name__ and __main__

each module has a built-in attribute called __name__, which Python creates and
assigns automatically as follows:

* If the file is being run as a top-level program file, __name__ is set to the
  string "__main__" when it starts.

* If the file is being imported instead, __name__ is set to the module’s name
  as known by its clients.

The upshot is that a module can test its own __name__ to determine whether
it's being run or imported.

In effect, a module’s __name__ variable serves as a `usage mode flag`,
allowing its code to be leveraged as both an importable library and a
  top-level script.

Coding self-test code at the bottom of a file under the __name__ test is
probably the most common and simplest unit-testing protocol in Python.

In addition, the __name__ trick is also commonly used when you’re writing
files that can be used both as command-line utilities and as tool libraries.


<reference>
29.4. __main__ — Top-level script environment

'__main__' is the name of the `scope` in which top-level code executes. A
module's __name__ is set equal to '__main__' when read from standard input, a
script, or from an interactive prompt.

A module can discover whether or not it is running in the `main-scope` by
checking its own __name__, which allows a common idiom for conditionally
executing code in a module when it is run `as-a-script` or with python -m but
not when it is imported:

if __name__ == "__main__":
    # execute only if run as a script
    main()

For a package, the same effect can be achieved by including a __main__.py
module, the contents of which will be executed when the module is run with -m.

<reference>
Python Scripts as a Replacement for Bash Utility Scripts

http://www.linuxjournal.com/content/python-scripts-replacement-bash-utility-scripts?page=0,0

Pros:

Python is a fully featured programming language. Code reuse is simple, because
Python modules easily can be imported and used in any Python script. Scripts
easily can be extended or built upon.

Python has access to an excellent standard library and thousands of third-party
libraries for all sorts of advanced utilities, such as parsers and request
libraries. For instance, Python's standard library includes datetime libraries
that allow you to parse dates into any format that you specify and compare it to
other dates easily. 

<ex>
#!/usr/bin/env python
import sys

if __name__ == "__main__":

    # initialize a names dictionary as empty to start with.
    # each key in this dictionary will be a name and the value will be
    # the number of times that names appears. name-value-pair
    names = {}

    # sys.stdin is a file object. all the same functions that can be
    # applied to a file object can be applied to sys.stdin. 
    for name in sys.stdin.readlines():

        # each line will have a newline on the end that should be
        # removed.
        name = name.strip()

        if name in names:
            names[name] += 1
        else:
            names[name] = 1

    # iterating over the dictionary. print name followed by a space and 
    # the number of times it appeared.
    for name, count in names.iteritems():
        sys.stdout.write("%d\t%s\n" % (count, name))


$ cat names.log | python namescount.py


The standard library of Python provides a CSV reader. The Python script below
completes this goal:


*py-cvs-reader*

#!/usr/bin/env python
# CSV module that comes with the Python standard library
import csv
import sys

if __name__ == "__main__":
    # The CSV module exposes a reader object that takes
    # a file object to read. In this example, sys.stdin.
    csvfile = csv.reader(sys.stdin)

    # The script should take one argument that is a column number.
    # Command-line arguments are accessed via sys.argv list.
    column_number = 0
    if len(sys.argv) > 1:
            column_number = int(sys.argv[1])

    # Each row in the CSV file is a list with each 
    # comma-separated value for that line.
    for row in csvfile:
            print row[column_number]


*py-stmplib*

#!/usr/bin/env python
import smtplib
import sys


GMAIL_SMTP_SERVER = "smtp.gmail.com"
GMAIL_SMTP_PORT = 587

GMAIL_EMAIL = "Your Gmail Email Goes Here"
GMAIL_PASSWORD = "Your Gmail Password Goes Here"


def initialize_smtp_server():
    '''
    This function initializes and greets the smtp server.
    It logs in using the provided credentials and returns 
    the smtp server object as a result.
    '''
    smtpserver = smtplib.SMTP(GMAIL_SMTP_SERVER, GMAIL_SMTP_PORT)
    smtpserver.ehlo()
    smtpserver.starttls()
    smtpserver.ehlo()
    smtpserver.login(GMAIL_EMAIL, GMAIL_PASSWORD)
    return smtpserver


def send_thank_you_mail(email):
    to_email = email
    from_email = GMAIL_EMAIL
    subj = "Thanks for being an active commenter"
    # The header consists of the To and From and Subject lines
    # separated using a newline character
    header = "To:%s\nFrom:%s\nSubject:%s \n" % (to_email,
            from_email, subj)
    # Hard-coded templates are not best practice.
    msg_body = """
    Hi %s,

    Thank you very much for your repeated comments on our service.
    The interaction is much appreciated.

    Thank You.""" % email
    content = header + "\n" + msg_body
    smtpserver = initialize_smtp_server()
    smtpserver.sendmail(from_email, to_email, content)
    smtpserver.close()


if __name__ == "__main__":
    # for every line of input.
    for email in sys.stdin.readlines():
            send_thank_you_mail(email)


*py-optionparser*

Thankfully, Python has a number of modules to deal with command-line arguments.
My personal favorite is OptionParser. OptionParser is part of the optparse
module that is provided by the standard library.

if __name__ == "__main__":
    usage = "usage: %prog [options]"
    parser = OptionParser(usage=usage)
    parser.add_option("--email", dest="email",
            help="email to login to smtp server")
    parser.add_option("--pwd", dest="pwd",
            help="password to login to smtp server")
    parser.add_option("--smtp-server", dest="smtpserver",
            help="smtp server url", default="smtp.gmail.com")
    parser.add_option("--smtp-port", dest="smtpserverport",
            help="smtp server port", default=587)
    options, args = parser.parse_args()

    if not (options.email or options.pwd):
            parser.error("Must provide both an email and a password")

    smtpserver = initialize_smtp_server(options.stmpserver,
            options.smtpserverport, options.email, options.pwd)

    # for every line of input.
    for email in sys.stdin.readlines():
            send_thank_you_mail(email, smtpserver)
    smtpserver.close()


There are a lot of aspects to Python in the shell that go beyond the scope of
  this article, such as the os module and the subprocess module. The os module
  is a standard library function that holds a lot of key operating system-level
  operations, such as listing directories and stating files, along with an
  excellent submodule os.path that deals with normalizing directories paths. The
  subprocess module allows Python programs to run system commands and other
  advanced operations, such as handling piping as described above within Python
  code between spawned processes. Both of these libraries are worth checking out
  if you intend to do any Python shell scripting. 


={============================================================================
|kt_dev_py_0001| py-function

LPY. CHAPTER 16 Function Basics

Functions are declared using the `def` keyword and returned from using the
`return` keyword:

def my_function(x, y, z=1.5):
  if z > 1:
    return z * (x + y)
  else:
    return z / (x + y)

If the end of a function is reached without encountering a return statement,
    `None` is returned.


{functions-are-objects}
The `def` header line specifies a function name that is assigned the function
object, along with a list of zero or more arguments in parentheses.

Since Python functions are objects, many constructs can be easily expressed
that are difficult to do in other languages.

Suppose we were doing some data cleaning and needed to apply a bunch of
transformations to the following list of strings:

>>> states = [' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda', \
  'south carolina##', 'West virginia?']

>>> states
[' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda', 'south carolina##',\
    'West virginia?']

>>> import re
>>> def clean_strings(strings):
...     result=[]
...     for value in strings:
                # these are `str` methods
...             value = value.strip()
...             value = re.sub('[!#?]', '', value)
...             value = value.title()
...             result.append(value)
...     return result
... 

# see address
>>> clean_strings
<function clean_strings at 0xb7509b1c>

>>> clean_strings(states)
['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia']


An alternate approach that you may find useful is to make a list of the
operations you want to apply to a particular set of strings:

>>> def remove_punctuation(value):
...     return re.sub('!?#', '', value)
... 
>>> clean_ops=[str.strip, `remove_punctuation`, str.title]

# see addresses
>>> clean_ops
[<method 'strip' of 'str' objects>, <function remove_punctuation at 0xb750979c>, 
  <method 'title' of 'str' objects>]

>>> def clean_strings_ops(strings, ops):
...     result=[]
...     for value in strings:
...             for function in ops:
...                     value = function(value)
...             result.append(value)
...     return result
... 

>>> states
[' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda', 'south carolina##', 
  'West virginia?']

# WTF? oops since have error in remove_punctuation function.
>>> clean_strings_ops(states, clean_ops)
['Alabama', 'Georgia!', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia?']

# going to work if define it again?
>>> def remove_punctuation(value):
...     return re.sub('[!?#]', '', value)
... 

# still see !? and not working?
>>> clean_strings_ops(states, clean_ops)
['Alabama', 'Georgia!', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia?']

# define clean_ops again and see different address for remove_punctuation
>>> clean_ops
[<method 'strip' of 'str' objects>, <function remove_punctuation at 0xb750979c>, 
  <method 'title' of 'str' objects>]

>>> clean_ops=[str.strip, remove_punctuation, str.title]
>>> clean_ops
[<method 'strip' of 'str' objects>, <function remove_punctuation at 0xb7509e9c>, 
  <method 'title' of 'str' objects>]

>>> clean_strings_ops(states, clean_ops)
['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia']


A more `functional pattern` like this enables you to easily modify how the
strings are transformed at a very high level. The clean_strings function is
also now more reusable!

<map-function>
Use functions as arguments to other functions like the built-in `map
function`, which applies a function to a collection of some kind:

>>> map(remove_punctuation, states)
[' Alabama ', 'Georgia', 'Georgia', 'georgia', 'FlOrIda', 
  'south carolina', 'West virginia']


={============================================================================
|kt_dev_py_0001| py-function-polymorphism

<dynamic-typing>

>>> def times(x, y):  # Create and assign function
...   return x * y    # Body executed when called

>>> times(2, 4) # Arguments in parentheses
8

>>> x = times(3.14, 4) # Save the result object
>>> x
12.56

>>> times('Ni', 4) # Functions are "typeless"
'NiNiNiNi'

The very meaning of the expression x * y in our simple times function depends
completely upon the kinds of `objects` that x and y are - thus, the same
function can perform multiplication in one instance and repetition in another.
Python leaves it up to the objects to do something reasonable for the syntax.

def intersect(seq1, seq2):
  res = []            # Start empty
  for x in seq1:      # Scan seq1
    if x in seq2:     # Common item?
    res.append(x)     # Add to end
  return res

it works on arbitrary types, `as long as` they support the expected object
interface:

>>> x = intersect([1, 2, 3], (1, 4)) # Mixed types
>>> x # Saved result object
[1]

Means that the first argument has to support the for loop, and the second has
to support the in membership test.

<not-care-about-type>
If the objects passed in do not support this expected interface, Python will
detect the error when the * expression is run and raise an exception
automatically. It's therefore usually pointless to code error checking
ourselves. In fact, doing so would limit our function's utility, as it would
be restricted to work only on objects whose types we test for.

This turns out to be a crucial philosophical difference between Python and
statically typed languages like C++ and Java: in Python, your code is not
supposed to care about specific data types. If it does, it will be limited to
working on just the types you anticipated when you wrote it, and it will not
support other compatible object types that may be coded in the future.
Although it is possible to test for types with tools like the type built-in
function, doing so breaks your code's flexibility. By and large, we code to
object `interfaces` in Python, not data types.

This polymorphic model of programming means we have to test our code to detect
errors, rather than providing type declarations a compiler can use to detect
some types of errors for us ahead of time. 

In exchange for an initial bit of testing, though, we radically reduce the
amount of code we have to write and radically increase our code's flexibility.
As you'll learn, it's a net win in practice.


={============================================================================
|kt_dev_py_0001| py-function-scope

LPY. CHAPTER 17 Scopes

The term `scope` refers to a namespace: that is, the location of a name's
`assignment` in your source code determines the scope of the name's visibility
to your code. 

<namespace>
Functions can access variables in two different scopes: global and local. An
alternate and more descriptive name describing a variable scope in Python is a
namespace.

As names in Python spring into existence when they are first assigned values,
and Python uses the location of the assignment of a name to associate it with
  a particular namespace. In other words, the place where you assign a name in
  your source code determines the namespace it will live in, and hence its
  scope of visibility.

all names assigned inside a function are associated with that function's
namespace


<local-nonlocal-global>
If a variable is assigned inside a def, it is local to that function.

If a variable is assigned in an enclosing def, it is nonlocal to nested
functions.

If a variable is assigned outside all defs, it is global to the entire file.

The global scope spans a single file only. 
Don't be fooled by the word "global" herenames at the top level of a file are
global to code within that single file only. There is really no notion of a
single, all-encompassing global file-based scope in Python. Instead, names are
partitioned into modules, and you must always import a module explicitly if
you want to be able to use the names its file defines. When you hear "global"
in Python, think "module."


Name Resolution: The LEGB Rule

Name references search at most four scopes: local, then enclosing functions
(if any), then global, then built-in.

E - the scopes of enclosing defs or lambdas - 
can technically correspond to more than one lookup level. This case only comes
into play when you nest functions within functions, and is enhanced by the
nonlocal statement in 3.X.

note:
so E matters for lambda since not see 3.X now.

TODO: more on lambda and closure

{lambda}
Anonymous or lambda functions, which are really just simple functions
consisting of a single statement, the result of which is the return value.
They are defined using the `lambda keyword`

They are especially convenient in data analysis because, as you'll see, there
are many cases where data transformation functions will take functions as
arguments. It's often less typing (and clearer) to pass a lambda function as
opposed to writing a full-out function declaration or even assigning the
lambda function to a local variable. For example, consider this silly example:

>>> def apply_to_list(some_list, f):
...     return [f(x) for x in some_list]
... 

>>> ints = [4,0,1,5,6]
>>> apply_to_list(ints, lambda x: x*2)
[8, 0, 2, 10, 12]

You could also have written [x * 2 for x in ints], but here we were able to
succintly pass a custom operator to the apply_to_list function.


{closures}
In a nutshell, a closure is any `dynamically-generated function` returned by
another function. The key property is that the returned function has access to
the variables in the local namespace where it was created. Here is a very
simple example:

>>> def make_closure(a):
...     def closure():
...             print('I know the secret: %d' % a)
...     return closure
... 

>>> closure = make_closure(5)
>>> closure
<function closure at 0xb75125dc>
>>> closure()
I know the secret: 5
>>> closure()
I know the secret: 5


The difference between a closure and a regular Python function is that the
closure continues to have access to the namespace (the function) where it was
created, even though that function is done executing. So in the above case,
  the returned closure will always print "I know the secret: 5" whenever you
  call it. 

While it's common to create closures whose internal state (in this example,
    only the `value` of a) is `static`, you can just as easily have a
`mutable` object like a dict, set, or list that can be modified. For example,
  here's a function that returns a function that keeps track of arguments it
  has been called with:

def make_watcher():
  have_seen = {}

  def has_been_seen(x):
    if x in have_seen:
      return True
    else:
      have_seen[x] = True
      return False
  return has_been_seen

Using this on a sequence of integers I obtain:

In [496]: watcher = make_watcher()
In [497]: vals = [5, 6, 1, 5, 1, 6, 3, 5]
In [498]: [watcher(x) for x in vals]
Out[498]: [False, False, False, True, True, True, False, True]

one technical limitation to keep in mind is that while you can mutate any
internal state objects (like adding key-value pairs to a dict), you cannot
bind variables in the enclosing function scope. One way to work around this is
to modify a dict or list rather than binding variables:

>>> def make_counter():
...     count = [0]
...     def counter():
...             count[0] +=1
...             return count[0]
...     return counter
... 
>>> cnt = make_counter()
>>> cnt
<function counter at 0xb7512684>
>>> cnt()
1
>>> cnt()
2

>>> def make_counter_two():
...     count = 0
...     def counter():
...             count +=1
...             return count
...     return counter
... 
>>> cnt_two = make_counter_two()
>>> cnt_two
<function counter at 0xb75126f4>
>>> cnt_two()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 4, in counter
UnboundLocalError: local variable 'count' referenced before assignment


Why this is useful? In practice, you can write very `general functions` with
lots of options, then fabricate simpler, more specialized functions. Here's an
example of creating a string formatting function:


Here's an example of creating a string formatting function:

def format_and_pad(template, space):
  def formatter(x):
    return (template % x).rjust(space)
  return formatter

You could then create a floating point formatter that always returns a
length-15 string like so:

In [500]: fmt = format_and_pad('%.4f', 15)
In [501]: fmt(1.756)
Out[501]: ' 1.7560'

If you learn more about object-oriented programming in Python, you might
observe that these patterns also could be implemented (albeit more verbosely)
  using classes.


={============================================================================
|kt_dev_py_0001| py-function-arguments

LPY. CHAPTER 18 Arguments

{return-multiple-values}
What's happening here is that the function is actually just returning `one`
object, namely a tuple, which is then being unpacked into the result
variables.

>>> def f():
...     a=5
...     b=6
...     c=7
...     return a,b,c
... 

>>> a,b,c = f()
>>> a
5
>>> b
6
>>> c
7


{argument-matching}

Argument Matching Basics

By default, arguments are matched by position, from left to right, and you
must pass exactly as many arguments as there are argument names in the
function header. However, you can also specify matching by name, provide
default values, and use collectors for extra arguments.


Positionals: matched from left to right
The normal case, which we’ve mostly been using so far, is to match passed
argument values to argument names in a function header by position, from left
to right.

Keywords: matched by argument name
Alternatively, callers can specify which argument in the function is to
receive a value by using the argument’s name in the call, with the name=value
syntax.

Defaults: specify values for optional arguments that aren’t passed
Functions themselves can specify default values for arguments to receive if
the call passes too few values, again using the name=value syntax.

TODO: more for the rest such as Varargs collecting

func(value)           Caller Normal argument: matched by position
func(name=value)      Caller Keyword argument: matched by name

def func(name)        Function Normal argument: matches any passed value 
                      by position or name
def func(name=value)  Function Default argument value, if not passed in the call

In a function call, simple values are matched by position, but using the
name=value form to match by name to arguments instead; these are called
`keyword arguments`

In a function header, a simple name is matched by position or name depending
on how the caller passes it, but the name=value specifies a `default value`

<restriction>
In a function call, any positional arguments (value); followed by a
combination of any keyword arguments (name=value)

In a function header, arguments must appear in this order: any normal
arguments (name); followed by any default arguments (name=value)


={============================================================================
|kt_dev_py_0001| py-function-

LPY. CHAPTER 19 Advanced Function Topics


={============================================================================
|kt_dev_py_0001| py-class


<class-variable>
Class variable: A variable that is shared by all instances of a class. Class
variables are defined within a class but outside any of the class's methods.
Class variables are not used as frequently as instance variables are. 

Instance variable: A variable that is defined inside a method and belongs only
to the current instance of a class. 

class Employee:
   'Common base class for all employees'
   empCount = 0

   def __init__(self, name, salary):
      self.name = name
      self.salary = salary
      Employee.empCount += 1

empCount is a `class variable` whose value is shared among all instances of a
  this class. This can be accessed as Employee.empCount from inside the class
  or outside the class.


To create instance:

"This would create first object of Employee class"
emp1 = Employee("Zara", 2000)
"This would create second object of Employee class"
emp2 = Employee("Manni", 5000)


To access attribute:

emp1.displayEmployee()
emp2.displayEmployee()
print "Total Employee %d" % Employee.empCount


<when-create-instance-variable>
Created when used so use `__init__` to create variables used by methods. 

note: different from C++.

class HousePark:
    def setname(self, name):
        self.fullname = name

    def setlastname(self, name):
        self.lastname = name

    def printname(self):
        # @65
        print "last %s, full %s" % (self.lastname, self.fullname)

pey = HousePark()
pey.setname(" kit")
pey.printname()

Traceback (most recent call last):
  File "./class-05.py", line 70, in <module>
    pey.printname()
  File "./class-05.py", line 65, in printname
    print "last %s, full %s" % (self.lastname, self.fullname)
AttributeError: HousePark instance has no attribute 'lastname'


<scope>

class HousePark:
    lastname = "park"

    def setname(self, name):
        # has no effect
        # lastname = "LEE"
        self.fullname = self.lastname + name

    def setlastname(self, name):
        self.lastname = name

    def printname(self):
        print "last %s, full %s" % (self.lastname, self.fullname)

pey = HousePark()
pey.setlastname("LEE")
pey.setname(" kit")
pey.printname()

print HousePark.lastname

pey2 = HousePark()
pey2.setname(" kj")
pey2.printname()


last LEE, full LEE kit    # use local variable
park                      # class variable do not change
last park, full park kj   # use class variable


pey = HousePark()
pey.setlastname("LEE")
pey.setname(" kit")
pey.printname()

print HousePark.lastname

pey2 = HousePark()
pey2.setlastname("JUNG")
pey2.setname(" kj")
pey2.printname()

last LEE, full LEE kit
park
last JUNG, full JUNG kj     # shows that instance has own local


How to use `class variable`?

    def setname(self, name):
        self.fullname = HousePark.lastname + name

    def setlastname(self, name):
        HousePark.lastname = name


<built-in-attributes>
Can be accessed using dot operator like any other attribute.


{dtor}
Python's garbage collector runs during program execution and is triggered when
an object's reference count reaches zero. An object's reference count changes
as the number of aliases that point to it changes.


<ex>
Are these `local` to this method? No since these are `instance variable` 

class X:

    def getTagCode (self, branch, tag=None):

        retVal = False
        FOLDER = "Ethan"

        # ...

        return retVal, FOLDER

<global>
#!/usr/bin/env python

CL_STATUS_OK = 0
CL_STATUS_ERROR = 1

if __name__ == "__main__":
    pass

Use

import scripts.common.cmdLine as cmdLine

def func (branch, tag, dir):
    retVal = cmdLine.CL_STATUS_ERROR


<staticmethod>
https://docs.python.org/2/library/functions.html#staticmethod

staticmethod(function)

    Return a static method for function.

    A static method does not receive an `implicit first argument` 
    
    To declare a static method, use this idiom:

    class C(object):
        @staticmethod
        def f(arg1, arg2, ...):
            ...

    The @staticmethod form is a `function decorator` see the description of
      function definitions in Function definitions for details.

    It can be called either on the class (such as C.f()) or on an instance
    (such as C().f()). The instance is ignored except for its class.

    Static methods in Python are similar to those found in Java or C++. Also
    see classmethod() for a variant that is useful for creating alternate
    class constructors.

    For more information on static methods, consult the documentation on the
    standard type hierarchy in The standard type hierarchy.

    New in version 2.2.

    Changed in version 2.4: Function decorator syntax added.


{inheritance}
`overriding` when `name` is the same.

note: different from C++ where `name` and `params` should be the same.

class HousePark:
    def __init__(self, name):
        self.fullname = self.lastname + name
    def travel(self, where):
        print("%s, %s...." % (self.fullname, where))

class HouseKim(HousePark):
    def travel(self, where, day):
        print("%s, %s...." % (self.fullname, where, day))


={============================================================================
|kt_dev_py_0001| py-exception

{with-as-context}
Python 2.6 and 3.0 introduced a new exception-related statementthe with, and
its optional as clause. This statement is designed to work with context
manager objects, which support a new method-based protocol,

In short, the with/as statement is designed to be an `alternative` to a common
`try/ finally` usage idiom; like that statement, with is in large part
intended for specifying termination-time or "cleanup" activities that must run
`regardless of whether an exception occurs` during a processing step.

Unlike try/finally, the with statement is based upon an object `protocol` for
specifying actions to be run around a block of code. This makes `with` less
general, qualifies it as redundant in termination roles, and requires coding
classes for objects that do not support its protocol. 

On the other hand, `with` also handles entry actions, can reduce code size,
   and allows code contexts to be managed with full OOP.

Python enhances some built-in tools with context managers, such as files that
automatically close themselves and thread locks that automatically lock and
unlock, but programmers can code context managers of their own with classes,
  too.


with expression [as variable]:
  with-block

The `expression` here is assumed to return an object that supports the context
management protocol (more on this protocol in a moment). This object may also
return a value that will be assigned to the name `variable` if the optional as
clause is present.

Note that the variable is not necessarily assigned the result of the
expression; the result of the expression is the object that supports the
context protocol, and the variable may be assigned something else intended to
be used inside the statement. The object returned by the expression may then
run startup code before the with-block is started, as well as termination code
after the block is done, regardless of whether the block raised an exception
or not.

file objects have a context manager that automatically closes the file after
the `with block` regardless of whether an exception is raised, and regardless of
if or when the version of Python running the code may close automatically:

with open(r'C:\misc\data') as myfile:
  for line in myfile:
    print(line)
      ...more code here...

Here, the call to open returns a simple file object that is assigned to the
name myfile. We can use myfile with the usual file tools - in this case, the
file iterator reads line by line in the for loop.

Guarantees that the file object referenced by myfile is automatically closed,
           even if the for loop raised an exception while processing the file.

The with statement in this role is an alternative that allows us to be sure
that the close will occur after execution of a specific block of code.

As we saw earlier, we can achieve a similar effect with the more general and
explicit try/finally statement, but it requires three more lines of
administrative code in this case (four instead of just one):

myfile = open(r'C:\misc\data')
try:
  for line in myfile:
    print(line)
    ...more code here...
finally:
  myfile.close()


={============================================================================
|kt_dev_py_0001| py-re



==============================================================================
Copyrightobjdump see |ktkb|                        vim:tw=100:ts=3:ft=help:norl:
