*kt_dev_02*                                                           tw=100, utf-8


/^[#=]{
Use #{ for a group and ={ for a item

#{ dev questions
#{ test framework

#{ dev questions
*kt_dev_quiz_001* code-sites
|kt_dev_quiz_001| bits: how to swap two vars without using a temp {xor-swap-algorithm}
|kt_dev_quiz_002| bits: how to find a item in array that appear an odd number of times.
|kt_dev_quiz_003| array and string: how to determine if a string has all unique characters. 
|kt_dev_quiz_004| array and string: reverse a string {two-pointers}
|kt_dev_quiz_005| array and string: reverse a string without duplicates
|kt_dev_quiz_006| array and string: to check if it's anagram of the other. {anagram}
|kt_dev_quiz_007| algo-find-unique-byte
|kt_dev_quiz_008| 
|kt_dev_quiz_009| i = i+j means? (from me)
|kt_dev_quiz_010| intersects between rectangles (interview)
|kt_dev_quiz_011| find a path in a maze {freopen}
|kt_dev_quiz_012| get msb position
|kt_dev_quiz_013| get the longest sequence (interview) {the-longest-increasing-sequence}
|kt_dev_quiz_014| code review task
|kt_dev_quiz_015| sorting and searching questions from {ref-004}
|kt_dev_quiz_016| cycle detection {tortoise-and-hare}
|kt_dev_quiz_017| power of two (interview)
|kt_dev_quiz_018| linked list questions from {ref-004} {runner-technique} {tortoise-and-hare}
|kt_dev_quiz_019| array and string questions from {ref-004}
|kt_dev_quiz_020| coding task
|kt_dev_quiz_021| BB questions

#{ PROBLEM SLOVING
|kt_dev_quiz_100| codility: equilibrium index of a sequence
|kt_dev_quiz_101| codility: TapeEquilibrium 
|kt_dev_quiz_102| codility: absolute distinct count of this array
|kt_dev_quiz_103| codility: how much water between walls? {two-pointers}
|kt_dev_quiz_104| codility: frog jump
|kt_dev_quiz_105| codility: find missing element. PermMissingElem
|kt_dev_quiz_106| codility: PermCheck
|kt_dev_quiz_107| codility: frog river
|kt_dev_quiz_108| codility: missing integer counters
|kt_dev_quiz_109| codility: max counters
|kt_dev_quiz_110| codility: passing cars
|kt_dev_quiz_111| codility: count div
|kt_dev_quiz_112| codility: number of identical pairs

#{ TRAIN
|kt_dev_quiz_200| codility: train: lesson 01: time complexity
|kt_dev_quiz_201| codility: train: lesson 02: counting elements
|kt_dev_quiz_300| problems: repairman

#{ algorithm
|kt_dev_algo_000| sentinel
|kt_dev_algo_001| stack {bracket-matching}
|kt_dev_algo_002| simple list {abstract-data-type} <list-find-end-idiom> <list-walk-along-idiom>
|kt_dev_algo_003| list {contiguous-vs-linked} {list-contiguous-and-linked}
|kt_dev_algo_004| queue {queue-circular-array}
|kt_dev_algo_005| array: index shift
|kt_dev_algo_006| the game of life
|kt_dev_algo_007| recursion
|kt_dev_algo_008| binary search {big-o-notation}
|kt_dev_algo_009| sort {mergesort} {quicksort} {find-middle-in-a-linked-list}
|kt_dev_algo_010| table and hash {radixsort}
|kt_dev_algo_011| binary tree {binary-search-tree} {treesort}
|kt_dev_algo_012| avl tree
|kt_dev_algo_013| multiway tree {b-tree} {red-black-tree}
|kt_dev_algo_050| comparison of methods

#{ CASES
|kt_dev_algo_100| dobble linked list 

#{ DISCUSSION
|kt_dev_algo_300| C++ map insertion and lookup performance and storage overhead

#{ GLIBC
|kt_dev_glib_000| glib sites
|kt_dev_glib_001| atoi, htoi {getchar}
|kt_dev_glib_002| atof 
|kt_dev_glib_003| itoa
|kt_dev_glib_004| printf
|kt_dev_glib_005| qsort
|kt_dev_glib_006| tail-program
|kt_dev_glib_007| fopen
|kt_dev_glib_008| isdigit
|kt_dev_glib_010| abs
|kt_dev_glib_101| general tips

|kt_dev_glib_200| strcpy and strncpy
|kt_dev_glib_201| strlen
|kt_dev_glib_202| strcat
|kt_dev_glib_203| strstr, strindex
|kt_dev_glib_204| strcmp
|kt_dev_glib_205| strpbrk, strtok
|kt_dev_glib_206| strdup
|kt_dev_glib_207| strchr and basename

|kt_dev_glib_300| malloc


#{ test framework
|kt_dev_test_001| gtest
|kt_dev_test_002| gtest: intro
|kt_dev_test_003| gtest: own example

|kt_dev_test_100| cppunit
|kt_dev_test_101| cppunit: cookbook
|kt_dev_test_102| cppunit: simple
|kt_dev_test_103| cppunit: macros
|kt_dev_test_104| cppunit: example
|kt_dev_test_105| cppunit: with gmock example
|kt_dev_test_106| cppunit: display test name when run
|kt_dev_test_107| cppunit: inject dependency to object under test
*kt_dev_test_108* cppunit: test runner command line options

|kt_dev_test_200| gmock:
|kt_dev_test_201| gmock-for-dummies
*kt_dev_test_201* gmock-sequence
|kt_dev_test_202| gmock: example
|kt_dev_test_203| gmock: cook: write action
|kt_dev_test_204| gmock: cheat: cardinality
|kt_dev_test_205| gmock: cheat: using a function as action
|kt_dev_test_206| gmock: cheat: combine actions
|kt_dev_test_207| gmock: cook: nice and strict mock
*kt_dev_test_208* gmock-errors when misses expectation
*kt_dev_test_208* gmock: case example


# ============================================================================
#{ dev questions
={============================================================================
*kt_dev_quiz_001* code-sites

https://leetcode.com
https://www.hackerrank.com


={============================================================================
*kt_dev_quiz_001* bits: how to swap two vars without using a temp

It's the standard a=a+b, b=a-b, a=a-b problem. We hired the guy who said, well, "if they're
integers, then I'd do it by a=a|b, b=a^b, a=a^b. But I don't know how to do it if they're strings."

logical OR is + and XOR is -. why? THIS IS WRONG!.

From Cracking the coding interview, p430,

| -- | ------ | ----
     a        b 

a=a+b, b=a-b, a=a-b

void swap_ari( int& first, int& second )     // basic
{
  first  = first + second;
  second = first - second; // first org
  first  = first - second; // second
}

void swap_ari_two( int& first, int& second )
{
  first  = first - second; // diff
  second = first + second; // first
  first  = second - first; // second
}

void swap_bit( int& first, int& second )
{
  first  = first | second;
  second = first ^ second; // first org
  first  = first ^ second; // second
}

void swap_bit_two( int& first, int& second ) // xor
{
  first  = first ^ second;
  second = first ^ second; // first org
  first  = first ^ second; // second
}

int _tmain(int argc, _TCHAR* argv[])
{
  int a =  9, b = 4;

  swap_ari( a , b );
  cout << "a = " << a << ", b= " << b << endl;

  a = 9; b = 4;

  swap_ari_two( a , b );
  cout << "a = " << a << ", b= " << b << endl;

  a = 9; b = 4;

  swap_bit( a , b );
  cout << "a = " << a << ", b= " << b << endl;

  a = 9; b = 4;

  swap_bit_two( a , b );
  cout << "a = " << a << ", b= " << b << endl;
  return 0;
}

<key> swap_bit_two uses <xor-swap-algorithm> xor has these important properties: 
X XOR  X  = 0
X XOR  0  = X
X XOR  1  = ~X    // X XOR (~0) = ~X
X XOR ~X  = 1
      ^^    ^^    note that these can be exchanged to remember

00000000000000000000111111000000 // x
00000000000000000000111111000000 // x^0
11111111111111111111000000111111 // x^(~0) but not x^1

x = 1010; y = 0011;           # before

x =  1001 =  1010  ^ 0011     # x = x^y
y =  1010 = [1001] ^ 0011     # y = x^y # y = (x^y)^y = (x^0) # get x
x = [0011] =  1001 ^ [1010]   # x = x^y # x = (x^y)^x = (y^0) # get y

x = 0011; y = 1010;           # after

The algorithm typically corresponds to three machine code instructions.

Pseudocode     IBM System/370    x86 assembly
X := X XOR Y   XR    R1,R2       xor      eax, ebx
Y := X XOR Y   XR    R2,R1       xor      ebx, eax
X := X XOR Y   XR    R1,R2       xor      eax, ebx

In the above System/370 assembly code sample, R1 and R2 are distinct registers, and each XR
operation leaves its result in the register named in the first argument. Using x86 assembly, values
X and Y are in registers eax and ebx (respectively), and xor places the result of the operation in
the first register.


={============================================================================
*kt_dev_quiz_002* bits: how to find a item in array that appear an odd number of times

Amazon phone interview question. 02/05/2013

// You are going to be passed as input an array with an interesting property: the array contains
// non-negative numbers that appear an even number of times throughout the array, save one, that
// appears an odd number of times.
//
// Your code should accept the array as input and return the number that appears an odd number of
// times as output.
//
// [1, 3, 1]   // returns 3
// [2, 4, 6, 8, 10, 12, 10, 8, 6, 4, 12, 12, 4, 2, 4]    // returns 12
// [1, 0, 1, 0, 1, 4, 4, 0, 3, 7, 0, 3, 7]    // returns 1

[1, 3, 1]
0001, 0011, 0001
0001 ^ 0011 ^ 0001
(0001 ^ 0001) ^ 0011 = 0000 ^ 0011 = 0011 (3)

<key>
This uses two xor properties and uses that xor is transitive.

00 0      Y xor Y = 0  (2 times)
01 1      0 xor Y = Y  (3 times)
10 1      Y xor Y = 0  (4 times)
11 0      0 xor Y = Y  (5 times)

If do xor even times, becomes 0.

{use-xor}
{
  int result = 0;

  for( auto element : int_arr )
    result ^= element;

  cout << "result is " << result << endl;
}

{use-stl}
{
  int int_arr[] = {2, 4, 6, 8, 10, 12, 10, 8, 6, 4, 12, 12, 4, 2, 4};
  multiset<int> mset( begin(int_arr), end(int_arr));

  for( auto element : mset )
  {
    if( mset.count(element) % 2 )
      cout << element << " has " << mset.count(element) << " occurance" << endl;
  }
}

// problem codes using stl
int find_odd_stl(int* arr, int size)
{
  std::multiset<int> mset( begin(arr), end(arr) ); // {sizeof-problem}

  std::multiset< int>::const_iterator cit = mset.cbegin();

  while( cit != mset.cend() )
  {
    if( mset.count( *cit )%2 )
      return *cit;

    ++cit;
  }
}


={============================================================================
*kt_dev_quiz_003* array and string: how to determine if a string has all unique characters.

From Cracking the coding interview, p172,

Q. Implement an algorithm to determine if a string has all unique characters. What if you cannot use
additional data structures?

note: 
<1> Questions to ask for clarity. ASCII or UNICODE? Assume ASCII. If it's alphabet then it reduce
space to require so clarify specification.

<2> One simple optimization. return false if the length of input string is greater than the number
of uniques chars in the set; ASCII.


{code-c}
// false when there are multi chars
bool does_have_unique(char* str)
{
  if(!str)
    return false;

  bool bset[256] = {false};

  while(*str)
  {
    if(bset[*str])
      return false;
    else
      bset[*str] = true;

    ++str;
  }

  return true;
}


{code-cpp}
#include <iostream>
#include <string>

using namespace std;

// time O(n) and space O(1)

bool isUniqueCharSet( string &s )
{
  int sizeString = s.size();

  // ASCII is 256
  if( sizeString > 256 ) return false;

  bool bitset[256] = {false};

  for(int i = 0; i < sizeString; ++i )
  {
    // already found
    if( bitset[ s[i] ] ) 
      return false;
    else
      bitset[charValue] = true;
  }

  return true;
}


{code} when string uses 'only' the lower case alphabet. int has 32 bits and save space.
bool isUniqueCharSet( string &s )
{
  int sizeString = s.size();

  if( sizeString > 26 ) return false;

  int bitset = 0;

  for(int i = 0; i < sizeString; ++i )
  {
    int charValue = s[i] - 'a';

    // already found
    if( bitset & (1 << charValue) )
      return false;
    else
      bitset |= ( 1 << charValue);
  }

  return true;
}

int main()
{
  string input1 = "abcdefghijklmnopqa";
  string input2 = "abcdefghijklmnopqr";

  cout << "input1 is " << isUniqueCharSet( input1 ) << endl;
  cout << "input2 is " << isUniqueCharSet( input2 ) << endl;

  return 0;
}

Alternatively, can use STL multiset and count(). but not better than above in time and space. 


={============================================================================
*kt_dev_quiz_004* array and string: reverse a string

From Cracking the coding interview, p173,

Q. implement a function void reverse(char* str) in C/C++ which reverse a null-terminated string.

2014.02. approach was that loops an array to get a size, alloc and copy input and copy one by one
from the end of copied array while end ptr of copied input > start ptr of input array. Same time but
more space that c-version.

<c-version> if use c only and no additional memory
#include <iostream>
#include <string>

using namespace std;

void reverse_c(char* str)
{
  if(!str) return;

  char* end = str;
  char temp = 0;

  // find end of the string. 'end' points null char
  while(*end)
    ++end;

  // <wrong> since needs two set two char back since 'end' points next char after null char
  // char str[] = "hello";
  // (gdb) p str 
  // $1 = "hello"
  // (gdb) p /x str // before reverse
  // $2 = {0x68, 0x65, 0x6c, 0x6c, 0x6f, 0x0}
  // (gdb) p /x str // after reverse
  // $3 = {0x0, 0x6f, 0x6c, 0x6c, 0x65, 0x68}
  // while(*end++)
  //   ;

  // not work when empty string input
  // while(*++end)
  //   ;

  // [DN] set one char back, since last char is null and will cover when str has one length
  // a b c \0
  // 0 1 2 3 
  --end;

  // [DN] swap chars from the start of string with the end of the string, until the pointers meet in
  // the middle note: str < end
  while(str < end)
  {
    temp = *str;
    *str++ = *end; // [DN] 
    *end-- = temp;
  }
}

<example> ansic, p62
void reverse(char s[])
{
  int c, i, j;

  for( i = 0, j = strlen(s)-1; i < j; i++, j-- )
    c = s[i], s[i] = s[j], s[j] = c;
}

<exercise>
The ansic, page 64, exercise 4-13. Write a recursive version of the function reverse(s) , which
reverses the string s in place.

// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_4:Exercise_13
// A shorter cat 0 solution by Sander Goos 
// like this since uses the system stack by recursive calls.
void reverse_one(char s[])
{
  static int i = 0, n;
  int c = s[i];

  if (c) {
    i++;
    reverse_one(s);
    s[n-i] = c;
    i--;
  } else {
    n = i;
  }
}

#include <iostream>
#include <cstring>

using namespace std;

void rreverse( char s[] )
{
  int static count = 0, depth = 0;
  char c = s[count];

  if( c != '\0')
  {
    count++;
    rreverse( s );
    s[depth-count] = c;
    count--;
  }
  else
    depth = count;
}

void reverse(char s[])
{
  int c, i, j;

  for( i = 0, j = strlen(s)-1; i < j; i++, j-- )
    c = s[i], s[i] = s[j], s[j] = c;
}

int main(int argc, char* argv[])
{
  {
    printf("-----------------\n");

    char tests[][20] = { "Hello world!", "abcd", "abc", "ab", "a", "" };
    int i;

    for (i = 0; i < 6; i++) {
      printf("%d: %20s ==> ", i, tests[i] );
      reverse(tests[i]);
      printf("%20s \n", tests[i] );
    }
  }

  {
    printf("-----------------\n");

    char tests[][20] = { "Hello world!", "abcd", "abc", "ab", "a", "" };
    int i;

    for (i = 0; i < 6; i++) {
      printf("%d: %20s ==> ", i, tests[i] );
      rreverse(tests[i]);
      printf("%20s \n", tests[i] );
    }
  }

  return 0;
} 


void reverse_one(char s[])
{
  static int i = 0, n;
  int c = s[i];

  if (c) {
    i++;
    printf("> i : %d, n : %d, c: %c\n", i, n, c );
    reverse_one(s);
    printf("< i : %d, n : %d, c: %c\n", i, n, c );
    s[n-i] = c;
    i--;
  } else {
    n = i;
    printf("= i : %d, n : %d, c: %c\n", i, n, c );
  }
}

> i : 1, n : 0, c: H
> i : 2, n : 0, c: e
> i : 3, n : 0, c: l
> i : 4, n : 0, c: l
> i : 5, n : 0, c: o
= i : 5, n : 5, c: 
< i : 5, n : 5, c: o
< i : 4, n : 5, c: l
< i : 3, n : 5, c: l
< i : 2, n : 5, c: e
< i : 1, n : 5, c: H

0  1  2  3  4  5
H  E  L  L  O  0
{  }                    // save c and call
   {  }
      {  }
         {  }
            {  }
            0
         1
      2
   3
4

<key>
1. Use static since there is one argument and use static to keep values between recursive calls.
2. Use system stack to save each char and which is the 'previous' char before increasing index.
3. Use no special check or handling on termination since it ends when recursive chain ends.


<cpp-version> if use arg as a output
void reverse_cpp(char* str)
{
  if(!str) return;

  char *end = nullptr;

  std::string istr(str);
  std::string rstr( istr.rbegin(), istr.rend());

  // {Q} really need const_cast? Yes see {string-and-c-str} in *kt_dev_01* Otherwise, got an error:
  // error: invalid conversion from ‘const char*’ to ‘char*’ [-fpermissive]
  end = const_cast<char*> (rstr.c_str()); 

  while(*end)
  {
    *str++ = *end++;
  }
}

<cpp-version> if returns a string
string reverse_cpp_two(char* str)
{
  if(!str) return string();
  string istr(str);

  // {sizeof-problem} note: the below causes error as with sizeof operator problem in called function.
  // return string( begin(str), end(str) );

  return string( istr.crbegin(), istr.crend() );   # return temp(unnamed) string object
}

int _tmain(int argc, _TCHAR* argv[])
{
  char arr[] = "KYOUNG TAEK PARK";

  cout << "before: " << arr << endl;
  reverse_c(arr);
  cout << "after : " << arr << endl;
  cout << "---------" << endl;

  cout << "before: " << arr << endl;
  reverse_cpp(arr);
  cout << "after : " << arr << endl;
  cout << "---------" << endl;

  cout << "before: " << arr << endl;
  cout << "after : " << reverse_cpp_two(arr) << endl;

  return 0;
}

All cpp versions use additional memory which is string so c version is better choice.


={============================================================================
*kt_dev_quiz_005* array and string: reverse a string without duplicates

From the internet

Write a program to reverse a string with all its duplicates removed. Only the last instance of a
character in the reverse string has to appear. Also, the following conditions are to be satisfied:
Assume only Capital Letters.

Minimum Time, Minimum Space, Minimum Lines of Code

string reverse(string instr);

before: JTVAKAVISHAAAL
inter : JTVAKISHL
after : LHSIKAVTJ


#include <iostream>
#include <string>

using namespace std;

string reverse(string instr)
{
  if(instr.empty()) return string();

  string outstr = "";
  int input_size = instr.size();
  int bitset = 0, value = 0;

  for( int index=0; index < input_size; ++index)
  {
    value = instr[index] - 'A';

    // seen first.
    // Note: only count the first occurance as it will be the last in the
    // reverse.
    if( !(bitset & (1<<value)) )
    {
      //outstr.append( 1, instr[index] );
      outstr += instr[index];
      bitset |= (1<<value);
    }
  }

  return string( outstr.rbegin(), outstr.rend());
}

int _tmain(int argc, _TCHAR* argv[])
{
  string input1 = "JTVAKAVISHAAAL";
  string input2 = "AVISHAL";

  cout << "before: " << input1 << endl;	
  cout << "after : " << reverse(input1) << endl;
  cout << "---------" << endl;

  cout << "before: " << input2 << endl;	
  cout << "after : " << reverse(input2) << endl;
  cout << "---------" << endl;

  return 0;
}

Output:

before: JTVAKAVISHAAAL
after : LHSIKAVTJ
---------
before: AVISHAL
after : LHSIVA
---------


={============================================================================
*kt_dev_quiz_006* array and string: to check if it's anagram of the other.

From Cracking the coding interview, p174,

Q. Given two strings, write a method to decide if one is a anagram(permutation) of the other. 

bool func(string &one, string &two);

note: questions to ask for clarity.
1. case sensitive? such as God or dog?
2. whitespace is significant? such as "god   " and "dog".
3. ASCII?

Assume that all are the case. Optimization? 

<1> If they are different lengths then they cannot be anagrams.


{code-cpp}
#include <iostream>
#include <string>
#include <algorithm>

using namespace std;

// simple, clean and easy to understand
//
bool anagram_one(string& one, string& two)
{
  // input error check
  if( one.size() != two.size() ) return false;

  sort(one.begin(), one.end());
  sort(two.begin(), two.end());

  return ( one == two );
}

// if efficiency is very important
//
bool anagram_two(const string& one, const string& two)
{
  // input error check
  int oneSize = one.size(), twoSize = two.size();

  if( oneSize != twoSize ) return false;

  // assume ASCII set
  int charSet[256] = {0};

  // iterate one string to count num of each char
  for( int nIndex = 0; nIndex < oneSize; ++nIndex )
  {
    ++charSet[one[nIndex]];
  }

  // do not cover when there are multiple same chars but different occurances?
  for( int nIndex = 0; nIndex < twoSize; ++nIndex )
  {
    // seen first, then not the anagram
    if( charSet[two[nIndex]] == 0 )
      return false;
  }

  return true;
}


int _tmain(int argc, _TCHAR* argv[])
{
  string input1 ="PARK";
  string input2 ="APRK";

  if(anagram_one( input1, input2 ))
    cout << "they are anagram" << endl;
  else
    cout << "they aren't anagram" << endl;

  string input3 ="PARK";
  string input4 ="APRK";

  if(anagram_two( input1, input2 ))
    cout << "they are anagram" << endl;
  else
    cout << "they aren't anagram" << endl;

  return 0;
}


={============================================================================
*kt_dev_quiz_007* algo-find-unique-byte

Q: Given an eventually very large stream of bytes, find the first unique byte in
this stream.

Catch evntually, byte, first, unique

<inns-solution>
Since it's byte, use two array.

uint occurance[256];
uint order[256];

Get order and occurance.

index = 1;

for byte in stream {

  // see the byte
  occurance[byte]++;

  // set when see the first time
  if (order[byte] == 0) {
    order[byte] = index;
  }

  index++;
}

Has time complexity is O(n), space complexity O(1)

for 0 to 255
{
  find lowest order among occurance 1;
}

This is simply to find min so time complexity and space complexity are O(1)

So the final complexity is time:O(n), space:O(1). Think that this is optimal
solution.


={===========================================================================
*kt_dev_quiz_009* i = i+j means? (from me)

Its meaning depends on its type as type decides operations that can be used on that type. If it's
arith type, this means addition. what if these are of class type?


={===========================================================================
*kt_dev_quiz_010* intersects between rectangles (interview)

From NDS CF office interview. 

Problem: implement the intersects method contained within the rectangle class below. The method
should return true if the supplied rectangle intersects with the internally represented rectangle.

<intersect_one>
This works regardless of how rect defined, in other words, no assumption.

<intersect_two>
This is in ansic, p 130. This has assumption which is:

   +--------+ pt2(x2, y2)
   |        |
   |        |
   +--------+
pt1(x1,y1)

That is pt1 < pt2 and this is how ptinrect is implemented. Also it has convention that a rectangle
includes left and bottom side but not top and right side.

How can make it working without assumtion? This is:

int ptinrect( const point p, const rect r )
{
  return (p.x >= r.bot.x && p.x <= r.upp.x) || (p.x >= r.upp.x && p.x <= r.bot.x )
      && (p.y >= r.bot.y && p.y <= r.upp.y) || (p.y >= r.upp.y && p.y <= r.bot.y );
}

Two things to ask:
1) pt1 < pt2 assumption, 2) which side should be included, that is == on edges.

note:
1. For each point, both x and y must overlaps at the same time.
2. To ask if there is an assumption(bot < up) of a rectangle which point upper is greater than bottom.
3. To ask whether to include '==' in overlapping cases?

note: approach two is better since it consumes two function calls and clearer logic.


{approach-one}
This approach handles each x and y seperately.

(x1,y1)
   +--------+
   |        |
   |        |        (x3,y3)
   +--------+           +--------+
            (x2,y2)     |        |
                        |        |
                        +--------+
                                 (x4,y4)

- ---------------------------------------> x axis
  x1        x2          x3       x4


<code>
#include <stdio.h>

// can be signed
typedef struct {
  unsigned int x;
  unsigned int y;
} point;

// works for intersect_two
// typedef struct {
//   point bot;
//   point upp;
// } rect;

// do not work for intersect_two
typedef struct {
  point upp;
  point bot;
} rect;


void printrect( const char* name, const rect r)
{
  printf("rect : %s: { %d, %d } -> { %d, %d }\n", name, r.upp.x, r.upp.y, r.bot.x, r.bot.y );
}

// note: there is no assumption that x1 < x2 since this handles each value rather than a rectangle
// x1 < x' < x2 or x2 < x' < x1
// note: do not need () since <= is higher than &&
int isinrange( const unsigned int x1, const unsigned int x2, const unsigned int z)
{
  // return ( ((x1 < z ) && ( z < x2)) || ((x2 < z ) && ( z < x1)) );
  return ( ((x1 <= z ) && ( z <= x2)) || ((x2 <= z ) && ( z <= x1)) );
}

int intersect_one( const rect r1, const rect r2)
{
  int xi = 0, yi = 0;

  xi = isinrange( r1.upp.x, r1.bot.x, r2.upp.x ) || isinrange( r1.upp.x, r1.bot.x, r2.bot.x );
  yi = isinrange( r1.upp.y, r1.bot.y, r2.upp.y ) || isinrange( r1.upp.y, r1.bot.y, r2.bot.y );

  return (xi && yi);
}


{approach-two}
This approach has assumption about rectangle and handles point than each value.

// handles equal case
int ptinrect( const point p, const rect r )
{
  return p.x >= r.bot.x && p.x <= r.upp.x
      && p.y >= r.bot.y && p.y <= r.upp.y;
}

int intersect_two( const rect r1, const rect r2)
{
  return ptinrect( r1.upp, r2 ) || ptinrect( r1.bot, r2 );
}

int main(int argc, char* argv[])
{
  int ret = 0;

  {
    rect one ={10,10,20,20};
    rect two ={15,15,25,25};

    printrect("one", one );
    printrect("two", two );

    ret = intersect_one(one, two);

    printf("ret is %s\n", (ret ? "intersected" : "not intersected"));

    rect rec3 ={10,10,20,20};
    rect rec4 ={20,20,25,25};

    printrect("rec3", rec3 );
    printrect("rec4", rec4 );

    ret = intersect_one(rec3, rec4);

    printf("ret is %s\n", (ret ? "intersected" : "not intersected"));
  }

  {
    rect one ={10,10,20,20};
    rect two ={15,15,25,25};

    printrect("one", one );
    printrect("two", two );

    ret = intersect_two(one, two);

    printf("ret is %s\n", (ret ? "intersected" : "not intersected"));

    rect rec3 ={10,10,20,20};
    rect rec4 ={20,20,25,25};

    printrect("rec3", rec3 );
    printrect("rec4", rec4 );

    ret = intersect_two(rec3, rec4);

    printf("ret is %s\n", (ret ? "intersected" : "not intersected"));
  }
}


={============================================================================
*kt_dev_quiz_011* find a path in a maze

From SS.

You are given an N*N matrix with white, black, or gray cells. You have to find a white path from
(1, 1) to (N, N). 

Here (1, 1) means the top-leftmost cell and (N, N) means th bottom-rightmost cell. You can move from
one cell to an 

o horizontally, vertically, or diagonally adjacent cells.

o You cannot visit a cell more than once. # condition

o one gray cell is given and your path must visit the gray cell in the path. 

The cells (1, 1) and (N, N) cannot be the gray cell. Your path does not have to be the shortest
path. Given an N*N matrix with white cells, black cells, and a gray cell. Generate a program that
finds a white-cell path from (1, 1) to (N, N) which visits the gray cell in the middle of the path.

o should visit green cell first.

This problem can be difficult for some special cases. To ease the problem, there are not more than
four white cells adjacent to the gray one. For partial points, a considerable part of the test cases
will be rather easy. 

In three of the test cases, just finding a path from (1, 1) to the gray cell and then finding a path
from the gray cell to (N, N) will always find a successful path. 

And in other three of the test cases, only ** two white cells will be adjacent to the gray cell. It
will be guaranteed that all of the test cases will have a solution. That is, it will be always
possible to find a valid path.

  
[Constraints]
5=N=100.

[Input]
10 test cases are given. In each case, the first line has N, the dimension of the matrix, and the
next N lines show the shape of the matrix. 

o A black cell is represented by 1, a white cell by 0, and the gray cell by 2. 
  
[Output]
Write the 10 answers in 10 lines. Each line starts with #x where x means the index of a case, puts
a space, and then prints a path. A path is represented by the coordinates of cells visited in order.
A coordinate is represented by row column. For example, in the matrix below, the only successful
path is (1, 1)->(2, 1)->(3, 2)->(3, 3); it is represented in the output as 1 1 2 1 3 2 3 3.


<code-frame>

#include<iostream>

using namespace std;

int A[101][101], N;
int Answer1[10001], Answer2[10001], AnswerN;

int main(int argc, char** argv)
{
  int test_case;
  /*
     freopen function below opens input.txt file in read only mode, and afterward,
     the program will read from input.txt file instead of standard(keyboard) input.
     To test your program, you may save input data in input.txt file,
     and use freopen function to read from the file when using scanf function.
     You may remove the comment symbols(//) in the below statement and use it.
     But before submission, you must remove the freopen function or rewrite comment symbols(//).
   */
  // freopen("input.txt", "r", stdin);


  /*
     Your program should handle 10 test cases given.
   */
  for(test_case = 1; test_case <= 10; ++test_case)
  {
    int i, j;

    /*
       Read each test case from standard input.
       The dimension of the matrix will be stored in variable N,
       and the matrix will be stored in an array A[1..N][1..N].
     */
    cin >> N;
    for(i = 1; i <= N; i++)
    {
      for (j = 1; j <= N; j++)
      {
        cin >> A[i][j];
      }
    }


    /////////////////////////////////////////////////////////////////////////////////////////////
    /*
       Implement your algorithm here.
       The length of the path will be stored in variable AnswerN,
       and the coordinates will be stored in arrays (Answer1[1..AnswerN], Answer2[1..AnswerN]).
     */
    /////////////////////////////////////////////////////////////////////////////////////////////
    AnswerN = 1;
    Answer1[1] = Answer2[1] = 0;


    // Print the answer to standard output(screen).
    cout << "#" << test_case;
    for(i = 1; i <= AnswerN; i++) cout << " " << Answer1[i] << " " << Answer2[i];
    cout << endl;
  }

  return 0; //Your program should return 0 on normal termination.
}


<test-cases>

5
0 0 0 0 0
1 1 1 1 0
0 0 0 0 0
0 1 1 1 1
2 0 0 0 0
10
0 1 0 1 0 1 0 0 0 1
0 1 0 1 0 1 1 1 0 1
0 0 0 0 0 1 0 0 0 1
0 1 0 1 1 1 0 1 1 1
0 1 2 1 0 0 0 0 0 1
1 1 0 1 0 1 1 1 1 1
0 1 0 0 0 0 0 1 0 1
0 1 1 1 0 1 1 1 0 1
0 0 0 0 0 0 0 0 0 1
1 1 1 1 1 1 1 1 1 0
15
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 0 1 0 0 0 1 0 1 0 1 0 1 0
0 1 0 0 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 0 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1
2 0 0 0 0 0 0 0 0 0 0 0 0 0 0
20
0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 1
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1
0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1
0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1
0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1
0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1
0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1
0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1
0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1
0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1
0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1
0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1
0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
29
0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0
0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0
0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0
0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0
0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0
0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0
0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0
0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0
0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0
0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0
0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0
0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1
0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0
0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0
0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0
1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1
0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0
1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0
0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0
0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0
0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0
1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1
0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0

There are more up to 99.


={============================================================================
*kt_dev_quiz_012* get msb position

From SS in which a problem to get how many bits are the same between two integers. For example:

A = 35 = 10 0011
B =  9 =    1001

Ans = 2 because only counts bit positions which are valid position in both integers.

<code-example>
#include <iostream>

using namespace std;

unsigned int A, B, Answer;

int main(int argc, char** argv)
{
  int test_case;

  freopen("input.txt", "r", stdin);

  for(test_case = 1; test_case <= 10; test_case++)
  {
    cin >> A; cin >> B;

    if( (A <0) || (B<0))
      return -1;

    int shift = 0, msb = 0, target = 0;
    Answer = 0;

    // only think about the samaller
    target = min(A, B);

    // get msb position. assumes the first 10 bits.
    for(shift = 0; shift < 10; shift++)
    {
      if( target & (1<<shift))
        msb = shift;
    }

    for( shift = 0; shift <= msb; shift++)
    {
      if( (A & (1<<shift)) == (B & (1<<shift)) )
        Answer++;
    }

    cout << "#" << test_case << " " << Answer << endl;
  }

  return 0;//
}

note:
1. If one of input is zero then the return should be zero.

2. To remove assumption on getting msb, scan for '1' from the msb of the input and stops when found it. How?
Get 31th bit from target while shifting it to left in a loop. If found 1 then stop the loop and get
position. Can use getbits(target, 31, 1)

3. Get size of the int type and use it.

TODO: use >> to get msb without assumption and use >> to cals bit counts.


={===========================================================================
*kt_dev_quiz_013* get the number of occurance in sequence {interview}

From Park-in when have a interview at BB. When input is "AAABBBCCCCDDD" then write func that returns
C and 4

<code-example>
#include < iostream>

#define GT(a,b) ((a)>(b))

void getLargestOccurance(int size, const char* input)
{
   if( size==0 || input==nullptr )
      return;

   unsigned int countCurrent = 1, countMax = 1; 
   char charCurrent = input[0], charMax = 0;

   for(int i = 1; i < size; ++i )
   {
     // if see different char
     if( charCurrent^input[i] ) 
     {
       // update max when current is greater
       if( GT( countCurrent, countMax ))
       {
         countMax = countCurrent;
         charMax  = charCurrent;
       }

       charCurrent = input[i];
       countCurrent = 1;
     }
     else
       countCurrent++;
   }

   std::cout << "max: (" << charMax << ", " << countMax << ")" << std::endl;
}

int main()
{
   //const char* input = "AAABBCCCCDDD";
   //const char input[] = "AAABBCCCCDDD";
   const char input[] = "AAABBCCCCDDDEEFFFFFFFFFFFFFFFFFFHHHSSSSSSSSSS";

   getLargestOccurance(sizeof(input)/sizeof(input[0]), input);
}


<follow-ups>
Follow-up questions:

1. How to handle when there are many with the 'same' length? 
A: With the above approach, will have the last.

2. How to modify to print the first when there are many with the same length?

3. How to draw out complexity?
A: With the above approach, O(n).

4. Is there any other way to reduce complexity?

<second-approach-from-me>
Use multimap< occurance, char* > and get the end iterator-1 which is the biggest occurance because
it is ordered map. From iterator, get it.first which is a key_type and use find(key_type) to get the
iterator to the first element of the same occurance.

This requires O(n) to scan through the input and O(logn) to use find() since map uses red-black
tree.

<suggested-solution>

 0-1-2-3-4-5-6-7-8-9 -10-11-...
 -----------------------------
 1 2 3 4 5 6 7 8 9 10 11 12
 <-------> <-------->
           x        y

 inspect [current i(6) + current max(5) -1]. so skip over.

If first sequence ends and see a new character; say x was the first character of new sequence and
inspect array[current i + the current max(first occurance)-1], say y, since array index starts from
0 and count starts from 1:

1) if it is different, then means there is no bigger sequences than the first between position x and
y-1. So SKIP this block by current max and continue this. Starts from [current i + current max]

2) if it is the same, then means there might be a bigger sequence than the first and start from the
current index and scan through until a sequence ends because it could be either a bigger sequence or
a different sequence with the same character. If the occurance is bigger then the previous, update
occurance and string.

If think only the first or last sequence of the same occurance by keeping the first or the last,
then it is less than O(n) since it is skipping characters while scanning. So better than using a
map.

If requires to maintain the set of the same occurance, then need to data structure to hold and it
depends on requirements such as searching, insertion and deletion.

void getLargestOccurance(int size, const char* input)
{
  if( size==0 || input==nullptr )
    return;

  unsigned int countCurrent = 1, countMax = 1; 
  char charCurrent = input[0], charMax = 0;

  for(int i = 1; i < size; )
  {
    if( charCurrent^input[i] ) 
    {
      // do not need. if( GT( countCurrent, countMax ))
      {
        countMax = countCurrent;
        charMax 	= charCurrent;
      }

      if( arr[i] == arr[i+countmax-1] )
      {
        charCurrent = input[i];
        countCurrent = 1;
      }
      else
        i += countMax;
    }
    else
      countCurrent++;
  }

  std::cout << "max: (" << charMax << ", " << countMax << ")" << std::endl;
}

<updated>
The possibility that can skip over some elements since there is no bigger sequence between the new
start and the new start+current max sequence seems wrong:

0 1 2 3 | 4 5 6 7  | 8 
A A A A   B B B B    B
          B X X B    B
          B X B B    B

          B X X X    C     // when different
          B B B B    C
          B C C C    C     // how about this?

If simply skip over then miss out the last case. Therefore, cannot skip over elements for the better
performance. 

Re "occurance" above, this is wrong since the problem is about longest(length) sequence. So if
requires to maintain a data structure as per the length, input is not complete, and to maintain it
to be ready all the time so that can find the first and last sequence for the longest length then
can think of uisng map.

1. Parse input to sequence token, string.
2. Use map<int length, string sequence>
3. Find the largest and get the first and last int the same range.

See <example> algorithm-max_element with multimap in map


={{===========================================================================
*kt_dev_quiz_014* code review task {interview}

Code Review Task

Code Review:
systematic examination (often as peer review) of computer source code intended to find and fix
mistakes overlooked in the initial development phase, improving both the overall quality of software
and the developers' skills.

The aim of this task is to examine a piece of code that your colleague has written. You must
critically analyse and report on the quality of the code and review it for any mistakes, bugs or
issues that you feel are present. You can make any comments, improvements or suggestions that you
feel are appropriate about style, design and logic.

Please write any review comments inline in the code below in bold red text.

There is no time or word limit but try to not spend too long completing the task. Treat it as if it
were a real review in your day as a developer.

This example is massively contrived and intentionally badly coded; don't expect code like this in
your day to day life.


General Comments On Code:

#include <cstdio>
#include <cstring>
#include <map>
#include <iostream>
#include <string>

/*
// Read file in
// Stock, TimeInterval, Volume Traded, High, Low.
VOD.L 1 100 184.0 183.7
BT.L 1 14 449.4 448.2 
VOD.L 2 434 184.1 182.4
BT.L 2 234 449.8 449.5
..

// Find the total volume traded for each stock
// Find the high and low for each stock.

// Write file a to stdout
// Per stock per interval output the %volume traded in that interval as a percentage of the whole day
// Stock, Interval, %Vol for day.

VOD.L,1,2.0
BT.L,1,1.1
VOD.L,2,8.2
BT.L,2,19.0

// Write file b to stdout
// Stock, day high, day low
VOD.L,186.7,182.4
BT.L,445.3,450.9
*/

using namespace std;
typedef basic_string<char> string;

class CHighLow
{
  public:
    CHighLow() : nCurLow(0), nCurHigh(0) {};

    void add(int nHigh, int nLow)
    {
      if (nHigh > nCurHigh)
        nCurHigh = nHigh;

      if (nLow < nCurLow)
        nCurLow = nLow;
    }

    int nCurLow;
    int nCurHigh;
};

int main(int argc, char* argv[])
{
  if (!strcmp("version", argv[1]))
  {
    cerr << "Using version 1.0 VWAPer" << endl;
    return 0;
  }

  FILE* file = fopen(argv[2], "r");

  cerr << "Reading file" << argv[2] << endl;

  char line[256];
  char Stocks[1000][10];
  int Intervals[1000];
  int Volumes[1000];
  float Highs[1000];
  float Lows[1000];

  int i = 0;
  int sum = 0;

  // read input file
  while (fgets(line, 256, file))
  {
    sscanf(line, "%s %d %d %f %f", Stocks[i], &Intervals[i], &Volumes[i], &Highs[i], &Lows[i++]);
  }

  cerr << "Calculating total volumes" << endl;

  // for each stock, loop through all inputs and add volumes to get the total. Given map used, the
  // same stock lines in the input will be merged into the one stock.
  // i is total # of lines

  map<std::string, int> TotalVolumes;

  for (int s = 0; s <= i; ++s)
  {
    std::string stockname = Stocks[s];

    for (int j =0; j <= i; ++j)
    {
      if (!strcmp(Stocks[j], stockname.c_str()))
      {
        TotalVolumes[stockname] += Volumes[j];
      }
    }
  }

  cerr << "Calculating high lows" << endl;

  map<std::string, CHighLow> HighLows;

  for (int s = 0; s <= i; ++s)
  {
    HighLows[Stocks[s]].add(Highs[s], Lows[s]);
  }

  cerr << "Writing files" << endl;

  // [KT] However here write out each stock so need to maintain duplicated stocks.

  // write file a
  for (int s = 0; s <= i; ++s)
  {
    cout << Stocks[s] << "," << Intervals[s] << "," 
      << TotalVolumes[Stocks[s]] / Volumes[s] * 100 << endl;
  }

  // write file b
  map<std::string, CHighLow>::iterator itr = HighLows.begin();
  while (itr != HighLows.end())
  {
    cout << (*itr).first << "," << (*itr).second.nCurLow << "," << (*itr).second.nCurHigh << endl;
    ++itr;
  }

  return 1;
}


{review-by-ian}
General Comments On Code:

// File header is missing. If it is a real situation, I would strongly complaining like "no comment
// on each classes and functions at all"
#include <cstdio>
#include <cstring>
#include <map>
#include <iostream>
#include <string>

/*
// Read file in
// Stock, TimeInterval, Volume Traded, High, Low.
VOD.L 1 100 184.0 183.7
BT.L 1 14 449.4 448.2 
VOD.L 2 434 184.1 182.4
BT.L 2 234 449.8 449.5
..

// Find the total volume traded for each stock
// Find the high and low for each stock.

// Write file a to stdout
// Per stock per interval output the %volume traded in that interval as a percentage of the whole day
// Stock, Interval, %Vol for day.
VOD.L,1,2.0
BT.L,1,1.1
VOD.L,2,8.2
BT.L,2,19.0

// Write file b to stdout
// Stock, day high, day low
VOD.L,186.7,182.4
BT.L,445.3,450.9
*/

using namespace std;
// I would prefer not to use std namespace. Consider using standard library with 'std::' prefix.

typedef basic_string<char> string;
// In most of case this type definition is not necessary.

class CHighLow
{
  public:
    CHighLow() : nCurLow(0), nCurHigh(0) {};
    // note: minor. about invalid value.
    // Setting the initial value of <nCurLow> to zero is wrong. Define a constant variable like
    // 'MAX_PRICE' with large integer value and set it to nCurLow. Otherwise, you need to add
    // another comparison in add() function. For a case when there is an input with value 0.

    // note: major. about type. cause truncation.
    // As the high and low values are float value, change the type of parameters to float
    void add(int nHigh, int nLow)
    {
      // note: minor. agree about assumption on High > Low.
      // Need to check if nHigh is lower than nLow and handle the case properly

      if (nHigh > nCurHigh)
        nCurHigh = nHigh;

      // note: that is why suggest to set nCurLow(MAX)
      // If you set nCurLow to zero, this would not be working at all. You need to assign nLow
      // to nCurLow if nCurLow is zero for it. However I would prefer setting initial value with
      // maximum value.  
      if (nLow < nCurLow)
        nCurLow = nLow;
    }

    // As the input has floating point, define those variables as float. Prefer a prefix m_ for
    // the names of member variables. Member variables should be under the private keyword 
    int nCurLow;
    int nCurHigh;
};

int main(int argc, char* argv[])
{
  // This comparison is ambiguous. Please put comments explaining why the first argument should
  // not be 'version'
  if (!strcmp("version", argv[1]))
  {
    cerr << "Using version 1.0 VWAPer" << endl;
    return 0;
  }

  // Consider using ifstream. You did not check if there is the second argument. Otherwise you will
  // see a segmentation fault when argv[2] is null.
  FILE* file = fopen(argv[2], "r");

  // Add a white space after the log message otherwise file and argv[2] will be put together so
  // file name will be looking weird.
  cerr << "Reading file" << argv[2] << endl;

  // If you are sure a line is not longer than 256 bytes this is ok, however please define a
  // constant variable like MAX_LINE_LENGTH rather than just using the number.
  char line[256];

  // Like above comment, you should define MAX_STOCK_NAME_LENGTH instead of putting 10. You assume
  // the input file has 1000 lines at most. This is limitation. I will suggest better design later.
  // Anyway define MAX_INPUT_LINE_COUNT as above.
  char Stocks[1000][10]; 
  int Intervals[1000]; 
  int Volumes[1000]; 
  float Highs[1000]; 
  float Lows[1000];

  int i = 0;
  // sum is not used at all. Delete this.
  int sum = 0;

    // Replace 256 to MAX_LINE_LENGTH. If you use ifstream, getLine function can replace this. If you use
    // ifstream, cin can replace sscanf
    while (fgets(line, 256, file))
    {
      // note: major. agree.
      // You made big mistake here. Increasing i in the parameter is very dangerous. The evaluation
      // order of function parameter is undefined in spec and usually they are evaluated in reverse
      // order in most of compilers. Therefore i will be increased firstly and the data for
      // Stocks,Intervals,Volumes and Highs will be stored in the next row. The data will be totally
      // mangled. Increase i in the separated line.
      sscanf(line, "%s %d %d %f %f", Stocks[i], &Intervals[i], &Volumes[i], &Highs[i], &Lows[i++]);
    }

  cerr << "Calculating total volumes" << endl;

  map<std::string, int> TotalVolumes;

  // note: major. no need to have double loop and must be re-written
  // This double looping is really bad idea especially when the input file is huge. Exponential
  // complexity is expected and we can avoid this problem by adopting a new design. I will describe
  // later.
  // change 's <=i' to 's < i'
  for (int s = 0; s <= i; ++s)
  {
    // No reason to create string object. Please avoid unnecessary object creation and memory copy
    std::string stockname = Stocks[s];

    // Change 'j <=i' to 'j < i'
    for (int j =0; j <= i; ++j)
    {
      // So this just can be comparing Stocks[j] and Stocks[s]
      if (!strcmp(Stocks[j], stockname.c_str()))
      {
        // Map can work with char* even though it's key is string type. Just use Stocks[s] here.
        // [KT] may disagree since will cause creating a temp string objects.
        TotalVolumes[stockname] += Volumes[j];
      }
    }
  }

  cerr << "Calculating high lows" << endl;

  // You use this type of map later again. Set a typedef for the readability.
  map<std::string, CHighLow> HighLows;

  // note: major. good spot.
  // Calculating high and low value could be done while reading file. Running another loop is not
  // necessary. 
  // note: major. good spot. Change 's <=i' to 's < i'
  for (int s = 0; s <= i; ++s)
  {
    HighLows[Stocks[s]].add(Highs[s], Lows[s]);
  }

  cerr << "Writing files" << endl;

  // Change s <=i to s < i
  for (int s = 0; s <= i; ++s)
  {
    // note: major. good spot.
    // You don't want to devide by zero when Volume[s] is zero. Check the volume in advance and
    // handle the case properly.

    cout << Stocks[s] << "," << Intervals[s] << "," << TotalVolumes[Stocks[s]] / Volumes[s] * 100 <<
      endl; 
  }

  // Writing the whole definition of map is stressful always. Prefer using typedef as I mentioned
  // before.
  map<std::string, CHighLow>::iterator itr = HighLows.begin();

  // note: minor. agree. 
  // For this simple iteration, for( ; itr != HighLows.end() ; ++itr) is useful. You would never
  // need to worry about not increasing the iterator with it.
  while (itr != HighLows.end())
  {
    cout << (*itr).first << "," << (*itr).second.nCurLow << "," << 
      (*itr).second.nCurHigh << endl;

    ++itr;
  }

  return 1;
}


<design-suggestion>
You can slightly improve collecting and writing logic by adopting a wrapper class. So you can call
add() function to collect, and can do 'cout << highLowMapper' for printing out.

class CHighLowMapper
{
  public:
    CHighLowMapper() {};
    void add(const char* stock, int nHigh, int nLow) {
      m_HighLows[stock].add(nHigh, nLow);
    }

    friend ostream& operator<<(ostream& os, const CHighLowMapper& hlm) {
      HLMap::const_iterator itr = hlm.m_HighLows.begin();
      while (itr != hlm.m_HighLows.end())
      {
        cout << (*itr).first << "," << (*itr).second.nCurLow << "," << (*itr).second.nCurHigh << endl;
        ++itr;
      }
      return os;
    }

  private:
    typedef map<std::string, CHighLow> HLMap;
    HLMap    m_HighLows;
};


The double looping to calculate the total volume must be replaced with better logic. Here is a class
to collect volume information and accumulate the total volume for each stock. Therefore the required
information can be collected in the file reading loop. This class overrides operator >> therefore
users are able to printout the result using cout. CVolumeCollector takes maxSize for the vector
reservation. If flexibility and scalability are more important than performance, you can omit it.

class CVolumeCollector
{
  public:
    struct VolumeInfo{
      string stock;
      int interval;
      int volume;
    };

    CVolumeCollector(int maxSize = 0) {
      if(maxSize > 0) {
        m_volumeInfoList.reserve(maxSize);   // note: good to have since it is vector
      }
    };

    void add(const char* stock, int interval, int volume) {
      VolumeInfo vi;
      vi.stock = stock;
      vi.interval = interval;
      vi.volume = volume;

      m_volumeInfoList.push_back(vi);
      m_volumes[stock] += volume;
    }

    const int getVolumeForStock(const string& stock) const {
      int totalVolume = 0;
      VolMap::const_iterator itr = m_volumes.find(stock);
      if(itr != m_volumes.end()) {
        totalVolume = itr->second;
      }
      return totalVolume;
    }

    // note: this calculation seems wrong to get % since (volume/totalvolume)*100. also, % volume
    // seems float type from the input description.
    // note: must be float since there may be a problem of integer division.
    friend ostream& operator<<(ostream& os, const CVolumeCollector& vc) {
      VolInfoVec::const_iterator itr = vc.m_volumeInfoList.begin();
      while(itr != vc.m_volumeInfoList.end()) {
        cout << (*itr).stock << "," << (*itr).interval << "," 
          << vc.getVolumeForStock((*itr).stock) / (*itr).volume * 100 
          << endl;
        ++itr;
      }
      return os;
    }

  private:
    typedef map<string, int> VolMap;
    VolMap  m_volumes;

    typedef vector<VolumeInfo> VolInfoVec;
    VolInfoVec m_volumeInfoList;
};

Using CVolumeCollector and CHighLowMapper described above, the main function is much simpler and
well structured.

int main(int argc, char* argv[])
{
  // omitted
  char line[MAX_LINE_LENGTH];

  CHighLowMapper hlm;
  CVolumeCollector vc(MAX_INPUT_FILE);

  // note: can use C++ way using ifstrem and stringstream or use freopen( argv[1], "r", stdin ) to use cin.
  while (fgets(line, MAX_LINE_LENGTH, file))
  {
    char stock[MAX_STOCK_NAME_LENGTH];
    int interval;
    int volume;
    float high;
    float low;
    sscanf(line, "%s %d %d %f %f", stock, &interval, &volume, &high, &low);
    hlm.add(stock, high, low);
    vc.add(stock, interval, volume);
  }

  cout  << "Writing files"  << endl;
  // write file a
  cout << vc;
  // write file b
  cout << hlm;
  return 1;
}

note: how about having a single class and a single map rather than two classes and three containers?

struct Record;
{
  int interval;
  float volume;
  float totalvolume;
  float high;
  float low;
};

map<stock, Record>

No since totalvolume, high, and low are about each stock and input has many records for the same
stock.

Then how about one vector for input and one map for totoalvolume, high and low? Okay.


={============================================================================
*kt_dev_quiz_015* sorting and searching questions from {ref-004}

1. You are given two sorted arrays, A and B, where A has a large enough buffer at the end to hold B.
Write a method to merge B into A in sorted order.

Our logic should invlove simply comparing elements of A and B and inserting them in order, until we
have exhausted all elements in A and in B. The issue is that if insert an element into the front of
A, then we will have to shift the existing elements backwards. Better to insert elements into the
back where there is empty space. In short, combine in mergesort but from back.

void merge( int* a, int* b, int lastA, int lastB )
{
	int indexA = lastA-1, indexB = lastB-1;
	int indexMerged = lastB+lastA-1;

	while( indexA >= 0 && indexB >= 0 )
	{
		if( a[indexA] > b[indexB] )
		{
			a[indexMerged] = a[indexA];
			indexMerged--;
			indexA--;
		}
		else
		{
			a[indexMerged] = a[indexB];
			indexMerged--;
			indexB--;
		}
	}
	
	while( indexB >= 0 )
			a[indexMerged] = a[indexB];
			indexMerged--;
			indexB--;
}


2. Write a method to sort an array of strings so that all the anagrams are next to each other.

Ask us to group the strings in an array that the anagrams appear next to each other. Note that no
specific ordering of the words is required.

One way to do this is to use any standard sorting and modify the comparator. What's the easiest way
of checking if two words are anagrams? Could count occurrences of chars or could sort the string.


But do not actually need to fully sort the array. Only need to group the strings in the array by
anagram. Can do this by using a hash table which maps from the sorted version of a word to a list of
its anagrams. So, for example, 'acre' will map to the list {acre, race, care}. Once we've grouped
all the words into these list by anagram, can then put them back into the array.

public void sort( String[] array )
{
	Hashtable< String, LinkedList< String >> hash = new Hashtable< String, LinkedList< String >>();

	// group words by anagram
	for( String s : array ) {
		String key = sortChars(s);
		if( !hash.containsKey(key))
			hash.put( key, new LinkedList<String>());

		LInkedList< String > anagrams = hash.get(key);
		anagrams.push(s);
	}

	// convert hash table to array
	int index = 0;
	for( String key : hash.keySet())
	{
		LinkedList< String > list = hash.get(key);
		for( String t : list ) {
			array[index] = t;
			index++;
		}
	}
}

If use STL, then can code:

bool isAnagram( string a, sting b )
{
	if( a.size() != b.size() ) return false;

	sort( a.begin(), a.end() );
	sort( b.begin(), b.end() );

	return a == b;
}

func( vector< string > &svec )
{
	sort( svec.begin(), svec.end(), isAnagram );
}

However, question is how the final vector looks like?


3. Given a sorted array of n integers that has been rotated an unknown unmber of times, wrtie code
to find an element in the array. You may assume that the array was originally sorted in increasing
order.

EXAMPLE
input: find 5 in {15, 16, 19, 20, 25, 1, 3, 4, 5, 7, 10, 14}
output: 8 (the index of 5 in the array)

The complication is that the array is rotated and may have an inflection point and consider
following examples:

A1{10, 15, 20,  0,  5}
A2{50,  5, 20, 30, 40}

See that 5 appears on different side so comparing x with the midpoint is insufficient. However, if
you look a bit DEEPER, one half of the array must be ordered (regardless of how much it is rotated.) 
This is key observation which allows us to determine whether should search the left or right half.

 [KT] The rotation breaks sorted array but there is still one half ordered.

For example of searching 5 in A1, look at the left element, 10, and middle, 20. Since 10 < 20, the
left half must be ordered and since 5 is not in left half, must search the right half.

So determine the ordered half and see if a key is in the the ordered half. If so, do binary search
or sequential if n is small. If not, do sequential on the opposite half.

The tricky is if the left and the middle are identical, as in the example array

{2, 2, 2, 3, 4, 2}
       m

    m
2 2 2 2 3 4 (left)
4 2 2 2 2 3
3 4 2 2 2 2
2 3 4 2 2 2 
2 2 3 4 2 2 
2 2 2 3 4 2 (right)
2 2 2 2 3 4 (left)

In this case, check if the rightmost element is different. If it is, can search just the right side.
Otherwise, we have no choice but to search both halves.

public int search( int a[], int left, int right, int x ) {
	int mid = ( left + right )/2;

	// check mid first
	if( x == a[mid] )
		return mid;

	if( right < left )
		return -1;

	// left is ordered
	if( a[left] < a[mid] )
	{
		if( x >= a[left] && x <= a[mid] ) 		// is in the left and search it
			return search( a, left, mid-1, x );
		else
			return search( a, mid+1, right,x );	// is not in the left and search the right
	}
	// right is ordered
	else if( a[mid] < a[left] )
	{
		if( x >= a[mid] && x <= a[right] )		// search right
			return search(a, mid+1, right, x );
		elser
			return search(a, left, mid-1, x );	// search left
	}
	// left is all repeats
	else if( a[left] == a[mid] )
	{
		if( a[mid] != a[right])
			return search(a, mid+1, right, x);			// search right
		else
		{
			int result = search(a, left, mid-1, x );	// search left
			if( result == -1 )
				return search(a, mid+1, right, x );		// search right
			else
				return result;
		}
	}

	return -1;
}

This will run in O(logn) if all the elements are unique. However, with many duplicates is actually
O(n). This is because with many duplicates, will often have to search both.

 [KT] If n is large, can use iterative binary1 search on ordered half.


4. Imagine you have a 20GB file with one string per line. Explain how you would sort the file.

In this case, it suggests that they don't want you to bring all the data into memory. We'll divide
the fine into chunks which are x MB each where x is the amount of memory we have available. Each
chunk is sorted separately and then saved back to the file system.

Once all the chunks are sorted, we then merge the chunks, one by one. At the end, we have a fully
sorted file. This is known as external sort.

 [KT] For sorting chunks, load it to a memeory and use quicksort as it is good for contig memory and
 can use mergesort for merging sorted chunks which are in file system. 


<5> Given a sorted array of string which is interspersed with empty string, write a method to find
the location of a given string.

EXAMPLE
input: find 'ball' in { "at", "", "", "", "ball", "", "", "cor", "", "", "dad", "", "" }
output: 4 (the index of 4 in the array)


{A} Can implement simple modification of binary search. All we need to do is fix the comparison
against mid, in case mid is an empty string. Simply move mid to the closest non-empty string. 

public int searchR( String[] strings, String str, int first, int last )
{
	int mid = (last+first)/2;

	// if mid is empty, find closest non-empty string in both direction.
	if( strings[mid].isEmpty())
	{
		int left = mid-1;
		int right = mid+1;

		while(true)
		{
			if(left < first && right > last)
				return -1;
			else if( right <= last && !strings[right].isEmpty())
			{
				mid = right; break;
			}
			else if( left >= first && !strings[left].isEmpty())
			{
				mid = left; break;
			}

			right++; left--;
		}
	}

	// check for string, and recurse if necessary
	if( str.equals( strings[mid] ))		// found
		return mid;
	else if( strings[mid].compareTo(str) < 0)
		return searchR( strings, str, mid+1, last );		// search right
	else
		return searchR( strings, str, first, mid-1 );	// search left
}

public int search( String[] strings, String str )
{
	if( strings == null || str == null || str == "" )
		return -1;

	return searchR( strings, str, 0, strings.length-1 );
}


Careful consideration should be given to the situation when someone searches for the empty string.
Should we find the location( which is an O(n) operation)? Or should we handle this as an error?
There is no correct answer here. This is an issue you should raise with your interviewer. Simply
asking this question will demonstrate that you are a careful coder.

 [KT] Is it possible since do not know how to identify a empty string between them?



<6> Given MxN matrix in which each row and column is sorted, write a method to find an element.

{A} If do binary search on every row, then O(M logN). This is a good approach to mention to your
interviewer before you proceed with a better algorithm.

[approach-one] use first and last element.

Use these observations:
- if the start of col is greater than x, x is to the left of the col. exclude col.
- if the end of col is less than x, x is to the right of the col.

- if the start of row is greater than x, x is above that row.
- if the end of row is less than x, x is below that row.

15 20 40  85
20 35 80  95
30 55 95  105
40 80 100 120

Use 1 and 4 condition and repeatedly apply these to search for 55. Eleminate row and col from
top-right of array and so EQ check on the first at each iteration which is top-right. See that
top-right is both the start of col and the end of row.

bool findElement( int [][] matrix, int elem )
{
	int row = 0;
	int col = matrix[0].length -1;

	while( row < matrix.length && col >= 0 )
	{
		if( matrix[row][col] == elem )
			return true;
		else if( matrix[row][col] > elem )	// start of col
			col--;
		else 											// end of row
			row++;
	}
	return false;
}


[approach-two]
This more directly looks like binary search. More complicated but it applies many of the same
learnings.

The observation is that when see 95, all elements in sub rectangle are less than 95 and this is true
along the diagonal. So do binary search on the diagonal.

15 20 70 |85
20 35 80 |95
30 55 95 |105
----------
40 80 100 120

In search for 85, it cannot be in top-left and bot-right sub rectangle and continue for other sub
rectangles.

 15  20  * [70]  85
 20  35  *  80  [95]
***************
[30] 55  * [95] 105
 40 [80] * 100  120

static Coordinate findElement( int matrix[][], int x )
{
	Coordinate origin = new Coordinate(0, 0);
	Coordinate dest = new Coordinate( matrix.length-1, matrix[0].length-1 );

	return findElement(matrix, origin, dest, x );
}

// origin is top-left and dest is bot-right
public Coordinate findElement( int [][] matrix, Coordinate origin, Coordinate dest, int x )
{
	if( !origin.inbounds( matrix ) || !dest.inbounds(matrix) )
		return null;

	// EQ on origin
	if( matrix[origin.row][origin.col] == x )
		return origin;

	else if( !origin.isBefore(dest))
		return null;

	// get start and end of diagonal since the grid may not be square, the end of the diagonal may
	// not equal dest.
	Coordinate start = (Coordinate) origin.clone();
	int diagDist = Math.min( dest.row - origin.row, dest.col - origin.col );
	Coordinate end = new Coordinate( start.row + diagDist, start.col + diagDist );

	// do binary search on the diagonal, looking for the first element greater than x
	// but seems wrong. think of searcing 25.
	Coordinate p = new Coordinate(0,0);

	while( start.isBefore(end))
	{
		p.setToAverage( start, end );

		if( x > matrix[p.row][p.col] )
		{
			start.row = p.row+1; start.col = p.col+1;
		}
		else
		{
			end.row = p.row-1; end.col = p.col-1;
		}
	}

	return partitionAndSearch( matrix, origin, dest, start, x );
}

public Coordinate partitionAndSearch( int [][] matrix, Coordinate origin, Coordinate dest,
		Coordinate pivot, int elem )
{
	// origin and dest for low-left sub rectangle
	Coordinate lowerLeftOrigin	 =  new Coordinate( pivot.row, origin.col );
	Coordinate lowerLeftDest	 =  new Coordinate( dest.row, pivot.col-1 );

	// origin and dest for up-right sub rectangle
	Coordinate upperRightOrigin =  new Coordinate( origin.row, pivot.col );
	Coordinate upperRightDest 	=  new Coordinate( pivot.row-1, dest.col );

	Coordinate lowerLeft = findElement( matrix, lowerLeftOrigin, lowerLeftDest, elem );
	if( lowerLeft == null )
		return findElement(matrix, upperrightorigin, upperRightDest, elem );

	return lowerLeft;
}



<7> A circus is designing a tower routine consisting of people standing atop one another's shoulder.
For practical and aesthetic reasons, each person must be both shorter and lighter than the person
below him or her. Given the heights and weights of each person in the circus, write a method to
compute the largest possible number of people in such a tower.

We have a list of pairs of items. Find the longest sequence such that both the first and second
items are in increasing order. Apply the simple-and-generalize approach and can relate this problem
to finding the-longest-increasing-sequence in an array.

If the elements do not need to stay in the same(relative) order, then we would simply sort the
array. This makes the problem too trivial, so let's assume that the elements need to stay in the
same order.

The first recursive approach:

Array: 13, 14, 10, 11, 12
Longest(0 through 0) : 13
Longest(0 through 1) : 13, 14
Longest(0 through 2) : 13, 14
Longest(0 through 3) : 13, 14 or 10, 11
Longest(0 through 4) : 10, 11, 12

The different approach: Rather then trying to find the longest increasing subsequence across
elements 0 through i, can find the longest subsequence which [ends] with element i. 

Array: 13, 14, 10, 11, 12
Longest(ending with A[0]) : 13
Longest(ending with A[1]) : 13, 14
Longest(ending with A[2]) : 10
Longest(ending with A[3]) : 10, 11
Longest(ending with A[4]) : 10, 11, 12

For the real problem, sort the list of people by their hights and then apply the second approach on
their weights. The solution is the exact implementation of the second and to build a array of list
where a list is sequence. This scans from 0 for every element.

 [KT] The approach in *kt_dev_quiz_013* looks better than this.


<8> sorting and searching questions from {ref-004}, p122
Imagine you are reading a stream of integers. Periodically, you wish to be able to look up the rank
of a number x (the number of values less than or equal to x).

Implement the data structures and algorithms to support these operations.

That is, implement the method track(int x), which is called when each number is generated, and the
method getRankOfNumber(int x), which returns the number of values less than or equal to x (not
including x itself).


{A} A easy way would be to use an array. As with contiguous list, not efficient whenever element
arrives, insert, sort, do binary search, and return the found index. Return -1 when not found. This is what BST
solves. To find the rank of a number, we could do an inorder traversal and this is exactly
{treesort}. The key is that the rank of the node is the number of nodes in the left subtree.

Two solutions?

1) build BST when element comes in and do inorder traversal when getRankOfNumber() is called. Count
the number of visits until found a match and -1 if not found. However, this approach requires full
traversal. 

2) In the book, it have left count per each node and increase it whenever inserting on left happens
since it means that element which is less is inserted. That is, build a BST with left count as add
new elements to the left subtree. When getting the rank, traverse a tree by adding left count and
and 1 when move right since it need to add node itself before move to right. By doing this, can save
some time of traversal to left subtree so better than the full traversal.

                  20[4] ()

         15[3] ()                25[2] ()

   10[1] ()                   23[0] ()          // notice it has 0

5[0] () 13[0] ()                 24[0] ()

where [x] means left count and as an example, take 24 which returns 6.

// outline. recursive version
//
in getRank( Node node, int x )
{
  if x is node.data
    return node.leftSize();

  // when move to left, do not get the rank since the rank of the left is already calculated. this
  // book said that "not passing over any samller nodes". 
  if x is on left of node
    return getRank( node.left, x );

  // when move to right, add +1 since should include the current node, and get the right.
  if x is on right of node
    return node.leftSize() +1 + getRank( node.right, x );
}

// reference java code
public class Question {
  private static RankNode root = null;

  public static void track(int number) {
    if( root == null )
      root = new RankNode(number);
    else
      root.insert(number);
  }

  public static int getRankOfNumber(int number) {
    return root.getRank(number);
  }
}

class RankNode {
  int left_size = 0;
  RankNode left, right;
  int data = 0;

  public void insert(int d) {
    if ( d <= data )                // suggest that 'equal' items on its left.
    {
      if( left != null ) left.insert(d);
      else left = new RankNode(d);
      left_size++;                  // increase counts
    }
    else 
    {
      if( right != null ) right.insert(d);
      else right = new RankNode(d);
    }
  }

  public int getRank(int d) {
    if( d == data )
    { return left_size; }
    else if( d < data )
    {
      if( left == null ) return -1;
      else return left.getRank(d);
    }
    else    // move to right
    {
      int right_rank = right == null ? -1 : right.getRank(d);

      if( right_rank == -1 ) return -1;         
      // this is necessary. otherwise, will return left_size even if it is not found in the right tree.
      else return left_size + 1 + right_rank;
    }
  }
};

Handled the case in which d is not found in the tree and return -1 up the tree. It is important that
you handle cases like that.


={{===========================================================================
*kt_dev_quiz_016* cycle detection

From {find-middle-in-a-linked-list} in mergesort, this is to find the middle of the simple list.
When entries are odd numbers, the first half is one larger. If think it using the number of node:

middle   current  diff
0        1        1
1        3        2
2        5        3
3        7        4
...

This shows that middle or slow node moves at one element and current or fast moves two. However this
assumes that there is no cycle in the single linked list. This is similar with the tortoise-and-hare
but different because tries to find the middle and starts from 0 and 1 with checks. See mergesort
for more.


<1> {tortoise-and-hare}
From http://stackoverflow.com/questions/494830/how-to-determine-if-a-linked-list-has-a-cycle-using-only-two-memory-locations

This is known as "floyd's cycle finding algorithm or the tortoise and the hare algorithm" and has
O(n) for time and O(1) for space.

function boolean hasLoop(Node startNode) {

  Node slowNode = Node fastNode1 = Node fastNode2 = startNode;

  // see how to move two using three variables in while statement.
  // f2(first) -> [f1 -> f2] -> [f1 -> f2 ] -> 
  while (slowNode && fastNode1 = fastNode2.next() && fastNode2 = fastNode1.next())
  {

    if (slowNode == fastNode1 || slowNode == fastNode2) return true;

    slowNode = slowNode.next();
  }

  return false;
}

The list covers all cases so do not need to check if startNode is null and ListSize.

From {Q} below, thought that this approach won't detect the case that a difference is more than 2
such as:

Node0 -> Node1 -> Node2 -> Node3 -> Node4 -> ...
                        -> Node0 : cannot detect this

This is wrong since if contines loop, there is a point when nodes are the same. Therefore as long as
there is a cycle out of step, then will eventually find it since there should be wraps. In other
words, if there is a loop, hare will go forever and will meet toroise.

{Q} not sure what this below mean since hare will catch tortoise in the end if there is a loop.

what happens if we advance the fastNode by three at a time instead of two? Can't we detect that
fastNode has crossed slowNode. Obviously the equality check (which we are currently using for
detecting this) need not necessarily work with advances of three. What do you think? Wont this
(hop more steps at a time) be a better algorithm? –  Lazer Apr 3 '10 at 2:49

@Lazer - there's a risk for small loops that both pointers wrap like that –  Flexo Oct 7 '11 at
10:46 

{Q} what is the benefit of comparing fastnode1? since cannot exist both cases. For example, 0 and 1
and 0 and 2. 

<2>
http://codingfreak.blogspot.com/2012/09/detecting-loop-in-singly-linked-list_22.html

tortoise := firstNode  
hare := firstNode  
  
forever:  
  
  if hare == end   
    return 'No Loop Found'  
  
  hare := hare.next  
  
  if hare == end  
    return 'No Loop Found'  
  
  hare = hare.next  
  tortoise = tortoise.next  
  
  if hare == tortoise  
    return 'Loop Found'

<3> <selcted>
bool hasLoop(List* list)
{
  ListNode *hare = *tor = list->head;

  while( tor && hare = hare->next && hare = hare->next )
  {
    if( tor == hare )
      return true;

    tor = tor->next;
  }

  return false;
}

Tha above has errors and should be coded as below. Can you find where and why?

bool hasLoop(List* list)
{
  ListNode *tor = list->head;
  ListNode *hare = list->head;

  // note: do not use tor for updating hare
  while( tor && (hare = hare->next) && (hare = hare->next) )
  {
    if( tor == hare )   // single compare
      return true;

    // note: one step move
    tor = tor->next;
  }

  return false;
}


Irrespective of the shape of the cycle, one thing is clear - that the Tortoise can never catch up
with the Hare if there is no loop. If the two has to meet, the Hare has to catch up with the
Tortoise from behind.

With that established, consider the two possibilities

    Hare is one step behind Tortoise
    Hare is two step behind Tortoise

All greater distances will reduce to One or Two. Let us assume always Tortoise moves first  (it
could be even other way).

In the first case were the distance between Hare and Tortoise is one step. Tortoise moves one step
forward and the distance between Hare and Tortoise becomes 2. Now Hare moves 2 steps forward meeting
up with Tortoise.

In the second case were the distance between Hare and Tortoise is two steps. Tortoise moves one step
forward and the distance between Hare and Tortoise becomes 3. Now Hare moved 2 steps forward which
makes the distance between Hare and Tortoise as 1. It is similar to first case which we already
proved that both Hare and Tortoise will meet up in next step.

Let the length of the loop be 'n' and there are 'p' variables before the loop. Hare traverses the
loop twice in 'n' moves, they are guaranteed to meet in O(n).

<key>
The point is that there is a loop when hare meets tortoise and needs only single condition to
compare.


={{===========================================================================
*kt_dev_quiz_017* power of two

From google phone interview, quick calculation of 2^24.

2^10 = 10^3 = 1K
2^20 = 10^6 = 1000K = 1M = million
2^24 = 2^4 * 2^20 = 16M


={============================================================================
*kt_dev_quiz_018* linked list questions from {ref-004}

single-or-double

When you are dicussing a linked list in an interview, must understand whether it is a singly linked
list or a doubly linked list.

delete-a-node-in-a-list

Given a node n, find the previous node prev and set prev.next equal to n.next. If the list is doubly
linked, must also update n.next to set n.next.prev equal to n.prev. Also important to check for the
null pointer, to update the head or tail as necessary, or to do memory management.


<2-1> Write code to remove duplicates from an unsorted linked list. Follow up. How would you solve
this problem if a temporary buffer is not allowed?

A simple hash table will work well here. Simply iterate through the linked list, adding each element
to a hash table. When discover a duplicate element, remove the element and continue iterating. Can
do this all in one pass since we are using a linked list.

public static void deleteDups( LinkedListNode n )
{
	Hashtable table = new Hashtable();

	LinkedListNode prev = null;

	while( n != null )
	{
		if( table.containsKey(n.data))
		{
			prev.next = n.next;
		}
		else
		{
			table.put(n.data, true );
			prev = n;
		}

		n = n.next;
	}
}

This takes O(n) time. [KT] Can use stl::set and should delete duplicate node. 

If do not have a buffer, can iterate with two pointers; current which iterates through the linked
list, and runner which checks all subsequent nodes for duplicates.

public static void deleteDups( LinkedListNode head )
{
	if( head == null ) return;

	LinkedListNode current = head;

	while( current != null )
	{
		LinkedListNode runner = current;
		while( runner.next != null )
		{
			if( runner.next.data == current.data )
				runner.next = runner.next.next;
			else
				runner = runner.next;
		}

		current = current.next;
	}
}

This runs in O(1) space and O(n2) time. This is called [runner-technique] which is the second
pointer used in many linked list problems.


<2-2> Implement an algorithm to find the kth to last element of a singly linked list.

If the size of the linked list is known, the kth to last is the (length-k) th element. Just iterate
through the list to find this element. Because this solution is so trivial, we can almost be sure
that this is not what the interviewer intended. [KT] The solutions in this book looks odd and don't
get why since iterating through from the head is better and ture when do not know the size as when
know the size.


<2-3> Implement an algorithm to delete a node in the middle of a singly linked list, given only access
to that node.

You are not given the head of the list and only have access to that node. The solution is to copy
the data from the next node over to the current and delete the next node.

public static boolean deleteNode( LinkedListNode n ) {
	if( n == null || n.next == null )
		return false;

	LinkedListNode next = n.next;
	n.data = next.data;
	n.next = next.next;

	// must delete next;
	return true;
}

This connot solve if the node to be deleted is the last node since it do not have next. That is okay
as long as you can point that out. Can add a dummy node.


<2-4> Write a code to partition a linked list around a value x, such that all nodes less than x come
before all nodes greater than or equal to x.

If this were an array, be careful about how we shifted elements since array shift are very
expensive. However in a linked list the situation is much easier and can create two different linked
lists; before and after list. Once completed splitting and reached the end, merge the two list.

ListNode* partition( List* list, int x )
{
	ListNode* beforeStart = null;
	ListNode* beforeEnd = null;
	ListNode* afterStart = null;
	ListNode* afterEnd = null;

	ListNode* node = list->header;

	while(node != null)
	{
		// save next node
		ListNode* next = node->next;
		
		// break a link but not needed
		node->next = null;

		if( node->data < x )
		{
			// insert node into the before list
			if( beforeStart == null )
			{ beforeStart = node; beforeEnd = beforeStart; }
			else
			{ beforeEnd->next = node; beforeEnd = node; }
		}
		else
		{
			// insert node into the after list
			if( afterStart == null )
			{ afterStart = node; afterEnd = afterStart; }
			else
			{ afterEnd->next = node; afterEnd = node; }
		}

		node = next;
	}

	if( beforeStart == null )
		return afterStart;

	// merge before and after list
	beforeEnd->next = afterStart;
	return beforeStart;
}

If it bugs you to keep four different variables, can get rid of some with a minor hit to the
efficiency. This drop comes because have to traverse the list an extra time. The big-O time will
remain the same though and we get shorter and cleaner code. Instead of inserting nodes into the end
of list, inserts node into the front of them.

ListNode* partition( List* list, int x )
{
	ListNode* beforeStart = null;
	ListNode* afterStart = null;

	ListNode* node = list->header;

	while(node != null)
	{
		// save next node
		ListNode* next = node->next;
		
		if( node->data < x )
		{
			node->next = beforeStart;
			beforeStart = node;
		}
		else
		{
			node->next = afterStart;
			afterStart = node;
		}

		node = next;
	}

	if( beforeStart == null )
		return afterStart;

	// find end of before list and merge them
	ListNode* head = beforeStart;		// node = beforeStart; to use node variable.
	while( beforeStart->next != null )
		beforeStart = beforeStart.next;

	beforeStart->next = afterStart;
	return head;
}

[KT] Thought about modification of BST since it has the left which is less and the right which is
greater than node entry. For example, use fixed entry value of root and node either left or right.
Not recursive since need only the right and the left. After all, this has two pointers and is the
same as above. Also think {mergesort}


<2-5> You have two numbers represented by a linked list, where each node contains a single digit.
The digits are stored in reverse order, such that the 1's digit is at the head of the list. Write a
function that adds the two numbers and returns the sum as a linked list.

The book's approach is to use how addition works and can do this process recursively by adding node
by node, carrying over any excess to the next node.

 7 -> 1 -> 6 -> X
+5 -> 9 -> 2 -> X
------------
 2 -> 1 -> 9
 ----------> pass carry forward

Be careful to handle the condition when one list is shorter than another.

LinkedListNode addLists( LinkedListNode lone, LinkedListNode ltwo, int carry )
{
	// done if both lists are null and the carry is 0, no need to check on carry
	if( lone == null && ltwo == null && carry == 0 )
		return null;

	LinkdedListNode result = new LinkedListNode( carry, null, null );

	int value = carry;

	if( lone != null )
		value += lone.data;

	if( ltwo != null )
		value += ltwo.data;

	result.data = value % 10;
	
	if( lone != null || ltwo != null || value >= 10 )
	{
		LinkedListNode more = addLists( lone == null ? null : lone.next,
				ltwo == null ? null : ltwo.next,
				value >= 10 ? 1 : 0 );

		result.setNext(more);
	}

	return result;
}

<code-example>

#include <iostream>
#include <cstdlib>

typedef int ListEntry;

typedef struct node
{
	ListEntry 	entry;
	node*			pnext;
} ListNode;

typedef struct {
   int   count;
	ListNode*	header;
} List;

ListNode* MakeListNode( ListEntry entry )
{
	ListNode* pnode = NULL;

	if( (pnode = (ListNode*) malloc( sizeof(ListNode))) == NULL )
	{
		std::cout << "no more memory" << std::endl;
		return NULL;
	}

	pnode->entry = entry;
	pnode->pnext = NULL;

	return pnode;
}

void CreatList( List* list )
{ 
   list->count = 0;
   list->header = NULL; 
}	

bool ListEmpty( List* list )
{ return ( list->header == NULL ); }

// add only at the end
bool ListAdd( List* list, ListEntry entry )
{
	ListNode* pnode, *pend;

	if( (pnode = MakeListNode(entry)) == NULL )
	{
		std::cout << "add: mem is full" << std::endl;
		return false;
	}

   if( ListEmpty( list ) )
   {
      list->header = pnode;
   }
   else
   {
      for( pend = list->header; pend->pnext; pend = pend->pnext )
         ;

      pend->pnext = pnode;
   }

   list->count++;

   std::cout << "add: added " << entry << ", count " << list->count << std::endl;

	return true;
}

typedef void(*TRAVERSEFUNC)(ListEntry);	

void ListTraverse( List* list, TRAVERSEFUNC func)
{
	ListNode* pnode;

	if( ListEmpty(list) )
	{
		std::cout << "list is empty" << std::endl;
		return;
	}
	
	pnode = list->header;

	while(pnode)
	{
		func(pnode->entry);
		pnode = pnode->pnext;
	}
}

void EntryPrint(ListEntry item)
{
   std::cout << "item is: " << item << std::endl;
}

ListNode* sumLists( ListNode *one, ListNode *two, ListEntry carry )
{
	if( one == NULL && two == NULL )
		return NULL;

	ListNode* pnode = MakeListNode( carry );
	if(!pnode)
	{
		std::cout << "sumLists: mem is full" << std::endl;
		return NULL;
	}

	if( one != NULL )
		carry += one->entry;

	if( two != NULL )
		carry += two->entry;

	pnode->entry = carry % 10;

// This was an attempt to reduce one recursive call because the book's approach make a one last call
// when both input node is null. For example
//
// 1->2->X
// 3->4->5->X // here a call made to X on this list
//
// However, this cause a crash because when one of both is null, cannot use one->pnext or
// two->pnext.
//
// {LL} When use recursive, must careful about NULL and accessing data from NULL.
//
//	if( one->pnext != NULL || two->pnext != NULL )
//		pnode->pnext = sumLists( one->pnext, two->pnext, carry >= 10 ? 1 : 0 );
//

	if( one != NULL || two != NULL )
		pnode->pnext = sumLists( one == NULL ? NULL : one->pnext, two == NULL ? NULL : two->pnext, 
				carry >= 10 ? 1 : 0 );

	return pnode;
}

int main()
{
	int item = 0;

	// first
	List first;
	CreatList(&first);

	std::cout << "type in 2 numbers." << std::endl;

	for(int i=0; i < 2; i++)
	{
		std::cin >> item;
		ListAdd(&first, item );
	}		

	// second
	List second;
	CreatList(&second);

	std::cout << "type in 3 numbers." << std::endl;

	for(int i=0; i < 3; i++)
	{
		std::cin >> item;
		ListAdd(&second, item );
	}		

	std::cout << "first:" << std::endl;
	ListTraverse(&first, EntryPrint);

	std::cout << "=======" << std::endl;
	std::cout << "second:" << std::endl;
	ListTraverse(&second, EntryPrint);

	// sum
	List sum;
	CreatList(&sum);

	sum.header = sumLists( first.header, second.header, 0 );

	ListTraverse(&sum, EntryPrint);
}


[KT] If there is no need to build a list for a result, simply follow a list and build number and do
integer addition.

1's			10's			100's
10^0			10^1			10^2
node*10^0	node*10^1	node*10^2


<follow-up> Suppose the digits are stored in forward order. Repeat the above problem.

Two complications:

- One list may be shorter then the other. For example, 1->2->3->4 and 5->6->7. Need to know that the
5 should be matched with the 2, not the 1. How? Compare the length of the lists and pad the shorter
list with zeros.

- In the previous, the successive results were added to the tail, ie., passed carry forward. In this
case results are added to the head, ie., passed backward. This time recursive call must return the
carry as well. Can solve this by creating a wrapper class, PartialSum.


1 -> 2 -> 3 -> X
4 -> 5 -> 6 -> X
h
               sum
          sum+val+carry
     sum+val+carry
sum+val+carry

So PartialSums is one to pass backward sum and carry.


public class PartialSum {
	public LinkedListNode sum = null;
	public int carry = 0;
}

LinkedListNode padList( LinkedListNode l, int padding )
{
	LinkedListNode head = l;

	for( int i = 0; i < padding; i++ )
	{
		LinkedListNode n = new LinkedListNode( 0, null, null );
		// if it is single linked list 
		// head.prev = n;
		n.next = head;
		head = n;
	}
}

LinkedListNode insertBefore( LinkedListNode list, int data )
{
	LinkedListNode node = new LinkedListNode( data, null, null );

	if( list != null )
	{
		// list.prev = node;
		node.next = list;
	}

	return node;
}

// See how the recursive is used to start from the end node.
PartialSum addListsHelper( LinkedListNode l1, LinkedListNode l2 )
{
	if( l1 == null && l2 == null )
	{
		PartialSum sum = new PartialSum();
		return sum;
	}

	// add smaller digit recursively up to null
	PartialSum sum = addListsHelper( l1.next, l2.next );

	// add carry to current data
	int val = sum.carry + l1.data + l2.data;

	// insert sum of current digit. Initially, sum.sum is null.
	LinkedListNode full_result = insertBefore( sum.sum, val%10 );

	// return sum so far and the carry value
	sum.sum = full_result;
	sum.carry = val / 10;

	return sum;
}

// see that there is no carry arg
LinkedListNode addLists( LinkedListNode l1, LinkedListNode l2 )
{
	int len1 = length(l1); int len2 = length(l2);

	// pad the shorter list with zeros
	if( len1 < len2 )
		l1 = padList( l1, len2-len1);
	else
		l2 = padList( l2, len1-len2);

	PartialSum sum = addListsHelper( l1, l2 );

	if( sum.carry == 0 )
		return sum.sum;
	else
	{
		LinkedListNode result = insertBefore( sum.sum, sum.carry );
		return result;
	}
}

See have pulled insertBefore(), padList() into their own methods. This makes the code cleaner and
easier to read. Wise thing to do in your interview.


<2-6> Given a circular linked list, implement an algorithm which returns the node at the beginning
of the loop.

This is a modification of a classic interview problem: detect if a linked list has a loop. Let's
apply the pattern matching approach. See {tortoise-and-hare}. 


==============================================================================
*kt_dev_quiz_019*	array and string questions from {ref-004}

{1-4} Write a method to replace all spaces in a string with '%20'. You may assume that the string
has sufficient space at the end of the string to hold the additional characters, and that you are
given the 'true' length of the string.

EXAMPLE
input:   "Mr John Smith    "
output:  "Mr%20John%20Smith"

A common approach is to edit the string straight from the end and work backwards because we have
extra buffer at the end.

o If cannot use extra space and have to use input to edit, then use two pass approach like
reference. One pass to find out how many spaces are needed; this is new length. Two pass to replace
chars.

o If can use extra space then use one pass approach to copy and replace chars.

<ref-code>
public void replaceSpaces( char[] str, int length ) {

  int spaceCount = 0, newLength, i = 0;
  for( i = 0; i < length; i++ ) {
    if( str[i] == ' ' )
      spaceCount++;
  }

  newLength = length + spaceCount*2;

  str[newLength] = '\0';

  for( i = length-1; i >= 0; i-- )
  {
    if( str[i] == ' ' )
    {
      str[newLength-1] = '0'; 
      str[newLength-2] = '2'; 
      str[newLength-3] = '%'; 
      newLength = newLength-3;
    }
    else
    {
      str[newLength-1] = str[i];
      newLength = newLength-1;
    }
  }
}

{1-5} Implement a method to perform basic string compression using counts of repeated characters.
For example, the string aabcccccaaa would becomre a2b1c5a3. If the compressed string would not
become smaller than the original string, your method should return the original string.

<ref-code> poor
public String compressBad( String str )
{
  String mystr = "";
  char last = str.charAt(0);
  int count = 1;

  for( int i = 1; i < str.length(); i++ )
  {
    if( str.charAt(i) == last )
      count++;
    else
    {
      mystr += last + "" + count;   // why need ""?
      last = str.charAt(i);
      count = 1;
    }
  }

  // since the last sequence wouldn't be set in the compressed string yet.
  return mystr + last + count;
}

This does not handle the case when the compressed string is longer than the original string but it
otherwise works. Efficient? This is O(n + k^2) where k is the number of sequence because string
concatenation happens whenever there is a sequence and string + operates in O(n^2). See
{inefficient-concatnation}

<ref-code> better
String compressBetter(String str)
{
  // check if compression would create a longer string.
  int size = countCompression(str);
  if( size >= str.length())
    return str;

  StringBuffer mystr = new StringBuffer();
  char last = str.charAt(0);
  int count = 1;
  for( int i = 1; i < str.length(); i++ )
  {
    if( str.charAt(i) == last )
      count++;
    else
    {
      mystr.append(last);
      mystr.append(count);
      // mystr += last + "" + count;   // why need ""?
      last = str.charAt(i);
      count = 1;
    }
  }

  mystr.append(last);
  mystr.append(count);
  return mystr.toString();
}

int countCompression(String str)
{
  char last = str.charAt(0);
  int size = 0;
  int count = 1;

  for( int i = 1; i < str.length(); i++ )
  {
    if( str.charAt(i) == last )
      count++;
    else
    {
      last = str.charAt(i);
      size += 1 + String.valueOf(count).length();
      count = 1;
    }
  }
  
  // valueOf returns string representation of count since count could be big and needs more spaces
  // in character representation.
  //
  size += 1 + String.valueOf(count).length();
  return size;
}

This runs on O(n) space and time. If cannot use StringBuffer then create a char array.


={============================================================================
*kt_dev_quiz_020* coding task

For Kantar media, second phase after phone call and used via email.

The test is as follow. Please send the code and results to me within 24 hours if you can.

A sample daily viewing file called sample.SWD, which contains the following fields (start position,
character length).

·         Home ID (0,7)
·         Individual ID (7,2)
·         Channel ID (9,4) {the corresponding channel description is in StnDesc.txt}
·         Start time - hhmmss (13,6)
·         End time - hhmmss (19,6)
·         TV set ID (25,1)

- Please extract the viewing distribution (number of viewing statements) by minute and identify any
unusual patterns.

- Please find out the percentage of unmatched tuning (i.e. Channel ID 49) to the total tuning across
the whole day.

- Please find out the top 10 channels based on the volume of viewing.

<sample.swd>
10001340100491938001945591
10001340100491951002049591
10001340100492055002108591
10001340100492124002135591
10001340100492145002156591
10001340100492204002205591
10001340100492211002222591
10001340100492230002236591
10001340200491938001945591
10001340200491951002049591
10001340200492055002108591
10001340200492124002135591
10001340200492145002156591
...

<stndesc.txt>
1;BBC1 London
2;BBC2 London
3;ITV London
4;Pick TV
5;Dave
6;ITV2
7;ITV3
8;ITV4
9;Challenge TV
10;ITV2+1
11;E4
12;E4+1
...

<code-submitted>

#include <iostream>
#include <fstream>
#include <string>
#include <vector>
#include <map>

class viewEntry
{
  public:
    viewEntry(): viewCount(0), viewVolume(0), cid(0) {}
    unsigned int viewCount;
    unsigned long long viewVolume;
    unsigned int cid;
};

class Viewing
{
  private:
    const int MINUTES_A_DAY;
    unsigned int viewTotal;

    std::vector<int> minutes; 

    typedef std::map<unsigned int, viewEntry> VIEWS;
    VIEWS views;

    unsigned int _getMinutes(std::string time);
    void _countViews( unsigned int line, unsigned int start, unsigned int end );
    unsigned int _getPercent(unsigned int minute, unsigned int max);

  public:
    Viewing( std::ifstream &ifs );

    void getTop10();

    void getPercent(int channel);

    void getDistribution(unsigned int percent, unsigned int max);
};

// Note: Used 25 hours since the data have entries such as 25:59:59
Viewing::Viewing( std::ifstream &ifs ) : viewTotal(0), MINUTES_A_DAY(1560)
{
  unsigned int lineno = 0;
  std::string line, chname, cid, stime, etime;
  unsigned int icid = 0, istime = 0, ietime = 0;

  for(int i = 0; i <= MINUTES_A_DAY; i++)
    minutes.push_back(0);

  // build data
  while(std::getline( ifs, line))
  {
    cid = line.substr(9,4);
    stime = line.substr(13,6);
    etime = line.substr(19,6);

    icid = std::stoi(cid);
    istime = _getMinutes(stime);
    ietime = _getMinutes(etime);

    // handle invalid entries
    if( icid == 950 )
      continue;

    // build views map
    auto& entry = views[icid];
    entry.viewCount++; 
    entry.viewVolume += (ietime-istime);
    entry.cid = icid;

    // build distribution vector
    _countViews( lineno, _getMinutes(stime), _getMinutes(etime));

    lineno++;
  }
}

unsigned int Viewing::_getMinutes(std::string time)
{
  return std::stoi(time.substr(0,2))*60 + std::stoi(time.substr(2,2));
}

void Viewing::_countViews(unsigned int line, unsigned int start, unsigned int end)
{
  if(start > MINUTES_A_DAY || end > MINUTES_A_DAY)
  {
    std::cout << "countViews: error: time is out of a day limit. line: " << line << std::endl;
    return;
  }

  for(int idx = start+1; idx <= end; idx++)
  {
    minutes[idx] += 1;
  }
  
  viewTotal++;
}

unsigned int Viewing::_getPercent(unsigned int minute, unsigned int max)
{
  return (minutes[minute]*100 / max);
}

// Please find out the top 10 channels based on the volume of viewing
// Note: here assumes that this is rarely used and if not, need to consider having a running
// structure rather than a temporay.
void Viewing::getTop10()
{
  VIEWS::iterator views_it = views.begin();
  typedef std::map<int, int> VOLUMES;
  VOLUMES volumes;

  for(views_it; views_it != views.end(); ++views_it)
  {
    volumes[views_it->second.viewVolume] = views_it->second.cid;
  }

  int i = 0;
  VOLUMES::iterator volumes_it = volumes.end();
  for(--volumes_it, i; i < 10; i++)
  {
    std::cout << i+1 << "th channel is " << (*volumes_it).second << std::endl;
    --volumes_it;
  }
}

// Please find out the percentage of unmatched tuning (i.e. Channel ID 49) to the total tuning across the whole day.
void Viewing::getPercent(int channel)
{
  auto& entry = views[channel];
  double result = (entry.viewCount*100/viewTotal);
  std::cout << "The channel " << channel << " has " << result << " % in total" << std::endl;
}


// Please extract the viewing distribution (number of viewing statements) by minute and identify any unusual patterns.
// Note: Assumes that viewing distribution means that the number of viewes in a specific minute and
// that it is unusal when it is over the specified percentage in the scaled down space. Here used
// 50% and 4000 as a max.
void Viewing::getDistribution(unsigned int percent, unsigned int max)
{
  for(unsigned int i = 1; i <= MINUTES_A_DAY; i++)
  {
    unsigned int scaled_percent = 0;

    if( (scaled_percent = _getPercent(i, max)) > percent )
      std::cout << i << " minutes has " << scaled_percent << " % viewers in the scaled-down space."  << std::endl;
  }
}

// Note: Generally no error handling, design, and space/time cosideration since no requirement was given. Aim
// to get the answer and to run in a rather quick fashion since was told it's about 30 minute task. 
int main()
{
  std::string line;
  int lnum = 0;
  std::ifstream ifs("sample.SWD", std::ifstream::in );

  if( ifs.is_open() )
  {
    Viewing view(ifs);

    std:: cout << "==================================================" << std::endl;
    std:: cout << "Q 01" << std::endl;
    std:: cout << "==================================================" << std::endl;
    view.getTop10();
    std:: cout << "==================================================" << std::endl;
    std:: cout << "Q 02" << std::endl;
    std:: cout << "==================================================" << std::endl;
    view.getPercent(49);
    std:: cout << "==================================================" << std::endl;
    std:: cout << "Q 03" << std::endl;
    std:: cout << "==================================================" << std::endl;
    view.getDistribution(50, 4000);

    ifs.close();
  }
  else
    std:: cout << "file is not opened" << std::endl;
}

// <The output from a run>
// ==================================================
// Q 01
// ==================================================
// 1th channel is 49
// 2th channel is 52
// 3th channel is 45
// 4th channel is 3
// 5th channel is 1
// 6th channel is 2
// 7th channel is 96
// 8th channel is 69
// 9th channel is 73
// 10th channel is 67
// ==================================================
// Q 02
// ==================================================
// The channel 49 has 35 % in total
// ==================================================
// Q 03
// ==================================================
// 1211 minutes has 51 % viewers in the scaled-down space.
// 1213 minutes has 51 % viewers in the scaled-down space.
// 1214 minutes has 51 % viewers in the scaled-down space.
// 1216 minutes has 51 % viewers in the scaled-down space.
// 1217 minutes has 51 % viewers in the scaled-down space.
// 1218 minutes has 51 % viewers in the scaled-down space.
// 1219 minutes has 52 % viewers in the scaled-down space.
// 1220 minutes has 51 % viewers in the scaled-down space.
// 1221 minutes has 51 % viewers in the scaled-down space.
// 1222 minutes has 52 % viewers in the scaled-down space.
// 1223 minutes has 51 % viewers in the scaled-down space.
// 1224 minutes has 52 % viewers in the scaled-down space.
// 1225 minutes has 51 % viewers in the scaled-down space.
// 1226 minutes has 51 % viewers in the scaled-down space.
// 1227 minutes has 51 % viewers in the scaled-down space.
// 1231 minutes has 51 % viewers in the scaled-down space.
// 1232 minutes has 52 % viewers in the scaled-down space.
// 1233 minutes has 52 % viewers in the scaled-down space.
// 1234 minutes has 53 % viewers in the scaled-down space.
// 1235 minutes has 53 % viewers in the scaled-down space.
// 1236 minutes has 52 % viewers in the scaled-down space.
// 1237 minutes has 52 % viewers in the scaled-down space.
// 1238 minutes has 52 % viewers in the scaled-down space.
// 1239 minutes has 53 % viewers in the scaled-down space.
// 1240 minutes has 52 % viewers in the scaled-down space.
// 1241 minutes has 53 % viewers in the scaled-down space.
// 1242 minutes has 53 % viewers in the scaled-down space.
// 1243 minutes has 53 % viewers in the scaled-down space.
// 1244 minutes has 53 % viewers in the scaled-down space.
// 1245 minutes has 53 % viewers in the scaled-down space.
// 1246 minutes has 53 % viewers in the scaled-down space.
// 1247 minutes has 53 % viewers in the scaled-down space.
// 1248 minutes has 53 % viewers in the scaled-down space.
// 1249 minutes has 53 % viewers in the scaled-down space.
// 1250 minutes has 54 % viewers in the scaled-down space.
// 1251 minutes has 53 % viewers in the scaled-down space.
// 1252 minutes has 53 % viewers in the scaled-down space.
// 1253 minutes has 53 % viewers in the scaled-down space.
// 1254 minutes has 54 % viewers in the scaled-down space.
// 1255 minutes has 52 % viewers in the scaled-down space.
// 1257 minutes has 52 % viewers in the scaled-down space.
// 1258 minutes has 52 % viewers in the scaled-down space.
// 1262 minutes has 51 % viewers in the scaled-down space.
// 1263 minutes has 51 % viewers in the scaled-down space.
// 1264 minutes has 53 % viewers in the scaled-down space.
// 1265 minutes has 52 % viewers in the scaled-down space.
// 1266 minutes has 53 % viewers in the scaled-down space.
// 1267 minutes has 53 % viewers in the scaled-down space.
// 1268 minutes has 53 % viewers in the scaled-down space.
// 1269 minutes has 54 % viewers in the scaled-down space.
// 1270 minutes has 54 % viewers in the scaled-down space.
// 1271 minutes has 54 % viewers in the scaled-down space.
// 1272 minutes has 54 % viewers in the scaled-down space.
// 1273 minutes has 54 % viewers in the scaled-down space.
// 1274 minutes has 54 % viewers in the scaled-down space.
// 1275 minutes has 55 % viewers in the scaled-down space.
// 1276 minutes has 54 % viewers in the scaled-down space.
// 1277 minutes has 54 % viewers in the scaled-down space.
// 1278 minutes has 54 % viewers in the scaled-down space.
// 1279 minutes has 54 % viewers in the scaled-down space.
// 1280 minutes has 54 % viewers in the scaled-down space.
// 1281 minutes has 54 % viewers in the scaled-down space.
// 1282 minutes has 55 % viewers in the scaled-down space.
// 1283 minutes has 55 % viewers in the scaled-down space.
// 1284 minutes has 54 % viewers in the scaled-down space.
// 1285 minutes has 54 % viewers in the scaled-down space.
// 1286 minutes has 54 % viewers in the scaled-down space.
// 1287 minutes has 54 % viewers in the scaled-down space.
// 1288 minutes has 55 % viewers in the scaled-down space.
// 1289 minutes has 54 % viewers in the scaled-down space.
// 1290 minutes has 54 % viewers in the scaled-down space.
// 1291 minutes has 53 % viewers in the scaled-down space.
// 1292 minutes has 53 % viewers in the scaled-down space.
// 1293 minutes has 54 % viewers in the scaled-down space.
// 1294 minutes has 54 % viewers in the scaled-down space.
// 1295 minutes has 54 % viewers in the scaled-down space.
// 1296 minutes has 54 % viewers in the scaled-down space.
// 1297 minutes has 54 % viewers in the scaled-down space.
// 1298 minutes has 52 % viewers in the scaled-down space.
// 1299 minutes has 53 % viewers in the scaled-down space.
// 1300 minutes has 53 % viewers in the scaled-down space.
// 1301 minutes has 53 % viewers in the scaled-down space.
// 1302 minutes has 53 % viewers in the scaled-down space.
// 1303 minutes has 53 % viewers in the scaled-down space.
// 1304 minutes has 53 % viewers in the scaled-down space.
// 1305 minutes has 53 % viewers in the scaled-down space.
// 1306 minutes has 53 % viewers in the scaled-down space.
// 1307 minutes has 53 % viewers in the scaled-down space.
// 1308 minutes has 53 % viewers in the scaled-down space.
// 1309 minutes has 52 % viewers in the scaled-down space.
// 1310 minutes has 53 % viewers in the scaled-down space.
// 1311 minutes has 52 % viewers in the scaled-down space.
// 1312 minutes has 52 % viewers in the scaled-down space.
// 1313 minutes has 52 % viewers in the scaled-down space.
// 1314 minutes has 53 % viewers in the scaled-down space.
// 1315 minutes has 52 % viewers in the scaled-down space.
// 1316 minutes has 52 % viewers in the scaled-down space.
// 1317 minutes has 52 % viewers in the scaled-down space.


={============================================================================
*kt_dev_quiz_021* BB questions

From TEKSystem for BB.

{01}
Technical:

- What is polymorphism?

- Give an example of usage of virtual functions.

- How are virtual functions implemented?

- How many vTables are there?

- What is a deadlock?

- How would you prevent a deadlock?

- Can you give an example for a deadlock that isn't due to mutual locks?

- What Versions of C++ did you use?

- Do you know what's changed in C++11?

- What types of STL containers do you know?

- What is the insertion complexity for a vector?

- What types of iterators are there?

- What's the difference between a forward and random access iterator?

- Do you know what static polymorphism is?

- (After explaining) How would you implement it?

- What are C++ Traits?

- Any experience with JavaScript?

- Any experience with Boost? 

Logical:
You have 3 baskets, one with apples, one with oranges and one with both apples and oranges mixed.
Each basket is closed and is labeled with 'Apples', 'Oranges' and 'Apples and Oranges'. However,
each of these labels is always placed incorrectly. How many fruits would you need to pick from
the baskets in order to place the labels correctly on all the baskets?

<answer>
http://www.mytechinterviews.com/apples-and-oranges

These kinds of questions make for a good warm up in an interview. Frankly speaking, this puzzle just
needs a little thought. It really doesn't take any algorithmic genius.

Say you pick a fruit from the basket labeled 'Apples and Oranges'. If this fruit is an apple, then
we know that since the label is incorrect, this basket only contains apples. Now that we've
determined that the basket marked as 'Apples and Oranges' only contains apples, we can figure out
what the other baskets contain. 

If we look at the basket labeled as 'Oranges', we know that since the label is incorrect, this
basket either has only apple in it or has both apples and oranges.  Since we've already established
that the basket labeled 'Apples and Oranges' contains only apples, we know that the basket labeled
as 'Oranges' contains both apples and oranges.

Then by simple process of 'elimination', we know that the basket labeled as 'Apples' contains only
oranges.

You can apply the same logic if you assume you picked an orange from the basket labeled as 'Apples
and Oranges'.

note: the key is "each of these labels is always placed incorrectly" and the answer 1.


{02}
About yourself

1. Tell about your work experience

2. Why you left the company?

3. What do you anticipate in Bloomberg?

Technical questions

1. What is a virtual function?

2. How does it work (inner mechanism)?

3. Compare sorted vector and sorted list

4. Complexity of inserting of an element in a vector and in a list

5. What is RAII (Resource Acquisition Is Initialization) technique?

6. Which patterns of programming do you know?

7. How the singleton pattern can be implemented?

8. Why it can be wrong to use it?

9. What is deadlock and how it can be prevented?

Logical task
There are 4 people who want to go across the bridge. Bridge is strength enough to carry not more
than 2 people at the time. People need a torch to cross the bridge, the torch is only one. The first
man goes across the bridge for 1 minute, the second for 2 minutes, the third for 5 minutes, the
forth for 10 minutes. What is the fastest way for all people to get to another side of the river?


Move                             Time
(1) & (2) Cross with Torch       2
(1) Returns with Torch           1
(5) & (10) Cross with Torch      10
(2) Returns with Torch           2
(1) & (2) Cross with Torch       2
                                 17


Out Of The Box Thinking
Eric Bowman E-Mailed me with a 10 minute solution. The solution is to have Dave(10) carry the torch
and begin to cross with any of the others lets say Adam(1). Each continues at their own pace so in 1
minute Adam has reached the other side and one of the others can begin to cross say Bob(2), when he
reaches the other side Clair(5) can begin to cross. Adam, Bob & Clair will be done in 8 minutes and
Dave will be done in a further 2.

This solution satisfies the criteria that there are never more than 2 people on the bridge and the
torch is always on the bridge whilst someone is crossing. So in that sense it is a neat solution. I
personally don't think that this is the solution intended, not least because the question
specifically asks you to show it can be done in 17 minutes but also because I believe the torch or
flashlight is intended to bind the traveling pairs together. Always with these puzzles it is a
matter of extracting the logic of the puzzle from the more verbose real world metaphor and that is
my interpretation. However, if you regard these questions as interview preparation then an
understanding of the 10 minute argument can do you no harm at all. 


{03}
Example revision questions

- what is your background / experience ?

- why would you find another job?

- why Bloomberg?

- what do you know about Bloomberg ?

- what do you expect from a job at Bloomberg ?

technical questions :

- what is a pointer  ?

- what is it useful for ?

- what are the differents types of memory ? 
note: assume it's not about hardware.

- what is dynamic allocation ?

- what are the differences of dynamic allocation between C and C++ ?
C malloc() and free() do not call constructors or destructors. C++ new and delete operators are
"class aware" and will call class constructors when a class is allocated with new and a destructor
when delete is called.

Mixing malloc with delete or new with free is undefined. In addition, C++ new and delete operators
were introduced with the C++ practice of allocating memory in constructors and deallocating the same
memory with a destructor.

new/delete advantages:

new/delete invokes constructor/destructor. Malloc/free will not.
new does not need typcasting. Malloc requires typcasting the returned pointer.
new/delete operators can be overloaded, malloc/free can not.
new does not require you to explicitly calculate the quantity of memory required. (Unlike malloc)

- what is the risk of dynamic allocation ?

- how memory leaks can occur?

- if an object is allocated by a new at the beginning of a function, and freed by a delete at the
end of it, is it possible to have memory leaks, and why ?

- how this could be avoided?

- why it is no safe to throw exceptions in a destructor ?

- what happen if an exception is thrown by a destructor while another exception is being processed
(stack unwinding) ?

- how can be implemented a smart pointer with a reference counter?

- do you use STL ?

- what is the complexity of a search in a map container ?

- what is the complexity of a search in a hash table ?

- what is a collision in a hash table?

- is it better to handle collisions in hash tables using lists or vectors?

- what are the differences between multi-threads and multi-processes ?

- what is virtual memory?


# ============================================================================
#{ PROBLEM SLOVING

1. check array or vector input size.
2. use -1 for a error return.
3. 

={============================================================================
*kt_dev_quiz_100* codility: equilibrium index of a sequence

The equilibrium index of a sequence is an index such that the sum of elements at lower indexes is
equal to the sum of elements at higher indexes. For example, in a sequence A:

A[0]=-7 A[1]=1 A[2]=5 A[3]=2 A[4]=-4 A[5]=3 A[6]=0    [-7, 1, 5, 3, -4, 3, 0]

3 is an equilibrium index, because: A[0]+A[1]+A[2]=A[4]+A[5]+A[6]

6 is also an equilibrium index, because: A[0]+A[1]+A[2]+A[3]+A[4]+A[5]=0 (The sum of zero elements
is zero) 

7 is not an equilibrium index - because it is not a valid index of sequence A. If you still have
doubts, here is a precise definition: 

The integer k is an equilibrium index of a sequence A[0],A[1]..,A[n-1] if and only if 0<= k and
sum(A[0..(k-1)])=sum(A[(k+1)..(n-1)]). Assume the sum of zero elements is equal to zero.

Write a function

int equi(int A[], int n);

that, given a sequence, returns its equilibrium index (any) or -1 if no equilibrium index exists.
Assume that the sequence may be very long. 

The problem can be solved by using various approaches, the most common being simply to follow the
equilibrium definition:

// while moving index, continues to sum right and left sum.
//
int equi ( int A[], int n ) {

  int k, m, lsum, rsum; 

  for(k = 0; k < n; ++k) { 
    lsum = 0; rsum = 0;
    for(m = 0; m < k; ++m) lsum += A[m]; 
    for(m = k + 1; m < n; ++m) rsum += A[m];  
    if (lsum == rsum) return k;
  } 
  return -1; 
} 

Unfortunately, this approach has two disadvantages:

o it fails on large input data sets, since the time complexity is O(n2)
o it fails on large input values (for example if the input array contains values like MIN/MAX_INT)
due to the arithmetic overflows

We can fix the first problem with a better algorithm, and the second problem with a better data-type
(for example, using long long type instead of int for sum computations). The key observation for
better running time is to update the left/right sums in constant time instead of recomputing them
from the scratch. O(n)

<code-example>
int equi(int arr[], int n) {

  if (n==0) return -1; 

  long long sum = 0;
  int i; 

  for(i=0;i<n;i++) sum+=(long long) arr[i]; 

  long long sum_left = 0;    

  for(i=0;i<n;i++) {
    long long sum_right = sum - sum_left - (long long) arr[i];

    if (sum_left == sum_right)
      return i;

    sum_left += (long long) arr[i];
  } 

  return -1; 
} 

<code> wrong
This is what I wrote when try to implement the point above and this is wrong. This shows that
requires careful reading of question since equilibrium index is not part of both sum.

      [0] [ ] [ ] ... [ ]
   ->     <------------->
   lsum   rsum

      [0] [1] [ ] ... [ ]
   ----->     <------------->
   lsum   rsum

      [0] [1] [2] [3] ... [ ]
   --------->     <------------->
   lsum   rsum

int equi(int arr[], int n) 
{
  if (n==0) return -1; 

  long long rsum = 0, lsum = 0;

  for(int i=0;i<n;i++) rsum +=(long long) arr[i]; 

  for(int i=0;i<n;i++) {
    rsum -= arr[i];
    lsum += arr[i];

    if ( lsum == rsum )
      return i;
  } 

  return -1; 
} 

<code>
#include <iostream>

int tequi( int A[], int n )
{
  if( !n || !A )
    return -1;

  long long sum = 0, rsum = 0, lsum = 0;

  for(int i=0; i<n; i++)
    sum += A[i];

  for(int i=0; i<n; i++)
  {
    rsum = sum - lsum - A[i];

    if( lsum == rsum )
      return i;

    lsum += A[i];
  }
}

int main()
{
  int arr[] = {-7, 1, 5, 3, -4, 3, 0};

  int ret = tequi( arr, sizeof(arr)/sizeof(int) );

  std::cout << ret << std::endl;

  return 0;
}

<code>
int tequi( int A[], int n )
{
  if( !n || !A )
    return -1;

  long long rsum = 0, lsum = 0;

  for(int i=0; i<n; i++)
    rsum += A[i];

  for(int i=0; i<n; i++)
  {
    rsum -= A[i];

    if( lsum == rsum )
      return i;

    lsum += A[i];
  }
}


={============================================================================
*kt_dev_quiz_101* codility: TapeEquilibrium 
https://codility.com/train/

<description> note when choose C++
A non-empty zero-indexed array A consisting of N integers is given. Array A represents numbers on a
tape.

Any integer P, such that 0 < P < N, splits this tape into two non-empty parts: 
A[0], A[1], ..., A[P - 1] and A[P], A[P + 1], ..., A[N - 1].

The difference between the two parts is the value of: 
|(A[0] + A[1] + ... + A[P - 1]) - (A[P] + A[P + 1] + ... + A[N - 1])|

In other words, it is the absolute difference between the sum of the first part and the sum of the
second part.

For example, consider array A such that:

  A[0] = 3
  A[1] = 1
  A[2] = 2
  A[3] = 4
  A[4] = 3

We can split this tape in four places:

  P = 1, difference = |3 - 10| = 7
  P = 2, difference = |4 - 9| = 5
  P = 3, difference = |6 - 7| = 1
  P = 4, difference = |10 - 3| = 7

Write a function:

int solution(vector<int> &A);

that, given a non-empty zero-indexed array A of N integers, returns the minimal difference that can
be achieved.

For example, given:

  A[0] = 3
  A[1] = 1
  A[2] = 2
  A[3] = 4
  A[4] = 3

the function should return 1, as explained above.

Assume that:

N is an integer within the range [2..100,000];
each element of array A is an integer within the range [-1,000..1,000].

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(N), beyond input storage (not counting the storage
required for input arguments).

Elements of input arrays can be modified.

you can also use includes, for example:
#include <algorithm>


<code>
#include <iostream>
#include <climits>
 
int solution(vector<int> &A) 
{
  // write your code in C++98
  if( !A.size() )
    return -1;

  long long sum = 0, rsum = 0, lsum = 0;
  int cmin = INT_MAX;

  for(int i=0; i<A.size(); i++)
    sum += A[i];

  lsum = A[0];

  // note: it is okay to use (n-1)th to calc lsum since not used anyway.
  for(int i=1; i<A.size(); i++)
  {
    rsum = sum - lsum;

    // cmin = abs cause warning of possible loss since assign from long long to int.
    if( abs(lsum-rsum) < cmin )
      cmin = abs(lsum-rsum);

    lsum += A[i];
  }

  return cmin;
}

<code>
#include <iostream>
#include <vector>

using namespace std;

int solution(vector<int> &A)
{
  if(!A.size())
    return -1;

  long long tsum = 0;

  for(unsigned int i=0; i < A.size(); i++)
    tsum += A[i];

  long long rsum = 0, lsum = 0;
  int runabs = INT_MAX, curabs = 0;

  for(unsigned int i=0; i < A.size()-1; i++)
  {
    lsum += A[i];
    rsum = tsum - lsum;

    curabs = abs(lsum-rsum);

    if(runabs > curabs)
      runabs = curabs;
  }

  return runabs;
}

int _tmain(int argc, _TCHAR* argv[])
{
  vector<int> ivec;

  ivec.push_back(3);
  ivec.push_back(1);
  ivec.push_back(2);
  ivec.push_back(4);
  ivec.push_back(3);

  cout << "return: " << solution(ivec) << endl;

  return 0;
}


={============================================================================
*kt_dev_quiz_102* codility: absolute distinct count of this array

A non-empty zero-indexed array A consisting of N numbers is given. The absolute distinct count of
this array is the number of distinct absolute values among the elements of the array.

For example, consider array A such that:

A[0] = -5    A[1] = -3    A[2] = -1
A[3] =  0    A[4] =  3    A[5] =  6

The absolute distinct count of this array is 5, because there are 5 distinct absolute values among
the elements of this array, namely 0, 1, 3, 5 and 6.

Write a function:

int absDistinct(int A[], int N);

that, given a non-empty zero-indexed array A consisting of N numbers, returns absolute distinct
count of array A.

For example, given array A such that:

A[0] = -5    A[1] = -3    A[2] = -1
A[3] =  0    A[4] =  3    A[5] =  6

the function should return 5, as explained above.

Assume that:

N is an integer within the range [1..100,000]; each element of array A is an integer within the
range [-2,147,483,648..2,147,483,647]; array A is sorted in non-decreasing order.

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(N), beyond input storage (not counting the storage
required for input arguments).

Elements of input arrays can be modified.

<cpp-version>
See that abs is not defined.

#include <iostream>
#include <algorithm>
#include <vector>
#include <set>

using namespace std;

bool absLessThan(int a, int b)
{
  return abs(a) < abs(b);
}

bool absEqual(int a, int b)
{
  return abs(a) == abs(b);
}

int absDistinct(int A[], int N)
{
  if(N==0)
    return -1;

  vector<int> ivec;
  int count = 0;

  for(int i = 0; i < N; ++i)
    ivec.push_back( *(A+i) );

  sort( ivec.begin(), ivec.end(), absLessThan );
  auto it_end_unique = unique( ivec.begin(), ivec.end(), absEqual );

  auto it_begin = ivec.begin();

  while( it_begin != it_end_unique )
  {
    ++it_begin;
    ++count;
  }

  return count;
}

<cpp-version>
int absDistinct_set(int A[], int N)
{
  if(N==0)
    return -1;

  set<int> iset;

  for(int i = 0; i < N; ++i)
    iset.insert( abs(*(A+i)) );

  return iset.size();
}

int _tmain(int argc, _TCHAR* argv[])
{
  int iarray[] = {-5, -3, -1, 0, 3, 6};

  int ret = absDistinct(iarray, 6);
  cout << ret << endl;

  ret = absDistinct_set(iarray, 6);
  cout << ret << endl;

  return 0;
}

<cpp-version>
https://codility.com/train/AbsDistinct 

#include <set>

int solution(const vector<int> &A) {
    // write your code in C++98
    int size = A.size();
    
    if( !size )
        return -1;
        
    std::set<int> iset;
    
    for( int i = 0; i <  size; i++ )
        iset.insert( abs(A[i]) );
        
    return iset.size();
}

Test score: 100% 100 out of 100 points 
Detected time complexity: O(N) or O(N*log(N))
  
{Q} How to implement it using c? 2014.02. How about running the modified binary search that use abs
comparison on each item? May be nlogn? That may be the same as set version?

2014.04.12. cannot use binary search since when move index from the start, no way to set bottom and
top.

i = 0, bs(1, n-1)
i = 1, bs(2, n-1)    // missing 0th.
...

So shall use data structures to put inputs like set. or BST?


={============================================================================
*kt_dev_quiz_103* codility: how much water between walls?

From online: http://qandwhat.runkite.com/i-failed-a-twitter-interview/

<question>
"Consider the following picture:"
              _ _
7             7 7 _
6   _         # # 6
5   5         # # #
4   #       4 # # #
3 _ #     3 # # # #
2 2 #   2 # # # # #
1 # # 1 # # # # # #
  -----------------
  0 1 2 3 4 5 6 7 8

In this picture we have walls of different heights. This picture is represented by an array of
integers, where the value at each index is the height of the wall. The picture above is represented
with an array as [2,5,1,2,3,4,7,7,6].

Now imagine it rains. How much water is going to be accumulated in puddles between walls?
              _ _
7             7 7 _
6   _         # # 6
5   5 * * * * # # #
4   # * * * 4 # # #
3 _ # * * 3 # # # #
2 2 # * 2 # # # # #
1 # # 1 # # # # # #
  -----------------
  0 1 2 3 4 5 6 7 8

We count volume in square blocks of 1X1. So in the picture above, everything to the left of index 1
spills out. Water to the right of index 7 also spills out. We are left with a puddle between 1 and 6
and the volume is 10. 

<KT> 2014.04.12. Initial thought by drawings is that
1. only have waters when there is down-and-up, i.e., 5-1-2. 
2. there are as many as down-and-ups in a array. 
3. when goes down including the start from 0 index, set the hightest.
4. when goes up, check with the previous heightest to see which is less than, then there is water up
to the less on hight.

This has the same flaw as the author's initial try has since only get the part.

The first thing I tried to do was to figure out how much water we would have at any given index.
This stroke a resemblance with Calculus and integrals, so I immediately remembered that looking for
local maximums could be of use. And indeed, in the picture above, the water above index 2 is bounded
by the smaller of the two surrounding maximums at index 1 and 6. 

I was thinking out loud: "What if we found all the local maximums, and filled in water between them.
Would that work?"

"Yeah, that should work" replied Justin.

So I went ahead and coded this solution. Then Justin asked me for a bunch of test cases which I
provided. All the test cases we talked about seemed to work.

"Do you have questions for me?" Justin asked. "How did I do?" "Reasonably well. Your solution does 2
passes, but there is a more interesting one that does only 1"

The second I hung up I realized my solution was wrong. Think about this input:

[2, 5, 1, 3, 1, 2, 1, 7, 7, 6]

<this-is-flaw>
My solution solved between the local maximums and looked like this: 

7               # # _
6   _           # # #
5   #           # # #
4   #           # # #
3 _ # * #       # # #
2 # # * # * # * # # #
1 # # 1 # # # # # # #
  --------------- ---
  0 1 2 3 4 5 6 7 7 8

But the result should have been one puddle between the two taller towers: 

7               # # _
6   _           # # #
5   # * * * * * # # #
4   # * * * * * # # #
3 _ # * # * * * # # #
2 # # * # * # * # # #
1 # # 1 # # # # # # #
  --------------- ---
  0 1 2 3 4 5 6 7 7 8

Now I ask myself: what have I learned from this? Realistically - not much. I am upset that the
interviewer didn't ask me the right questions to guide me towards the right train of thought. I
don't know why Justin told me "this should work," when my solution in fact didn't. I know that this
should have come up in the test cases he asked for, but since I missed the flaw when coming up with
the algorithm, I didn't think of testing for it. 

The logic is as follows:

If we traverse the list from left to right, the amount of water at each index is at most the largest
value we have discovered so far. That means that if we knew for a fact that there is something
larger or equal to it somewhere on the right, we would know exactly how much water we can hold
without spilling. Same goes for traversing in the opposite direction: if we know we have found
something larger on the left than the largest thing on the right, we can safely fill up water.

With this in mind, one solution would be to first find the absolute maximum value, traverse from the
left to the maximum, and then traverse from the right to the maximum. This solution does 2 passes:
one to find the maximum, and the other is split into two subtraversals.

<two-pass-beg> Why two pass? For one pass, find the first high and see if there is larger or equal to
it. The calculate the water between two points. But if not find larger or equal to it then? More
than two pass? Need to loop in the first pass? This could be difficult since if the first high do
not have the larger or equal to it in the list then need to try the second high and so on.

No. This approach is to find the max in the list and have two traversals to the max. 

left ...              max ... right
sum towards to max -> *
                        <- sum towards to max

So one pass to find the max ine list and two pass to sum waters.
<two-pass-end> 

The solution in one pass (shown in the gist) avoids finding the maximum value by moving two pointers
from the opposite ends of the array towards each other. If the largest value found to the left of
the left pointer is smaller than the largest value found to the right of the right pointer, then
move the left pointer one index to the right. Otherwise move the right pointer one index to the
left. Repeat until the two pointers intersect. This is a wordy explanation, but the code is really
simple.

class Ideone
{
  public static void main (String[] args) throws java.lang.Exception
  {
    int[] myIntArray = {2, 5, 1, 2, 3, 4, 7, 7, 6};
    System.out.println(calculateVolume(myIntArray));
  }

  public static int calculateVolume(int[] land) {
    int leftMax = 0;
    int rightMax = 0;
    int left = 0;
    int right = land.length - 1;
    int volume = 0;

    while(left < right) {

      // update current max for left and right.
      if(land[left] > leftMax) {
        leftMax = land[left];
      }
      if(land[right] > rightMax) {
        rightMax = land[right];
      }

      // decide to which direction it start to sum. Should from the lesser. If equals, from right
      // but do not matter when start from left.
      if(leftMax >= rightMax) {
        volume += rightMax - land[right];
        right--;
      } else {
        volume += leftMax - land[left];
        left++;
      }
    }

    return volume;
  }
}

<code> vc cpp version
#include <iostream>
#include <vector>

using namespace std;

int solution(vector<int> &A)
{
  if(!A.size())
    return -1;

  int left=0, leftmax=0, right=0, rightmax=0, volume=0;

  left = 0; right = A.size()-1;

  while( left < right )
  {
    // update each max
    if( leftmax < A[left] )
      leftmax = A[left];

    if( rightmax < A[right] )
      rightmax = A[right];

    // when leftmax is bigger, calc and decrease right
    if( leftmax >= rightmax )
    {
      volume += rightmax - A[right];
      right--;
    }
    else
    {
      volume += leftmax - A[left];
      left++;
    }
  }

  return volume;
}

int _tmain(int argc, _TCHAR* argv[])
{
  vector<int> coll1, coll2;

  // coll1 = {2,5,1,2,3,4,7,7,6};
  coll1.push_back(2);
  coll1.push_back(5);
  coll1.push_back(1);
  coll1.push_back(2);
  coll1.push_back(3);
  coll1.push_back(4);
  coll1.push_back(7);
  coll1.push_back(7);
  coll1.push_back(6);

  cout << "coll1 volume : " << solution(coll1) << endl;

  // coll2 = {2,5,1,3,1,2,1,7,7,6};
  coll2.push_back(2);
  coll2.push_back(5);
  coll2.push_back(1);
  coll2.push_back(3);
  coll2.push_back(1);
  coll2.push_back(2);
  coll2.push_back(1);
  coll2.push_back(7);
  coll2.push_back(7);
  coll2.push_back(6);

  cout << "coll2 volume : " << solution(coll2) << endl;

  return 0;
}

<code> gcc cpp version
#include <iostream>
#include <vector>

using namespace std;

int solution(vector<int> &A)
{
  if(!A.size())
    return -1;

  int left{}, leftmax{}, right{}, rightmax{}, volume{};

  left = 0; right = A.size()-1;

  while( left < right )
  {
    // update each max
    if( leftmax < A[left] )
      leftmax = A[left];

    if( rightmax < A[right] )
      rightmax = A[right];

    // when leftmax is bigger, calc and decrease right
    if( leftmax >= rightmax )
    {
      volume += rightmax - A[right];
      right--;
    }
    else
    {
      volume += leftmax - A[left];
      left++;
    }
  }

  return volume;
}

int main()
{
  vector<int> coll1, coll2;

  coll1 = {2,5,1,2,3,4,7,7,6};
  cout << "coll1 volume : " << solution(coll1) << endl;

  coll2 = {2,5,1,3,1,2,1,7,7,6};
  cout << "coll2 volume : " << solution(coll2) << endl;

  return 0;
}

coll1 volume : 10
coll2 volume : 17

<key>
1. should move the less max towards the bigger max while doing sum.
2. should have equal case in one of max comparisons since shall cover when both max is the same.


={============================================================================
*kt_dev_quiz_104* codility: frog jump

A small frog wants to get to the other side of the road. The frog is currently located at position X
and wants to get to a position greater than or equal to Y. The small frog always jumps a fixed
distance, D.

Count the minimal number of jumps that the small frog must perform to reach its target.

Write a function:

int solution(int X, int Y, int D); 

that, given three integers X, Y and D, returns the minimal number of jumps from position X to a
position equal to or greater than Y.

For example, given:

  X = 10
  Y = 85
  D = 30

the function should return 3, because the frog will be positioned as follows:

  after the first jump, at position 10 + 30 = 40
  after the second jump, at position 10 + 30 + 30 = 70
  after the third jump, at position 10 + 30 + 30 + 30 = 100

Assume that:

X, Y and D are integers within the range [1..1,000,000,000];
X <= Y.

Complexity:

expected worst-case time complexity is O(1);
expected worst-case space complexity is O(1).

note: key conditions are: X and Y is > 0. X <= Y.

<1>
int frog( int x, int y, int d )
{
  long long sum = 0;
  int jump;

  for( jump=1; sum < y; jump++ )
  {
    sum = x + d*jump;
    std::cout << "-> " << sum << ":" << jump << std::endl;
  }

  std::cout << "-! " << sum << ":" << jump << std::endl;

  return jump;
}

int main()
{
  int ret = frog( 10, 85, 30 );

  std::cout << ret << std::endl;

  return 0;
}

-> 40:1
-> 70:2
-> 100:3
-! 100:4
4

Have wondered why this returns 4 not 3 as below? Thought 4 is right. Later, saw it again on the same
day and didn't get why thought 4 is right. Thing is that increase happens after the body.

j=1 : 10 + 30 = 40, j=2
j=2 : 10 + 60 = 70, j=3
j=3 : 10 + 90 = 100, j=4


note: see test cases

Code: 11:55:32 UTC, cpp, final, score: 33.00 

Detected time complexity: O(Y-X)
test                       time        result
example test               0.020 s.	OK
simple1 
simple test                0.020 s.	OK
simple2                    0.020 s.	OK

extreme_position 
no jump needed             0.020 s.	WRONG ANSWER got 1 expected 0

small_extreme_jump 
one big jump               0.020 s.	OK

many_jump1 
many jumps, D = 2          0.980 s.	TIMEOUT ERROR running time: >0.98 sec., time limit: 0.10 sec.

many_jump2 
many jumps, D = 99         1.020 s.	TIMEOUT ERROR running time: >1.02 sec., time limit: 0.10 sec.

many_jump3 
many jumps, D = 1283       0.990 s.	TIMEOUT ERROR running time: >0.99 sec., time limit: 0.10 sec.

big_extreme_jump 
maximal number of jumps    1.010 s.	TIMEOUT ERROR running time: >1.01 sec., time limit: 0.10 sec.

small_jumps 
many small jumps           0.290 s.	TIMEOUT ERROR running time: >0.29 sec., time limit: 0.10 sec.


Have missed the condition which is O(1) and unit test cases. How to solve?

<2>
int frog( int X, int Y, int D )
{
  long long sum = 0;
  int jump = -1;

  if( X == Y )
  {
    jump = 0;
  }
  else if (X < Y)
  {
    int diff = Y-X;

    if( (diff / D)  == 0)
    {
      jump = 1;
    }
    else if( ((diff/D) > 0) && ((diff%D) == 0) )
    {
      jump = diff/D;
    }
    else if( ((diff/D) > 0) && ((diff%D) != 0) )
    {
      jump = (diff/D)+1;
    }
  }

  return jump;
}

score: 100 of 100. Detected time complexity:O(1)

X==Y : no jump
X<Y  : ----------------------
        X         Y   D         
        
   (Y-X)/D == 0. needs one jump.
   (Y-X)/D > 0. needs more jump.
      -----------------------
        X         Y
             D   D
      (Y-X)%D == 0. fall exactly on Y.
      (Y-X)%D != 0. +1 jump.

Lesson learned. Read the question carefully such as 'greater or equal', 'X <= Y', and O(1).

<3> on Nov 2014 and got 100%
There are three cases:

                  Y    Y   Y
-------------- | ----- | ----- | ---------------------- 
                      jumps == X + D*jump;

int solution( int X, int Y, int D )
{
  if( X>Y || D==0 ) return -1;

  int jumps = (Y-X)/D;

  // Y >  X + jumps
  if( Y > (X + D*jumps) )
    return jumps+1;
  // Y <= X + jumps; covers when X == Y
  else
    return jumps;
}

<4> on Dec 2014
int solution( int X, int Y, int D )
{
  if( X>Y || D==0 ) return -1;

  int diff = (Y-X);
  int jump = diff/D;

  if( (diff % D) == 0 )
    return jump;
  else
    return jump+1;
}


={============================================================================
*kt_dev_quiz_105* codility: find missing element. PermMissingElem

A zero-indexed array A consisting of N different integers is given. The array contains integers in
the range [1..(N + 1)], which means that exactly one element is missing.

Your goal is to find that missing element.

Write a function:

int solution(int A[], int N);

that, given a zero-indexed array A, returns the value of the missing element.

For example, given array A such that:

  A[0] = 2
  A[1] = 3
  A[2] = 1
  A[3] = 5

the function should return 4, as it is the missing element.

Assume that:

N is an integer within the range [0..100,000]; the elements of A are all distinct; each element of
array A is an integer within the range [1..(N + 1)].

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(1), beyond input storage (not counting the storage
required for input arguments).

Elements of input arrays can be modified.

<1>
#include <iostream>
int solution(vector<int> &A) 
{
  // write your code in C++98
  if( !A.size() )
    return 0;

  long long isum = 0;

  for( unsigned int i = 0; i < A.size(); i++ )
    isum += A[i];

  long long csum = 0;

  for( unsigned int i = 1; i <= A.size()+1; i++ )
    csum += i;

  return csum - isum;
}

score: 90 of 100
Detected time complexity: O(N)

test 	time 	result
Example tests
example
example test 	0.020 s. 	OK

Correctness tests

empty_and_single
empty list and single element 	0.020 s. 	WRONG ANSWER got 0 expected 1
<Q> why is this?

missing_first_or_last the first or the last element is missing 	0.020 s. 	OK
single single element 	0.020 s. 	OK
double two elements 	0.020 s. 	OK
simple simple test 	0.020 s. 	OK

Performance tests
medium1        medium test, length = ~10,000 	0.020 s. 	OK
medium2        medium test, length = ~10,000 	0.020 s. 	OK
large_range    range sequence, length = ~100,000 	0.030 s. 	OK
large1         large test, length = ~100,000 	0.040 s. 	OK
large2         large test, length = ~100,000 	0.030 s. 	OK

<analysis>
This is about permutation. For example, {1,2,3,4,5} can have

{1,2,3,4} is missing 5
{2,3,4,5} is missing 1
{1,3,4,5} is missing 2

Reversely, 
if N==3 inputs are given, then it's one of permutation of 4. [1,4]
if N==2 inputs are given, then it's one of permutation of 3. [1,3]
if N==1 inputs are given, then it's one of permutation of 2. [1,2]
if N==0 inputs are given, then it's one of permutation of 1. [1] so the missing is always 1.

<2>
note: don't need to include headers and to use using namespace std
note: A.size() returns unsigned so used unsigned to prevent warnings
note: do not copy and paste from editor to test screen

#include <iostream>
int solution(vector<int> &A) 
{
  // write your code in C++98
  if( !A.size() )
    return 1;                                      // note: changed from return 0;

  long long isum = 0;

  for( unsigned int i = 0; i < A.size(); i++ )
    isum += A[i];

  long long csum = 0;

  for( unsigned int i = 1; i <= A.size()+1; i++ )  // note: <=
    csum += i;

  return csum - isum;
}

score: 100 of 100

<3>
int solution(vector<int> &A) 
{
  // write your code in C++98
  if( !A.size() )
    return 1;

  long long isum = 0;
  unsigned int n = A.size();

  for( unsigned int i = 0; i < n; i++ )
    isum += A[i];

  long long csum = 0;
  
  // use fact that sum of 1...N is N*(N+1)/2
  csum = (n+1)*((n+1+1)/2);         // note: this causes fail
  csum = (n+1)*(n+1+1)/2;           // note: this passes

  return csum - isum;
}

when fails:

example
example test 	0.008 s 	OK
Correctness tests
empty_and_single
empty list and single element 	0.008 s 	WRONG ANSWER
got 1 expected 2
missing_first_or_last
the first or the last element is missing 	0.008 s 	WRONG ANSWER
got 3 expected 6
single
single element 	0.008 s 	WRONG ANSWER
got 1 expected 2
double
two elements 	0.008 s 	OK
simple
simple test 	0.008 s 	OK
Performance tests
medium1
medium test, length = ~10,000 	0.012 s 	WRONG ANSWER
got -4544 expected 456
medium2
medium test, length = ~10,000 	0.012 s 	WRONG ANSWER
got 4998 expected 9998
large_range
range sequence, length = ~100,000 	0.024 s 	WRONG ANSWER
got -24999 expected 1
large1
large test, length = ~100,000 	0.044 s 	OK
large2
large test, length = ~100,000 	0.028 s 	WRONG ANSWER
got -20024 expected 10001


={============================================================================
*kt_dev_quiz_106* codility: PermCheck

https://codility.com/programmers/lessons/2
PermCheck

A non-empty zero-indexed array A consisting of N integers is given.

A permutation is a sequence containing 'each' element from 1 to N once, and only once.

For example, array A such that:

    A[0] = 4
    A[1] = 1
    A[2] = 3
    A[3] = 2

is a permutation, but array A such that:

    A[0] = 4
    A[1] = 1
    A[2] = 3

is not a permutation.

The goal is to check whether array A is a permutation.

Write a function:

    int solution(int A[], int N); 

that, given a zero-indexed array A, returns 1 if array A is a permutation and 0 if it is not.

For example, given array A such that:

    A[0] = 4
    A[1] = 1
    A[2] = 3
    A[3] = 2

the function should return 1.

Given array A such that:

    A[0] = 4
    A[1] = 1
    A[2] = 3

the function should return 0.

Assume that:

N is an integer within the range [1..100,000]; each element of array A is an integer within the
range [1..1,000,000,000].

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(N), beyond input storage (not counting the storage
required for input arguments).

Elements of input arrays can be modified.

<idea> nov 2014. both are O(n)
1. To get N, find the max value in the input and the sum of input in a single loop
2. If the sum is different from sum[1,N] then return false. 

<idea> nov 2014.
1. To get N, find the max value in the input.
2. If N is different from input size then return false.

<1>
int solution1( vector<int> &A )
{
  int max = 0;

  for( unsigned int i=0; i < A.size(); i++ )
  {
    if( max < A[i] )
      max = A[i];
  }

  return max == A.size();
}

80% since failed on:

antiSum1
total sum is correct, but it is not a permutation, N <= 10 	0.008 s 	WRONG ANSWER
got 1 expected 0

antiSum2
total sum is correct, but it is not a permutation, N = ~100,000 	0.044 s 	WRONG ANSWER
got 1 expected 0

<2> failed on 50%
int solution1( vector<int> &A )
{
  int max = 0;
  set<int> iset;

  for( unsigned int i=0; i < A.size(); i++ )
  {
    iset.insert( A[i] );

    if( max < A[i] )
      max = A[i];
  }

  return max == iset.size();
}

double
two elements 	0.008 s 	WRONG ANSWER got 1 expected 0

small_permutation note: such as {4,1,3,2,1};
permutation + one element occurs twice, N = ~100 	0.008 s 	WRONG ANSWER got 1 expected 0

<3> still fails when use sum and iset. 

<key> The problem is to understand question which is confusing. The question is that N is the size
of array and also is the N for permutation. That is there shall be [1,N] elements in the input. If
not, not a permutation. This becomes bit set problem to see if all elements are seen.

int solution1( vector<int> &A )
{
  if( !A.size() )
    return 0;

  // default is false
  vector<bool> flag( A.size() );

  for( unsigned int i=0; i < A.size(); i++ )
  {
    // note: -1 since permutation starts from 1 but index starts from 0
    // note: 'unsigned' to handle possible negative input which will be caught below if statement.
    unsigned int value = A[i]-1;

    // note: this covers values which are not in [1, N]
    if( value < A.size() )
      flag[value] = true;
    else
      return 0;
  }

  // note: if it is permutation then there is no flase in flag set
  return count( flag.cbegin(), flag.cend(), false ) == 0;
}

The count() in the return which is a loop can be removed as below since can return 0 as soon as
duplucates.

int solution1( vector<int> &A )
{
  if( !A.size() )
    return 0;

  // default is false
  vector<bool> flag( A.size() );

  for( unsigned int i=0; i < A.size(); i++ )
  {
    // note: -1 since permutation starts from 1 but index starts from 0
    // note: 'unsigned' to handle possible negative input which will be caught below if statement.
    unsigned int value = A[i]-1;

    // note: this covers values which are not in [1, N]
    if( value < A.size() && !flag[value])
      flag[value] = true;
    else
      return 0;
  }

  return 1;
}

100% pass
Detected time complexity: O(N * log(N)) or O(N)


={============================================================================
*kt_dev_quiz_107* codility: frog river

FrogRiverOne 

A small frog wants to get to the other side of a river. The frog is currently located at position 0,
and wants to get to position X. Leaves fall from a tree onto the surface of the river.

You are given a non-empty zero-indexed array A consisting of N integers representing the falling
leaves. A[K] represents the position where one leaf falls at time K, measured in minutes.

The goal is to find the earliest time when the frog can jump to the other side of the river. The
frog can cross only when leaves appear at every position across the river from 1 to X.

For example, you are given integer X = 5 and array A such that:

  A[0] = 1
  A[1] = 3
  A[2] = 1
  A[3] = 4
  A[4] = 2
  A[5] = 3
  A[6] = 5
  A[7] = 4

In minute 6, a leaf falls into position 5. This is the earliest time when leaves appear in every
position across the river.

Write a function:

    int solution(int X, int A[], int N); 

that, given a non-empty zero-indexed array A consisting of N integers and integer X, returns the
earliest time when the frog can jump to the other side of the river.

If the frog is never able to jump to the other side of the river, the function should return -1.

For example, given X = 5 and array A such that:

  A[0] = 1
  A[1] = 3
  A[2] = 1
  A[3] = 4
  A[4] = 2
  A[5] = 3
  A[6] = 5
  A[7] = 4

the function should return 6, as explained above. Assume that:

N and X are integers within the range [1..100,000];
each element of array A is an integer within the range [1..X].

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(X), beyond input storage (not counting the storage
required for input arguments).

Elements of input arrays can be modified.

<1>
#include <iostream>
#include <vector>

int solution( int X, std::vector<int> &A )
{
  if( A.empty() || X==1 )
    return -1;

  bool *pbitset = new bool(X);
 
  int idx;                        
  int count=0;

  // bitset{0, X-1}
  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < A.size(); idx++)    // signed and unsigned warning.
  {
    // wasn't set before?
    if( pbitset[A[idx]-1] == false )
    {
      // set it and increase count
      pbitset[A[idx]-1] = true;
      count++;

      // are all position set?
      if( count == X )                 // signed and unsigned warning.
      {
        delete pbitset; return idx;
      }
    }
  }

  delete pbitset; return -1;
}

Failed on 25%:

simple simple test        0.020 s.     OK
single single element     0.020 s.     WRONG ANSWER got -1 expected 0
extreme_frog frog never across the river     0.020 s.     OK

small_random1 3 random permutation, X = 50     0.020 s.     RUNTIME ERROR
tested program terminated unexpectedly

stdout:

[MONITOR DEBUG] open("/dev/tty", 2306) denied
[MONITOR] syscall open was blocked!
*** glibc detected *** ./user.e: free(): invalid next size (fast): 0x09cc9008 ***
======= Backtrace: =========
/lib/libc.so.6(+0x6c12a)[0x401c512a]
/lib/libc.so.6(+0x6d988)[0x401c6988]
/lib/libc.so.6(cfree+0x6d)[0x401c9afd]
/usr/lib/libstdc++.so.6(_ZdlPv+0x1f)[0x4007554f]
./user.e[0x804905c]
/lib/libc.so.6(__libc_start_main+0xe6)[0x4016fbc6]
./user.e[0x8048971]
======= Memory map: ========
[MONITOR DEBUG] open("/proc/self/maps", 0x0000) - opening /proc/ files is disabled!
[MONITOR] syscall tgkill was blocked!
[MONITOR] syscall tgkill was blocked!

note: 
1. signed and unsigned that complier warns mismatch between signed and unsigned. No such error when
run with GCC 4.6.3.

2. this is wrong since it allocate a single bool but not array. Failed on other many test cases with
the same error. But why no such error on GCC 4.6.3. This sites uses C++98 so may be new initialize
way in C++11?

<2> 
#include <iostream>
#include <vector>

int solution( int X, std::vector<int> &A )
{
  if( A.empty() || X==1 )
    return -1;

  bool *pbitset = new bool(X);
 
  int idx;                        
  int count=0;

  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < A.size(); idx++)
  {
    if( pbitset[A[idx]-1] == false )
    {
      pbitset[A[idx]-1] = true;
      count++;

      if( count == X )
      {
        delete[] pbitset; return idx;  // diff
      }
    }
  }

  delete[] pbitset; return -1;         // diff
}

Still failed with the same error.

<3>
#include <iostream>
#include <vector>

int solution( int X, std::vector<int> &A )
{
  if( A.empty() || X==1 )
    return -1;

  bool *pbitset = new bool[X];   // diff
 
  int idx;                        
  int count=0;

  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < A.size(); idx++)
  {
    if( pbitset[A[idx]-1] == false )
    {
      pbitset[A[idx]-1] = true;
      count++;

      if( count == X )
      {
        delete[] pbitset; return idx;
      }
    }
  }

  delete[] pbitset; return -1;
}

90 out of 100 points. Detected time complexity: O(N). Failed on:

single single element     0.020 s.     WRONG ANSWER got -1 expected 0

note: think about when single element has big value(position)


<4> final
#include <iostream>
#include <vector>

int solution( int X, std::vector<int> &A )
{
  if( A.empty() || X==0 )           // diff
    return -1;

  bool *pbitset = new bool[X];
 
  int idx;                        
  int count=0;

  // bitset{0, X-1}
  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < A.size(); idx++)
  {
    // wasn't set before?
    if( (A[idx]-1 < X) && pbitset[A[idx]-1] == false )   // diff
    {
      // set it and increase count
      pbitset[A[idx]-1] = true;
      count++;

      // are all position set?
      if( count == X )
      {
        delete [] pbitset; return idx;
      }
    }
  }

  delete [] pbitset; return -1;
}

int main()
{
  std::vector<int> A2 = { 1,3,1,4,2,3,5,4 };
  std::cout << solution( 5, A2 ) << std::endl;

  std::vector<int> A3 = { 2,3,4,5,1,3,5,4 };
  std::cout << solution( 1, A3 ) << std::endl;

  std::vector<int> A4 = { };
  std::cout << solution( 5, A4 ) << std::endl;

  std::vector<int> A5 = { 1 };
  std::cout << solution( 5, A5 ) << std::endl;

  std::vector<int> A6 = { 2 };
  std::cout << solution( 1, A6 ) << std::endl;

  std::vector<int> A7 = { 1 };
  std::cout << solution( 1, A7 ) << std::endl;

  return 0;
}

100 out of 100 points. Detected time complexity: O(N) 

<5> final revised
#include <iostream>
#include <vector>

int solution( int X, std::vector<int> &A )
{
  if( A.empty() || X==0 )           // diff
    return -1;

  bool *pbitset = new bool[X];
 
  int idx;                        
  int count=0;

  // bitset{0, X-1}
  for(idx=0; idx < X; idx++)
    pbitset[idx] = false;

  for(idx=0; idx < A.size(); idx++)
  {
    unsigned value = A[idx]-1;

    // wasn't set before?
    if( (value < X) && pbitset[value] == false )   // diff
    {
      // set it and increase count
      pbitset[value] = true;
      count++;

      // are all position set?
      if( count == X )
      {
        delete [] pbitset; return idx;
      }
    }
  }

  delete [] pbitset; return -1;
}

note:
The key idea is that it is about counting and to use counter to check if receives all inputs rather
than using loops or function call like bitset.

<6> use vector-bool
int solution(int X, vector<int> &A) {
  // write your code in C++11
  if( A.empty() || !X )
    return -1;

  vector<bool> flags(X);
  int count = 0;

  for(unsigned int i=0; i < A.size(); i++ )
  {
    unsigned int value = A[i]-1;

    if( value < X && flags[value] == false )
    {
      flags[value] = true;
      count++;
    }

    if( count == X )
      return i;
  }

  return -1;
}

Detected time complexity: O(N)

<7> bitset-attempt. this is still fixed size and not suitable when X is bigger than 32
#include <iostream>
#include <vector>
#include <bitset>

const size_t size = sizeof(unsigned long)*8;    // 32
typedef std::bitset<size> my_bitset;

int solution( int X, std::vector<int> &A )
{
  if( A.empty() || X==1 )
    return -1;

  my_bitset bitvec(X);
  bitvec.reset();

  int idx;
  int count=0;

  std::cout << "bitvec size: " << bitvec.size() << std::endl;

  for(idx=0; idx < A.size(); idx++)
  {
    if( bitvec[A[idx]-1] == false )
    {
      bitvec[A[idx]-1] = true;
      count++;

      std::cout << "idx: " << idx << ", bitvec[" << A[idx]-1 << "] = " << bitvec[A[idx]-1]
        << ", count: " << count << std::endl;

      if( count == X )
        return idx;
    }
  }

  return -1;
}

int main()
{
  std::vector<int> A2 = { 1,3,1,4,2,3,5,4 };
  std::cout << solution( 5, A2 ) << std::endl;

  std::vector<int> A3 = { 1,3,1,4,2,3,5,4 };
  std::cout << solution( 1, A3 ) << std::endl;

  std::vector<int> A4 = { };
  std::cout << solution( 5, A4 ) << std::endl;

  std::vector<int> A5 = { 1 };
  std::cout << solution( 5, A4 ) << std::endl;
}


={===========================================================================
*kt_dev_quiz_108* codility: missing integer

Find the minimal positive integer not occurring in a given sequence.

Write a function:

int solution(int A[], int N); 

that, given a non-empty zero-indexed array A of N integers, returns the minimal positive integer
that does not occur in A.

For example, given:

  A[0] = 1    
  A[1] = 3    
  A[2] = 6
  A[3] = 4    
  A[4] = 1    
  A[5] = 2

the function should return 5.

Assume that:

N is an integer within the range [1..100,000];
each element of array A is an integer within the range [-2,147,483,648..2,147,483,647].

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(N), beyond input storage (not counting the storage
required for input arguments).

Elements of input arrays can be modified.

note: Use bool vector approach? The input element can be negative so ignore negegative inputs.
However, the problem is input value can be too big to have bool vector. how to solve?

<Key> The key is whatever the input value is the aim to find the minimum positive value which is
missed. So have bool vector(N) and only consider inputs in 0 < x <= N. Since even if there is no
input in the specificed range then it simply means that it misses the whole value of the range and
need to get the first false in the bool vector. If bool vector has all set then return N+1.

<1> O(N), 100%
#include <iostream>
#include <vector>

using namespace std;

int solution(vector<int> &A)
{
  vector<bool> flags(A.size());

  for(unsigned int i=0; i < A.size(); i++)
  {
    int value = A[i];

    if( value > 0 && value <= A.size() )
      flags[value-1] = true;
  }

  for(unsigned int i=0; i < flags.size(); i++)
    if( flags[i] == false )
      return i+1;

  return A.size()+1;
}

int main()
{
  // vector<int> ivec{ 1, 3, 6, 4, 1, 2};
  vector<int> ivec{ 6, 7, 100, 400, 4000, 40000};

  cout << "ret: " << solution(ivec) << endl;
}


={===========================================================================
*kt_dev_quiz_109* codility: max counters

Calculate the values of counters after applying all alternating operations: increase counter by 1;
set value of all counters to current maximum.

You are given N counters, initially set to 0, and you have two possible operations on them:

increase(X) − counter X is increased by 1,
max_counter − all counters are set to the maximum value of any counter.

A non-empty zero-indexed array A of M integers is given. This array represents consecutive
operations:

if A[K] = X, such that 1 ≤ X ≤ N, then operation K is increase(X),
if A[K] = N + 1 then operation K is max_counter.

For example, given integer N = 5 and array A such that:

    A[0] = 3
    A[1] = 4
    A[2] = 4
    A[3] = 6
    A[4] = 1
    A[5] = 4
    A[6] = 4

the values of the counters after each consecutive operation will be:

    (0, 0, 1, 0, 0)
    (0, 0, 1, 1, 0)
    (0, 0, 1, 2, 0)
    (2, 2, 2, 2, 2)
    (3, 2, 2, 2, 2)
    (3, 2, 2, 3, 2)
    (3, 2, 2, 4, 2)

The goal is to calculate the value of every counter after all operations.

Assume that the following declarations are given:

    struct Results {
      int * C;
      int L;
    }; 

Write a function:

struct Results solution(int N, int A[], int M); 

that, given an integer N and a non-empty zero-indexed array A consisting of M integers, returns a
sequence of integers representing the values of the counters.

The sequence should be returned as:

a structure Results (in C), or
a vector of integers (in C++), or
a record Results (in Pascal), or
an array of integers (in any other programming language).

For example, given:

    A[0] = 3
    A[1] = 4
    A[2] = 4
    A[3] = 6
    A[4] = 1
    A[5] = 4
    A[6] = 4

the function should return [3, 2, 2, 4, 2], as explained above.

Assume that:

N and M are integers within the range [1..100,000];
each element of array A is an integer within the range [1..N + 1].

Complexity:

expected worst-case time complexity is O(N+M);
expected worst-case space complexity is O(N), beyond input storage (not counting the storage
required for input arguments).

Elements of input arrays can be modified.

<1> if simply follows the descriptions
#include <iostream>
#include <vector>

using namespace std;

template <typename T>
void PRINT_ELEMENTS( T& coll, const string optstr="" )
{
  cout << optstr;

  for( const auto &elem : coll )
    cout << elem << " ";

  cout << endl;
}

vector<int> solution(int N, vector<int>& A)
{
  vector<int> counters(N, 0);

  int current_max = 0;

  for( int i=0; i < A.size(); i++ )
  {
    // set current max to all
    if( A[i] >= N+1 )
    {
      PRINT_ELEMENTS( counters, "counters: " );

      for( int j=0; j < counters.size(); j++ )
        if( counters[j] > current_max )
          current_max = counters[j];

      for( int j=0; j < counters.size(); j++ )
        counters[j] = current_max;
    }
    // increment a counter
    else
      counters[A[i]-1] += 1;
  }

  PRINT_ELEMENTS( counters, "counters: " );

  return counters;
}

int main()
{
  vector<int> ivec{ 3, 4, 4 ,6 ,1 ,4 ,4 };
  vector<int> rvec;

  rvec = solution( 5, ivec );

  cout << "{" << endl;

  for( const auto &elem : rvec )
    cout << " " << elem << endl;

  cout << "}" << endl;
}

The result is that 100% correctness and 40% performance. O(N*M). Therefore, can see the problem is
the max-all operation and as a worst case, when there are N max-all operations this will be O(N*M).

So the key is to find a way to have max-all effect without doing a loop. How?

<2> solution from online.
http://codility-lessons.blogspot.co.uk/2014/07/lesson-2maxcounters.html

    (0, 0, 1, 0, 0)        (0, 0, 1, 0, 0)
    (0, 0, 1, 1, 0)        (0, 0, 1, 1, 0)
    (0, 0, 1, 2, 0)        (0, 0, 1, 2, 0)
    (2, 2, 2, 2, 2)        (-, -, -, -, -)   max=2, maxLastMaxOp = 2
    (3, 2, 2, 2, 2)        (3, 0, 1, 2, 0)
    (3, 2, 2, 3, 2)        (3, 0, 1, 3, 0)
    (3, 2, 2, 4, 2)        (3, 0, 1, 4, 0)
                           (3, 2, 2, 4, 2)   set maxLastMaxOp to all which are not increased since
                           last max-all operation.

note: This approach use flags to know which is increased since the last max-all operation and set
maxLastMaxOp to all which are not increased since the last max-all.

The key 'observation' is that max-all sets the 'base' for following increase operations. This
approach still however didn't meet performance goal. 88%.

struct Results solution(int N, int A[], int M) 
{
  struct Results result;
  result.C = calloc(sizeof(int), N);
  result.L = N;

  int* flg = alloca(sizeof(int) * N);
  memset(flg, 0x00, sizeof(int) * N);

  int max = 0;
  int maxAtTheLastMaxCntOp = 0;

  int i;
  for (i = 0; i < M; i++){
    int op = A[i];
    //if the op is max counter.
    if (op == N + 1){
      maxAtTheLastMaxCntOp = max;
      memset(flg, 0x00, sizeof(int) * N);    
    }
    //if the op is increase(x)
    else {
      //op is beweetn 1 to N, but the index for the array C 
      //is between 0 and (N-1). Decrease op to adjust it.
      op--; 
      if (flg[op] == 1){
        result.C[op]++;
      }
      else {
        result.C[op] = maxAtTheLastMaxCntOp + 1;
        flg[op] = 1;                
      }

      if (result.C[op] > max){
        max = result.C[op];
      }
    }
  }

  //apply the 'max counter' operation
  //to the slot(s) where it should be applied. 
  int j;  
  for (j = 0; j < N; j++){
    if (flg[j] == 0){
      result.C[j] = maxAtTheLastMaxCntOp;
    }
  }
  return result;
}

<3> the final solution from online.

This approach removes the use of flags. As with the above observation, max-all set the base that
means any following increase should be based on 'hidden' base. So if result[op] < maxLastMaxOp then
result[op] = maxLastMaxOp+1. Once done a loop, handle all which are not increased since the last
max-all by checking less than maxLastMaxOp. Verified 100% peformance mark.

#include <iostream>
#include <vector>

using namespace std;

template <typename T>
void PRINT_ELEMENTS( T& coll, const string optstr="" )
{
  cout << optstr;

  for( const auto &elem : coll )
    cout << elem << " ";

  cout << endl;
}

vector<int> solution(int N, vector<int> &A) {
  // write your code in C++11
  vector<int> result(N,0);

  unsigned int maxLast =0, maxCurrent = 0;

  for(unsigned int i = 0; i < A.size(); i++ )
  {
    int op = A[i];

    if( op == N+1 )   // max-all op
      maxLast = maxCurrent;
    else              // inc op
    {
      op--;

      if( result[op] < maxLast )
        result[op] = maxLast+1;
      else
        result[op]++;

      if( result[op] > maxCurrent )
        maxCurrent = result[op];
    }
  }

  for( unsigned int i =0; i < N; i++ )
    if( result[i] < maxLast )
      result[i] = maxLast;

  return result;
}

int main()
{
  vector<int> ivec{ 3, 4, 4 ,6 ,1 ,4 ,4 };
  vector<int> rvec;

  rvec = solution( 5, ivec );

  PRINT_ELEMENTS( rvec, "result : " );
}


<key> The observation and see that max-all op is used as performance input cases.


={===========================================================================
*kt_dev_quiz_110* codility: passing cars

From chapter 3, prefix sum.

A non-empty zero-indexed array A consisting of N integers is given. The consecutive elements of
array A represent consecutive cars on a road.

Array A contains only 0s and/or 1s:

0 represents a car traveling east,
1 represents a car traveling west.

The goal is to count passing cars. We say that a pair of cars (P, Q), where 0 ≤ P < Q < N, is
passing when P is traveling to the east and Q is traveling to the west.

For example, consider array A such that:

  A[0] = 0
  A[1] = 1
  A[2] = 0
  A[3] = 1
  A[4] = 1

We have five pairs of passing cars: (0, 1), (0, 3), (0, 4), (2, 3), (2, 4).

Write a function:

    int solution(int A[], int N); 

that, given a non-empty zero-indexed array A of N integers, returns the number of passing cars.

The function should return -1 if the number of passing cars exceeds 1,000,000,000.

For example, given:

  A[0] = 0
  A[1] = 1
  A[2] = 0
  A[3] = 1
  A[4] = 1

the function should return 5, as explained above.

Assume that:

N is an integer within the range [1..100,000];
each element of array A is an integer that can have one of the following values: 0, 1.

Complexity:

expected worst-case time complexity is O(N);
expected worst-case space complexity is O(1), beyond input storage (not counting the storage
    required for input arguments).

Elements of input arrays can be modified.

<1> 
If take simple approach like: take value 0 element and scan through the array. If see 1 and increase
count. Repeat this for all 0 values and sum count. This would be O(n^2). How to improve?

<2>
From http://codility-lessons.blogspot.co.uk/2014/07/lesson-3-passingcars.html.

The idea is that

   0 1 0 1 1
   *------->
       *--->

#include <iostream>
#include <vector>

using namespace std;

int solution( vector<int> &A )
{
  int count = 0, countEast = 0;

  for( unsigned int i=0; i < A.size(); i++ )
  {
    if( A[i] == 0 )
      countEast++;
    else
    {
      count += countEast;

      if( count > 1000000000 )
        return -1;
    }
  }

  return count;
}

int main()
{
  vector<int> ivec{0,1,0,1,1};

  cout << "ret : " << solution(ivec) << endl;
}


={===========================================================================
*kt_dev_quiz_111* codility: count div

From chapter 3, prefix sum.

Write a function:

int solution(int A, int B, int K); 

that, given three integers A, B and K, returns the number of integers within the range [A..B] that
  are divisible by K, i.e.:

    { i : A ≤ i ≤ B, i mod K = 0 }

For example, for A = 6, B = 11 and K = 2, your function should return 3, because there are three
  numbers divisible by 2 within the range [6..11], namely 6, 8 and 10.

Assume that:

A and B are integers within the range [0..2,000,000,000];
K is an integer within the range [1..2,000,000,000];
A ≤ B.

Complexity:

expected worst-case time complexity is O(1);
expected worst-case space complexity is O(1).

<1> from http://codility-lessons.blogspot.co.uk/2014/07/lesson-3-countdiv.html
This is a simple match question.

when A%K == 0, where * notes point when %K == 0

  A                 B
  *   *   *   *   *   *   *
  <----------------->
          B-A

when A%K != 0,

    A               B
  *   *   *   *   *   *   *
    <--------------->
          B-A
  <->
  A%K
  <----------------->
     B-(A-(A%K))

note: this has 75% correctness

int solution(int A, int B, int K) {
 // write your code in C++11
 if( A%K == 0 )
   return (B-A)/K +1;
 else
   return (B-A-A%K)/K;
}

int solution(int A, int B, int K) {
 // write your code in C++11
 if( A%K == 0 )
   return (B-A)/K +1;
 else
   return (B-(A-A%K))/K;
}


={===========================================================================
*kt_dev_quiz_112* codility: number of identical pairs

The quiz from a real test. Find the number of identical pairs in an array where 0 <= P < Q < N, A[P]
= A[Q] in O(N) in performace and O(1) in space.

A[0] = 3
A[1] = 5
A[2] = 6
A[3] = 3
A[4] = 3
A[5] = 5

The answer is 4.


={===========================================================================
*kt_dev_quiz_200* codility: train: lesson 01: time complexity

Time complexity

Use of time complexity makes it easy to estimate the running time of a program. Performing an
accurate calculation of a program's operation time is a very labour-intensive process (it depends on
the compiler and the type of computer or speed of the processor). Therefore, we will not make an
accurate measurement; just a measurement of a certain order of magnitude. Complexity can be viewed
as the maximum number of regular operations that a program may execute. Regular operations are
single additions, multiplications, assignments etc. We may leave some operations uncounted and
concentrate on those that are performed the largest number of times. Such operations are referred to
as 'dominant'. The number of dominant operations is considered on the basis of the specific input
data. We usually want to know how the performance time depends on a specific 'aspect' of the data.
This is most frequently the data size, but it can also be the size of a square matrix or the value
of some input variable.

1.1 : Which is the dominant operation?
1 def dominant(N):
2  result = 0
3  for i in xrange(N):
4     result += 1
5  return result

The operation in line 4 is dominant and will be executed N times. The complexity is recorded in
Big-O notation: in this case O(N) - linear complexity. 

The complexity specifies the order of 'magnitude' within which the program will perform its
operations. More precisely, in the case of O(N), the program may perform cN operations, where c is a
constant; however, it may not perform N^2 operations, for example, since this involves a different
order of magnitude of data. In other words, when calculating the complexity we omit constants: i.e.
regardless of whether the loop is executed 20N times or N/5 times, we still have a complexity of
O(N), even though the running time of the program may vary. When analyzing the complexity we must
look for specific, malicious examples of data that the program will take a long time to process.

1.1. Comparison of different time complexities

Let's compare some basic time complexities.

1.2 : Constant time - O(1).
1 def constant(N):
2  result = N * N
3  return result

There is always a fixed number of operations.


1.3 : Logarithmic time - O(log N).
1 def logarithmic(N):
2  result = 0
3  while (N > 1):
4     N = N // 2
5     result += 1
6  return result

The value of N is halved on each iteration of the loop. If N = 2^X then log N = X. How long would
the program below take to execute, depending on the input data?


1.4 : Linear time - O(N).
1 def linear(N, A):
2  for i in xrange(N):
3     if A[i] == 0:
4        return 0
5  return 1

Let's note that if the first value of array A is 0 then the program will end immediately. But
remember, when analyzing time complexity we should check for malicious cases. The program will take
the longest time to execute if array A does not contain any 0.


1.5 : Quadratic time - O(N^2).
1 def quadratic(N):
2  result = 0
3  for i in xrange(N):
4     for j in xrange(i, N):
5        result += 1
6  return result

The result of the function equals 1/2 · ( N · ( N + 1)) (the explanation is in the exercises). When
we omit the constants we get quadratic time complexity. Sometimes the complexity depends on more
variables (see example below).

1.6 : Linear time - O(N + M).
1 def linear2(N, M):
2  result = 0
3  for i in xrange(N):
4     result += i
5  for j in xrange(M):
6     result += j
7  return result

Exponential and factorial time

It is worth knowing that there are other types of time complexity such as factorial time O(N!) and
exponential time O(2^N). Algorithms with such complexities can solve problems only for very small
values of N, because they would take too long to execute for large values of N.

1.2. Time limit

Nowadays, an average computer can perform 10^8 operations in less than a second. Sometimes we have
the information we need about the expected time complexity, but sometimes we do not (for example,
Codility specifies the expected time complexity). The time limit set for online tests is
usually 1 - 10 seconds. We can therefore estimate the expected complexity. During contests, we are
often given a limit on the size of data, and therefore we can guess the time complexity within which
the task should be solved. This is usually a great convenience because we can look for a solution
that works in a specific complexity instead of worrying about a faster solution. For example, if:

- N <= 1 000 000, the expected time complexity is O(N) or O(N log N),
- N <= 10 000, the expected time complexity is O(N^2),
- N <= 500, the expected time complexity is O(N^3).

Of course, these limits are not precise. They are just approximations, and will vary depending
on the specific task.


1.3. Space complexity

Memory limits provide information about the expected space complexity. You can estimate the number
of variables that you can declare in your programs. In short, if you have constant numbers of
variables, you also have constant space complexity: in Big-O notation this is O(1). If you need to
declare array with N elements, you have linear space complexity - O(N). 

More specifically, space complexity is the amount of memory needed to perform the computation. It
includes all the variables, both global and local, dynamic pointer data-structures and, in the case
of recursion, the contents of the stack. Depending on the convention, input data may also be
included. It is more tricky to calculate than the time complexity because not all of these variables
and data-structures may be needed at the same time. Global variables exist and occupy memory all the
time; local variables (and additional information kept on the stack) will exist only during
invocation of the procedure. The existence of the dynamic pointer data-structures is explicitly
controlled by the program.


1.4. Exercise

Problem: You are given an integer N. Count the total of 1 + 2 + ...  + N.
Solution: The task can be solved in several ways. A first person, who knows nothing about time
complexity, may implement an algorithm in which the result is incremented by 1:

1.7 : Solution A - time complexity O(n^2).
1 def solution_A(N):
2  result = 0
3  for i in xrange(N):              // for( i < N )
4     for j in xrange(i + 1):       //  for( j < i+1 )
5        result += 1
6  return result

A second person may increment the result respectively by 1, 2,..., N. This algorithm is much faster:

1.8 : Solution B - time complexity O(n).
1 def solution_B(N):
2  result = 0
3  for i in xrange(N):              // for( i < N )
4     result += (i + 1)
5  return result

But the third person's solution is even quicker. Let us write the sequence 1, 2,..., N and repeat
the same sequence underneath it, but in reverse order. Then just add the numbers from the same
columns:

1     2     3     ...      N-1   N
N     N-1   N-2   ...      2     1
N+1   N+1   N+1   ...      N+1   N+1

The result in each column is N + 1, so we can easily count the final result:

1.9 : Solution C - time complexity O(1).
1 def solution_C(N):
2  result = N * (N + 1) // 2
3  return result


={===========================================================================
*kt_dev_quiz_201* codility: train: lesson 02: counting elements

Chapter 2

Counting elements

A numerical sequence can be stored in an array in various ways. In the standard approach, the
consecutive numbers a0, a1 ,...,an-1 are usually put into the corresponding consecutive indexes of
the array:

A[0] = a0 A[1] = a1 ... A[n-1] = an-1

We can also store the data in a slightly different way, by making an array of counters. Each number
may be counted in the array by using an index that corresponds to the 'value' of the given number.

a0 a1 a2 a3 a4 a5 
0  0  4  2  4  5

count [] 2 0 1 0 2 1
index    0 1 2 3 4 5    // values

Notice that we do not place elements directly into a cell; rather, we simply count their
occurrences. It is important that the array in which we count elements is sufficiently large. If we
know that all the elements are in the set {0, 1,..., m}, then the array used for counting should be
of size m + 1.

2.1 : Counting elements.
1 def counting(A, m):
2  n = len(A)
3  count = [0] * (m + 1)         // allocate array[m+1]
4  for k in xrange(n):
5     count[A[k]] += 1
6  return count

With this approach, the time complexity is O(n + m).

The limitation here may be available memory. Usually, we are not able to create arrays of 10^9
integers, because this would require more than one gigabyte of available memory. 

Counting the number of negative integers can be done in two ways. The first method is to add some
big number to each value: so that, all values would be greater than or equal to zero. That is, we
shift the representation of zero by some arbitrary amount to accommodate all the negative numbers we
need. In the second method, we simply create a second array for counting negative numbers.

2.1. Exercises

Problem: You are given an integer m such that ( 1 <= m <= 1 000 000) and a non-empty, zero-
indexed array A of <n> integers: a0, a1,..., an-1 such that ( 0 <= ai <= m). Count the number of
occurrences of the values 0, 1,..., m.

Solution: The simple way is to iterate through the whole array, searching for each value 0, 1 ,...,
m separately, but that produces a time complexity of O(nm). The better approach is to count the
elements in the array.

2.1. Exercise

Problem:
You are given an integer m ( 1 <= m <= 1000000) and two non-empty, zero-indexed arrays A and B of n
integers, a0 , a1, ..., an-1 and b0, b1, ..., bn-1 respectively ( 0 <= ai, bi <= m). The goal is to
check whether there is a swap operation which can be performed on these arrays in such a way that
the sum of elements in array A equals the sum of elements in array B after the swap. By swap
operation we mean picking one element from array A and one element from array B and exchanging them.

Solution O(n2): 
The simplest method is to swap every pair of elements and (then) calculate the totals. Using that approach
  gives us O(n3) time complexity. A better approach is to calculate the sums of elements at the
  beginning, and check only how the totals change during the swap operation.

2.2 : Swap the elements - O(n2).
1 def slow_solution(A, B, m):
2     n = len(A)
3     sum_a = sum(A)
4     sum_b = sum(B)
5     for i in xrange(n):
6        for j in xrange(n):
7           change = B[j] - A[i]
8           sum_a += change
9           sum_b -= change
10          if sum_a == sum_b:
11             return True
12          sum_a -= change
13          sum_b += change
14    return False

Solution O(n + m) :
The best approach is to count the elements of array A and calculate the difference d between the
  sums of the elements of array A and B. For every element of array B, we assume that we will swap
  it with some element from array A. The difference d tells us the value from array A that we are
  interested in swapping, because only one value will cause the two totals to be equal. The
  occurrence of this value can be found in constant time from the array used for counting.

2.3 : Swap the elements — O ( n + m) .
1 def fast_solution(A, B, m):
2     n = len(A)
3     sum_a = sum(A)
4     sum_b = sum(B)
5     d = sum_b - sum_a
6        if d % 2 == 1:
7           return False 
8     d //= 2
9     count = counting(A, m)
10    for i in xrange(n):
11       if 0 <= B[i] - d and B[i] - d <= m and count[B[i] - d] > 0:
12          return True
13    return False


={===========================================================================
*kt_dev_quiz_300* problems: repairman

{desc}
On every morning, a repairman is assigned the jobs for the day. The particular repairman we are
interested in has taken charge of jobs located on a straight road. For convenience, assume that the
N jobs are given at locations xi (i=1,...,N) on a straight line. He should start at one of these
locations and he must visit all the locations to complete the jobs. 

For a client requesting a job located at [xi], the time when he waits for a repairman is assumed to
be proportional to the distance [di] in which the repairman travels to arrive at xi from the
starting location. So, to reduce the waiting times of clients, the repairman should minimize the sum
of distances di. 

Our problem is slightly more complicated because there is a weight [wi] for the job at location xi
which represents the importance of the client. Thus the repairman should minimize the weighted sum
of distances wi di. 

More precisely, given locations (or coordinates) xi and weights wi of points on a line, the
repairman starts at one of these points, say s, and visits all the points at least once. Let di be
the distance in which the repairman travels to visit a point of location xi for the first time. We
may find the moving route of the repairman that minimizes 

SUMiWiDi (math summation where i means input)

{problem}
The minimum value is denoted by T(s) for a specific starting point. Consequently, we can compute
T(s) for each starting location s. The problem is to find a starting location [s] such that T(s) is
minimized over all the locations and to print the minimum value. 

For example, given points on a line, as in Figure 1, if the repairman starts at location 6, then the
red arrows represent a route to minimize the total weighted distance and the minimum value is 180.


Wi:     1       2       10 3  5          1 
 -------*-------*-------*--*--*----------*--------
Xi:     1       6       12 13 14         24
                ------------------------->
        <---------------------------------

180 = 2*0 + 10*6 + 3*(6+1) + 5*(6+1+1) + 1*(6+1+1+10) + 1*(6+1+1+10+23)

 [KT] Not sure why this should add all points every time such as 6+1+1.

But if the repairman starts at location 12 as in Figure 2, then a route minimizing the total
weighted distance is represented by the red arrows below and the minimum value is 86. Also this is
the minimum of T(s) over all the locations s. 

Wi:     1       2       10 3  5          1 
 -------*-------*-------*--*--*----------*--------
Xi:     1       6       12 13 14         24
                        ------> 
        <----------------------
        --------------------------------->


Time Limit: 1 second for 20 cases. If your program exceeds this time limit, the answers that have
been already printed are ignored and the score becomes 0.

So, it may be better to print a wrong answer when a specific test case might cause your program to
exceed the time limit. One guide for the time limit excess would be the size of the input.

[Input]
There can be more than one test case in the input file. The first line has C, the # of test cases.
Then the totally C test cases are provided in the following lines (1≤C≤20). In each test case, the
first line contains one integer N representing the number of points on a line (2≤N≤1,000). In the
second line, the N integers xi representing the locations of the points are given (1≤x_i≤1,000,000).
These integers are distinct and given in increasing order. In the third line, the N integers wi
representing the weights of the points are given (1≤wi≤1,000).

[Output]
The output for each test case should contain two lines. For the T-th test case, "Case #T" should be
printed out in the first line. The second line should contain the integer, representing the minimum
value for the starting location s to minimize T(s). This integer may be so large that it cannot be
stored in 4-byte integer variables. So you can use 64-bit integer (long long type) variables. 

[I/O Example]
Input
2                             // There are 2 test cases
6                             // Starting Case 1
1 6 12 13 14 24               // xi
1 2 10 3 5 1                  // wi
15                            // Starting Case 2
5 34 45 49 51 52 53 56 63 81 84 88 93 99 106
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1

Output
Case #1
86
Case #2
630


{winner-code} 
This file should be .cpp to build and run since it mixes C and CPP.

#include <stdio.h>
#include <map>
#include <vector>
#include <set>

using namespace std;

typedef long long lint;

int T, N;

int xi[1000];
int wi[1000];

#define abs(a) (((a) > 0)?(a):-(a))
#define min(a,b) (((a) < (b))?(a):(b))

// {Q} does the order matter? for example, abs(s-e) or abs(e-s)
#define TIME(s,e) (abs(xi[e] - xi[s]))

lint sum(int s, int e, lint time = 0);
lint sum(int s1, int s2, int s3, lint time = 0);

lint sum(int s, int e, lint time)
{
  if(s == e)
  {
    return 0;
  }
  int dx = ((e > s)? 1:-1);
  lint res = 0;

  // [1] 
  // here time is sum of absolute distance of between points and res is the sum of weighted
  // distance.
  //
  // for s < e case
  // s == 0  : i == 1,   dx == 1
  //         TIME(1,0), abs(0-1) res = time*wi[1];
  //
  // for s > e case
  // s == N-1: i == N-2, dx == -1 
  //           TIME(N-2, N-1), res = time*wi[N-2]
  //
  // this is a code to implement the summation above but it is cool to use one single function for
  // both direction. This dx variable is direction.
  //
  // ->  s     e: abs(e-s), abs(1-0), abs(1-0)*w[1]
  //
  //     0th   1th    2th    n-1 : N array
  // ----*-----*------*------*---
  //
  //               <-  e     s: abs(e-s), abs((n-2)-(n-1)), abs((n-2)-(n-1))*w[n-2]
  //
  // [2] no exit condition in for loop
  //
  for(int i = s + dx; ; i+=dx)
  {
    time += TIME(i, i - dx);
    res += time*(lint)wi[i];
    if( i == e )
    {
      return res;
    }
  }

  return res;
}

lint sum(int s1, int s2, int s3, lint time)
{
	// (s2 - s1)*(s3 - s1) < 0
	lint d1 = sum(s1, s2, time);
	//lint d2 = sum(s2, s3);
	lint d3 = sum (s1, s3, time + 2*TIME(s2, s1));

	return d1 + d3;
}

pair<lint, lint> search(int s, int e)
{
  lint dMin = sum(s, e);
  int ind = s;

  if(s == e)
  {
    return make_pair(0, 0);
  }
  int dx = ((e > s)? 1:-1);

  lint sumT = 0;
  lint time = 0;

  for(int i = s + dx; i != e; i += dx)
  {
    lint res = sum(i, s, e);

    if(res < dMin || res == dMin && abs(i - s) > abs(ind - s))
    {
      dMin = res;
      ind = i;
    }
  }

  if(ind != s)
  {
    pair<lint, lint> res = search(ind, s);	
    sumT += res.first;
    time += res.second + TIME(ind, s);		

    //printf("%d->%d->%d\n", ind, s, e);
  }

  sumT += sum(ind, e, time);
  time += TIME(ind, e);

  return make_pair(sumT, time);
}

int main()
{
  scanf("%d", &T);

  for(int t = 0; t < T; ++ t)
  {
    scanf("%d", &N);

    for(int n = 0; n < N; ++ n)
    {
      scanf("%d", xi + n); 
    }

    for(int n = 0; n < N; ++ n)
    {
      scanf("%d", wi + n); 
    }

    pair<lint, lint> res1 = search(0, N - 1);
    pair<lint, lint> res2 = search(N - 1, 0);

    printf("Case #%d\n", t + 1);
    printf("%lli\n", min(res1.first, res2.first));
  }
}

# ============================================================================
#{ ALGORITHM
==============================================================================
*kt_dev_algo_000*	sentinel

{hedge-or-sentinel}

From {ref-001}. A hedge or sentinel is an extra entry put into a data structure so that boundary
conditions need not be treated as a [special-case]. For example of this life game, need to check if
it is in the array when counting neighbours. Can avoid complicated checks by having extra lows and
columns:

arr[MAXROW+2][MAXCOL+2];

0 1 2 3 .... MAX MAX+1
1 X
2
3
.
.
MAX
MAX+1

Where all operation performs in range of [1, MAX] dimension and no need to boundary check when doing
for X.


={============================================================================
*kt_dev_algo_001* stack

A stack is a version of a 'list' that is particularly useful in applications involving a 'reverse'.
This is contiguous stack implementation with handling errors. See {stack-stl} for STL example.

{stack-contiguous-implementation}
This uses contiguous and is 'traversable' stack. The push and pop (insertion and deletion) happens
at the the 'end' of storage and use index. No overhead of moving elements.

<do> write a contiguous stack implementation which have following interfaces.

void CreatStack( Stack* stack );
bool StackFull( Stack* stack );
bool StackEmpty( Stack* stack );
bool StackPush( Stack* stack, EntryType entry );
void StackPop( Stack* stack );
EntryType StackTop( Stack* stack );
void StackTraverse( Stack* stack, void(*func)(EntryType));

<code>
<1> own implementation, cpp version
Used stack-stl interface which means top() returns an element and pop() removes an element without
getting it from a stack. So do top and pop. If do pop without top, will lost item. 

note: use 'top' var which is size or count of a stack and top index as well so use top in pop and
top funcs.
note: top is the 'next' position to push so initialized as 0 and do -1 first at top() as 'diff'
shows.

#include <iostream>

#define MAXENTRY 10

typedef int EntryType;

typedef struct {
  int top;                    // count
  EntryType entry[MAXENTRY];
} Stack;

void CreatStack( Stack* stack )
{
  stack->top = 0;    // 'diff'

  for( int i=0; i < MAXENTRY; i++ )
    stack->entry[i] = (EntryType)0;
}

bool StackFull( Stack* stack )
{
  return ( stack->top >= MAXENTRY );
}

bool StackEmpty( Stack* stack )
{
  return ( stack->top <= 0 );
}

bool StackPush( Stack* stack, EntryType entry )
{
  if( StackFull(stack) )
  {
    std::cout << "stack is full" << std::endl;
    return false;
  }

  stack->entry[ stack->top++ ] = entry;
  return true;
}

void StackPop( Stack* stack )
{
  if( StackEmpty(stack) )
  {
    std::cout << "stack is empty" << std::endl;
    return;
  }

  stack->top--;
}

EntryType StackTop( Stack* stack )
{
  if( StackEmpty(stack) )
  {
    std::cout << "stack is empty" << std::endl;
    return (EntryType)0;
  }

  return stack->entry[stack->top-1];   // 'diff'
}

typedef void(*TRAVERSEFUNC)(EntryType);

void StackTraverse( Stack* stack, TRAVERSEFUNC func)
//void StackTraverse( Stack* stack, void(*func)(EntryType))
{
  if( StackEmpty(stack) )
  {
    std::cout << "stack is empty" << std::endl;
    return;
  }

  for(int i=0; i < stack->top; i++)
  {
    func(stack->entry[i]);
  }
}

void EntryPrint(EntryType item)
{
  std::cout << "item is: " << item << std::endl;
}

int main()
{
  int item = 0;

  Stack stack;
  CreatStack(&stack);
  std::cout << "type in 10 integer numbers." << std::endl;

  for(int i=0; i < MAXENTRY; i++)
  {
    std::cin >> item;
    StackPush(&stack, item );
  }

  std::cout << "top is " << StackTop(&stack) << std::endl;
  std::cout << "top is " << StackTop(&stack) << std::endl;

  StackPop(&stack);
  StackPop(&stack);

  StackTraverse(&stack, EntryPrint);
}


<2> code-from-ref-001, cpp version
typedef char StackEntry;

typedef struct stack {
  int top;
  StackEntry entry[MAXSTACK];
} Stack;

void CreateStack( Stack* s )
{ s->top = 0; }

Boolean StackEmpty( Stack* s )
{ return s->top <= 0; }

Boolean StackFull( Stack* s )
{ return s->top >= MAXSTACK; }

void Push( StackEntry item, Stack* s )
{
   if( StackFull(s) )
      Error("stack is full");
   else
      s->entry[s->top++] = item;
}

void Pop( StackEntry *item, Stack* s )       // notice that it return item
{
   if( StackEmpty(s) )
      Error("stack is empty");
   else
      *item = s->entry[--s->top];
}

void Top( StackEntry *item, Stack* s ) // returned the top item and the stack remains unchanged.
void TraverseStack( Stack*s, void(*Visit)())


<3> code-from-class-example
typedef char Stack_entry;

Error_code Stack::push( const Stack_entry& item )
{
  Error_code outcome = success;

  if( count >= maxstack )
    outcome = overflow;
  else
    entry[count+1] = item;

  return outcome;
}

Error_code Stack::pop()
{
  Error_code outcome = success;

  if( count == 0 )
    outcome = underflow;
  else --count; // note: 

  return outcome;
}

Error_code Stack::top( Stack_entry& item ) const
{
  Error_code outcome = success;

  if( count == 0 )
    outcome = underflow;
  else
    item = entry[count-1];

  return outcome;
}

bool Stack::empty() const;


<4> own, c version
#include <stdio.h>

// not need when use g++ -g -std=c++0x $1
//#define true (1)
//#define false (0)
//typedef int bool;

#define MAX_ENTRY 100

typedef int EntryType;

typedef struct 
{
  EntryType entry[MAX_ENTRY];
  int count;
} Stack;

void CreatStack( Stack* stack );
bool StackFull( Stack* stack );
bool StackEmpty( Stack* stack );
bool StackPush( Stack* stack, EntryType entry );
void StackPop( Stack* stack );
EntryType StackTop( Stack* stack );
void StackTraverse( Stack* stack, void(*func)(EntryType));

void CreatStack( Stack* stack )
{
  stack->count = -1;    // 'diff'
}

bool StackFull( Stack* stack )
{
  if( stack->count+1 >= MAX_ENTRY )
    return true;

  return false;
}

bool StackEmpty( Stack* stack )
{
  if( stack->count == -1 )
    return true;

  return false;
}

bool StackPush( Stack* stack, EntryType entry )
{
  // if stack is full, return false
  if( StackFull( stack ) )
    return false;

  // insert an entry    'diff'
  stack->count += 1;
  stack->entry[stack->count] = entry;

  return true;
}

EntryType StackTop( Stack* stack )
{
  // this is ambigious since no way to signal invalid entry.
  if( StackEmpty( stack ) )
    return -1;

  return stack->entry[stack->count];
}

void StackTraverse( Stack* stack, void(*func)(EntryType))
{
  for( int i = 0; i <= stack->count; i++ )
    func( stack->entry[i] ); 
}

void StackPop( Stack* stack )
{
  // if stack is empty, return false
  if( StackEmpty( stack ) )
    return;

  // delete an entry
  stack->count -= 1;
}

void stack_print( EntryType item )
{
  printf("stack print: %d\n", item );
}

int main(int argc, char* argv[])
{
  int input[] = { 10, 25, 35, 9, 15, 45, 33, 51, 99, 80, 34 };

  Stack cstack;

  CreatStack( &cstack );

  for( int i = 0; i < sizeof(input)/sizeof(input[0]); i++ )
    StackPush( &cstack, input[i] );

  printf("top is %d\n", StackTop(&cstack) );

  StackPop(&cstack);
  StackPop(&cstack);

  printf("top is %d\n", StackTop(&cstack) );

  StackTraverse( &cstack, stack_print );
} 


$ ./a.out 
top is 34
top is 99
stack print: 10      // from 0 to top
stack print: 25
stack print: 35
stack print: 9
stack print: 15
stack print: 45
stack print: 33
stack print: 51
stack print: 99

<points-to-consider>
1. Use 'top' name for a easy reading
2. Can have differnt implementation depending on how to define 'empty' and value of top.

   when use 0th and use top as 'current' index inserted.
      -1 0 1 2 3 4 5 [6], init -1, and in push, top++ and entry[top];

   when do not use 0th and use top as 'current' top
      0 1 2 3 4 5 [6], init 0, and in push, top++ and entry[top];

   when use 0th and use top as 'next' index to insert which is for 1-3 examples.
      0 1 2 3 4 5 [6], init 0, and in push, entry[top] and top++;

   the last seems to be norm since ansic use the same:
   *p++ = val;    // push val onto stack
   val = *--p;    // pop top of stack into val

3. Examples do not have clear interface of top or pop when stack is empty. C++ STL also do not say
what will happen to call top when stack is empty. <?>


{stack-linked-implementation}
To pop, better to make all addition and deletion at the 'beginning' of the structure. Why? Since
this is one-way list, if to use the end to add, poping and pusing requires to search the end from
its 'header' every time.

<do> write a linked list stack implementation which do addition and deletion 'at-the-beginning' and
has following interfaces.

typedef struct node {
   ...
} Node;

typedef struct stack {
   ...
} Stack;

Node* MakeNode( EntryType item );
void CreatStack( Stack* stack );
bool StackEmpty( Stack* stack );
bool StackPush( Stack* stack, EntryType entry );
void StackPop( Stack* stack );
EntryType StackTop( Stack* stack );
void StackTraverse( Stack* stack, void(*func)(EntryType));

<code>
#include <iostream>
#include <cstdlib>

typedef int EntryType;

typedef struct node
{
  EntryType entry;
  node*     pnext;
} Node;

typedef struct {
  Node*  top;        // header
} Stack;

Node* MakeNode( EntryType entry )
{
  Node* pnode = NULL;

  if( (pnode = (Node*) malloc( sizeof(Node))) == NULL )
  {
    std::cout << "no more memory" << std::endl;
    return NULL;
  }

  pnode->entry = entry;
  pnode->pnext = NULL;

  return pnode;
}

void CreatStack( Stack* stack )
{ stack->top = NULL; }

bool StackEmpty( Stack* stack )
{ return ( stack->top == NULL ); }

bool StackPush( Stack* stack, EntryType entry )
{
  Node* pnode;

  if( (pnode = MakeNode(entry)) == NULL )
  {
    std::cout << "mem is full" << std::endl;
    return false;
  }

  pnode->entry = entry;
  pnode->pnext = stack->top;

  stack->top = pnode;

  return true;
}

void StackPop( Stack* stack )
{
  Node* pnode = NULL;

  if( StackEmpty(stack) )
  {
    std::cout << "stack is empty" << std::endl;
    return;
  }

  pnode = stack->top->pnext;
  free(stack->top);
  stack->top = pnode;

  // or save a node and update a header
  // pnode = stack->top;
  // stack->top = stack->top->next;
  // free(pnode);
}

EntryType StackTop( Stack* stack )
{
  if( StackEmpty(stack) )
  {
    std::cout << "stack is empty" << std::endl;
    return (EntryType)0;
  }

  return stack->top->entry;
}

typedef void(*TRAVERSEFUNC)(EntryType);

void StackTraverse( Stack* stack, TRAVERSEFUNC func)
{
  Node* pnode;

  if( StackEmpty(stack) )
  {
    std::cout << "stack is empty" << std::endl;
    return;
  }

  pnode = stack->top;

  while(pnode)
  {
    func(pnode->entry);
    pnode = pnode->pnext;
  }

  // for( Node* node = stack->header; node; node = node->next )
  //   func( node->entry ); 
}

void EntryPrint(EntryType item)
{
  std::cout << "item is: " << item << std::endl;
}

int main(int argc, char* argv[])
{
  int input[] = { 10, 25, 35, 9, 15, 45, 33, 51, 99, 80, 34 };

  Stack cstack;

  CreatStack( &cstack );

  for( int i = 0; i < sizeof(input)/sizeof(input[0]); i++ )
    StackPush( &cstack, input[i] );

  printf("top is %d\n", StackTop(&cstack) );

  StackPop(&cstack);
  StackPop(&cstack);

  printf("top is %d\n", StackTop(&cstack) );

  StackTraverse( &cstack, stack_print );

  for( Node* node = cstack.header; node; node = node->next )
    StackPop( &cstack ); 
} 

top is 34
top is 99
stack print: 99      // from top to 0
stack print: 51
stack print: 33
stack print: 45
stack print: 15
stack print: 9
stack print: 35
stack print: 25
stack print: 10


{case-app-one} reverse-polish-calculator
We shall write '?' to denote an instruction to read an operand from a user and push it onto the
stack; + , -, * , and / represent arithmetic operations which pops data; and = is an instruction to
print the top of the stack (but not pop it off). Further, we write a, b, c, and d to denote
numerical values such as 3.14 or -7. 

? a ? b + =    // ? 1 ? 2 + =

mean read and store the numbers a and b, calculate and store their sum, and then print the sum. 

? a ? b + ? c ? d + * = 

request four numerical operands, and the result printed is the value of (a + b) * (c + d).

? a ? b ? c - = * ? d + = 

mean push the numbers a, b, c onto the stack, replace the pair b, c by b - c and print its value,
calculate a * (b - c), push d onto the stack, and finally calculate and print (a * (b - c)) + d. 

The advantage of a reverse polish calculator is that any expression, no matter how complicated, can
be specified without the use of parentheses.

<example>
#include <iostream>
#include <stack>

using namespace std;

stack<int> st;

char get_command()
{
  char command = 0;
  bool wait = true;

  while( wait )
  {
    cin >> command;
    command = tolower(command);

    if( command == '?' || command == '=' || command == '-' ||
        command == '+' || command == '*' || command == '/' ||
        command == 'q' )
      wait = false;
    else
      cout << "please enter a valid command : " << endl;
  }

  return command;
}

int do_command( char command )
{
  int p, q;

  switch(command)
  {
    case '?':
      // cout << "enter a int number :" << flush;
      cin >> p;
      st.push( p );
      break;

    case '=':
      if( !st.empty() )
        cout << "result: " << st.top() << endl;
        cout << "select command and press enter: ";
      break;

    case '-':
      if( !st.empty() )
      {
        p = st.top(); st.pop();
        
        if( !st.empty() )
        {
          q = st.top();
          st.pop();

          st.push( p-q );
        }
        else
        {
          cout << "stack has just one entry." << endl;
          st.push(p);
        }
      }
      break;

    case '+':
      if( !st.empty() )
      {
        p = st.top(); st.pop();
        
        if( !st.empty() )
        {
          q = st.top();
          st.pop();

          st.push( p+q );
        }
        else
        {
          cout << "stack has just one entry." << endl;
          st.push(p);
        }
      }
      break;

    case 'q':
      cout << "calc finished" << endl;
      return false;
  }

  return true;
}

int main()
{
  cout << "select command and press enter: ";

  while( do_command( get_command() ) )
    ;
}

This works fine but can be re-written using cpp strings.

<2> from ansic, p 74. no read(?) operator

1 2 - 4 5 + * means ( 1 - 2 ) * ( 4 + 5 )

while( next operator or operand is not end-of-file indicator )
  if (number)
   push it
  else if (operator)
   pop operands
   do operation
   push result
  else if (newline)
   pop and print top of stack
  else
   error

#include <stdio.h>
#include <stdlib.h> 

#define MAXOP  100
#define NUMBER '0'

int getop( char [] );
void push( double );          // see double
double pop( void );

main()
{
  int type;
  double op2;
  char sp[MAXOP];

  while( (type = getop(s)) != EOF )
  {
    switch( type )
    {
      case NUMBER:
        push( atof(s) );
        break;

      case '+':
        push( pop() + pop() );
        break;

      case '*':
        push( pop() * pop() );
        break;

      case '-':                  // note: eval-order matters
        op2 = pop();
        push( pop() - op2 );
        break;

      case '/':
        op2 = pop();

        if( op2 != 0.0 )
          push( pop() / op2 );
        else
          printf("error: zero divisor\n");

        break;

      case '\n':
        printf("\t%.8g\n", pop());
        break;

      default:
        printf("error: unknown command %s\n", s );
        break;
    }
  } // while end
  return 0;
}

The + and * are commutative operators, the order in which the popped operands are combined is
irrelevant, but for - and / the left and right operands must be distinguished.

push( pop() - pop () );

This is wrong since the order in which the two calls of pop are evaluated is not 'defined'.

// stack

#define MAXVAL 100

int sp = 0;             // 'next' free stack position
double val[MAXVAL];

void push( double f )
{
  if( sp < MAXVAL )
    val[sp++] = f;
  else
    printf("error: stack full, can't push %g\n", f);
}

double pop(void)
{
  if( sp > 0 )
    return val[--sp];
  else
  {
    printf("error: stack empty\n");
    return 0.0;
  }
}

// getop: get next operator or numeric operand. if not return a string.

int getch(void);
void ungetch(int);

int getop( char s[] )      // s used only for numbers
{
  int i, c;

  while( (s[0] = c = getch()) == ' ' || c == '\t' )
    ;

  s[1] = '\0';    // this is for when it's not a number to print out a string

  if( !isdigit(c) && c != '.' )
    return c;     // not a number

  i = 0;
  if( isdigit(c) )   // c is read already and collect integer part
    while( isdigit( s[++i] = c = getch()) )
      ;

  if( c == '.' )     // c is read already and collect fraction part
    while( isdigit( s[++i] = c = getch()) )
      ;

  s[i] = '\0';

  if( c != EOF )
    ungetch(c);

  return NUMBER;
}

#define BUFSIZE 100

char buf[BUFSIZE];
int bufp = 0;        // next free position in buf

int getch(void)
{
  return (bufp > 0) ? buf[--bufp] : getchar();
}

void upgetch(int c)
{
  if( bufp >= BUFSIZE )
    printf("ungetch: too many characters\n");
  else
    buf[bufp++] = c;
}

<read-ahead>
It is often the case that a program cannot determine that it has read enough input until it has read
too much. Once instance is collecting the characters that make up a number: until the first
non-digit is seen, the number is not complete. But the program has read one character too far, a
character that it is not perpared for. The problem would be solved if it were possible to "un-read"
the unwanted character.

Why need? To have a token from a stream and to handle newline.

input: "4 2 *NL"
        ^^
          ^^
            ^^
Here a char which is not digit or "." is a seperator and if not ungetch this cannot handle NL since
it is already gone. This is how getop works.

<exercise>
From ansic, p79. exercise 4-3. Given the basic framework, it's straightforward to extend the
calculator. Add the modulus ( % ) operator and provisions for negative numbers.

http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_4:Exercise_3
Adding the modulus is easily done by another case in main and using the fmod function. The standard
library has been mentioned at this point so it should be valid to use this for type 0 compliance.
math.h should be added to the list of #includes for fmod. 

switch(type)
{
  /* other cases snipped for brevity */
  case '%':
    op2 = pop();
    if(op2)
      push(fmod(pop(), op2));
    else
      printf("\nError: Division by zero!");
    break;
    
  OR
  // Answer: Supporting modulus is indeed rather easy. The modulus operator
  // divides the first operand by the second and returns the remainder, and C
  // supports this out of the box, so there's no need to implement much math.
  // Note that the modulus operator does integer division to get its remainder.
  // Doing a "proper" modulus operator would require more work, and floats can
  // be tricky. I might implement this sometime. For now, I typecasted.

  case '%':
    op2 = pop();
    if (op2 != 0.0) {
      push((int)pop() % (int)op2);
    } else {
      printf("Error: Cannot modulo by zero.\n");
    }
    break;
}

// to support negative
int getop( char s[] )      // s used only for numbers
{
  int i, c;

  while( (s[0] = c = getch()) == ' ' || c == '\t' )
    ;

  s[1] = '\0';             // this is not necessary

  if( !isdigit(c) && c != '.' && c != '-' )  // <changed> to pass '-' (minus) through
    return c;     // not a number

  i = 0;
  if( isdigit(c) || c == '-' )   // <changed> c is read already and collect integer part
    while( isdigit( s[++i] = c = getch()) )
      ;

  if( c == '.' )     // c is read already and collect fraction part
    while( isdigit( s[++i] = c = getch()) )
      ;

  s[i] = '\0';

  if( c != EOF )
    ungetch(c);

  return NUMBER;
}


{case-app-two} {bracket-matching}
{a = (1 + v(b[3 + c[4]]))     // no matching 
{ a = (b[0) + 1]; }           // the number of brackets matches but no matching
{( )[( )]}                    // matches but not leagal

How stack can be used here?

Whenever see any closing bracket ), ], or }, it must correspond to the last unmatched opening
bracket, which should be in stack and now be retrieved and removed from storage. Finally, at the end
of the program, we must check that no unmatched opening brackets are left over.

#include <iostream>
#include <stack>

using namespace std;

stack<int> st;

int main()
{
  char current;
  bool match = true;

  while( match && ( current = cin.get() ) != '\n' )            // note: cin-get()
  {
    if( current == '{' || current == '(' || current == '[' )
      st.push(current);

    if( current == '}' || current == ')' || current == ']' )
    {
      if( st.empty() )
      {
        cout << "unmatched" << endl;
        match = false;
      }
      else
      {
        char previous = st.top();
        st.pop();

        cout << "? match: " << previous << ":" << current << endl;

        match = ( current == '}' && previous == '{' )
          || ( current == ')' && previous == '(' )
          || ( current == ']' && previous == '[' );

        if(!match)
          cout << "bad match: " << previous << ":" << current << endl;
      }
    }
  }

  if(!st.empty())
    cout << "unmatched delected" << endl;
}

<nested-parentheses>
http://ilovefoobar.wordpress.com/tag/codility/
Nested Parentheses where you will write a code to find if parentheses are properly nested on not.
If your have brackets like this ” ( ) ” or ” ( ( ) ) ( ) ” then it means that it is properly nested
but if you have bracket like this ” ( ( ) ” or ” ) ) ) ( ( ( ” then it means that its not properly
nested. And I was supposed to handle String of length 200,000 characters.

1. Remove all spaces from String.

2. Count the length of String, and find out if its odd or even number. If string is odd number then
it is not properly nested.  
<KT> 1 and 2 are input check which is good. But don't need these in the c approach.

3. If String is even number then run a loop and remove all matching ” () ” character from the
string.  

4. Now check the length of String, if length is zero then String is properly nested else its not.
<KT> This is the same check as size of stack in the c approach.

class Solution
{
  public int nesting ( String S )
  {
    int result = 1;

    if(S.contains(" "))
    {
        S = S.replaceAll(" ","");
    }

    while(S.contains("()"))
    {
        S = S.replaceAll("\\(\\)", "");
    }

    if(S.length() != 0)
    {
        result = 0;
    }

    return result;
  }
}


={============================================================================
*kt_dev_algo_002* simple list

{abstract-data-type} ADT
Drawing a spearation between the logical structure of our data and its implementation will help us
in designing problems. If there is no speration, for example, can implement reverse polish
calculator by replacing stack code with manipulating array and count directly. Problem?

1. How to change it to list implementation from array?
2. Use unnecessary effort verifying the details of codes rather than being able to concentrate on
logic to solve problem, that is, the ways in which the stack is being used. This is programmer's
failure to recognize the general concept of stack and to distinguish between this and
implementation.

<key> can use this reverse polish calculator to see if someone can use data type such as stack to
solve these case problems.

<encapsulation> 
In general, data is said to be 'encapsulated' if it can only be accessed by a controlled set of
functions. Without encapsulation, the operation on a data structure almost always depend on a
[precondition] of data members.

The mathematical definition of type is:
A 'type' is a set, and the elements of the set are called the 'values' of the type. 

ADT has two parts: First is a description of the way in which the components are related to each
other, and second is a statement of the operation. ADT is logical data structure such as list or
stack and physical implementation can vary as there are many different implementation of stack.


{simple-list}
<adt-definition>
A simple list of elements of type T is a finite sequence of elements of T together with the
following operations.

1. create the list, leaving it empty.
2. determine whether the list is empty or not.
3. determine whether the list is full or not.
4. find the size of the list.
5. add a new entry at the 'end' of the list, provided the list is not full.
6. traverse the list, performing a given operation with each entry.
7. clear the list to make it empty.

<stages-of-refinement>
<- concept and algorithm ------->
math      ADT              data           implementation                application
concept                    structure 

sequence  general list
          stack            ...
          queue            physical                                     line of people

                           linear         array

                           circular       array with counter            airport simulation
                                          array with flag
                                          array with skipped entry

                           linked         simple with two pointers
                                          circular with tail pointers
                                          array with two cursors


<list-data-structure>
A list is 'dynamic' data-structure because its size can change, while an array is a 'static'
data-structure because it has a fixed size.

<list-contiguous-implementation>
<do> write a contiguous list implementation which have following interfaces.

void CreateList(List*);
void ClearList(List*);
bool ListEmpty(const List*);
bool ListFull(const List*);
int ListSize(const List*);
void AddList(ListEntry x, List* list);
void TraverseList(List* list, void(*visit)(ListEntry));

<code>
The ListEntry can be anything. typedef T ListEntry;

typedef struct cell {
  int row, col;
} Cell;

typedef Cell ListEntry;

typedef struct list {
  int         count;
  ListEntry   entry[MAXLIST];
} List;

// add an entry at-the-'end'. As with the contiguous stack, count is 'next' to add.
vold AddList(ListEntry x, List* list)
{
  if(ListFull(list))
    Warning("attempt to insert at the end of a full list.");
  else
    list->entry[list->count++] = x;
}

void TraverseList(List* list, void(*visit)(ListEntry));
{ 
  for( int i = 0; i < list->count; i++)
    (*visit)(list->entry[i]);
}

Here, there is no function to remove and if remove an entry at random position, it is expensive as
have to move elements. This is the same as contiguous stack.


<list-linked-implementation>
A problem that never arises with contiguous. How do we find the beginning of the list? 'header' is a
pointer variable that locates the beginning of the list as in {stack-linked-implementation}.

typedef struct node {
  ListEntry   entry;
  struct node *next;
} Node;

typedef struct list {
  int     count;   // there is no need to keep an counter but for size function.
  Node*   header;  // header
} List;


If it has remove function, then less expansive than contiguous-implementation since it is linked but
need to search through from the header to find the end. <Q> How about having a Node* end in the List
struct to have a current end? So can implement to add a node either in the beginning or in the end.
However, still not support random removal.


<do> write a linked list implementation which have following interfaces.

void CreateList(List*);
void ClearList(List*);
int ListEmpty(const List*);
int ListSize(const List*);
void AddList(ListEntry x, List* list);
void TraverseList(List* list, void(*visit)(ListEntry));

<code> no ClearList
#include <iostream>
#include <cstdlib>

typedef int EntryType;

typedef struct node
{
  EntryType entry;
  node*     pnext;
} Node;

typedef struct {
  int    count;
  Node*  header;
} List;

Node* MakeNode( EntryType entry )
{
  Node* pnode = NULL;

  if( (pnode = (Node*) malloc( sizeof(Node))) == NULL )
  {
    std::cout << "no more memory" << std::endl;
    return NULL;
  }

  pnode->entry = entry;
  pnode->pnext = NULL;

  return pnode;
}

void CreatList( List* list )
{ 
  list->count = 0;
  list->header = NULL; 
}

bool ListEmpty( List* list )
{ return ( list->header == NULL ); }

// add only at the end. see there are approaches to find end; one is to use pnext and the other is
// to use count. 
bool AddList( List* list, EntryType entry )
{
  Node* pnode, *pend;

  if( (pnode = MakeNode(entry)) == NULL )
  {
    std::cout << "add: mem is full" << std::endl;
    return false;
  }

  if( ListEmpty( list ) )
  {
    list->header = pnode;
  }
  else
  {
#ifdef USE_PNEXT
    // search the end using pnext
    for( pend = list->header; pend->pnext; pend = pend->pnext )
      ;
#else
    // search the end using count
    pend = list->header;
    for( int current = 1; current < list->count; current++) // note that less than
      pend = pend->pnext;
#endif

    pend->pnext = pnode;
  }

  list->count++;

  return true;
}

typedef void(*TRAVERSEFUNC)(EntryType);

void TraverseList( List* list, TRAVERSEFUNC func)
{
  Node* pnode;

  if( ListEmpty(list) )
  {
    std::cout << "list is empty" << std::endl;
    return;
  }

  pnode = list->header;

  while(pnode)
  {
    func(pnode->entry);
    pnode = pnode->pnext;
  }
}

void EntryPrint(EntryType item)
{
  std::cout << "item is: " << item << std::endl;
}

int main()
{
  int item = 0;

  List list;
  CreatList(&list);

  std::cout << "type in 5 numbers." << std::endl;

  for(int i=0; i < 5; i++)
  {
    std::cin >> item;
    AddList(&list, item );
  }

  TraverseList(&list, EntryPrint);
}

<2> With ClearList
#include <stdio.h>
#include <stdlib.h>

// list
typedef int ListEntry;

typedef struct node {
  int       key;
  struct node *pnext;
} ListNode;

typedef struct {
  ListNode *header;
  int count;
} List;

void CreateList(List*);
void ClearList(List*);
int ListEmpty(const List*);
int ListSize(const List*);
void AddList(ListEntry x, List* list);
void TraverseList(List* list, void(*visit)(ListEntry));

void CreateList( List *list )
{
  list->header = NULL;
  list->count = 0;
}

// clean-up idiom from ansic, p167
//
// for( p = head; p != NULL; p = q )
// {
//    q = p->next;
//    free(p);
// }
//
void ClearList( List *list )
{
  ListNode *pend, *ptemp;
  for( pend = list->header; pend; )
  {
    // save current to the temp, move the current and free temp.
    ptemp = pend;
    pend = pend->pnext;
    free(ptemp);
    list->count--;
  }

  list->header = NULL;
  list->count = 0;
}

void AddList(ListEntry x, List *list)
{
  // make a node
  ListNode *pnode = (ListNode*) malloc( sizeof (ListNode) );
  if(!pnode)
  { printf("addlist: no more memory\n"); return; }

  // init a node
  pnode->key = x;
  pnode->pnext = NULL;

  if( !list->header ) // when it's first node
  {
    list->header = pnode;
    list->count++;
  }
  else                // when not a first, search the end
  {
    ListNode *pend;
    // <list-find-end-idiom>
    // notice that 'pend->pnext' in for condition which is different from traversing. The pend
    // points to the exact last node.
    for( pend = list->header; pend->pnext; pend = pend->pnext )
      ;

    pend->pnext = pnode;
    list->count++;
  }
}

int ListEmpty(const List *list)
{
  if( list->count == 0 )
    return 1;

  return 0;
}

int ListSize(const List *list)
{
  return list->count;
}

void TraverseList(List* list, void(*visit)(ListEntry))
{
  ListNode *pend;
  // <list-walk-along-idiom>
  // notice that pend points to the one off the last
  for( pend = list->header; pend; pend = pend->pnext )
    visit( pend->key );
}

void PrintList( ListEntry entry )
{
  printf("print list : %d\n", entry );
}


int main()
{
  int values[] = { 26, 33, 35, 29, 19, 12, 22 };
  List llist;

  CreateList(&llist);

  for(int i = 0; i < (sizeof values/sizeof(int)); i++)
    AddList( *(values+i), &llist );

  printf("list size is %d\n", ListSize( &llist ));

  TraverseList( &llist, PrintList );

  ClearList( &llist );

  printf("list size is %d\n", ListSize( &llist ));

  return 0;
}


<keys>
The stack and 'simple' list are essentially the same implementation in terms of contiguous and
linked implementation.


={============================================================================
*kt_dev_algo_003* list

{general-list}
As with a stack or a queue, the (general) list has a 'sequence' of entries as its data value.
However, unlike a stack or a queue, a list permits operations that alter 'arbitrary' entries of the
sequence.

1. Construct the list, leaving it empty.
2. Determine whether the list is empty or not.
3. Determine whether the list is full or not.
4. Find the size of the list.
5. Clear the list to make it empty.
6. Insert an entry at a 'specified' position of the list.
7. Remove an entry from a specified position in the list.
8. Retrieve the entry from a specified position in the list.
9. Replace the entry at a specified position in the list.
10. Traverse the list, performing a given operation on each entry.

The list support 'random'-read-write-access as oppose to a simple list that supports only addition
at the end:

<position>
To find an entry in a list, we use an integer that gives its position within the list. We shall
number the positions in a list so that the first entry in the list has position 0, the second
position 1, and so on. Hence, locating an entry of a list by its position is superficially like
indexing an array, but there are important differences. First, if we insert an entry at a particular
position, then the position numbers of all later entries increase by 1. If we remove an entry, then
the positions of all following entries decrease by 1. 

implementation independence. Moreover, the position number for a list is defined without regard to
the implementation. For a contiguous list, implemented in an array, the position will indeed be the
index of the entry within the array. But we will also use the position to find an entry within
linked implementations of a list, where no indices or arrays are used at all. 

note that insert allows position==n, since it is permissible to insert an entry after the last
entry of the list. This is only for insert.

void InsertList( position p, ListEntry x, List* list );

// the entry in position p of list has been returned as x and deleted from list.
void DeleteList( position p, ListEntry* x, List* list );

// the entry in position p of list has been returned as x and list remains unchanged.
void RetrieveList( position p, ListEntry* x, List* list);

// list remain unchanged 
void ReplaceList( position p, ListEntry x, List* list );

As with list and others, the general list has two kind of implementation: contiguous and linked. For
contiguous, shift later elements to support inserting and deleting in any position. For both, need
to scan from the first every time. 


<do> Here linked case. Add InsertList and DeleteList to the simple list using SetPosition which is
utility function.

// return a node 'at' the pos in [0, count-1]
void SetPosition( Position p, List* list, ListNode** current )
{
  int count;
  ListNode* q;

  if( p < 0 || p >= list->count )
    Error("attempt to set a position not in the list");
  else 
  {
    q = list->head;
    
    // this is to control loop runs but not to check position/count
    for( count = 1; count <= p; count++ )
      q = q->next;

    *current = q;
  }
}


<code> from the ref-001.
<1>
1. Should handle when add an entry to the the first position.
2. Should have the previous pos(p-1) for pos insertion.

// insert a node at any pos in the list or a new into the list when pos is count. insert a node at p
// meaning that a node is to be placed at position p. p in [0, count]
//
// count:
//  1   2   3   4   5  ...
// pos
//  0   1   2   3   4  
// [ ] [ ] [ ] [ ] [ ] ...
// 
//   [*] new node when insert(1)
// 

void InsertList( Position p, ListEntry x, List* list )
{
   ListNode *newnode, *current;

   // check if pos is in [0, count]
   if( p < 0 || p > list->count )
      Error("attempt to set a position not in the list");
   else 
   {
      newnode = MakeListNode(x);
      // <key> cannot use if( ListEmpty(list) ) since it only handle when the list empty. However,
      // this case also handle to insert a node at pos 0 when the list is not empty.
      if( p == 0 )   
      {
         newnode->next = list->head;
         list->head = newnode;
      }
      // <key> handles p[1, count] that means SetPosition[0, count-1]. In other words, SetPostion
      // returns the previous to the postion to insert. This is idiom.
      else
      {
         SetPosition( p-1, list, &current );
         newnode->next = current->next;
         current->next = newnode;
      }
      list->count++;
   }
}


<2> TODO: needs more to be precise.
The above example has mismatch between count and pos, that is:

count 1 2 3 4 5
pos   0 1 2 3 4

The following uses the same range for both count and pos. Make a note for that always need to handle
the first node separately and <the-previous> node to insert in the list.

#include <iostream>
#include <cstdlib>

typedef int EntryType;
typedef int Position;

typedef struct node
{
  EntryType entry;
  node*     pnext;
} Node;

typedef struct {
  int    count;
  Node*  header;
} List;

Node* MakeNode( EntryType entry )
{
  Node* pnode = NULL;

  if( (pnode = (Node*) malloc( sizeof(Node))) == NULL )
    return NULL;

  pnode->entry = entry;
  pnode->pnext = NULL;

  return pnode;
}

void CreatList( List* list )
{ 
   list->count = 0;
   list->header = NULL; 
}

bool ListEmpty( List* list )
{ return ( list->header == NULL ); }

// add only at the end
bool ListAdd( List* list, EntryType entry )
{
  Node* pnode, *pend;

  if( (pnode = MakeNode(entry)) == NULL )
  {
    std::cout << "add: mem is full" << std::endl;
    return false;
  }

  if( ListEmpty( list ) )
  {
    list->header = pnode;
  }
  else
  {
    // search the end using pnext
    for( pend = list->header; pend->pnext; pend = pend->pnext )
      ;

    pnode->entry = entry;

    pend->pnext = pnode;
  }

  list->count++;

  std::cout << "add: added " << entry << ", count " << list->count << std::endl;

  return true;
}

// support random-access
bool SetPosition( List* list, Position pos, Node** ppNode)
{
   Node* pnode;
   int current;

   // check if pos  is in [1, count]
   if( pos < 1 || pos > list->count )
   {
      std::cout << "error: attempt to insert in a position" << pos << " not in the list" << std::endl;
      return false;
   }

   pnode = list->header;

   #ifdef RETURN_THE_PREVIOUS
   for( current=2; current < pos; current++ )
      pnode = pnode->pnext;
   #endif
   for( current=1; current < pos; current++ )
      pnode = pnode->pnext;

   *ppNode = pnode;
}

 [KT] Compared the previous, this has a protection. If call this when a list empty, that is, pos=1,
 count=0, then error happens and return. Cannot use this when a list is empty. Why? Looks okay.

bool InsertList( List* list, EntryType entry, Position pos )
{
  Node* pnewnode, *pnode;

  // check if pos  is in [1, count]
  if( pos < 1 || pos > list->count )   // <diff>
  {
    std::cout << "error: attempt to insert in a position not in the list" << std::endl;
    return false;
  }

  // get a new node
  pnewnode = MakeNode(entry);
  if(pnewnode==NULL)
  {
    std::cout << "error: no more memory" << std::endl;
    return false;
  }

  if( pos == 1 ) // [KT]
  {
    pnewnode->pnext = list->header;
    list->header = pnewnode;
  }
  else
  {
    // get the prev node of pos node [2, count]
#ifdef RETURN_THE_PREVIOUS
    SetPosition( list, pos, &pnode );
#endif

    SetPosition( list, pos-1, &pnode );

    // insert a new node between pos-1 and pos node
    pnewnode->pnext   = pnode->pnext; 
    pnode->pnext      = pnewnode;
  }

  list->count++;
}

bool DeleteList( List* list, EntryType entry, Position pos )
{
}

typedef void(*TRAVERSEFUNC)(EntryType);

void ListTraverse( List* list, TRAVERSEFUNC func)
{
  Node* pnode;

  if( ListEmpty(list) )
  {
    std::cout << "list is empty" << std::endl;
    return;
  }

  pnode = list->header;

  while(pnode)
  {
    func(pnode->entry);
    pnode = pnode->pnext;
  }
}

void EntryPrint(EntryType item)
{
   std::cout << "item is: " << item << std::endl;
}

int main()
{
  int item = 0;

  List list;
  CreatList(&list);

  std::cout << "type in 5 numbers." << std::endl;

  for(int i=0; i < 5; i++)
  {
    std::cin >> item;
    ListAdd(&list, item );
  }

  InsertList(&list, 10, 6);
  InsertList(&list, 10, 1);  // expects an error
  InsertList(&list, 20, 6);

  ListTraverse(&list, EntryPrint);
}


<3> template contiguous version
#include <iostream>

const int MAXLIST=100;

typedef enum { success, overflow, underflow, range_error} Error_code;

template <typename T>
class List 
{
  public:
    List() { count = 0; };
    int size() const;
    bool full() const;
    bool empty() const;
    void clear();
    void traverse( void(*v)(T &));

    //Error_code retrieve( int pos, T &x) const;
    //Error_code replace( int pos, const T &x );
    // postcondition: If 0 <= position < n, where n is the number of entries in the List, the
    // function succeeds: The entry at position is removed from the List, and all later entries have
    // their position numbers decreased by 1. The parameter x records a copy of the entry formerly
    // at position. Else: The function fails with a diagnostic error code.
    //Error_code remove( int pos, T &x ); 
    Error_code insert( int pos, const T &x );

  protected:
    int count;
    T entry[MAXLIST];
};

template <typename T>
int List<T>::size() const
{
  return count;
}

template <typename T>
bool List<T>::full() const
{
  return count == MAXLIST;
}

template <typename T>
bool List<T>::empty() const
{
  return count == 0;
}

template <typename T>
void List<T>::clear()
{
  count = 0;
}

template <typename T>
void List<T>::traverse( void (*visit)(T &e))
{
  for( T* it = entry; it != entry+count; it++ )
    visit( *it );
}

template <typename T>
Error_code List<T>::insert( int pos, const T &e )
{
  if( full() )
    return overflow;

  if( pos < 0 || pos > count )
    return range_error;

  // <key> moving. make room to insert by moving elements. Thus we say that the amount of work the
  // insertion and deletion does is approximately 'proportional' to n, the length of the list

  // note: when pos==count, it does seems to move entry[count] = count[count-1] which is off-the-end
  // access. Okay? Thing is that this is when list is full and there is no room to move element and
  // this case is checked before so not in this loop.

  for( int i = count-1; i >= pos; i-- )
    entry[i+1] = entry[i];

  entry[pos] = e;
  count++;

  return success;
}

void printList( int &i )
{
  std::cout << i << std::endl;
}

int main()
{
  int iarr[] = { 1, 3, 4, 6, 7, 10, 12, 25, 16, 33, 48, 51, 55 };
  int isize = sizeof iarr/ sizeof iarr[0];
  
  List<int> tlist;

  for( int i = 0; i < isize; i++ )
    tlist.insert( i, iarr[i] );

  std::cout << "-----------" << std::endl;
  tlist.traverse( printList );
}

<4> template linked version
#include <iostream>

using namespace std;

typedef enum { success, overflow, underflow, range_error } Error_code;

// nodes
template<typename T>
struct Node {
  T entry;
  Node<T> *next;

  Node() { next = NULL; }
  Node( T item, Node<T> *link = NULL ) { entry = item; next = link; }
};

template<typename T>
class List {
  public:
    ~List();
    List() { head = NULL; count = 0; };
    // List( const List<T> &copy );
    // void operator=(const List<T> &copy );

    int size() const { return count; }
    bool empty() const { return count == 0; }
    void clear();
    // void traverse( void (*visit)(T&));
    void traverse();

    Error_code retrieve( int position, T& entry) const;
    Error_code replace( int position, const T& entry );
    Error_code remove( int position, T& entry );
    Error_code insert( int position, const T& entry );

  protected:
    int count;
    Node<T> *head;
    Node<T> *set_position( int position ) const;
};

template<typename T>
List<T>::~List()
{
  if( !empty() )
  {
    Node<T> *following;

    for( head; head; head = following )
    {
      following = head->next;
      delete head;
    }

    head = NULL;
    count = 0;
  }
}

// position in 0 <= position < count. returns a pointer to the node 'in' position.
template<typename T>
Node<T> *List<T>::set_position( int position ) const
{
  Node<T> *q = head;
  for( int i = 0; i < position; i++ )
    q = q->next;

  return q;
}

template<typename T>
Error_code List<T>::insert( int position, const T& entry )
{
  if( position < 0 || position > count )
    return range_error;

  Node<T> *new_node, *previous, *following;

  if( position > 0 )
  {
    previous = set_position( position-1 );
    following = previous->next;
  }
  else
    following = head;

  new_node = new Node<T>( entry, following );

  if( new_node == NULL )
    return overflow;

  if( position == 0 )
    head = new_node;
  else
    previous->next = new_node;

  count++;

  return success;
}

template<typename T>
Error_code List<T>::remove( int position, T& entry )
{
  // note: when position > count and tried to remove off the end, get core
  // dump.
  if( position < 0 || position >= count )
    return range_error;

  Node<T> *previous, *following;

  if( position == 0 )
  {
    following = head->next;
    entry = head->entry;

    delete head;
    head = following;
  }
  else
  {
    previous = set_position(position-1);
    following = previous->next;

    previous->next = following->next;
    entry = following->entry;
    delete following;
  }

  count--;

  return success;
}

template<typename T>
void List<T>::traverse()
{
  Node<T>* node = head;

  cout << "{ ";

  for( node; node; node = node->next )
  {
    cout << node->entry << ", ";
  }

  cout << "}" << endl;
}

int main()
{
  int iarr[] = { 1, 3, 4, 6, 7, 10, 12, 25, 16, 33, 48, 51, 55 };
  int isize = sizeof iarr/ sizeof iarr[0];
  int entry;
  
  List<int> tlist;

  for( int i = 0; i < isize; i++ )
    tlist.insert( i, iarr[i] );

  // { 1, 3, 4, 6, 7, 10, 12, 25, 16, 33, 48, 51, 55, }
  cout << "-----------" << endl;
  tlist.traverse();

  tlist.remove( 1, entry ); cout << "removed:" << entry << endl;
  tlist.remove( 1, entry ); cout << "removed:" << entry << endl;

  // { 1, 6, 7, 10, 12, 25, 16, 33, 48, 51, 55, }
  cout << "-----------" << endl;
  tlist.traverse();

  tlist.remove( 0, entry ); cout << "removed:" << entry << endl;
  tlist.remove( 10, entry ); cout << "removed:" << entry << endl;

  // { 6, 7, 10, 12, 25, 16, 33, 48, 51, 55 }
  cout << "-----------" << endl;
  tlist.traverse();
}

note: the use of 'mutable'. For example, retrieve method is defined as a constant method, but its
implementation will need to alter the last-used position, current_position, of a List. We recognize
that although this operation does change some data members of a List object, it does not change the
sequence of entries that represents the actual value of the object


{improved-list}
For cases refering to the same entry several times as an example, this can be improved by keeping
the 'current' position which is the last-used position; <locality-of-reference> that is, if one
entry is accessed, is it likely that it will next be accessed again:

typedef int Position;

// See {list-linked-implementation} for comparison
//
typedef struct list {
  int          count;
  ListNode*    head; 
  Position     currentpos; ~
  ListNode*    current; ~
} List;

void SetPosition( Position p, List* list )
{
  if( p < 0 || p >= list->count )
    Error("attempt to set a position not in the list");
  else 
  {
    if( p < list->currentpos )
    {
      list->currentpos = 0;
      list->current = list->head; // since it has one-way direction
    }

    for( ; list->currentpos != p; list->currentpos++ )   // <key> is for condition
      list->current = list->current->next;
  }
}

This improves its efficiency than the previous but the changes needed to the various functions are
minor: For repeated references to the same position, neither if and for will be excuted; that is
when p equals to currentpos. So takes almost no time. For 'forward' move, will be very fast and for
backward move, operates the same way as the previous.


{doubly-linked-list}
Not a simple DL list but supports <random-access> which is more complicated than thought.

typedef struct listnode {
  ListEntry entry;
  struct listnode* next;
  struct listnode* prev;
} ListNode;

typedef struct list {
  int          count;   // notice that count [1..n] and pos[0..n-1]. no header any more
  ListNode*    current; ~
  Position     currentpos; ~
} List;

// set current to the position in 0.. count-1. see no return of ppNode and no run when
// pos==currentpos.
void SetPosition( Position p, List* list )
{
  if( p < 0 || p >= list->count )
    Error("attempt to set a position not in the list.");
  // move 'forward'
  else if( list->currentpos < p )
  {
    for(; list->currentpos != p; list->currentpos++ )
      list->current = list->current->next;
  }
  // move 'backward'
  else if( list->currentpos > p )
  {
    for(; list->currentpos != p; list->currentpos-- )
      list->current = list->current->prev;
  }
}


void InsertList( Position p, ListEntry x, List* list)
{
  ListNode* newnode, *following;

  if( p < 0 || p > list->count )
    Error("attempt to set a position not in the list.");
  else
  {
    newnode = MakeListNode(x);

    // insert at the beginning as it is not circular. This means that: first node's prev is null.
    //
    if( p == 0 )
    {
      newnode->prev = NULL;

      if( list->count == 0 )     // <key> need to handle when list is empty
        newnode->next = NULL;
      else
      {
        Setposition( 0, list );  // set current to pos 0
        newnode->next = list->current;
        list-current->prev = newnode; 
      }
    }
    else    // insert later in the list
    {
      // For DL, need the prev and the current(following) regardless of return pos from SetPostion.
      // For SL, need to have the previous.
      SetPosition( p-1, list );

      /* is temp really required?
       *
       *             cur(pos-1)  pos(end)
       * [prev next] [prev next] [prev next]
       * 
       *                 new [prev next]
       *
       * if do without temp(following) then
       *
       * cur->next = new;
       * cur->next->prev = new;
       * new->prev = cur;
       * new->next = cur->next; but cur->next is already changed.
       *
       * new->next = cur->next;
       * new->prev = cur;
       * cur->next->prev = new;
       * cur->next = new;
       *
       * seems okay. [NO] because cur->next is null when inserting at the end. REALLY?
       *
       *                 pos-1   pos
       *                 cur     following
       *         [0]     [1]     [2] 
       *          next -> next -> next -> null
       * null <- prev <- prev <- prev
       *
       */
      following = list->current->next;

      // insert between current and following
      newnode->next = following;
      newnode->prev = list->current;
      list->current->next = newnode;

      // <key> this check is required when inserting at the end because cur->next is null
      if(following)
        following->prev = newnode;
    }

    list->current = newnode;
    list->currentpos = p;
    list->count++;
  }
}


{list-contiguous-and-linked} {contiguous-vs-linked}
In summary, contiguous storage is generally preferable when:

o the records are individually very small
o the size of list is known when the program is written
o 'few' insertion or deletion need to be made except at the end of the list
o random (read) access is important

linked storage proves superior when:

o the records are large
o the size of list is not known when the program is written
o flexibility is needed in inserting, deleting and rearranging the entries.

            Searching   Insertion/deletion other then the end
Contiguous: O(1)        O(n)
Linked    : O(n)        O(1)


={============================================================================
*kt_dev_algo_004* queue

The queue has head(front) and tail(rear).

{queue-contiguous-implementations}
<approach-one> 
Use single index and use always index 0 as a head and the end as a tail. However, use first entry
and then move all the remaining entries one position up. Poor choice.

note: head and tail notation

   head           tail        // uses in code example
   0  1  2  3  4  5
   * deQ
                  * inQ
                  
   tail           head

<approach-two>
Use array and two indices to keep track of both the front and the rear. However, has a defect that
both are increased but never decreased. Space problem. If can relocate queue regularly, two indices
and straight-line storage implementation is very efficient.

// code-example
//
#include <iostream>

#define MAXSIZE 5

typedef int EntryType;

typedef struct {
   EntryType   data[MAXSIZE];
   int         head;
   int         tail;
} Queue;

void CreateQueue(Queue* queue)
{
   queue->head = queue->tail = 0;
}

bool QueueEmpty(Queue* queue)
{
   if( queue->head == queue->tail )
   {
      std::cout << "empty(" << queue->head << "," << queue->tail << ")" << std::endl;
      return true;
   }

   return false;
}

bool QueueFull(Queue* queue)
{
   if( queue->tail >= MAXSIZE )
   {
      std::cout << "full(" << queue->head << "," << queue->tail << ")" << std::endl;
      return true;
   }

   return false;
}

void AddQueue( Queue* queue, EntryType entry )
{
   if( QueueFull(queue) )
      return;

   queue->data[queue->tail++] = entry;
}

void DelQueue( Queue* queue, EntryType* pentry )
{
   if( QueueEmpty(queue) )
      return;

   *pentry = queue->data[queue->head++];
}

void TraverseQueue( Queue* queue, void(*f)(int, EntryType))
{
   int current, end;

   for( current = queue->head, end = queue->tail; current < end; current++ )
      f(current, queue->data[current]);
}

void PrintEntry(int pos, EntryType entry)
{
   std::cout << " " << pos << " : [" << entry << "]" << std::endl;
}

int main()
{
   Queue queue;

   CreateQueue(&queue);

   QueueEmpty(&queue);

   AddQueue(&queue, 10);
   AddQueue(&queue, 11);
   AddQueue(&queue, 12);

   TraverseQueue(&queue, PrintEntry);

   AddQueue(&queue, 13);
   AddQueue(&queue, 14);
   AddQueue(&queue, 15);

   TraverseQueue(&queue, PrintEntry);

   return 0;
}


{queue-circular}
To solve space problem, can use 'circular'-array and decide boundary condition to indicate if a
queue is full or empty. However, there is no way, by looking at the indicies ALONE, to tell a full
queue from an empty one.

As with above code, it is a queue with size 5 then:

empty when head,tail is (0,0)
 0th : [10]
 1th : [11]
 2th : [12]
 3th : [13]
 4th : [14] // entry[tail++] = e;
full (0,5) 5%MAXSIZE = 0. Then head,tail is (0,0) so there is no way to tell empty or full

q which has one item
... [] ...
    rear
    front

q which is empty after removing one, that is, increase front index
... [] [] [] ...
    rear
       front

q which has one empty position left
... [] [] [] ...
    rear  front

q which is full after adding one, that is, increase rear index
... [] [] [] ...
    rear
       front

addQ is to insert item and inc rear and subQ is to remove item and dec front. See the result of the
code example. To solve that there is no difference between full and empty, there are three
approaches:

<approach-one> queue-circular-array, interview
Use circular array, two indicies and one position left 'vacant'.

... [] [*] [] ...
    rear
            front

So the idea is that empty is when rear == front and full when rear == front-2. note: That is wrong
and was difficult that thought.

From 8.4.3 in DATA STRUCTURES IN C++ (Google eBook) N. S. KUTTI, P. Y. PADHYE, think virtual-head
which means a real head and head which means vacant element. The head is always virtual head+1. The
head and virtual head moves along as rear do and there is no need to move elements to keep vacant
element. 

<key> 
1. Do not think about virtual head and just calc tail and head by adding one more when do inQ and
deQ operations. 

2. Unlike linear queue, stack, and simple list which has tail and head pointing to 'next' available
position, head points to the vacant and tail points to the last.

3. The empty condition is when head == tail and the full is when head == (tail+1)%SIZE.

(r,f)             full  empty                   full
(0,4) (0,3) (0,2) (0,1) (0,0) (1,0) (2,0) (3,0) (4,0)
-4    -3    -2    -1    0     1     2     3     4     rear-front
 1     2     3     4    5     6     7     8     9     +QSIZE(5)
 1     2     3     4    0     1     2     3     4     length = (rear-front+QSIZE)%QSIZE

init: head=tail=0;                       // can be any index
empt: return head==tail;
full: return (tail+1)%QSIZE == head;
leng: length = (tail+QSIZE-head)%QSIZE;  // can get any time
// do not think about this: haed: head = (front+1)%QSIZE;

<do>
void CreateQueue(Queue* queue)
bool QueueEmpty(Queue* queue)
bool QueueFull(Queue* queue)
void AddQueue( Queue* queue, EntryType entry )
void DelQueue( Queue* queue, EntryType* pentry )
void TraverseQueue( Queue* queue, void(*f)(int,int, EntryType))
void PrintEntry(int pos, int length, EntryType entry)

<example>
#include <iostream>

#define MAXSIZE 5

typedef int EntryType;

typedef struct {
   EntryType   data[MAXSIZE];
   int         head;
   int         tail;
} Queue;

void CreateQueue(Queue* queue)
{
   queue->head = queue->tail = 0;
}

bool QueueEmpty(Queue* queue)
{
   if( queue->head == queue->tail )
   {
      std::cout << "empty(" << queue->head << "," << queue->tail << ")" << std::endl;
      return true;
   }

   return false;
}

bool QueueFull(Queue* queue)
{
   if( (queue->tail+1)%MAXSIZE == queue->head ) // ~
   {
      std::cout << "full(" << queue->head << "," << queue->tail << ")" << std::endl;
      return true;
   }

   return false;
}

void AddQueue( Queue* queue, EntryType entry )
{
  if( QueueFull(queue) )
    return;

  queue->tail = (queue->tail+1)%MAXSIZE; // ~
  queue->data[queue->tail] = entry;      // ~

// std::cout << "add(" << queue->tail << ")" << std::endl;
}

void DelQueue( Queue* queue, EntryType* pentry )
{
  if( QueueEmpty(queue) )
    return;

  queue->head = (queue->head+1)%MAXSIZE;
  *pentry = queue->data[queue->head];

//   std::cout << "del(" << queue->head << ")" << std::endl;
}

void TraverseQueue( Queue* queue, void(*f)(int,int, EntryType))
{
  int count=0, current=0;

  // See *kt_dev_algo_005*
  // int length = abs( queue->tail - queue->head)%MAXSIZE; // this do not works.
  int length = ( queue->tail - queue->head + MAXSIZE )%MAXSIZE;

  for( current = queue->head+1, count=0; count < length; count++, current++ )
  {
    current = current%MAXSIZE;
    f(current, length, queue->data[current]);
  }
}

void PrintEntry(int pos, int length, EntryType entry)
{
  std::cout << " " << pos << ":" << length << " : [" << entry << "]" << std::endl;
}

int main()
{
  Queue queue;
  EntryType entry;

  CreateQueue(&queue);

  QueueEmpty(&queue);

  AddQueue(&queue, 10);
  AddQueue(&queue, 11);
  AddQueue(&queue, 12);

  TraverseQueue(&queue, PrintEntry);

  AddQueue(&queue, 13);
  AddQueue(&queue, 14);
  AddQueue(&queue, 15);

  TraverseQueue(&queue, PrintEntry);

  DelQueue(&queue, &entry);
  std::cout << "del " << entry << std::endl;

  DelQueue(&queue, &entry);
  std::cout << "del " << entry << std::endl;

  DelQueue(&queue, &entry);
  std::cout << "del " << entry << std::endl;

  AddQueue(&queue, 100);
  AddQueue(&queue, 101);
  AddQueue(&queue, 102);

  TraverseQueue(&queue, PrintEntry);

  DelQueue(&queue, &entry);
  std::cout << "del " << entry << std::endl;

  DelQueue(&queue, &entry);
  std::cout << "del " << entry << std::endl;

  AddQueue(&queue, 300);
  AddQueue(&queue, 301);
  AddQueue(&queue, 302);

  TraverseQueue(&queue, PrintEntry);

  return 0;
}

<manipulation-first-and-update-later>
Unlike the above which update index first and get/set later, if change the order of operation then
would it work?

inQ
{
    queue->data[queue->tail+1] = entry; 
    queue->tail = (queue->tail+1)%MAXSIZE;
}

deQ
{
    *pentry = queue->data[queue->head+1];
    queue->head = (queue->head+1)%MAXSIZE;
}

NO since it cause out of index access and mangles structure. See:

As this example, made it full and done three deletions then head, tail would be head(3) and tail(4).
This means q has one item.

0 1 2 3 4 -> 0 1 2 3 4 
  * * * *          v * 
                   h t

Now calls add, q is not full and add three items: add [5] and set tail=0; this will access [5] which
is out of range and overwrite queue->head because it is next to queue.entry. add [0] and set tail=1;
add [1] and set tail=2; [5] is off-the-end access and mangles queue structure and causes a problem
when delete items. 

circular q with vacant                       circular q with count
when t==3, t=4 from mod and inc; and [4]=x   when t==4, [4]=x; t=0 from mod and inc
this is differnt from the straight line implementation


<with-moving-window>
1. As with circular, has one vacant.

0 1 2 3 4   : h == t == 0

0 1 2 3 4   : h == 1
*

0 1 2 3 4   : h == 2
* *

0 1 2 3 4   : h == 3
* * *

0 1 2 3 4   : h == 4
* * * *

0 1 2 3 4   : full. t == 1, h == 0
x * * * *

0 1 2 3 4   : full. t == 2, h == 1
* x * * * 

2. No deQ interface and moves a window instead.

3. Maintain average of window.

template <class T>
class MovingAverage
{
public:
    MovingAverage(size_t initial_size=10)
    {
        resize(initial_size);
    }

    void reset()
    {
        accumulated_value = T();
        head = 0;
        tail = 0;
    }

    void resize(size_t new_size)
    {
        reset();
        values.resize(new_size+1, T()); // since the actual size is 1 less (one empty slot)
    }

    T add(T new_value)
    {
        const size_t max_size = values.size();

        // deQ. when full, do deQ rather than an error and by doing this, moves "widnows"
        if((head + 1) % max_size == tail)
        {
            accumulated_value -= values[tail];
            tail = (tail + 1) % max_size;
        }
        values[head] = new_value;
        head = (head + 1) % max_size;
        accumulated_value += new_value;

        return value();
    }

    T value() const
    {
        return accumulated_value / size();
    }

    size_t size() const
    {
        return (head - tail + values.size()) % values.size();
    }

    size_t max_size() const
    {
        return values.empty() ? 0 : values.size() - 1; // there's always one empty slot
    }

private:
    size_t head;
    size_t tail;

    std::vector<T> values;
    T accumulated_value;
};


<example> use reference
#include <iostream>

using namespace std;

const int MAXSIZE = 5;

typedef int EntryType;

typedef struct {
  int       head;
  int       tail;
  EntryType entry[MAXSIZE];
} Queue;

void CreateQueue(Queue& queue)
{
  queue.head = queue.tail = 0;  
}

bool QueueEmpty(Queue& queue)
{
  return (queue.head == queue.tail) ? true : false;
}

bool QueueFull(Queue& queue)
{
  return (queue.head == (queue.tail+1)%MAXSIZE) ? true : false;
}

void AddQueue( Queue& queue, EntryType entry )
{
  if( !QueueFull(queue) )
  {
    queue.tail = (queue.tail+1)%MAXSIZE;
    queue.entry[queue.tail] = entry;
  }
}

void DelQueue( Queue& queue, EntryType& pentry )
{
  if( !QueueEmpty(queue) )
  {
    queue.head = (queue.head+1)%MAXSIZE;
    pentry = queue.entry[queue.head];
  }
}

// note: shall use length to traverse and no need to have empty check
void TraverseQueue( Queue& queue )
{
  if( !QueueEmpty(queue) )
  {
    cout << "{ ";

    int count = (queue.tail-queue.head+MAXSIZE)%MAXSIZE;

    for( int current = queue.head+1, idx=0; idx < count; current++, idx++ )
    {
      cout << queue.entry[current%MAXSIZE] << ", ";
    }

    cout << "}" << endl;
  }
}

int main()
{
  Queue queue;
  EntryType entry;

  CreateQueue(queue);

  AddQueue(queue, 10);    // {10, 11,12}
  AddQueue(queue, 11);
  AddQueue(queue, 12);

  TraverseQueue(queue);

  AddQueue(queue, 13);    // {10, 11,12,13}
  AddQueue(queue, 14);
  AddQueue(queue, 15);

  TraverseQueue(queue);

  DelQueue(queue, entry);
  std::cout << "del " << entry << std::endl;

  DelQueue(queue, entry);
  std::cout << "del " << entry << std::endl;

  DelQueue(queue, entry);
  std::cout << "del " << entry << std::endl;

  AddQueue(queue, 100);   // {13, 100,101,102}
  AddQueue(queue, 101);
  AddQueue(queue, 102);

  TraverseQueue(queue);

  DelQueue(queue, entry);
  std::cout << "del " << entry << std::endl;

  DelQueue(queue, entry);
  std::cout << "del " << entry << std::endl;

  AddQueue(queue, 300);   // { 101, 102, 300, 301}
  AddQueue(queue, 301);
  AddQueue(queue, 302);

  TraverseQueue(queue);

  return 0;
}


<approach-two> 
Use circular array, two indicies and new variable: a bool 'flag' for full or empty. The flag is
toggle: For a case from a book, if q becomes diff(front-rear) == 1 while flag == full then q becomes
empty. Or int variable to indicate.

<approach-three>
Use circular array, two indicies and new variable: a counter(length) 

typedef T QueueEntry; // application-program dependent

typedef struct queue {
  int count; // 0 .. MAXQUEUE-1
  int front;
  int rear;
  QueueEntry entry[MAXQUEUE];
} Queue;

void CreatQueue(Queue* q)
{
  q->count = q->front = 0;
  q->rear = -1;               // emptiness
}

/* Or Insert. add an entry as its last */
void Append(QueueEntry x, Queue* q)
{
  if( QueueFull(q))
    Error(...);
  else
  {
    q->count++;
    // if use rear=-1 when init
    q->rear = (q->rear+1) % MAXQUEUE;
    q->entry[ q->rear ] = x;
    // if use rear=0 when init
    q->entry[ q->rear ] = x;
    q->rear = (q->rear+1) % MAXQUEUE;
  }
}

/* Or Delete. delete the first entry and note that *x */
void Serve(QueueEntry *x, Queue* q)
{
  if( QueueEmpty(q) )
    Error(...);
  else
  {
    q->count--;
    *x = q->entry[ q->front ];
    q->front = (q->front+1) % MAXQUEUE;
  }
}

Boolean QueueFull(Queue* q)
{
  return q->count >= MAXQUEUE;
}

Boolean QueueEmpty(Queue* q)
{
  return q->count <= 0;
}

int QueueSize(Queue* q)
{
  return q->count;
}

Also can have ClearQueue, QueueFront, and TraverseQueue.


note: There is no certain value for emptiness in init since use count for full and empty. As front
and rear always increases, fetch first and increase or decrease later. This is the same as the array
implementation except mod operation to make it circular.

// code-example
// 
#include <iostream>

#define MAXSIZE 5

typedef int EntryType;

typedef struct {
   EntryType   data[MAXSIZE];
   int         count;
   int         head;
   int         tail;
} Queue;

void CreateQueue(Queue* queue)
{
   queue->head = queue->tail = queue->count = 0;
}

bool QueueEmpty(Queue* queue)
{
   if( queue->count == 0 )
   {
      std::cout << "empty(" << queue->count << ")" << std::endl;
      return true;
   }

   return false;
}

bool QueueFull(Queue* queue)
{
   if( queue->count >= MAXSIZE )
   {
      std::cout << "full(" << queue->count << ")" << std::endl;
      return true;
   }

   return false;
}

// the same as the array implementation except mod operation to make it circular
void AddQueue( Queue* queue, EntryType entry )
{
   if( QueueFull(queue) )
      return;

   std::cout << "add(" << queue->tail << ")" << std::endl;
   queue->data[queue->tail++] = entry;
   queue->tail = (queue->tail)%MAXSIZE;

   queue->count++;
}

void DelQueue( Queue* queue, EntryType* pentry )
{
   if( QueueEmpty(queue) )
      return;

   *pentry = queue->data[queue->head++];
   queue->head = (queue->head)%MAXSIZE;

   queue->count--;
}

// changed
void TraverseQueue( Queue* queue, void(*f)(int,int, EntryType))
{
   int count=0, current=0;
   int length = queue->count;

   for( current = queue->head, count=0; count < length; count++, current++ )
   {
      current = current%MAXSIZE;
      f(current, length, queue->data[current]);
   }
}

void PrintEntry(int pos, int length, EntryType entry)
{
   std::cout << " " << pos << ":" << length << " : [" << entry << "]" << std::endl;
}

int main()
{
   Queue queue;
   EntryType entry;

   CreateQueue(&queue);

   QueueEmpty(&queue);

   AddQueue(&queue, 10);
   AddQueue(&queue, 11);
   AddQueue(&queue, 12);

   TraverseQueue(&queue, PrintEntry);

   AddQueue(&queue, 13);
   AddQueue(&queue, 14);
   AddQueue(&queue, 15);

   TraverseQueue(&queue, PrintEntry);

   DelQueue(&queue, &entry);
   std::cout << "del " << entry << std::endl;

   DelQueue(&queue, &entry);
   std::cout << "del " << entry << std::endl;

   DelQueue(&queue, &entry);
   std::cout << "del " << entry << std::endl;

   AddQueue(&queue, 100);
   AddQueue(&queue, 101);
   AddQueue(&queue, 102);

   TraverseQueue(&queue, PrintEntry);

   DelQueue(&queue, &entry);
   std::cout << "del " << entry << std::endl;

   DelQueue(&queue, &entry);
   std::cout << "del " << entry << std::endl;

   AddQueue(&queue, 300);
   AddQueue(&queue, 301);
   AddQueue(&queue, 302);

   TraverseQueue(&queue, PrintEntry);

   return 0;
}


<example> circular using count and class
#include <iostream>

using namespace std;

typedef int Queue_entry;

const int MAXSIZE = 5;

enum Error_code { success, underflow, overflow };

class Queue {
  public:
    Queue();
    bool empty() const;
    Error_code serve();
    Error_code append(const Queue_entry &item);
    Error_code retrieve(Queue_entry &item) const;
    void print() const;

  protected:
    int count;
    int front, rear;
    Queue_entry entry[MAXSIZE];
};

Queue::Queue()
{
  count = 0;
  front = 0;
  rear = MAXSIZE-1; // note: shall due to the way of increase
  // rear = 0;   // note: to use this, current = front+1 in print()
}

bool Queue::empty() const
{
  return count == 0;
}

// If there is space, x is added to the Queue as its rear. Otherwise an Error_code of overflow is
// returned.
Error_code Queue::append( const Queue_entry &item )
{
  if( count >= MAXSIZE ) return overflow;

  count++;

  // rear = (rear+1)%MAXSIZE;
  rear = (rear+1) == MAXSIZE ? 0 : (rear+1);
  entry[rear] = item;

  return success;
}

// If the Queue is not empty, the front of the Queue has been removed. Otherwise an Error_code of
// underflow is returned.
Error_code Queue::serve()
{
  if( count <=0 ) return underflow;

  count--;

  front = (front+1)%MAXSIZE;

  return success;
}

// If the Queue is not empty, the front of the Queue has been recorded as x. Otherwise an Error_code
// of underflow is returned.
Error_code Queue::retrieve( Queue_entry &item ) const
{
  if( count <=0 ) return underflow;

  item = entry[front];

  return success;
}

void Queue::print() const
{
  cout << "{ ";

  for( int current = front, idx = 0; idx < count; current++, idx++ )
    cout << entry[ current%MAXSIZE ] << ", ";

  cout << "}" << endl;
}

int main()
{
  Queue queue;
  Queue_entry entry;

  queue.append(10);    // {10,11,12}
  queue.append(11);
  queue.append(12);

  queue.print();

  queue.append(13);    // {10,11,12,13,14}
  queue.append(14);
  queue.append(15);

  queue.print();

  // DelQueue(queue, entry);
  queue.retrieve(entry); queue.serve();
  std::cout << "del " << entry << std::endl;

  queue.retrieve(entry); queue.serve();
  std::cout << "del " << entry << std::endl;

  queue.retrieve(entry); queue.serve();
  std::cout << "del " << entry << std::endl;

  queue.append(100);   // {13, 14, 100, 101, 102}
  queue.append(101);
  queue.append(102);

  queue.print();

  queue.retrieve(entry); queue.serve();
  std::cout << "del " << entry << std::endl;

  queue.retrieve(entry); queue.serve();
  std::cout << "del " << entry << std::endl;

  queue.append(300);   // { 100, 101, 102, 300, 301}
  queue.append(301);
  queue.append(302);

  queue.print();

  return 0;
}

{queue-linked-implementations}
Unlike contiguous queue, NO space problem and NO emptiness/fullness problem. So no full check and
only care about emptiness:

1. Addition when queue is empty must be treated 'separately' since addition to an empty queue
requires setting both the front and the rear to the new node, whereas addition to nonempty requires
changing only the rear. 

2. Deletion when queue goes empty must be treated since need to update rear as well.

typedef T QueueEntry;

typedef struct queuenode {
  QueueEntry entry;
  struct queuenode *next;
} QueueNode;

typedef struct queue {
  QueueNode* front;
  QueueNode* rear;
} Queue;

void CreateQueue(Queue *q)
{
  // this is a 'empty' condition which is NULL but the equal
  q->front = q->rear = NULL;
}

// QueueNode* pentry = (QueueNode*) malloc( sizeof(QueueNode) );
// AppendNode( pentry, q );
//
// note: This reveals that it is linked implementation since use of "Node" wording. Not well in
// hiding. The following is better?
//
// QueueItem* pitem = (QueueItem*) malloc( sizeof(QueueItem) );
// AppendQueue( pitem, q );
//
void AppendNode(QueueNode *p, Queue* q)
{
  if(!p)
    Error(...)
  else if( QueueEmpty(q) )
    q->front = q->rear = p;
  else
  {
    q->rear->next = p;
    q->rear = p;
  }
}

// 
// QueueNode* pentry;
// ServeNode( &pentry, q);
// ..
// use entry
// ..
// free(pentry);
//
void ServeNode(QueueNode**p, Queue* q)
{
  if( QueueEmpty(q) )
    Error(...);
  else
  {
    *p = q->front;
    q->front = q->front->next;

    // if q is empty, front is already null so mark rear null as well. Here empty condition is
    // when both are null but not the same.
    if( QueueEmpty(q) )
      q->rear = NULL;
  }
}


{queue-circularly-linked}
This is a linked list in which the node at the tail of the list, instead of having a null, points
back to the node at the head. Need only one pointer tail to access both ends of the list.


={============================================================================
*kt_dev_algo_005*	array: index shift

{example-one}

From *kt_dev_algo_007*	recursion:

4x4
00 01 02 03 : down diff -3. 4th covers 1 pos. -> 0th
10 11 12 13 : down diff -2. 5th covers 2         1th
20 21 22 23 : down diff -1. 6th covers 3         2th
30 31 32 33 : down diff  0. 0th covers 4         3th
            : down diff  1. 1th covers 3         4th
				: down diff  2. 2th covers 2         5th
				: down diff  3. 3th covers 1         6th

#define BOARDSIZE 	4						// 4x4 space
#define DIAGONAL		(2*BOARDSIZE-1)	// up or down diagonal size. 7
#define DOWNOFFSET	(BOARDSIZE-1)		// down diagonal offset. BOARDSIZE-1

bool downfree[ DIAGONAL ];

downfree[ queenrow - col + DOWNOFFSET ] = false;

Since array index cannot be negative, need to shift index into positive. Here -3...3 to 0...6 and
used DOWNOFFSET(3).

-3 -2 -1 0 1 2 3
 0  1  2 3 4 5 6 	// array[7];


{example-two}

From circular-queue, rear-front can have -4...4 and to get the length of queue can shift. Here
there is one vacant element.

 0  1  2  3  4
[f][h][ ][ ][r]

(r,f)                   empty                   full
(0,4) (0,3) (0,2) (0,1) (0,0) (1,0) (2,0) (3,0) (4,0)
-4    -3    -2    -1    0     1     2     3     4			rear-front
 1     2     3     4    5     6     7     8     9			+QSIZE(5)
 1     2     3     4    0     1     2     3     4			(rear-front+QSIZE)%QSIZE

 0     1     2     3    4     5     6     7     8			+QSIZE-1(4)
 
The difference is that there is one vacant element so used QSIZE to shift but not QSIZE-1. 0th is
not used.


==============================================================================
*kt_dev_algo_006*	the game of life

From {ref-001}. In short, the rule as to the neighbour count is:

o if 3 and the dead cell, gets live in the next run.
o if > 4 and the live cell, gets dead in the next run.
o if 2, makes no change.
o if 0, 1, gets dead. makes no change.

{first-version}

Grid map, newmap; // [MAXROW+2][MAXCOL+2]

do 
{
	 for( row = 1; row <= MAXROW; row++ )	// why starts from 1? see {hedge-or-sentinel}
		  for( col = 1; col <= MAXCOL; col++ )
				switch( NeighborCount( map, row, col )) 
				{
					 case 0: case 1:
					 newmap[row][col] = DEAD; break;

					 case 2:
					 newmap[row][col] = map[row][col]; break;

					 case 3:
					 newmap[row][col] = ALIVE; break;

					 case 4: case 5: case 6: case 7: case 8:
					 newmap[row][col] = DEAD; break;
				}

		CopyMap(map, newmap);
		WriteMap(map);

} while( UserSaysYes());

This approach is:

 map (current gen) -> cal and updated newmap(next gen) -> copy newmap to map
 ... repeats
	
MAXROW x MAXCOL = 20 x 60 = 1200. This amounts to about 18,000 statements.


{second-version}

Question is that is it necessary to calculate the number of neighbors of every cell at every
generation? No and improvements are:

o no copy from newmap to map.
o no cal for a whole map but for neighboring cells.

Grid map, numbernbrs;	// [MAXROW+2][MAXCOL+2]
List newlive, newdie;
List maylive, maydie;

while(UserSaysYes())
{
	 // current generation
	 // Vivify it in [map] and add it from [maylive] to [newlive] when it is dead and 3
	 TraverseList( &maylive, Vivify );
	 TraverseList( &maydie, Kill );
	 ClearList( &maylive );
	 ClearList( &maydie );

	 WriteMap( map );		// print to user

	 // next generation
	 // while traversing [newlive], cal neighbor count and update [numbernbrs]. Add it to [maylive]
	 // or [maydie]
	 TraverseList( &newlive, AddNeighbors );
	 TraverseList( &newdie, SubstractNeighbors );
	 ClearList( &newlive );
	 ClearList( &newdie );
}

{postpone-difficulty}

The subtle problem is that maylive/maydie can have multiple same entry and spurious entry and some
should be changed later because [numbernbrs] is not fully updated while traversing lists. This
difficluty is handled later when running vivify call because we have now completed neighbor counts,
that is [numbernbrs]. 

{loop-invariant}

The {loop-invariant} is a statement that is true at the beginning of every iteration of the loop. In
this example, that is:

At the beginning of the main loop, list maylive contains only dead cells, and list maydie contains
only living cells, but the list may contain duplicates or spurious entries whose counts are wrong.
The list newlive and newdie are empty.

The purpose of loop invariant is to capture the essence of the dynamic process. It is not always
easy to find.

{performance}

The amount of computation is no longer proportional to the size of the grid but to the number of
changes being made. Has about 2900 statements which is 6 times faster than the first. Is it
worthwhile although it is more complicated and costly to maintain? Usually there is
{space-and-time-trade-offs}. Depends on.


==============================================================================
*kt_dev_algo_007*	recursion

The recursion is [divide-and-conquer] as it reduce the large problem to one or more problems of a
similar nature but a smaller size. 

Must determine the [stopping-rule], the smallest case because there must be some way that the
recursion stops.


{the-tower-of-hanoi}

The idea is to concentrate not on the first step, but rather on the hardest step: moving the bottom
disk because condition is that only one disk can be moved at a time and the bottom, largest, one can
never be on top of any other.

Move( disk, start, finish, temp );

When there are 64 disks:

Move( 63, 1, 2, 3);                             // 63th disk
printf("move disk 64 from tower 1 to 3.\n");    // 64th disk
Move( 63, 2, 3, 1);                             // 63th disk

The stopping rule is when there is no disk to be moved, there is nothing to do.

#define DISKS	64

void Move(int count, int start, int finish, int temp)
{
	 if( count > 0 )
	 {
		  Move( count-1, start, temp, finish );
		  printf("move a disk from tower %d to %d.\n", start, finish );
		  Move( count-1, temp, finish, start );
	}
}

int main()
{
	 Move( DISKS, 1, 3, 2 );
	 return 0;
}

The number of non-leaves, that is the number of moves for 64 is 2^64-1. This is about 5x10^11 years
where 2x10^10 is 20 billion years

{recursion-tree}

This is a tool to visualize recursive call in which node represents recursion call. The time
requirement is the total number of nodes, vertices, in a recursion tree since traverse all nodes and
the space(stack space) is the depth of tree, not the number of nodes.

                                                          Move(3, 1,3,2) ()

                             Move(2, 1,2,3) ()                                              ...

         Move(1, 1,3,2) ()                      Move(1, 3,2,1) ()          

Move(0, 1,2,3) ()  Move(0, 2,3,1) ()   Move(0, 3,1,2) ()  Move(0, 1,2,3) ()


To get this in programming, can think of:

#include < iostream>

using namespace std;

#define DISKS	3

unsigned int depthRecursion;

void PrintDepth( bool dash, unsigned int depth )
{
	for( unsigned int i=0; i <= depth; ++i)
	{
		if(dash)
			cout << "--";
		else
			cout << "  ";
	}

	if(dash)
		cout << "(" << depth << ") ";
	else
		cout << "      ";
}

void Move(int count, int start, int finish, int temp)
{
	 depthRecursion++;
	 PrintDepth( true, depthRecursion );

	 cout << "Move(" << count << "," << start << "," << finish << "," << temp << ")" << endl;

	 if( count > 0 )
	 {
		  Move( count-1, start, temp, finish );
	 	  PrintDepth( false, depthRecursion );
		  cout << "move a disk " << count << " from tower " << start << " to " << finish << endl;
		  Move( count-1, temp, finish, start );
	 }

	 depthRecursion--;
}

int main()
{
	 Move( DISKS, 1, 3, 2 );
	 return 0;
}

kt@kt-ub-vb:~/c++$ ./a.out 
----(1) Move(3,1,3,2)
------(2) Move(2,1,2,3)
--------(3) Move(1,1,3,2)                        // { (1, s,f,t)
----------(4) Move(0,1,2,3)                      //    { (0, s,f,t)
              move a disk 1 from tower 1 to 3
----------(4) Move(0,2,3,1)                      //    } (0, s,f,t)
            move a disk 2 from tower 1 to 2
--------(3) Move(1,3,2,1)	                      // } (1, s,f,t)

----------(4) Move(0,3,1,2)
              move a disk 1 from tower 3 to 2
----------(4) Move(0,1,2,3)

          move a disk 3 from tower 1 to 3
------(2) Move(2,2,3,1)

--------(3) Move(1,2,1,3)
----------(4) Move(0,2,3,1)
              move a disk 1 from tower 2 to 1
----------(4) Move(0,3,1,2)

            move a disk 2 from tower 2 to 3
--------(3) Move(1,1,3,2)
----------(4) Move(0,1,2,3)
              move a disk 1 from tower 1 to 3
----------(4) Move(0,2,3,1)

Here counts is disks which are 1, 2, 3 and when follows the messages, get a problem solved. Note
that PrintDepth is correct showing the same depth of recursion in column.


{eight-queen-puzzle}

From {ref-001} and C version. The chess rules is that a queen can take another queen that is on the
same row, the same column, or the same diagonal.

<key-step>

This is formulating or outlining that use recursion to mean contiune to the next stage and repeat
the task.

This is naive approach when 8x8 board:

void AddQueen()
{
	 for( every unguarded position p on the board )
	 {
		  place a queen in position p;
		  queen++;

		  if( queen == 8 )
				print the configuration;
		  else
				AddQueen();

		  remove the queen from position p;
		  queen--;
	 }
}
 
4x4 eample

 dead end    dead end    solution    solution
  0 1 2 3     0 1 2 3     0 1 2 3     0 1 2 3 
0 Q ? ? ?   0 Q ? ? ?   0 X Q ? ?   0     Q   
1 X X Q ?   1 X X X Q   1 X X X Q   1 Q       
2 X X X X   2 X Q X X   2 Q X X X   2       Q 
3           3 X X X X   3 X X Q X   3   Q     

<backtrack> <postponing-the-work>

When reach a dead end, must backtrack by going back to the most recent choice we have made and
trying another possibility. Usally called [backtracking-algorithm] which attempt to complete a
search for a solution by constructing [partial-solution] and which proves useful in situation where
many possibilities may first appear such as scheduling problems and a compiler parsing to determine
the meaning of a statement. 

<data-structure>

To choose the data structure to represent data to solve a problem. In this case, array.

<observations>

observation-01: mark guarded and unguarded. 
If scan the board to see if a position is guarded whenever place a queen, would involve considerable
searching. As do on a paper, if can mark guarded posion when place a queen, can look for unguarded
position in the next stage. So reduced searching but a problem arise.

When remove a queen, should not necessrily change a position from false to true(unguarded) because
some other queen still guard that posiotion. So can use int array instead to count and position is
unguarded if and only if it has a count of 0. Better than the first approach but involves
considerable searching and calculation. How to improve? Need more observations.

observation-02: only one queen in each row

int queencol[ rows ] gives the column containing a queen and this covers vertical and horizental
positions.

observation-03: use [difference] for downwards and [sum] for upwards.

4x4
00 01 02 03 : down diff -3. 4th covers 1 pos. -> 0th
10 11 12 13 : down diff -2. 5th covers 2         1th
20 21 22 23 : down diff -1. 6th covers 3         2th
30 31 32 33 : down diff  0. 0th covers 4         3th
            : down diff  1. 1th covers 3         4th
				: down diff  2. 2th covers 2         5th
				: down diff  3. 3th covers 1         6th

The down and up diagonal examples are:

00 11 22 33 : down, 30 21 12 03 : up. where these are xy index in a array. 

The obseravtion here is that the main down diagonal has the same difference: 00 11 22 33 and otheres
are between -3..3. Since there is no minus index in array use offset to map 0..6 (shifted)

up diagonal are ones to upper-right. As down diagonal, cannot use difference because cannot uniquely
identify up diagonals. For example, 00 and 33 have 0 in difference. Therefore, use sum instead.

Try one example

  0 1 2 3
0 Q ? ? ?
1 X X Q ?
2 X X X X
3        

pos 00:Q: queencol[0] = 0. down diff 0 and 0th. up 0th.
pos 12:Q: queencol[1] = 2. down diff -1 and 6th. up sum 3.
    dead: backtrack. unset down 6th and up 3th. there is no duplicates in set/unset up and down diagonal
because pos on the same diagonal will not tried.

Therefore, no need to have int array for marking guarded and unguarded cells for a whole board.
Hence reduced calaulations and searching.

<analysis>

The navie approach which place 8 queens and reject illegal configutation every time when place a
queen. This is C(64, 8) = 64!/8!(64-8)! = 4,426,165,368. This is [combination] notation in math.

The [observation-02] cuts this to 8^8 = 16,777,216
The [observation-03] cuts this to 8! = 40,320

This shows the effectiveness of [backtrack] as reduce a recursion tree to manageable step. The
actual number of cases the program consider will be much less than this.

<code-program>

#include <iostream>

using namespace std;

#define BOARDSIZE 	4						// 4x4 space
#define DIAGONAL		(2*BOARDSIZE-1)	// up or down diagonal size
#define DOWNOFFSET	(BOARDSIZE-1)		// down diagonal offset. BOARDSIZE-1

// to set a column where queen is for a each row. For example,
//
//   0 1 2
// 0 Q
// 1 X X Q
//
// queencol has {0, 2, .. } means that row 0 has 0, row 1 has 2. this is the answer when finish.
//
int queencol[ BOARDSIZE ];					

// row where queen is and also means the number of queens has been put. recursion depth and
// horizental
int queenrow = -1;							

// bitset to mark guarded(occupied) or upguarded position for column, up and down diagonal
// for [backtrack]
bool colfree[ BOARDSIZE ];		// cloumn is guarded? vertical.
bool upfree[ DIAGONAL ];
bool downfree[ DIAGONAL ];

void PrintDepth( bool dash, unsigned int depth )
{
	for( unsigned int i=0; i <= depth; ++i)
	{
		if(dash)
			cout << "-";
		else
			cout << " ";
	}

	if(dash)
		cout << "(" << depth << ") ";
	else
		cout << "    ";
}

void WriteBoard()
{
	cout << "solution {";

	for( int i=0; i < BOARDSIZE; ++i)
		cout << queencol[i] << ",";

	cout << "}" << endl;
}

void AddQueen()
{
	 int col=0;

	 queenrow++;
	 PrintDepth(true, queenrow);
	 cout << "AddQueen(" << queenrow << ", " << col << ")" << endl;

	 for( col = 0; col < BOARDSIZE; col++ )
	 {
		  // check if colfree, upfree and downfree are unguarded
		  //
		  if( colfree[ col ] && upfree[ queenrow + col ] && downfree[ queenrow - col + DOWNOFFSET ] )
		  {
				// put a queen in position( queenrow, col )
				//
				PrintDepth(false, queenrow);
				cout << "added a queen(" << queenrow << ", " << col << ")" << endl;

				queencol[ queenrow ] = col;

				colfree[ col ] = false;
				upfree[ queenrow + col ] = false;
				downfree[ queenrow - col + DOWNOFFSET ] = false;

				if( queenrow == BOARDSIZE-1 ) // termination condition
					 WriteBoard();					// print out and should not terminate program to see all
					                           // solutions
				else 									// proceed recursively
					 AddQueen();

				PrintDepth(false, queenrow);
				cout << "removed a queen(" << queenrow << ", " << col << ")" << endl;

				// backtrack by removing the queen
				colfree[ col ] = true;
				upfree[ queenrow + col ] = true;
				downfree[ queenrow - col + DOWNOFFSET ] = true;
		  }
	 } // for end

	 queenrow--;
}

int main()
{
	 int i;
	 
	 // init bitsets
	 for(i = 0; i < BOARDSIZE; i++)
		  colfree[i] = true;	// unguarded

	 for(i = 0; i < DIAGONAL; i++)
	 {
		  upfree[i] = downfree[i] = true;
	 }

	 AddQueen();
	 return 0;
}

The output when run 4x4:

-(0) AddQueen(0, 0)
     added a queen(0, 0)
--(1) AddQueen(1, 0)
      added a queen(1, 2)
---(2) AddQueen(2, 0)
      removed a queen(1, 2)
      added a queen(1, 3)
---(2) AddQueen(2, 0)
       added a queen(2, 1)
----(3) AddQueen(3, 0)
       removed a queen(2, 1)
      removed a queen(1, 3)
     removed a queen(0, 0)
     added a queen(0, 1)
--(1) AddQueen(1, 0)
      added a queen(1, 3)
---(2) AddQueen(2, 0)
       added a queen(2, 0)
----(3) AddQueen(3, 0)
        added a queen(3, 2)
solution {1,3,0,2,}
        removed a queen(3, 2)
       removed a queen(2, 0)
      removed a queen(1, 3)
     removed a queen(0, 1)
     added a queen(0, 2)
--(1) AddQueen(1, 0)
      added a queen(1, 0)
---(2) AddQueen(2, 0)
       added a queen(2, 3)
----(3) AddQueen(3, 0)
        added a queen(3, 1)
solution {2,0,3,1,}
        removed a queen(3, 1)
       removed a queen(2, 3)
      removed a queen(1, 0)
     removed a queen(0, 2)
     added a queen(0, 3)
--(1) AddQueen(1, 0)
      added a queen(1, 0)
---(2) AddQueen(2, 0)
       added a queen(2, 2)
----(3) AddQueen(3, 0)
       removed a queen(2, 2)
      removed a queen(1, 0)
      added a queen(1, 1)
---(2) AddQueen(2, 0)
      removed a queen(1, 1)
     removed a queen(0, 3)


{designing-recursive}

o find the key step to divide a problem into parts
o find a stopping rule
o outline your algorithm
o check it with a small case
o draw a recursion tree.


{when-not-to-use-recursion} {tail-recursion}

The tail recursion when the last-executed statment is a recursive call waste space as do unnecessary
recusive call. Because when return, restore stack but terminates immediately. For this case, can
change it to iterative one. 

<example-one>

void Move(int count, int start, int finish, int temp)
{
	 if( count > 0 )
	 {
		  Move( count-1, start, temp, finish );
		  printf("move a disk %d from tower %d to %d.\n", count, start, finish );
		  Move( count-1, temp, finish, start );
	}
}


void Move(int count, int start, int finish, int temp)
{
	 int swap;

	 if( count > 0 )
	 {
		  Move( count-1, start, temp, finish );
		  printf("move a disk %d from tower %d to %d.\n", count, start, finish );
		  count--;
		  swap = start;   // swap(start, temp) how does it work???
		  start = temp;
		  temp = swap; 
	}
}


<factorial>

This is a function of non-negative integer and is defined

n! = 1          if n = 0
     n x (n-1)! if n > 0

1 when n=0
1 wnen n=1
2 when n=2
6 when n=3
...

The recursive ones:

int fact(int val)
{
	 if( val > 1 )
		 return fact(val-1)*val; 
	
	return 1;
}

// overflow when val is -1
int fact(int val)
{
	if( val == 0 )
		return 1;
	else
		return fact(val-1)*val;
}

Why is iterative ones better? Use less space and also often time as well. Looking at recursion tree,
it dwaws a chain, not a tree.

n! - (n-1)! - (n-2)! - ... - 2! - 1! - 0!

The iterative ones:
can do by reading the recursion tree [from bottom to top] instead of top to bottom. But not always as
seen at below.

1  when n=0
1  wnen n=1
2  when n=2
6  when n=3. 3x2!
24 when n=4. 4x3!
...

// what's the product value when n < 2 ?
int factorial( int n )
{
	 int count, product;
	 for( product=1, count=2; count <= n; count++)
		  product *= count;

	 return product;
}

Or use 4x3x2x1 from {ref-005}

int fact(int val)
{
	 int ret = 1;

	 while( val > 1 )
		  ret *= val--;
	
	return ret;
}


<fibonacci>

The definition is:

F0 = 0.
F1 = 1.
Fn = Fn-1 + Fn-2 for n >= 2

int fibonacci(int n)
{
	 if( n <= 0 )
		  return 0;
	 else if( n==1 )
		  return 1;
	 else
		  return fibonacci(n-1) + fibonacci(n-2);
}

Far more wasteful example when use recursive because when see recursion tree, after F5, it is done
but lost although it is required later in calculating other nodes. Fn grows exponentially with n. 

The interative version is:

current   one back(fn-1)   two back(fn-2)
2       = 1              + 0
3       = 2              + 1
4       = 3              + 2
5       = 4              + 3
6       = 5              + 4
...

int fibonacci(int n)
{
	 int n;
	 int twoback; // second previous Fi-2
	 int oneback; // previous number Fi-1
	 int current; // current Fi

	 if( n <= 0 )
		  return 0;
	 else if( n==1 )
		  return 1;
	 else
	 {
		  twoback = 0;
		  oneback = 1;

		  for( i=2; i <= n; i++ )
		  {
				current = twoback + oneback;
				twoback = oneback;
				oneback = current;
		  }

		  return current;
	 }
}


<make-a-decision>

The good starting point is to study a recursion tree.

o if it has a simple form like a chain, the iterative may be better. Such as factorial and can do by
reading the recursion tree from bottom to top instead of top to bottom.

o if it has duplicate tasks, use other data structure other than stack. fibonacci iterative version.

So use recursion when the tree appears quite bushy, with little duplication of tasks.


={============================================================================
*kt_dev_algo_008* binary search

{internal-and-external}
The case when to search records in files on disk or tape, external to the computer memory. The
external searching. The records to be searched are stored entirely within the computer memory.
Internal searching.

{target}
The key for which we are searching is called the target of the search. Here concerned only with
internal search and contiguous list.

{search-analysis}
Two premises:

The number of comparisons of keys give us the most useful information when wish to estimate the
computer time to require or to compare it with some other method. This is more useful than the total
running time which is too 'dependant' on programming variations and machines. This number of
comparisions of keys is 'measure' of analysis.

Use average behavior and means to take each possibility once and average the results. Limit our
attention to where all the possibilities are equally likely.

{ordered-list-adt}
An ordered list is a list in which each entry contains a key, such that the keys are in order. That
is, if entry i comes before entry j in the list, then the key of entry i is less than or equal to
the key of entry j. [min...max]

... [c] ...
  <  |  =>

void InsertOrder(List* list, ListEntry x)
{
  int current;
  ListEntry currententry;

  // searching.
  for( current=0; current < ListSize(*list); current++ )
  {
    currententry = RetrieveList(*list, current);
    if( LE(x.key, currententry.key )) or if( GT( current, insert ))
      break;
  }

  // inserting. use SetPostion( current-1 );
  InsertList(list, x, current);
}


{binary-search} 
The keys in the list are already 'sorted' into order. In only twenty steps, will locate any requested
key in a list containing more than a millions keys. This requires <random-access> so shall limit only
for <contiguous-implementation>.

One study showed that about 90 percent of professional programmers fail to code binary search
correctly, even after working on it for a full hour.

<one-the-forgetful-version>

<do>
Write a binary search to return a postion in [bot...top] array(contig. list) when found and -1 when
not found.

int RecBinary1( List list, KeyType target, int bottom, int top );
int RecBinary1( int array[], int target, int bottom, int top );
int binsearch1( int v[], int x, int n );   // (array, key, size)

This is one to forget the possibility that the target might be found quickly and continue, whether
target has been found or not, to search [until] when there is only one item, that is, the length or
count is 1 or when top == bottom. Then see either hit the target or not found. In other words, it
makes unnecessary iterations because fails to recognize that it can found the target before
continuing to iterate to until count is 1.


#define EQ(a,b) (!strcmp((a),(b)))
#define LT(a,b) (strcmp((a),(b)) < 0)

#define EQ(a,b) ((a) == (b))
#define LT(a,b) ((a) < (b))

typedef {
  ...
    KeyType key;  // can map any key to any entry
  ...
} ListEntry;

typedef struct list {
  int count;
  ListEntry entry[MAXLIST];
} List;

For convenience,

1 2 3 4 5 6 7 8 9 10 array index
1 2 3 4 5 6 7 8 9 10 keys

<comparison-and-first-occurance>
Depending on what comparison is used, differ on if it will find the first occurance or not when
there are many occurances in the input.

approach 01

if( GT(key, middle) ) bot = middle+1;
else top = middle;

   <=   |      > 
      middle
         (------------ do not include a middle
--------]

approach 02

if( LT(key, middle) ) top = middle-1;
else bot = middle;

   <   |     => 
      middle
         [------------ 
--------) do not include a middle

The first approach means that it will find the 'first' occurance of the target if it appears more
than once in the list since it removes the upper and the lower part still remains in search. For
example, think when search 2 in the list and middle is ^:

..2222...
   ^

int RecBinary1( List list, KeyType target, int bottom, int top ) 
{ 
  int middle = -1;   // {DN} used only single var but not two.

  if( bottom < top )
  {
    middle = (top + bottom)/2;

    // {DN} used GT; means that get the first occurance and do not include the middle for next
    // interation
    if( GT( target, list.entry[ middle ].key ))
      middle = RecBinary1( list, target, middle+1, top ); // remove lower half

    // used =<; means include the middle for next iteration so not middle-1 because should have a
    // middle in the search range
    else
      middle = RecBinary1( list, target, bottom, middle ); // remove upper half
  }
  // {DN} should use 'else if' not 'if' here. Otherwise, do if for every retrun from recursive call
  else if( bottom == top ) // the list has only one entry
  {
    if( EQ( target, list.entry[ top ].key ))
      middle = top;  // {DN} to pass up
  }

  return middle;
}

To adjust the params to standard conventions:

int RecBinary1Search(List list, KeyType target)
{ return RecBinary1( list, target, 0, list.count-1 ); }

This is tail-recursion so convert it into a iterative loop. [KT] Here top and bottom are actually
indexes and when top == bottom, means there is one item left. How to check empty list? Used count-1
and check on -1:

int Binary1Search( List list, KeyType target )
{
  int bottom, middle, top;

  top = list.count-1;    // array size-1
  bottom = 0;

  while( bottom < top )
  {
    middle = ( bottom + top )/2;

    if( GT( target, list.entry[middle].key ))
      bottom = middle+1;
    else
      top = middle;
  }

  // search for an emptry list always fails
  if( top == -1 )
    return -1;

  if( EQ( target, list.entry[top].key ))
    return top;
  else
    return -1;

  // return target == list.entry[top].key ? top : -1;
}

<code-example>
Used the simple array and moved up the check of empty list since this is a check on input but not on
calc during running.

#include <iostream>

using namespace std;

#define EQ(a,b) ((a) == (b))
#define GT(a,b) ((a) > (b))

typedef struct list {
  int count;
  int entry[10];
} List;

int Binary1Search( List list, int target )
{
  int bottom, middle, top;

  top = list.count-1;
  bottom = 0;

  // search for an emptry list always fails
  if( top == -1 )
  {
    cout << "list is empty" << endl;
    return -1;
  }

  while( bottom < top )
  {
    middle = ( bottom + top )/2;
    cout << "middle is " << middle << endl;

    if( GT( target, list.entry[middle]))
      bottom = middle+1;
    else
      top = middle;
  }

  if( EQ( target, list.entry[top]))
    return top;
  else
    return -1;
}

int main()
{
  int ret;
  List arr;

  for(int i=0; i < 10; ++i)
    arr.entry[i] = i;

  arr.count = 10;
  //arr.count = 0;

  ret = Binary1Search( arr, 4 );

  cout << "ret = " << ret << endl;

  return 0;
}


<two-the-equality-version>
To improve the forgetful version, check at each stage to see if it has found the target. This has
only LT and GT on checks and the equality, that is, found in the 'middle', is found when LT or GT is
false.

This may return [any-instance] of the target if target appears more than once in the list.

See that there is no EQ check in this function. When there is only one element but still not equal
then becomes bot > top and the last recursion returns -1. Hence not found. Otherwise, return middle
which means found.

int RecBinary2( List list, KeyType target, int bottom, int top )
{
  int middle = -1;

  if( bottom <= top )   // {DN} <=. when bottom == top, middle, bottom, and top are the same.
  {
    middle = (top+bottom)/2;

    if( LT( target, list.entry[ middle ].key ))
      middle = RecBinary2( list, target, bottom, middle-1); // {DN} middle-1
    else if ( GT( target, list.entry[ middle ].key ))
      middle = RecBinary2( list, target, middle+1, top);    // {DN} middle+1
  }

  return middle;
}

int Binary2Search( List list, KeyType target )
{
  int bottom, middle, top;

  top = list.count-1;
  bottom = 0;

  while( bottom <= top )
  {
    middle = (bottom+top)/2;

    if( EQ( target, list.entry[middle].key ))
      return middle;
    else if( LT( target, list.entry[middle].key ))
      top = middle-1;
    else // if ( GT( target, list.entry[middle].key ))
      bottom = middle+1;
  }

  return -1;
}

<ansic-example> p58
int binsearch(int x, int v[], int n)
{
  int low, high, mid;

  low = 0;
  high = n-1;

  while( low <= high )
  {
    mid = (low + high) / 2;

    if( x < v[mid] )
      high = mid-1;
    else if( x > v[mid] )
      low = mid+1;
    else    // found match
      return mid;
  }

  // no match
  return -1;
}


<binary-search-comparison-which-is-better> {comparison-tree}
Which one of these will do fewer comparisons? Binary2 will if found in the beginning of the search
but do 2 comparisons at each iteration.

Can draw a comparison tree to compare.

                   (5) ; root node representing a key
     '<='                       '>'
     (3)                        (8)
'<='       '>'
(2)        (4)
      '<='      '>'
...   (4)       (5)
    '=' '!='  '=' '!='
... [4] [F]   [5] [F]

For n=10, Binary1 does slightly fewer comparisons both for successful and for unsuccessful searches.
However, an optimizing compiler may not do as much work as two full comparisons. In that case,
Binary2 may be slightly better choice.

<binary-search-logn>
Sequential search needs O(n) and binary search needs O(logn) comparisons which is excellent since
log n grows very slowly as n increases.

These are only approximate. For large values of n, the difference between log n and log(n+1) is
insignificant and (n+1)/n is very nearly 1. Hence can simply results as:

               Successful     Unsuccessful search
Binary1Search  logn + 1       logn + 1
Binary2Search  2logn-3        2logn

All four cases are proportional to logn and the coefficients of logn are the number of comparisons
inside the loop.

To conclude, two points:

o For large problems, Binary1(the-forgetful-version) is better and for small problems sequential
search is better since when looks at logn and n graph, logn is bigger for small n. Binary2 may be
better when there is optimizing compiler.

o Binary1 pickes up the first occurance when there are many same occurances but Binary2 don't.


<Q> Why Binary1 has "while( bot < top )" but Binary2 has "while( bot <= top)"? Because when there is
only one item, that is bot == top, Binary1 end while and check if found or not. However, Binary2 has
that case when bot==top in while inside. So has to have "while( bot <= top )"


<exercise>
The ansic, page 58, exercise 3-1. Our binary search makes two tests inside the loop, when one would
suffice (at the price of more tests outside). Write a version with only one test inside the loop and
measure the difference in run-time.

<big-o-notation>
To present the operation count or running time for algorithm

O(1) to mean computing time that is bounded by a constant (not dependent on n)
O(n) to mean that the time is directly propotional to n. called liner time.
O(n2) called quadratic time
O(n3) called cubic time
O(2n) called exponential

<other-version>
See how to check empty list when this is array. However, this is not necessary when see the other
example code below. Why? Can have checks to see if start or end are negative than simply on end.

#include < iostream>

#define GT(x,y) ((x)>(y))
#define EQ(x,y) ((x)==(y))

int bsearch_one( int* list, int start, int end, int target )
{
  int pos = -1;

  // when the list is empty
  if( end == -1 )
  {
    std::cout << "list is empty" << std::endl;
    return pos;
  }

  while( start < end )
  {
    int middle = (start+end)/2;

    if( GT(target, list[middle] ) )
    {
      start = middle+1;
    }
    else
      end = middle;
  }

  // can remove check on start == end
  if( start == end )
  {
    if( EQ( target, list[end] ))
      pos = end;
  }

  return pos;
}

int main()
{
  int ret = -1;

  int brr[] = {};
  int bsize = ( sizeof(brr)/sizeof(brr[0]));

  // bsearch_one( , , length-1, );
  ret = bsearch_one( brr, 0, bsize-1, 15 );    ~
    std::cout << "returned pos is " << ret << std::endl; 

  int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  ret = bsearch_one( arr, 0, size-1, 15 );
  std::cout << "returned pos is " << ret << std::endl; 

  ret = bsearch_one( arr, 0, size-1, 17 );
  std::cout << "returned pos is " << ret << std::endl; 

  ret = bsearch_one( arr, 0, size-1, 2 );
  std::cout << "returned pos is " << ret << std::endl; 

  ret = bsearch_one( arr, 0, size-1, 99 );
  std::cout << "returned pos is " << ret << std::endl; 
}


//
// From p120 in cracking the coding interview. This is the Binary2.
//
int binary_search(int arr[], int length, int sought)
{
  // indexes
  int low = 0;
  int high = length-1;

  // int high = sizeof(arr)/sizeof(int)-1; Note: THIS DOESN'T WORK!
  int mid;

  // Note for condition.
  while( low <= high )
  {
    mid = (low+high)/2;

    if(arr[mid] < sought)
      low = mid+1; // exclues mid by +1
    else if( arr[mid] > sought)
      high = mid-1; // excludes mid by -1. throw upper
    else
      return mid;
  }

  return -1; //error
}


// example from C++P p112. 
//
vector<string> text;

auto begin = text.begin(), end = text.end();
auto middle = text.begin() + (end-begin)/2;

// while there are still elements to look at and we haven't yet found sought.
while( middle != end && *middle != sought )
{
  if( sought < *middle )
    end = middle;              # throw upper
  else
    begin = middle+1;

  middle = begin + ( end - begin )/2;
}

// when no found, begin, end, and middle are the same.


={============================================================================
*kt_dev_algo_009* sort

Here consider only internal sorting. Analysis concentrate on two actions: comparison and changing
pointers or moving entries. 

{sort-question} The question from {ref-004}: 
Given a very large array of Person objects, sort the people in increasing order of age.

We are given two interesting bits of knowledge here. 1: A large array, so efficiency is very
important. 2: Sorting based on ages, so we know the values are in a small range.

By scanning through the various sorting algorithms, we might notice that bucket sort(radixsort)
would be a perfect candidate for this problem. In fact, can make the buckets small(just 1 year
each) and get O(n) running time.

The merge, quick, and bucket are the most commonly used in interviews.


{insertion-selection-shell}

<insertion-sort>
From {ordered-list-adt}, the ordered list is ADT which has three more operations since they use
'keys' rather than position to locate the entry: retrieve, insert and sort. The retrieve and insert
need searching and the list must be ordered after insertion and deletion.

<why-sequential-is-better>
One method to do ordered insertion into a 'contiguous' ordered list is do binary search to find the
position since it is ordered and move entries to make a space to insert. Finally insert new entry
into the list. Since so much time is needed to 'move' entries <no-matter-how-the-search-is-done>, it
turns out in many cases to be just as fast to use sequential search as binary search: the search and
the movement of entries can be combined in a single loop, thereby reducing the overhead.

<-TODO
{Q} how can we use binary search to find a position which is less than or greater than a key to
insert? Think that unsorted set and sorted set and do binary search on sorted set with an entry from
unsorted set. To do this, change binary search function to return any of bot, top, or middle
whether or not binary search found a key since the returned position is either the last occurance of
the key or the position which is less than big entry in the sorted set. <= [m] > when use GT in
binary search. Then make a space at the position by moving down and insert.

Do not understand this now. The other is: two outcomes from binary search. when found, do not matter
to insert a new before or after the found. when not found, compare the middle which is the last of
search and decide after or before.
>-TODO

<key>
Move one entries from unsorted list to sorted list and use this observations: a list of length 1 is
automatically ordered.

init order     ...

[hen] sorted   [cow]           [cat]
$cow$ unsorted [hen] sorted    [cow]
$cat$          $cat$ unsoerted [hen] sorted
$ram$          $ram$           $ram$ unsorted
$ewe$          $ewe$           $ewe$
$dog$          $dog$           $dog$


<do> Write the below function using int array:
void InsertionSort(int* arr, int length);

<code> 
// reference code. contiguous version from the book. This is O(n2) in worst as to comparison.
typedef int Position;
typedef int Entry;

void InsertionSort(List* list)
{
  Position    fu;      // the start of unsorted
  Position    place;
  ListEntry   current;

  // fu-2 (place-1)
  // fu-1 (place)   sorted
  // fu   (place+1) unsorted

  for( fu = 1; fu < list->count; fu++ )
  {
    // note: This 'if' is important. ONLY if the first unsorted entry is less than the last sorted
    // entry, then need to sort. This means that the unsorted should be before the last sorted.
    // Otherwise simply increase the sorted set.

    // if( the unsorted < the sorted )
    if( LT( list->entry[fu].key, list->entry[ fu-1 ].key ))
    {
      // save the unsorted
      current = list->entry[fu];

      // search from the last sorted(place). Here do move and search in the same loop.
      for( place = fu-1; place >= 0; place-- )
      {
        // move down from the sorted to the unsorted
        list->entry[ place+1 ] = list->entry[ place ];

        // since already compared with place(fu-1) so compare on place-1, can save one comparison
        // [DN] Here assumes that place is signed and so must have place==0 check. If not, when
        // place is 0 and can access entry[-1].
        if( place == 0 || LT( list->entry[ place-1 ].key, current.key ))
          break;
      }

      list->entry[place] = current;
    }
  }
}

// same as the reference code; move, check, and decrease
void isort_one( int array[], int length )
{
  // loop through forwards from 1 since assume it's sorted when there is one element.
  for( int unsorted = 1; unsorted < length; unsorted++ )
  {
    // only if 'unsorted' < 'sorted' to insert it in to the sorted.
    if( array[unsorted] < array[unsorted-1] )
    {
      int save = array[unsorted];
      int sorted = unsorted-1;

      for( sorted; sorted >= 0; sorted-- )
      {
        // move down a element
        array[sorted+1] = array[sorted];
       
        // found that unsorted is bigger so stop or that reached to the first of the array.
        if( sorted == 0 || save > array[sorted-1] )
          break;
      }

      array[sorted] = save;
    }
  }
}

// same as isort_one but do check first and that's why sorted+1 to save
// one more if comprison on sorted which is already done
void isort_two( int array[], int length )
{
  for( int unsorted = 1; unsorted < length; unsorted++ )
  {
    if( array[unsorted] < array[unsorted-1] )
    {
      int save = array[unsorted];
      int sorted = unsorted-1;

      for( sorted; sorted >= 0; sorted-- )
      {
        if( save > array[sorted] )   // <diff> on check and index
          break;

        // move down a element
        array[sorted+1] = array[sorted];
      }
      array[sorted+1] = save; // <diff> on index
    }
  }
}

// same as isort_two but removed the check. However, when there is no need to move since it is
// already sorted, assign, array[unsorted], happens. That is the check becomes the assign. Which is
// more expensive?
void isort_three( int array[], int length )
{
  for( int unsorted = 1; unsorted < length; unsorted++ )
  {
    // <diff>
    {
      int save = array[unsorted];
      int sorted = unsorted-1;

      for( sorted; sorted >= 0; sorted-- )
      {
        if( save > array[sorted] )
          break;

        // move down a element
        array[sorted+1] = array[sorted];
      }

      array[sorted+1] = save;
    }
  }
}

// better naming
void isort_one(int* arr, int length)
{
  int unsorted, insert;

  for( unsorted = 1; unsorted < length; unsorted++ )
  {
    if( arr[unsorted] < arr[unsorted-1] )
    {
      int saved = arr[unsorted];

      // to find a insert position from sorted set
      for( insert = unsorted-1; insert >= 0; insert--)
      {
        // move down
        arr[insert+1] = arr[insert];

        // stop since found or reached top
        if( insert == 0 || arr[insert-1] < saved )
          break;
      }
      arr[insert] = saved;
    }
  }
}


// own implementation used outline <selected>
void isort_four(int* arr, int length)
{
  for( int unsorted = 1; unsorted < length; unsorted++ )
    for( int current = unsorted; current > 0 && arr[current] < arr[current-1]; current--)
    {
      int temp = arr[current];
      arr[current] = arr[current-1];
      arr[current-1] = temp;
    }
} 


int main()
{
  { // <isort_one>
    // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
    int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
    int size = ( sizeof(arr)/sizeof(arr[0]) );

    isort_one( arr, size );

    printf("{ ");
    for(int idx = 0; idx < size; idx++)
      printf( (idx < size-1) ? "%d, " : "%d ", arr[idx] );
    printf("}\n");
  }

  { // <isort_two>
    // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
    int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
    int size = ( sizeof(arr)/sizeof(arr[0]) );

    isort_two( arr, size );

    printf("{ ");
    for(int idx = 0; idx < size; idx++)
      printf( (idx < size-1) ? "%d, " : "%d ", arr[idx] );
    printf("}\n");
  }

  { // <isort_three>
    // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
    int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
    int size = ( sizeof(arr)/sizeof(arr[0]) );

    isort_three( arr, size );

    printf("{ ");
    for(int idx = 0; idx < size; idx++)
      printf( (idx < size-1) ? "%d, " : "%d ", arr[idx] );
    printf("}\n");
  }

  { // <isort_four>
    // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
    int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
    int size = ( sizeof(arr)/sizeof(arr[0]) );

    isort_four( arr, size );

    printf("{ ");
    for(int idx = 0; idx < size; idx++)
      printf( (idx < size-1) ? "%d, " : "%d ", arr[idx] );
    printf("}\n");
  }
}

// the result
// { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 }
// { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 }
// { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 }
// { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 }

<comparison-which-is-better>
note: The ref-example is better since it will one less comparison in inner for loop by moving down
first and compare. 
note: A list of length 1 is automatically ordered. That is the sorted set starts from size 1. 
note: Naming variable is important since managing array index is tricky and confusing.


<selection-sort>
The insertion-sort has major disadvantage: even after most entries have been sorted properly into
the sorted set, the insertion of a later entry may require that many of them should be moved because
the position of each entry is not a 'final' position. So would be far more efficient if an entry
being moved could be placed in its final position. How?

Start from empty sorted set which is different from insertion sort, scan unsorted list to find the
one that comes last in order; 'largest', alphabetical in this case. Swap this with the 'last' one of
the unsorted list. Repeat this until no more items in the unsorted list.

$hen$ scan and $hen$ *  $ewe$    ...
$cow$ swap     $cow$    $cow$
$cat$          $cat$    $cat$
$ram$ *        $dog$    $dog$ unsorted
$ewe$          $ewe$ *  [hen] sorted
$dog$ *        [ram]    [ram]

From {ref-004}, can do the opposite. Find the smallest and swap it with the first. Repeat it until
it is sorted.

<do> Write the below function using int array:
void SelectionSort(int* arr, int length);

// find the position of the largest key in the sublist
Position MaxKey(int begin, int end, int* arr);

// swap two entries in the contiguous list
void Swap(int begin, int end, int* arr);

<code> 

// the reference code from the book, p290.
void SelectionSort(List* list)
{
  Position current, max;

  // when the size of unsorted set is 1, means all sorted and do not need to do the last loop. Loop
  // size-1 times.
  for( current = list->count -1; current > 0; current-- )
  {
    max = MaxKey(0, current, list);
    Swap( max, current, list );
  }
}

// find the max whether or not input is positive or negative since picks up the first as a start.
// that is why 'low+1'
Position MaxKey( Position low, Position high, List* list )
{
  Position largest, current;

  largest = low;

  for( current = low+1; current <= high; current++ )
    if( LT( list->entry[largest].key, list->entry[current].key ))
      largest = current;

  return largest;
}

void Swap( Position low, Position high, List* list )
{
  ListEntry temp = list->entry[low];
  list->entry[low] = list->entry[high];
  list->entry[high] = temp;
}

// two. same as the reference but used array.
#include <iostream>

#define GT(x,y) ((x)>(y))
#define LT(x,y) ((x)<(y))
#define EQ(x,y) ((x)==(y))

typedef int Position;
typedef int Entry;

// expects start and end index
Position findPosofMax( Position start, Position end, int* array)
{
  Position max = start;

  for ( Position current = start+1; current <= end ; current++) 
  {
    if( GT( array[current], array[max] )) // when positive only, picks up the first of the array.
      max = current;
  }

  return max;
}

// expects start and end in index
void swapEntry( Position x, Position y, int* array )
{
  int xval = array[x];
  array[x] = array[y];
  array[y] = xval;
}

// expects the length of array. NO if in for loop.
void sortSelection(int* array, int length)
{
  for( ;length > 1; length--) {
    Position posMax = findPosofMax( 0, length-1, array );
    // std::cout << "posMax:length-1 = (" << posMax << ", " << length-1 << ")" << std::endl;
    swapEntry( posMax, length-1, array );
  }
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  sortSelection( arr, size );

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}

<code-three> outline by self
void ssort(list* list)
{
  int size = list->count-1;

  // use index. loop backwards until there is one unsorted
  for( int unsorted = size; unsorted > 0; unsorted-- )
  {
    // find the largest in [0, unsorted]
    int largest = max( 0, unsorted );

    // swap the largest with the the last of unsorted
    swap( largest, unsorted );
  }
}

note: must use swap and sorted set starts from empty.


<insertion-vs-selection>
The selection sort is useful for contiguous list with large entries for which movement of entries is
expensive since it uses fewer moves.

The selection do (n-1)x(n-2)x(n-3)x...x2x1 = 1/2*n(n-1) = 1/2*n^2+1/2n = 1/2*n^2+O(n) = 0.5n^2+O(n)
on comparisons. But the insertion do O(n2) for 'worst' case and less than this on average.

               comparison             moving
insertion         less                 more
selection         more                 less

If the entries are small, or if the list is linked, so that only pointers need be changed to sort
the list, then insertion-sort is usually faster than selection-sort since the insertion do more on
moving. For many applications, insertion can prove to be the best choice as easy to write and
maintain, runs efficiently for short list. Even for long list, if they are nearly in the correct
order, insertion will be very efficient. 

<key> insertion is generally better than selection.

<shell-sort>
This is an 'optimization' of insertion sort by reducing moves. How? Use increment(distance) between
keys to compare rather and when increment becomes 1, finally performs ordinary insertion sort. Each
pass moves elements 'close' to their final position so the sort goes rapidly. There is no magic
about choice of 'increment' and no complete the analysis of this. However, emprical studies shows
a subtantial improvement over insertion sort.

Unsorted    Sublist when inc is 5         5-sorted,      Recombined
 Tim        Tim                              Jim         Jim
 Dot              Dot                            ...     Dot
 Eva                    Eva                              Eva
 Roy                          Roy                        ...
 Tom                                Tom
 Kim        Kim                              Kim
 Guy              Guy
 Amy                    Amy
 Jon                          Jon
 Ann                                Ann
 Jim        Jim                              Tim
 Kay              Kay
 Ron                    Ron
 Jan                          Jan


As with insertion, shell checks on element(s) by increment towards beginning(backwards)
As with insertion, shell stops scanning backwards as soon as found a right place to insert.

                                    10                                  19
          0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18

g=9, i= 9, j=0 : v[0], v[ 9]               // start(unsorted)=9, 0
     i=10, j=1 : v[1], v[10]
     i=11, j=2 : v[2], v[11]
     i=12, j=3 : v[3], v[12]
     i=13, j=4 : v[4], v[13]
     i=14, j=5 : v[5], v[14]
     i=15, j=6 : v[6], v[15]
     i=16, j=7 : v[7], v[16]
     i=17, j=8 : v[8], v[17]
     i=18, j=9 : v[9], v[18] : v[0], v[9]  // start(unsorted)=18, 9, 0
g=4, i= 4, j=0 : v[0], v[ 4]
     i= 5, j=1 : v[1], v[ 5]
     ...
     i= 8, j=4 : v[4], v[ 8] : v[0], v[4]
     i= 9, j=5 : v[5], v[ 9] : v[1], v[5]
     ...
     i=12, j=8 : v[8], v[12] : v[4], v[8] : v[0], v[4]


<code>
// reference example, p294.
void ShellSort( List *list )
{
  int increment;
  Position start;

  increment = list->count;

  do {
    increment = increment/3 + 1;

    for( start = 0; start < increment; start++ )
      SortInterval( start, increment, list );

  } while( increment > 1 );
}

SortInterval is modified insertion sort except that the list starts at start instead of 0 and the
increment between successive values is as given instead of 1.

// shellsort from ansic, p62.
void ssort_one( int v[], int n )
{
  int gap, i, j, temp;

  for( gap = n/2; gap > 0; gap /= 2 )
    for( i = gap; i < n; i++ )
      for( j = i-gap; j >= 0 && v[j] > v[j+gap]; j -= gap )
      {
        temp = v[j];
        v[j] = v[j+gap];
        v[j+gap] = temp;
      }
}

// own implementation which extends insertion-sort
void ssort_two( int array[], int length )
{
  for( int gap = length/2; gap > 0; gap /= 2)
  {
    for( int unsorted = gap; unsorted < length; unsorted++ )
    {
      for( int key = unsorted; key-gap >= 0 && array[key] < array[key-gap]; key -= gap )
      {
        // swap
        int temp     = array[key];
        array[key]   = array[key-gap];
        array[key-gap] = temp;
      }
    }
  }
}


int main()
{
  { // <ssort_one>
    // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
    int arr[] = { 33, 28, 2, 31, 27, 5, 25, 19, 30, 11, 7, 34, 40, 6, 12, 10, 13, 15, 17, 29, 3 };
    int size = ( sizeof(arr)/sizeof(arr[0]) );

    ssort_one( arr, size );

    printf("{ ");
    for(int idx = 0; idx < size; idx++)
      printf( (idx < size-1) ? "%d, " : "%d ", arr[idx] );
    printf("}\n");
  }

  { // <ssort_two>
    // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
    int arr[] = { 33, 28, 2, 31, 27, 5, 25, 19, 30, 11, 7, 34, 40, 6, 12, 10, 13, 15, 17, 29, 3 };
    int size = ( sizeof(arr)/sizeof(arr[0]) );

    ssort_two( arr, size );

    printf("{ ");
    for(int idx = 0; idx < size; idx++)
      printf( (idx < size-1) ? "%d, " : "%d ", arr[idx] );
    printf("}\n");
  }
}


// the result
// { 2, 3, 5, 6, 7, 10, 11, 12, 13, 15, 17, 19, 25, 27, 28, 29, 30, 31, 33, 34, 40 }
// { 2, 3, 5, 6, 7, 10, 11, 12, 13, 15, 17, 19, 25, 27, 28, 29, 30, 31, 33, 34, 40 }


{merge-quick} divide-and-conquer-sort
It is much easier to sort short list than long ones. Two methods which has two basic actions:
partitioning and combining. mergesort does more work in combining and quicksort does more
work(sorting) in partitioning.

Sort(list)
{
  if the list has length greater than 1 then
  {
    partition the list into lowlist and highlist
    Sort(lowlist);
    Sort(highlist);
    Combine(lowlist, highlist);
  }
}


<mergesort> <merge-nlogn>
This is recursion-tree of 7 numbers. Combine() or merge part do most of work and sort. This is an
excellent method for 'external' sorting, linked list in random order but spends significant time
finding the center of the list. For contiguous list, not an unqualified success because needs one of
extra space(temp) to merge, computer time, or programming effort in merging two contiguous list. 

<Q> Why excellent for external?

The best time is O(nlogn)

                     start[down]   finish[up]
          <26 33 35 29 19 12 22> () 12 19 22 26 29 33 35
           list        second

     <26 33 35 29> () 26 29 33 35            <19 12 22> () 12 19 22
      list  second                           list

 <26 33> () 26 33  <35 29> () 29 35        ...
  list             list

<26> [] <33> []      <35> [] <29> [] 

where [] is leaf and () is node

<mergesort-linked> not contiguous list
// sort linked list and the keys in all the entries are sorted into increasing order.
void MergeSort(List* list);

// divide the list into two parts. If list has an odd number of entries, then its first half will be
// one entry larger than its second
void Divide(List* list, List* secondhalf);

// merge two list producing a thrid list. first and second are ordered linked list. out is an
// ordered list containing all entries that were in first and second. The first and second have been
// destroyed.
void Merge(List* list, List* second, List* out);

<ref-example>
From the reference book. Here list and secondhalf are list structure having a head so not a problem
when run recursive tree.

void MergeSort(List* list)
{
  List secondhalf;

  if( ListSize(list) > 1 )    // is there a need to sort? 2 at least
  {
    Divide( list, &secondhalf );
    MergeSort(list);          // when list size is 2, be called with 1 and has no effect
    MergeSort(&secondhalf);
    Merge( list, &secondhalf, list );  // see list used as out
  }
}

<find-middle-in-a-linked-list> <tortous-and-hare-approach>
This is interesting since it shows how to find the middle of the simple list. When entries are odd
numbers, the first half is <one-larger>. 

 0   1   2   3   4   5   6
[ ] [ ] [ ] [ ] [ ] [ ] [ ]
s    f                        // Assumption is that there are 2 at least since size > 1
 ----------------
     f'  f;                   // for check and if check. if there are 2 entries, ends in next for and s+1 is 1
     s       f;               // update (1,3) diff 2
 ----------------
             f   f;           // for check and if check. if there are 3 or 4, ends here. s+1 is 2
         s           f;       // update (2,5) diff 3
 ----------------
                     f;  f;   // for check and if check. if there are 5 or 6, ends here. s+1 is 3
                              // update (3,7) diff 4
                              
where ' means check and ; means checks and possible loop exit. 

s -> f -> f
0         2
  ->  s      -> f -> f
      1              4
       -> s            -> f -> f
          2                    6

void Divide(List* list, List* secondhalf)
{
  ListNode *current, *midpoint;        // current(fast), midpoint(slow)

  if((midpoint = list->head) == NULL ) // must use ()
    secondhalf->head = NULL;
  else
  {
    for( current = midpoint->next; current; )
    {
      current = current->next;
      // cannot move two in a single shot since do not know when one is the end.
      if(current)
      {
        midpoint = midpoint->next;
        current = current->next;
      }
    }
    // breaks up a list into two
    secondhalf->head = midpoint->next; // the second half
    midpoint->next = NULL;             // the first half
  }
}

Since there must be 2 nodes at lesat, can be shorten:

void Divide(List* list, List* secondhalf)
{
  ListNode *current, *midpoint;        // current(fast), midpoint(slow)

  midpoint = list->head;

  for( current = midpoint->next; current; )
  {
    current = current->next;
    // cannot move two in a single shot since do not know when one is the end.
    if(current)
    {
      midpoint = midpoint->next;
      current = current->next;
    }
  }

  // breaks up a list into two
  secondhalf->head = midpoint->next; // the second half
  midpoint->next = NULL;             // the first half
}

void Divide( List *first, List *second )
{
  set slow to the first(head);

  for( set fast by +1 and contiue while fast is not null )
  {
    move fast by +1;

    if( fast )
    {
      move slow by +1;
      move fast by +1;
    }
  }

  set second to slow +1;
  set first end;
}


<keys>
1. Do move s by 1 and move f by 2.
2. When size is odd, first set has one more.
3. Every single node is cheked before moving forward.
4. Consider better names for args.
void Divide( List *in_left, List *out_right );
void Divide( List *first, List *second );


<variations>
// one
Divide( List* left, List* right )
{
  slow = fast = left->head;

  while( fast )
  {
    fast = fast->next;

    if( fast )
    {
      slow = slow->next;
      fast = fast->next;
    }
  }

  right = slow;

}


// two
Divide( List* left, List* right )
{
  slow = fast = left->head;

  while( fast )
  {
    slow = slow->next;
    fast = fast->next;

    if( fast )
      fast = fast->next;
  }

  right = slow;

}

The both seems fine as well since checks every node forwards and fast moves +2. However, the problem
is that cannot set end of the first since set the second with slow but not slow+1. This is not a
double linked list.

For example, two shows

 0   1   2   3   4   5   6
[ ] [ ] [ ] [ ] [ ] [ ] [ ]
s/f'
 ----------------------------
     s
     f' f;
 ----------------------------
        s                        // when 3 or 4 nodes, second=2.
             f;  f;
 ----------------------------
             s                   // when 5 or 6 nodes, second=3.
                     f;  f;
 ----------------------------


<combine>
See that first and out can be the same list since first used one step before out list. Thing's to
remember is that first and second list are sorted list before merging.

// Seems better to have void Combine(List* left, List* right, List* out);
void Merge(List* first, List* second, List* out)
{
  ListNode *p1, *p2;      // pointers to traverse first and second list
  ListNode *lastsorted;   // always points to last node of sorted list

  // <key> if one of both lists is null, then no need to merge
  if( !first->head )
    *out = *second;
  else if( !second->head )
    *out = *first;
  else
  {
    p1 = first->head; p2 = second->head;

    // <key> necessary to set the head of the merged output list.
    if( LE(p1->entry.key, p2->entry.key))
    {
      *out = *first;
      p1 = p1->next;
    }
    else
    {
      *out = *second;
      p2 = p2->next;
    }

    lastsorted = out->head;

    // sort and build the merged list
    while(p1&&p2)
    {
      if( LE(p1->entry.key, p2->entry.key))
      {
        lastsorted->next = p1;   // make a link
        lastsorted = p1;         // move a pointer
        p1 = p1->next;           // move to next candidate
      }
      else
      {
        lastsorted->next = p2;
        lastsorted = p2;
        p2 = p2->next;
      }
    }

    // [DN]
    // whichever lists is used up, if all items are added to the sorted list and reached to the
    // end then simply add remaining list to that end because the remaining list is bigger than
    // the lastsorted. For example, think [26,29,33,35] and [12,19,22] in the above example tree.
    if(p1)
      lastsorted->next = p1;
    else
      lastsorted->next = p2;
  }
}

<do> Write a mergesort of linked list.

<code> C version

#include <stdio.h>
#include <stdlib.h>

#define LE(a, b) ((a) < (b))

// list
typedef int ListEntry;

typedef struct node {
  int       key;
  struct node *pnext;
} ListNode;

typedef struct {
  ListNode *header;
  int count;
} List;

void CreateList(List*);
void ClearList(List*);
int ListEmpty(const List*);
int ListSize(const List*);
void AddList(ListEntry x, List* list);
void TraverseList(List* list, void(*visit)(ListEntry));

void CreateList( List *list )
{
  list->header = NULL;
  list->count = 0;
}

void ClearList( List *list )
{
  ListNode *pend, *ptemp;
  for( pend = list->header; pend; )
  {
    // save current to the temp, move the current and free temp.
    ptemp = pend;
    pend = pend->pnext;
    free(ptemp);
    list->count--;
  }

  list->header = NULL;
  list->count = 0;
}

void AddList(ListEntry x, List *list)
{
  // make a node
  ListNode *pnode = (ListNode*) malloc( sizeof (ListNode) );
  if(!pnode)
  { printf("addlist: no more memory\n"); return; }

  // init a node
  pnode->key = x;
  pnode->pnext = NULL;

  if( !list->header ) // when it's first node
  {
    list->header = pnode;
    list->count++;
  }
  else                // when not a first, search the end
  {
    ListNode *pend;
    // note that 'pend->pnext' condition which is different from traversing
    for( pend = list->header; pend->pnext; pend = pend->pnext )
      ;

    pend->pnext = pnode;
    list->count++;
  }
}

int ListEmpty(const List *list)
{
  if( list->count == 0 )
    return 1;

  return 0;
}

int ListSize(const List *list)
{
  return list->count;
}

void TraverseList(List* list, void(*visit)(ListEntry))
{
  ListNode *pend;
  for( pend = list->header; pend; pend = pend->pnext )
    visit( pend->key );
}

void PrintList( ListEntry entry )
{
  printf("print list : %d\n", entry );
}

// msort
void divide_list( List *first, List *second )
{
  ListNode *slow, *fast;

  slow = fast = first->header;

  for( fast = slow->pnext; fast; )
  {
    fast = fast->pnext;

    if(fast)
    {
      fast = fast->pnext;
      slow = slow->pnext;
    }
  }

  second->header = slow->pnext;
  slow->pnext = NULL;
}

void merge_list( List *first, List *second, List *merged )
{
  // handle when one of lists is empty
  if( !first->header )
  {
    *merged = *second;
    return;
  }
  else if ( !second->header ) 
  {
    *merged  = *first;
    return;
  }

  // handle first comparison
  ListNode *pfirst = first->header, *psecond = second->header;
  ListNode *psorted;

  if( LE( pfirst->key, psecond->key ) )
  {
    merged->header = pfirst;
    pfirst = pfirst->pnext;
  }
  else
  {
    merged->header = psecond;
    psecond = psecond->pnext;
  }

  psorted = merged->header;

  // sort until finish one of lists because first and second is alreay sorted itself
  while( pfirst && psecond )
  {
    if( LE( pfirst->key, psecond->key ) )
    {
      psorted->pnext = pfirst;
      psorted = pfirst;
      pfirst = pfirst->pnext;
    }
    else
    {
      psorted->pnext = psecond;
      psorted = psecond;
      psecond = psecond->pnext;
    }
  }

  // when one of lists are finished, simply append the other list to the sorted
  if(!pfirst)
    psorted->pnext = psecond;
  else
    psorted->pnext = pfirst;
}

void msort_list( List* list )
{
  List second;

  // <key> why this? Without this, seg fault happens. Since no handle of size in divide, mort_list
  // continues even when there is one node. No exit condition of recursive. This means the reference
  // code will not work either.

  if( list->header->pnext ) // if list->header->pnext is not null, means list has more than one
  //if( ListSize( list ) > 1 )
  {
    divide_list( list, &second );
    msort_list( list );
    msort_list( &second );
    merge_list( list, &second, list );
  }
  // else
  // {
  //   printf("list has one: %d\n", list->header->key );
  // }
}

int main()
{
  int values[] = { 26, 33, 35, 29, 19, 12, 22 };
  List llist;

  CreateList(&llist);

  for(int i = 0; i < (sizeof values/sizeof(int)); i++)
    AddList( *(values+i), &llist );

  printf("list size is %d\n", ListSize( &llist ));

  TraverseList( &llist, PrintList );

  msort_list( &llist );
  printf("---------------\n");

  TraverseList( &llist, PrintList );

  ClearList( &llist );

  printf("list size is %d\n", ListSize( &llist ));

  return 0;
}


<mergesort-contiguous>
This is a java code from {ref-004}.

void MergeSort(int[] array, int low, int high)
{
  if (low < high) // 2 at least
  {
    int middle = (low+high)/2;
    MergeSort( array, low, middle );      // sort left
    MergeSort( array, middle+1, high );   // sort right
    Merge( array, low, middle, high );    // merge them
  }
}

small                 big
low        middle     high
[0.........x..........x]
left        right(middle+1)

void Merge( int[] array, int low, int middle, int high )
{
  int[] = helper = new int[array.length];

  for( int i = low; i <= high; i++ )
    helper[i] = array[i];

  int helperLeft = low, helperRight = middle+1;
  int current = low;

  while( helperLeft <= middle && helperRight <= high )
  {
    if( helper[helperLeft] <= helper[helperRight])	// [KT] used <=
    {
      array[current] = helper[helperLeft];
      helperLeft++;
    }
    else
    {
      array[current] = helper[helperRight];
      helperRight++;
    }

    current++;
  }

  // Similar to the linked version, should handle the remaining items. Why Left? Since all items
  // are already copied to the temp array and if done for the left part which has items with small
  // keys then no need to do the right part. So only check on left part.

  int remaining = middle - helperLeft;
  for( int i = 0; i <= remaining; i++ )
    array[current+i] = helper[helperLeft+i];
}


<code-eample>
When tried to do the same myself, got crashes.

#include < iostream>

#define GT(x,y) ((x)>(y))
#define LT(x,y) ((x)<(y))
#define EQ(x,y) ((x)==(y))

typedef int Position;
typedef int Entry;

unsigned int depthRecursion;
void PrintDepth( bool dash, unsigned int depth )
{
  for( unsigned int i=0; i <= depth; ++i)
  {
    if(dash)
      std::cout << "--";
    else
      std::cout << "  ";
  }

  if(dash)
    std::cout << "(" << depth << ") ";
  else
    std::cout << "      ";
}

// see the use of the same array in recursion but within the [start,end] for each iteration.
void Merge( Entry* array, Position length, Position start, Position middle, Position end )
{
  // have temp space for unsorted
  Entry out[length];
  int posLeft = start, posRight = middle+1;

  // [KT] got a crash when not init with start like int posCurrent;
  int posCurrent = start;

  PrintDepth( false, depthRecursion );
  std::cout << "Mege(" << length << ", " << start << ", " << middle << ", " << end << ")" << std::endl;

  // copy entries from array and out
  for(int pos = start; pos <= end; pos++)
    out[pos] = array[pos];

  // sort and copy entries
  while( posLeft <= middle && posRight <= end )
  {
    // [KT] use of LT which is different from the above but not matter. This sort cover the same
    // elements.
    if( LT( out[posLeft], out[posRight] ))
    {
      // [KT] use of posCurrent
      array[posCurrent] = out[posLeft];
      posLeft++;
    }
    else
    {
      array[posCurrent] = out[posRight];
      posRight++;
    }

    posCurrent++;

    // refactored
    // if( LT( out[posLeft], out[posRight] ))
    //   array[posCurrent++] = out[posLeft++];
    // else
    //   array[posCurrent++] = out[posRight++];
  }

  // [KT] 1st crash error since posCurrent can bigger if middle is big enough since used pos <=
  // middle but not pos <= remaining
  //for( int pos = middle - posLeft; pos <= middle;)
  // array[posCurrent++] = out[pos++];

  // [KT] 2nd crash error as the same above.
  //for( int pos = middle - posLeft; pos <= middle; pos++)
  //  array[posCurrent+pos] = out[posLeft+pos];

  // copy remaining entries in the left if they are. Only need to check on the left because the
  // right is already in array.
  int remaining = middle - posLeft;
  for( int pos = 0; pos <= remaining; pos++)
    array[posCurrent+pos] = out[posLeft+pos];
}

// this includes [start, end] and need length arg since need to have temp space.
void sortMerge( Entry* array, Position length, Position start, Position end )
{
  if( start < end )
  {
    depthRecursion++;
    PrintDepth( true, depthRecursion );

    int middle = (start + end )/2;

    // PrintDepth( false, depthRecursion );
    std::cout << "sortMerge(" << length << ", " << start << ", " << middle << ", " << end << ")" << std::endl;

    sortMerge( array, length, start, middle ); // [start, middle]
    sortMerge( array, length, middle+1, end ); // [middle+1, end]
    Merge( array, length, start, middle, end);

    depthRecursion--;
  }
}


int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  sortMerge( arr, size, 0, size-1 );

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}


{Q}
In an attempt to save sapce in Merge and changed to have a temp[start,end]. But didn't work as
planned. More wriedly, why size in main changes? Cannot reduce the size of temp array since combine
call use position left and right without adjustment when the sub array near to the right end which
has big start and end. So use the same length and the eaiser code.

void sortMerge( Entry* array, Position length, Position start, Position end )
{
  if( start < end )
  {
    depthRecursion++;
    PrintDepth( true, depthRecursion );

    int middle = (start + end )/2;

    // PrintDepth( false, depthRecursion );
    std::cout << "sortMerge(" << length << ", " << start << ", " << middle << ", " << end << ")" << std::endl;

    //sortMerge( array, length, start, middle );
    //sortMerge( array, length, middle+1, end );
    sortMerge( array, middle-start+1, start, middle );
    sortMerge( array, end-(middle+1)-1, middle+1, end );
    Merge( array, length, start, middle, end);

    depthRecursion--;
  }
}


int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  // int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 3 };
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  std::cout << "size: " << size << std::endl;

  sortMerge( arr, size, 0, size-1 );

  std::cout << "size: " << size << std::endl;

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}

size: 13
----(1) sortMerge(13, 0, 6, 12)
------(2) sortMerge(7, 0, 3, 6)
--------(3) sortMerge(4, 0, 1, 3)
----------(4) sortMerge(2, 0, 0, 1)
                Mege(2, 0, 0, 1)
----------(4) sortMerge(0, 2, 2, 3)
                Mege(0, 2, 2, 3)
              Mege(4, 0, 1, 3)
--------(3) sortMerge(1, 4, 5, 6)
----------(4) sortMerge(2, 4, 4, 5)
                Mege(2, 4, 4, 5)
              Mege(1, 4, 5, 6)
            Mege(7, 0, 3, 6)
------(2) sortMerge(4, 7, 9, 12)
--------(3) sortMerge(3, 7, 8, 9)
----------(4) sortMerge(2, 7, 7, 8)
                Mege(2, 7, 7, 8)
              Mege(3, 7, 8, 9)
--------(3) sortMerge(1, 10, 11, 12)
----------(4) sortMerge(2, 10, 10, 11)
                Mege(2, 10, 10, 11)
              Mege(1, 10, 11, 12)
            Mege(4, 7, 9, 12)
          Mege(13, 0, 6, 12)
size: 2 ~
{ 2, 5, }


<excution-tree-or-recursion-tree>
----(1) sortMerge(13, 0, 6, 12)
------(2) sortMerge(13, 0, 3, 6)
--------(3) sortMerge(13, 0, 1, 3)
----------(4) sortMerge(13, 0, 0, 1)
                Mege(13, 0, 0, 1)
----------(4) sortMerge(13, 2, 2, 3)
                Mege(13, 2, 2, 3)
              Mege(13, 0, 1, 3)
--------(3) sortMerge(13, 4, 5, 6)
----------(4) sortMerge(13, 4, 4, 5)
                Mege(13, 4, 4, 5)
              Mege(13, 4, 5, 6)
            Mege(13, 0, 3, 6)
------(2) sortMerge(13, 7, 9, 12)
--------(3) sortMerge(13, 7, 8, 9)
----------(4) sortMerge(13, 7, 7, 8)
                Mege(13, 7, 7, 8)
              Mege(13, 7, 8, 9)
--------(3) sortMerge(13, 10, 11, 12)
----------(4) sortMerge(13, 10, 10, 11)
                Mege(13, 10, 10, 11)
              Mege(13, 10, 11, 12)
            Mege(13, 7, 9, 12)
          Mege(13, 0, 6, 12)
{ 2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33, }


{quicksort}
This is great for 'contiguous' list and the contiguous list is the most important application for
quicksort because prove to be fast and has the advantage over contiguous mergesort of not requiring
extra space, complicated and difficult programming effort. Unlike mergesort, the size of the sublist
cannot be predicted in advance since it depends on pivot selection. Poor worst case, O(n2) and
excellent average case O(nlogn).

It uses swapping entries and keep sublists(subsets) in the same list so no extra space. It is sorted
during partition and choose different pivot for each sublist. The sublists are 'not' sorted and entry
is 'not' in the final position during running. <key> The final step of combining sorted list is not
necessary.

<partioning> <choice-of-pivot> <worst-case> how to partition as evenly as possible.
There are several methods but the algorithm we develop is much simpler and easier to understand, and
not slow; in fact it does the smallest possible number of key comparisons of any partitioning
algorithm. This algorithm uses the 'middle' as a 'pivot' and 'swap' it to the 'first', and do
partitioning.  So any can be a pivot because can choose any entry and swap it with the first entry
before beginning the loop. 

The first is often a poor choice for pivot when the list is already sorted and one of the sublists
will be empty. Hence the careful choice of pivot to make this worst case unlikey: use near the
center of list as a pivot in the hope that it will partition the keys so that about half come on
each side of the pivot. 

The average when applied to lists in random order turns out to be the best of any sorting
algorithms.

note. KT. Why is it better to have about half on each side? Otherwise, will end up with long and
narrow comparison tree, meaning a chain which is a bad case for comparison tree. The worst case is
when the keys are in their natural order or in their reverse order if choose the pivot as the first
or the last key. 

To allow for the possibility that more than one entry has key equal to p, the left of pivotpos have
keys strictly less than p and the right have greater than or equal to p.

|  < p   | p |    p =<      |
low                      high

Suppose that pivot starts in the first position and leave it there temporarily then the list has
following 'property' in the middle of loop: loop invariant

| p |  < p  *|   p =<   |* ?   |
low         lastsmall    i

When inspect i, there are two cases: if the entry is >= p then simply increase i and maintain the
property. If the entry < p then restore the property by increasing pivotpos(lastsmall) and swapping
it with entry i. note that swap happens when i < p and 'lastsmall' starts from beginning. So
swapping on the same index, swap(i, i), happens until see the >= p itmes when smaller items are in a
row.


| p |  < p   |*| >= p   |*| ?  |
low           lastsmall  i

When loop ends, will have:

| p |           < p     |      >= p  | 
low                    lastsmall     

Then swap(low, lastsmall) and get 

|      < p     | p |      p <=       | 

<key> The important property is to have sublists which are < and >= and each sublist is 'not'
sorted. Hence swapping is possible.


<ref-example>
Choose the first number on a list as the pivot:

[26] 33 35 29 19 12 22 [pivot]

< 26              => 26
[19] 12 22        [33] 35 29

12 
...

// execution-trace
Sort( 26, 33, 35, 29, 19, 12, 22 )
  Partition into ( 19, 12, 22 ) and ( 33, 35, 29 ); pivot = 26, pivotpos = 3

  Sort( 19, 12, 22 )    // [0-2]
    Partition into ( 12 ) and ( 22 ); pivot = 19, pivotpis = 1   // 12 19 22
    Sort(12)
    Sort(22)

  Sort( 33, 35, 29 )    // [4-6]
    Partition into ( 29 ) and ( 35 ); pivot = 33, pivotpos = 5   // 29 33 35
    Sort(29)
    Sort(35)


   0   1   2   3   4   5   6
( 29, 33, 35,<26> 19, 12, 22 )
( 26, 33, 35, 29, 19, 12, 22 )
( 26, 19, 12, 22, 33, 35, 29 )
( 22, 19, 12, 26, 33, 35, 29 )

( 22, 19, 12 )  ( 33, 35, 29 )
( 19, 22, 12 )  ( 35, 33, 29 )
( 19, 12, 22 )  ( 29, 33, 35 )   // here pivotpos is 6
( 12, 19, 22 )  
 [12]    [22]   ( 29, 33)[35]
                 [29][33]

( 12, 19, 22, 26, 29, 33, 35 )

// recustion-tree

----(1) sortQuick(0, 6)
          buildPartion( Pivot[26]), middle[3
          buildPartion(0, 6) returned posPivot = 3, Pivot[26]
------(2) sortQuick(0, 2)
            buildPartion( Pivot[19]), middle[1
            buildPartion(0, 2) returned posPivot = 1, Pivot[19]
------(2) sortQuick(4, 6)
            buildPartion( Pivot[35]), middle[5
            buildPartion(4, 6) returned posPivot = 6, Pivot[35]
--------(3) sortQuick(4, 5)
              buildPartion( Pivot[29]), middle[4
              buildPartion(4, 5) returned posPivot = 4, Pivot[29]

{ 12, 19, 22, 26, 29, 33, 35, }

// excludes a pivot itself when calls next
void RecQuickSort( List* list, Position low, Position high )
{
  Position pivotpos;

  if( low < high )
  {
    pivotpos = Partition( list, low, high );
    RecQuickSort( list, low, pivotpos-1 );
    RecQuickSort( list, pivotpos+1, high );
  }
}

// This returns the last index of lastsmall. The exact outline of explanation above.
Position Partition(List* list, Position low, Position high)
{
  ListEntry pivot;
  Position i, lastsmall, pivotpos;

  Swap( low, (low+high)/2, list );
  pivot = list->entry[low];
  pivotpos = low;
  for( i=low+1; i <= high; i++ )
    if( LT( list->entry[i].key, pivot.key ))
      Swap( ++pivotpos, i, list );

  Swap(low, pivotpos, list);
  return pivotpos;
}

<code>
<1>
#include <iostream>

#define GT(x,y) ((x)>(y))
#define LT(x,y) ((x)<(y))
#define EQ(x,y) ((x)==(y))

typedef int Position;
typedef int Entry;

unsigned int depthRecursion;
void PrintDepth( bool dash, unsigned int depth )
{
  for( unsigned int i=0; i <= depth; ++i)
  {
    if(dash)
      std::cout << "--";
    else
      std::cout << "  ";
  }

  if(dash)
    std::cout << "(" << depth << ") ";
  else
    std::cout << "      ";
}

// expects start and end in index
void swapEntry( Position x, Position y, int* array)
{
  int xval = array[x];

  array[x] = array[y];
  array[y] = xval;
}

Position buildPartion( Entry* array, Position start, Position end )
{
  Position idx, posPivot;
  Entry entryPivot;

  // use the center as a pivot, <key> swap happens on the 'same' index 
  swapEntry( start, (start+end)/2, array );

  // from start+1 since start is a pivot
  for( idx = start+1, posPivot = start, entryPivot = array[start]; idx <= end; idx++ )
  {
    if( LT( array[idx], entryPivot ))
      swapEntry( ++posPivot, idx, array );  // <key> swap happens on the 'same' index
  }

  // swap back <key> swap happens on the 'different' index from the middle
  swapEntry( start, posPivot, array );

  PrintDepth( false, depthRecursion );
  std::cout << "buildPartion(" << start << ", " << end << ") returned posPivot = " << posPivot << std::endl;

  // this posPivot varies depending on input
  return posPivot;
}

// expects the length of array
void sortQuick( Entry* array, Position start, Position end )
{
  Position posPivot;

  if( start < end )  // <key> this means when there is one is the stop condition.
  {
    depthRecursion++;
    PrintDepth( true, depthRecursion );

    std::cout << "sortQuick(" << start << ", " << end << ")" << std::endl;

    posPivot = buildPartion( array, start, end );
    sortQuick( array, start, posPivot-1 );  // <key> +1 and -1.
    sortQuick( array, posPivot+1, end );

    depthRecursion--;
  }
}

int main()
{
   // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
   int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6 };
   int size = ( sizeof(arr)/sizeof(arr[0]));

   sortQuick( arr, 0, size-1 );

   std::cout << "{ "; 
   
   for(int idx = 0; idx < size; idx++)
      std::cout << arr[idx] << ", "; 

   std::cout << "}" << std::endl; 
}

<recustion-tree>
----(1) sortQuick(0, 12)
          buildPartion(0, 12) returned posPivot = 5
------(2) sortQuick(0, 4)
            buildPartion(0, 4) returned posPivot = 1
--------(3) sortQuick(2, 4)
              buildPartion(2, 4) returned posPivot = 2
----------(4) sortQuick(3, 4)
                buildPartion(3, 4) returned posPivot = 3
------(2) sortQuick(6, 12)
            buildPartion(6, 12) returned posPivot = 7
--------(3) sortQuick(8, 12)
              buildPartion(8, 12) returned posPivot = 8
----------(4) sortQuick(9, 12)
                buildPartion(9, 12) returned posPivot = 12
------------(5) sortQuick(9, 11)
                  buildPartion(9, 11) returned posPivot = 10

{ 2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33, }

Compared with the mergesort, see that it has rather simple tree. Hence better.

<when-input-is-already-sorted>
----(1) sortQuick(0, 12)
swap: x == y
swap: x == y
swap: x == y
swap: x == y
swap: x == y
swap: x == y
          buildPartion(0, 12) returned posPivot = 6
------(2) sortQuick(0, 5)
swap: x == y
swap: x == y
            buildPartion(0, 5) returned posPivot = 2
--------(3) sortQuick(0, 1)
swap: x == y
swap: x == y
              buildPartion(0, 1) returned posPivot = 0
--------(3) sortQuick(3, 5)
swap: x == y
              buildPartion(3, 5) returned posPivot = 4
------(2) sortQuick(7, 12)
swap: x == y
swap: x == y
            buildPartion(7, 12) returned posPivot = 9
--------(3) sortQuick(7, 8)
swap: x == y
swap: x == y
              buildPartion(7, 8) returned posPivot = 7
--------(3) sortQuick(10, 12)
swap: x == y
              buildPartion(10, 12) returned posPivot = 11

{ 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33, }


<when-is-not-sorted>

{ 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6 };

----(1) sortQuick(0, 12)
          swap: 1, 1
          buildPartion(0, 12) returned posPivot = 5, Pivot[12]
------(2) sortQuick(0, 4)
            swap: 1, 1
            buildPartion(0, 4) returned posPivot = 1, Pivot[5]
--------(3) sortQuick(2, 4)
              swap: 2, 2
              buildPartion(2, 4) returned posPivot = 2, Pivot[6]
----------(4) sortQuick(3, 4)
                swap: 3, 3
                swap: 3, 3
                buildPartion(3, 4) returned posPivot = 3, Pivot[6]
------(2) sortQuick(6, 12)
            buildPartion(6, 12) returned posPivot = 7, Pivot[15]
--------(3) sortQuick(8, 12)
              swap: 8, 8
              buildPartion(8, 12) returned posPivot = 8, Pivot[17]
----------(4) sortQuick(9, 12)
                swap: 10, 10
                swap: 11, 11
                swap: 12, 12
                buildPartion(9, 12) returned posPivot = 12, Pivot[33]
------------(5) sortQuick(9, 11)
                  buildPartion(9, 11) returned posPivot = 10, Pivot[30]

{ 2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33, }

<2>
#include <iostream>

#define LT(x,y) ((x)<(y))

void swap( int *array, int x, int y )
{
  int temp = array[x];

  array[x] = array[y];
  array[y] = temp;
}

int divide( int *array, int start, int end )
{
  int pospiv = (start+end)/2;
  int pivot = array[pospiv];
  int lastsmall = start;
  
  // swap start and selected pivot
  swap( array, start, pospiv );

  // divide as to property
  for( int i = start+1; i <= end; i++ )
    if( LT( array[i], pivot ) )
      swap( array, ++lastsmall, i );

  // swap back
  swap( array, start, lastsmall );

  return lastsmall;
}

// do not work, why?
int divide_mod( int *array, int start, int end )
{
  int pospiv = (start+end)/2;
  int pivot = array[pospiv];
  int lastsmall = start;
  
  // divide as to property
  for( int i = start; i <= end; i++ )
    if( LT( array[i], pivot ) )
      swap( array, lastsmall++, i );

  return lastsmall;
}

void mqsort( int *array, int start, int end )
{
  if( start < end ) 
  {
    int posdiv = divide_mod( array, start, end );
    //int posdiv = divide( array, start, end );
    mqsort( array, start, posdiv-1 );
    mqsort( array, posdiv+1, end );
  }
}

int main()
{
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  mqsort( arr, 0, size-1 );

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}

<3> from ansic, p87. exactly same way.
void cqsort( int v[], int left, int right )
{
  int i, last;

  // do nothing if array contains fewer than two elements
  if( left >= right )
    return;

  // move partition elem
  swap( v, left, (left+right)/2 );

  last = left;  // to v[0]

  // partition
  for(i = left+1; i <= right; i++)
    if( v[i] < v[left] )
      swap( v, ++last, i );   // shall ++last

  // restore partition elem
  swap(v, left, last);

  cqsort( v, left, last-1 );
  cqsort( v, last+1, right );
}


{heapsort}
Some kind of input can make quicksort misbehave badly and heapsort overcomes this problem. Like the
pecking order in a corporate hierarchy and each employee supervises exactly two others.

When putting 2-tree into a list, found that:

The left and right children of the node with position k are in positions 2k+1 and 2k+2 of the list.
If these positions are beyond the end of the list, then these children do not exist. means leaf.
(this is about position)

The heap is a list in which each entry contains a key, and, for all positions k in the list, the key
a position k is at least [as-large-as-the-key] in positions 2k+1 and 2k+2, provided these positions
exist in the list. (this is about key)

The sample heap as a 2-tree and a list

                () y
        () r          () p
  () d     () f    () b   () k
() a () c


[y r p d f b k a c]

The first entry must be the largest key in the heap. Heapsort has two phases: arrange a list to make
a heap and remove the top of the heap and promote another entry to take its place.

For second phase, move the first entry to the last position: save the last to current, move the
first to the last, and place the current to the right position while building the heap. Decrease a
counter lu(last unsorted). 

This means that heap sort needs random-access and only for contiguous list.

void HeapSort(List* list)
{
	Position lu;
	ListEntry current;

	BuildHeap(list);

	for( lu = list->count-1; lu >=1; lu-- )
	{
		current = list->entry[lu];
		list->entry[lu] = list->entry[0];
		InsertHeap( current, 0, lu-1, list );
	}
}

[y r p d f b k a c]
[  r p d f b k a | y] c = c
[r f p d c b k a | y] 
[p f k d c b a | r y] 
...
[a | b c d f k p r y]

// see the left and right child of low and promote the bigger into low. also loop throuth the list.

void InsertHeap( ListEntry current, Position low, Position high, List* list )
{
	Position large;
	large = 2*low+1;	// index of left child

	while( large <= high )
	{
		// LT(left, right) and choose bigger one
		if( large < high && LT(list->entry[large].key, list->entry[large+1].key ))
			large++;

		// if current is bigger then
		if( GE( current.key, list->entry[large].key ))
			break;
		else
		{
			list->entry[low] = list->entry[large];
			low = large;
			large = 2*low+1;
		}
	}

	// when current is bigger or is out of index meaning there is no child
	list->entry[low] = current;
}

// p326. 2-tree with one node automatically satisfies heap and therefore not worry about leaves of
// the tree. Idea is if begin at the midpoint of the list and work our way back toward the start,
// can use InsertHeap to insert each entry into the partial heap consisting all later entries.

void BuildHeap(List* list)
{
	Position low;

	for(low = list->count/2-1; low >= 0; low-- )
		InsertHeap( list->entry[low], low, list->count, list );
}

 0 1 2 3 4 5 6 7 8
[y r p d f b k a c] low=3, list->count=9 IH( [3], 3, 9 ) : 3, 6, 7 
                    low=2, list->coutt=9 IH( [2], 2, 9 ) : 2, 4, 5
                    low=1, list->coutt=9 IH( [1], 1, 9 ) : 1, 2, 3, 4, 5, 6, 7
                    low=0, list->coutt=9 IH( [0], 0, 9 ) : 0, 1, 2, 3, 4, 5, 6, 7


<heapsort-application> {priority-queue}

The priority queue. each contains a key called priority and queue has two operations: insert and
remove the entry having largest (or smallest) key.

If represent a priority queue as a [sorted] contiguous list, in which case removal is immediate but
insertion take time proportional to n. Or represent it as an [unsorted], in which case insertion is
rapid but removal is slow.

The representation of a priority queue as a heap proves advantageous [for large n] since it is
represented efficiently in contiguous storage and is guaranteeded to need only logarithmic time for
both insertion and deletion.


{sort-summary}

o in choosing a method, take into account the ways in which the keys will usually be arranged before
sorting, the size of application, the amount of time available for programming, the need to save
computer time and space. Futhermore, see statistical analysis such as standard deviation and
empirical testing.

o merge, quick and heapsort are powerful and efficient but more difficult to program when applied to
large lists.

o heapsort is like an insurance: usually slower than quicksort but guarantees that sorting will be
completed in O(nlogn) comparison of keys, something that quicksort cannot always do.


={============================================================================
*kt_dev_algo_010* table and hash

{logn-barrier}
As seen in binary search, by use of key comparisons alone, impossible to complete a search of n
items in fewer than logn on average: <binary-search-comparison-which-is-better>

The table lookup and searching share the same purpose: information retrieval. Searching uses key
comparison, whereas table lookup do not. Here assumes that each entry has only ''one'-key. The table
look-up is O(1) and can be more efficient than any searching method. Provides functions from set of
'keys' to 'location' of the entry.

Here study ways to implement and access tables in contiguous storage.


{index-function} {access-table}
Think a representation of rectangular array in a computer since computer storage is in a contiguous
sequence. So about how a way to store and read a rectangular table. 

This is row-major ordering. m x n where the columns from 0 to n-1:

Entry(i,j) goes to position ni+j

A formular of this kind is called index function. Rather than calculate index, can have a table
having pre-calculated-index then used for all later references. This is called an access-table to
eliminate the calculations.

rectangular    access table
array
[cost]    ->   [0]                  [costareatear] 
[area]         [4]                   0   4   8 
[tear]         [8]

This index function or access table describes mapping meaning that can represent various shape of
array. For example, triangular matrix(table).


{multiple-access-table} multikey-access-array
Consider the problem faced by the telephone company in accessing the records of its customers. To
publish the telephone book, the records must be sorted alphabetically by the name but to process
long-distance charges, the accounts must be sorted by telephone number. The company could keep
three(or more) set of its records, one sorted by name, one by number, and one by address. Doing this
would, however, not only be very wasteful of storage but it would introduce endless headaches if one
set of records were updated but another was not. note: each set has actuall copy of records.

By using access arrays we can avoid the multiple sets of records, and we can still find the records
by any of the three keys almost as quickly as if the records were fully sorted by that key. note:
this only has access array for each key and has only one set of records as with having pointers.

There is no particular reason why the records themselves need to be sorted according to one key
rather than another, or, in fact, why they need to be sorted at all. The records themselves can be
kept in an arbitrary order.

There is no reason why the records themselves need to be sorted according to one key rather than
another and also no difference whether the records are in array or in dynamic storage with the
access tables holding pointers to records.

It also makes no difference whether the records are in an array, with entries in the access arrays
being indices of the array, or whether the records are in dynamic storage, with the access arrays
holding pointers to individual records. In any case, it is the 'access' arrays that are used for
information retrieval, and, as ordinary contiguous arrays, they may be used for table lookup, or
binary search, or any other purpose for which a contiguous implementation is appropriate.

index    name     address     phone
1        Hill     High...     2829478
2        Baker    17 King     2884285
...
7        Moody    High King   2822214


access array(tables)

name     address     phone
2        3           5 
6        7           7
1        1           1
5        4           4
4        2           2
7        5           3
3        6           6


{table-adt}
This table is ADT which has 'domain'(index set) and the 'codomain'(base type or value type). A table
with index set I and base type T is a 'function' from I into T; which maps elements of domain to one
of codomain.

The table is ADT which has domain(index set) and the codomain(base type or value type). If, for
example, we have the array declaration

double array[n];

then the index set is the set of integers between 0 and n - 1, and the base type is the set of all
real numbers.

<definition>
A table with index set I and base type T is a 'function' from I into T; which maps elements of domain
to one of codomain.

1. Table access: Evaluate the function at any index in I .
2. Table assignment: Modify the function by changing its value at a specified index in I to the new
value specified in the assignment.
3. Creation: Set up a new function from I to T .
4. Clearing: Remove all elements from the index set I , so the remaining domain is empty.
5. Insertion: Adjoin a new element x to the index set I and define a corresponding value of the
function at x.
6. Deletion: Delete an element x from the index set I and restrict the function to the resulting
smaller domain.

<comparison>
retrieval
Let us compare the abstract data types list and table. The underlying mathematical construction for
a list is the sequence, and for a table, it is the set and the function. Sequences have an
'implicit' order; a first element, a second, and so on, but sets and functions have no such order.
Hence information retrieval from a list naturally involves a search like the ones studied in the
previous chapter, but information retrieval from a table requires different methods, access methods
that go directly to the desired entry. The time required for searching a list generally depends on
the number n of entries in the list and is at least lgn, but the time for accessing a table does not
usually depend on the number of entries in the table; that is, it is usually O(1). For this reason
in many applications, table access is significantly faster than list searching.

traversal
On the other hand, traversal is a natural operation for a list but not for a table. It is generally
easy to move through a list performing some operation with every entry in the list. In general, it
may not be nearly so easy to perform an operation on every entry in a table, particularly if some
special order for the entries is specified in advance.


{radixsort}
The idea is to consider the key, one character, at a time and to divide entries into as many sublists
as there are possibilities for the given character from the key. For example, if keys are words or
other alpabetic strings, divide the list into 26 sublists at 'each' stage.

note: The key is that set up a table of 26 sublists and distribute the entries from input list into
the sublist. Here use index to find corresponding list. Hence table.

<approach-one>
A person sorting words by working on only one column like mechanical card sorter might first
distribute the words into 26 lists according to the initial letter, then devide each sublist into
further sublist according to the second letter, and so on. (means do second list within the first).
This causes multiplicity of sublist.

<approach-two>
To eliminates multiplicity of sublists: partition the items into the table of sublists first by the
least significant position and to the most. When, after repetition of these steps, the list has been
partitioned by the most significant place and recombined, it will be completely sorted.

note: Why sorted? because uses alphabet order which is sorted so will be sorted by distributing keys
into sublist according to alphabet order.

This process is illustrated by sorting the list of nine three-letter words from 3rd, least
significant position to 1st, most siginificant position.

init     by 3rd      by 2nd      by 1st
rat      mop {       map {       car
mop      map         rap         cat
cat      top         car         cot
map      rap }       tar         map
car      car {       rat         mop
top      tar }       cat }       rap
cot      rat {       mop {       rat
tar      cat         top         tar
rap      cot }       cot }       top

<approach-three>
To see why should use LSB first to partition, try to use MSB first but the result is not sorted. 

init     by 1st char    by 2nd      by 3rd
rat      cat            cat         cat { not sorted
mop      car            car         car
cat      cot            map         cot }
map      mop            rat         map
car      map            rap         mop
top      rat            tar         rat {
cot      rap            cot         rap }
tar      top            mop         tar
rap      tar            top         top 

<example> reference example in C
Set up an array of 28 linked queues which is a table ADT. position 0 corresponds to a blank
character, position 1 through 26 to the letters and position 27 to any other character that appears
in the key. 

note: Why queue for a sublist? Since entries are always inserted at the end of a sublist and removed
from the beginning. (but not the first)

Traverse the linked list and add each item to the end of the appropriate queue. After partitioned,
recombine the queues into one list.

<assumptions>
The assumption is that no case since only lower case, ASCII

// this is EntryType and means that each entry has char array[KEYSIZE].
typedef char QueueEntry[KEYSIZE];

// shall set up array of 28 linked queue. position 0 corresponds to a blank character, position 1-26
// to the letters (no case), position 27 to any other character which is non-alphabet.
int QueuePosition(char c)
{
  if( c == ' ' ) return 0;
  else if( isalpha(c) )
    return tolower(c) - 'a' +1;
  else
    return 27;

  or to support upper and lower case

  if( c == ' ' ) return 0;
  if ('a' <= c && c <= 'z') return c − 'a' + 1;
  if ('A' <= c && c <= 'Z') return c − 'A' + 1;
  return 27;
}

// recombine all queues into one list
void Rethread(List* list, Queue queues[] )
{
  int i;
  Node* x;

  for( i=0; i < MAXQARRAY; i++ )
    while( !QueueEmpty( &queues[i] ))
    {
      ServeNode( &x, &queues[i] );
      InsertList( ListSize(list), x, list );
    }
}

void RadixSort(List *list)
{
  int i, j;
  Node *x;
  Queue queues[MAXQARRAY];

  for( i=0; i < MAXQARRAY; i++ )
    CreateQueue(&queue[i]);

  // for each key(char) starting from LSB in the key set
  for( j=KEYSIZE-1; j >= 0; j-- )
  {
    // get all node from input list and put it back to the corresponding queue. 
    // note: take a entry from list and put it to the queue as a node. so there is interface
    // difference between queue and list.
    while( !ListEmpty(list) )
    {
      // get the first entry from a list. DeleteList( pos, ListEntry*, List*) and see general list. 
      DeleteList( 0, &x, list );

      // make a node and put it into a corresponding queue. 
      AppendNode( x, &queue[ QueuePosition( x->entry[j]) ]);
    }

    // connect 28 queues together as a single list
    Rethread( list, queue );
  }
}

<analysis>
The radix sort is 'proportional' to nk, where n is the number of items and k is the number of
characters in a key. The time for all our other sorting methods denpends on n but not directly on
the length of a key.

To compare the relative performance with the best time of mergesort which is nlogn. So the relative
size of nk vs nlogn:

<key>
The relative performance of the methods will therefore relate in some ways to the relative sizes of
nk and nlgn; that is, of k and lgn. If the keys are long but there are relatively few of them, then
k is large and lgn relatively small, and other methods (such as mergesort) will outperform radix
sort; but if k is small (the keys are short) and there are a large number of keys, then radix sort
will be faster than any other method we have studied.

note: Very efficient sorting method for linked list implementations. For example, if input list and
sublist are lined implementation and can move around nodes when moving around between them.


{hash-table}
For cases where the key is no longer an index that can be used directly as in array indexing. What
we can do is to set up a one-to-one correspondence between the keys by which we wish to retrieve
information and indices that we can use to access an array.

The only difficulty arises when the number of possible keys exceeds the amount of space available
for our table. If, for example, our keys are alphabetical words of eight letters, then there are
26^8 = 2*10^11 possible keys, a number likely greater than the number of positions that will be
available in high-speed memory. In practice, however, only a small fraction of these keys will
actually occur. That is, the table is sparse. Conceptually, we can regard it as indexed by a very
large set, but with relatively few positions actually occupied. note: this is why hash table allows
collision.

Hash table is to allow many of the different possible keys that might occur to be mapped to the
'same' location under the action of index function. This 'index' function is 'hash' function which
map several different keys to the same index. This is 'collision'. So two questions: find good hash
function and how to resolve collisions.

<hash-function>
The good hash function has:

1. should be easy and quick to compute.
2. should achieve an 'even' distribution of the keys that actually occur across the range of indices.

Need even distribution of the keys but do not know in advance what keys will occur. There is nothing
random about a hash function. Three methods that can be put together in various way to build a hash
function. All about even distribution to avoid collisions.

The various to build good hash function:

<truncation>
Use part of key directly as the index. For example, for key 62538194, use 394 which is 1, 2 and 5
digits as the index. This is very fast but often fail to get even distribution.

<folding>
Partition the key into several parts and combine in convenient way. For example, 62538194 maps to
625+381+94 = 1100 which is truncated to 100. Since all information in the key is used, often have
better spread than truncation.

<modular>
Divide by the size of the index range and take remainder as the result. The spread depends very much
on the modulus( in this case, the size of the hash array). If the modulus is a power of a small
integer like 2 or 10, then many keys tend to map to the same index, while other indices remain
unused. The best is to use 'prime' numbers: not 1000 or 1024 but use 997 or 1009.

This is the best since can get good 'spread' and ensures that the result is in the proper range at
the same time. 

int Hash( Key s )
{
  unsigned h = 0;

  while(*s)
    h += *s++;

  return h % HASHSIZE;
}


// ansic, p144. form hash value for string
unsigned hash( char *s )
{
  unsigned hashval;

  for( hashval = 0; *s != '\0'; s++ )
    hashval = *s + 31 * hashval;

  return hashval % HASHSIZE;
}


<collision-resolution> 
rehashing:
There are many ways to do. rehashing uses a second hash function to obtain the second position to
consider.

chaining: Collision Resolution by Chaining

Up to now we have implicitly assumed that we are using only contiguous storage while working with
hash tables. Contiguous storage for the hash table itself is, in fact, the 'natural' choice, since
we wish to be able to refer quickly to random positions in the table, and linked storage is not
suited to random access. There is, however, no reason why linked storage should not be used for the
'records' themselves. We can take the hash table itself as an array of linked lists.

It is traditional to refer to the linked lists from the hash table as chains and call this method
collision resolution by chaining.

table
[ ]   -> list
[ ]   -> list
[ ]   -> list
[ ]   -> list


{summary}
We can summarize these observations for retrieval from n entries as follows:

1. Sequential search is O(n)
2. Binary search is Ò(log n)
3. Hash-table retrieval is Ò(1)

For speed and convenience, ordinary lookup in contiguous table is superior but there are many
applications to which it is inapplicable: when keys is sparse, when insertion or deletion are
frequent.


={============================================================================
*kt_dev_algo_011* binary tree

The linked list have great advantages of flexibility over contiguous implementation but have one
weak feature: {list-contiguous-and-linked} they are sequential list; that is, have to access through
them only one position at a time, not random access.

Tree overcome this and is valuable for problems of information retrieval.


{adt-definition} # binary-tree
A binary tree is either empty, or consist of a node called the 'root' together with two binary tree
called the 'left-subtree' and the 'right-subtree' of the root.

<condition>
The left and right are important for binary tree and has recursive nature that allows empty binary
tree and the empty tree is base case for recursive and determine when to stop.

2-tree is different from binary tree since 2-tree has always 0 or 2 children but never 1.

Excercise: get all fourteen binary trees with four nodes.


{traversal-orders}
There are many different traversal orders for trees and reduced to 'three' by permitting only the ways
in which the left is traversed before the right.

The (V)isiting a node, traversing the left subtree L, and the right subtree R. <note> that visit,
traverse and subtree in wording since traverse is not visit.

VLR(preorder) LVR(inorder) LRV(postorder)
^              ^             ^
Do this order for every node so has recursive nature. For example, traverse the following tree

  ()1
    ()2
  ()3
()4  ()5

pre 12345, in 14352 and post 45321


{linked-implementation}
A binary tree has a natural implementation in linked strorage. The root variable enable us to find
the tree and it will point to the root of the tree.

typedef struct treenode TreeNode;
typedef struct treenode {
  TreeEntry entry; // application dependant
  TreeNode  *left;
  TreeNode  *right;
} TreeNode;

// TreeNode* ttree; CreateTree(&ttree);
void CreateTree( TreeNode** root )
{ *root = NULL; }

Bool TreeEmpty( TreeNode* root )
{ return root == NULL; }

void Preorder( TreeNode* root, void (*Visit)(TreeEntry x))
{
  if(root)
  {
    Visit(root->entry);
    Preorder( root->left, Visit);
    Preorder( root->right, Visit);
  }
}

void Inorder( TreeNode* root, void (*Visit)(TreeEntry x))
{
  if(root)
  {
    Inorder( root->left, Visit );
    Visit(root->entry);
    Inorder( root->right, Visit );
  }
}

// ansic, p142. in-order print of tree
void treeprint( struct tnode *p )
{
  if( p != NULL )
  {
    treeprint( p->left );
    printf("%4d %s\n", p->count, p->word );
    treeprint( p->right );
  }
}


{binary-search-tree}
In {ref-004}, when given a binary tree question, many candidates assumes that it means binary search
tree. Be sure to ask whether or not the tree is a binary search tree(BST). A BST imposes the
'condition' that, for all nodes, the left children are less than or equal to the current node, which
is less than all the right nodes. BST is a 'special' kind of a binary tree.

The searching through the linked list always reduce to a sequential search and contiguous list is
much slower when frequently need to make changes in the list. The binary search tree is excellent
solution to this problem:

Can we find an implementation for ordered list in which we can search quickly (as with binary search
on a contiguous list) and in which we can make insertions and deletions quickly (as with a linked
list)?

By making the entries of an 'ordered' list into the nodes of a binary tree, O(logN) for search and
O(logN) for insertion and deletion as with binary search. The main design is to store the nodes as a
binary tree with the structure of comparison tree itself, with links used to describe the relations
of the tree. See {list-contiguous-and-linked}

This is especially appropriate when random access, traversal in predetermined order, and flexibility
are 'all' required.

<adt-definition>
The binary search tree is a binary tree that is either empty or in which every node contains a
key(entry) and satisfies the conditions:

1. The key in the 'left' child of a node (if it exists) is 'less' than the key in its parent node.
2. The key in the 'right' child of a node (if it exists) is 'greater' than the key in its parent node.
3. The left and right subtrees of the root are again binary search tree.

This ensures that 'no' two entries in a binary search tree can have 'equal' keys since keys are strictly
less or greater. Possible to change the definition to allow entries with equal keys, but doing so
make the algorithm complicated.

<comparison-trees>
This is a BST and here 0 means NULL for left or right subtree.

              Jim
     Dot              Ron
  Amy     Guy     Kay     Tim
0   Ann Eva Jan Jon Kim Roy Tom
    0 0 0 0 0 0 0 0 0 0 0 0 0 0
 
Preorder: Jim Dot Amy Ann Guy Eva Jan Ron Kay Jon Kim Tim Toy Tom
Inoder  : Amy Ann Dot Eva Guy Jan Jim Jon Kay Kim Ron Roy Tim Tom

<tree-search>
The search in a linked binary search tree and termination condition is if we find the key and if
not, then continue searching until hit an empty subtree. This is based closely on binary search so
do the same comparisons as binary search do. O(logN)

// Returns node pointer if an entry in the binary search tree has key equal to target; that is when
// root is not null and LT and GT are false. Otherwise, returns NULL which is a leaf. See returning
// root up the chain and 'else if (GT)' but not 'else'. Strictly less or greater.
TreeNode* TreeSearch( TreeNode* root, KeyType target )
{
  if(root)
  {
    if( LT( target, root->entry.key) )
      root = TreeSearch( root->left, target );
    else if( GT(target, root->entry.key) )            // see else if
      root = TreeSearch( root->right, target );
  }

  return root;    // return null or node ptr for a equal key
}

// Recursion removal version as it is tail recursion. returns node if found; otherwise, return null.
// Q: Why use 'position' variable? Seems that it is okay not to use position and use root.
TreeNode* TreeSearch( TreeNode* root, KeyType target)
{
  TreeNode* position = root;

  // note 1. Already checked equal case in while so no need to the same in if and else clause Why?
  // since run only equal case in recursion version and exit call when equal but here use while
  // instead. In other words, NE is 'hidden'(implicit) case in recursion version.

  // note 2. This finds equal (remember binary search has two versions) and when reaches a leaf then
  // means 'not found'.

  while( position && NE( target, position->entry.key ))
  {
    if( LT(target, position->entry.key ))
      position = position->left;
    else
      position = position->right;
  }

  return position;
}

Can think that the leaf node has imaginary left and right null node.


{random-binary-search-tree}
The same keys which are letters in this case can have quite different shapes of trees depending on
<how-a-tree-is-made>. In other words, how it is inserted into a tree range from the best which is
bushiest meaning fewerer "tree-height, comparison, or recursion depth" to the worst which is a
single chain and is equal to sequential search.

"dbacfeg" ->               d()                "abcdefg" -> ?
                       b()     f()
                     a() c() e() g()

Remember that binary search requires ordered list. The search performance of BST 'depends' on how a
tree constructed. The TreeInsert can handle the random input and when the input is ordered, BST
degenerates to the worst case, single chain. Think a tree shape when use TreeInsert with ordered
input. The worst case is extremely unlikely in practice so TreeSearch performs nearly as well as
binary search. 

For random order, it is 39% slower than the optimum(completely balanced) of (logN) comparisons.
Still better than sequential search. This is average.

Why random? This tree handles random input order in which includes worst case. Hence called random
BST.

<tree-insert> which supports the random input
The worst of a random binary search tree is when the keys are inserted into an initially empty tree
in their natural order, sorted. This will produce a chain, a tree with a single line. The same holds
if the keys are in reverse order or if they are nearly but not quite sorted into order. TreeInsert
should never be used with keys that are 'already' sorted into order.

<equal-key-support>
If the keys are equal, we shall adopt the convention of inserting the duplicate key into the 'right'
subtree. It inserts a new key that duplicates a previous key on the right side of the old entry.
TreeSearch, the searching function will always find the 'first' entry of duplicated keys.

note. Looks like searching will find the first entry regardless of right or left for duplicated
keys.

Example, "e, b, d, f, a, g, c"
          0  1

// See how return value is used; used to set left or right of the previous node. The last return
// value is always root. Also this shall be used once searching to insert is done. That is search
// and insert.
TreeNode* TreeInsert( TreeNode* root, TreeNode* newnode )
{
  if(!root)
  {
    root = newnode;
    root->left = root->right = NULL;
  }
  else if( LT(newnode->key.entry, root->key.entry ) )
    root->left = TreeInsert( root->left, newnode );
  else                                                      // see else that is <=
    root->right = TreeInsert( root->right, newnode );

  return root;
}

In regard to performance, TreeInsert will be very much the same as that of TreeSearch to find a
place to insert: O(logN)

The ansic example, p141, which is word frequency count example.

// addtree: add a node with w, at or below p
struct tnode *addtree( struct tnode *p, char *w )
{
  int cond;

  if( p == NULL )    // a new word has arrived
  {
    p = talloc();    // make a now node
    p->word = strdup(w);
    p->count = 1;
    p->left = p->right = NULL;
  }
  else if((cond = strcmp( w, p->word )) == 0 )
    p->count++;
  else if( cond < 0 )
    p->left = addtree( p->left, w );
  else
    p->right = addtree( p->right, w );

  return p;
}


<treesort>
The inorder(LVR) traversal of binary search tree always give the 'sorted' order for the keys. So
simply takes the entries to be sorted, use TreeInsert to build them into a binary search tree, and
use inorder traversal to put them out in order.

Notice the similarity with quicksort. The quicksort is usually an excellent method and treesort
makes the same comparisons as does quicksort. In the average, on a randomly ordered list of n,
treesort performs:

1.39 nlogn + O(n)

<why-bst-is-useful-for-a-stream>
For a use case, see <8> in *kt_dev_quiz_015* 

Treesort has one advantage over quicksort: Quicksort needs to have access to all the items to be
sorted but with treesort, the nodes need not all be available at the start of the process, but are
built into the tree one by one as they become available since as each node comes in, it goes into its
'final' position in the linked list. 

This is major advantage that 1) search tree 'remains' avaiable for later <insertions-and-deletions>, and
that 2) can be searched in logarithmic time, whereas all previous sorting either requires contiguous
list or produce linked list for sequential search.

As with quicksort, the major drawback is the worst case when input is already sorted, or are nearly
so.

<code-example>
#include <iostream>
#include <string>
#include <cstdlib>

#define LT(a,b) ((a) < (b))

typedef struct {
  int key;
} TreeEntry;

typedef struct treenode {
  TreeEntry entry; // application dependant
  treenode  *left;
  treenode  *right;
} TreeNode;

TreeNode* MakeTreeNode(int key)
{
  TreeNode* pnode = NULL;

  if( (pnode = (TreeNode*) malloc(sizeof(TreeNode))) == NULL )
  {
    std::cout << "MakeTreeNode: out of memory" << std::endl;
    return pnode;
  }

  pnode->entry.key = key;
  pnode->left = pnode->right = NULL;

  return pnode;
}

void CreateTree( TreeNode** root )
{ *root = NULL; }

TreeNode* TreeInsert( TreeNode* root, TreeNode* newnode )
{
  if(!root)
  {
    root = newnode;
    root->left = root->right = NULL;
    std::cout << "inserted: " << root->entry.key << std::endl;
  }
  else if( LT(newnode->entry.key, root->entry.key) )
    root->left = TreeInsert( root->left, newnode);
  else
    root->right = TreeInsert( root->right, newnode);

  return root;
}

void TreeInorder( TreeNode* root, void (*Visit)(TreeEntry x))
{
  if(root)
  {
    TreeInorder( root->left, Visit);
    Visit(root->entry);
    TreeInorder( root->right, Visit);
  }
}

void PrintTreeNode( TreeEntry entry )
{
  std::cout << ":" << entry.key << std::endl;
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  TreeNode *proot, *pnode;

  CreateTree( &proot );    // make proot is NULL

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
  {
    std::cout << "insert " << arr[idx] << " into a tree" << std::endl; 
    pnode = MakeTreeNode( arr[idx] );

    // TreeInsert( proot, pnode );
    // <key> <call-by-value-problem> notice that this is an bug. It is  call-by-value-problem since
    // TreeInsert get a copy and this causes always to insert new to the null root sicne proot is
    // not updated. Hence no output when traversing. 

    proot = TreeInsert( proot, pnode );
  }

  TreeInorder( proot, PrintTreeNode );

  std::cout << "}" << std::endl; 
}


{Q} can change these to use reference?


<tree-delete>
Why care about deleting a node in a tree? because it is one of advantages treesort provides and
which is that search remains avaialbe after insertion and 'deletion'. It is more complicated when
the node to be deleted has both left and right subtrees which are nonempty since it is easy to
delete a leaf and a node with only one subtree.

One possible solution when it has both subtrees:

1. To which of the subtree should the parent of the deleted node now point? Right or left subtree?
The one approach in this book is to attach the 'right' subtree in place of the deleted node.

2. What is to be done with the other subtree which is the left in this approach? Since every key in
the left subtree precedes(less than) every key of the right subtree, must be as 'far' to the 'left'
as possible. Remember the left subtree is also a tree. This point can be found by taking left
branches until an empty left subtree is found.

TreeNode* x;
DeleteNodeTree(&x->left);  // equals to DeleteNodeTree(&(x->left)); pointer to a node to delete;

// The parameter p is the address of actual node(not a copy) in a tree since the object is to update
// the BST, the actual parameter is the address of one of the links of the tree.
//
//              [ left, right ]                       // &x->left (*p)
//            
//                      [ left, right ]               // r
//
//            [ left, right]       [ left, right ]    // r->left or r->right
//
// <note> As shown <call-by-value-problem> in TreeInsert, this is why this has "**" argument type.
//
void DeleteNodeTree( TreeNode** p )
{
  // r points to node to delete which is *p (left or right child ptr of the parent)
  TreeNode *r = *p, *q;

  if( r == NULL )
    Error("attempt to delete a nonexistent node from binary search tree");

  // when a node has only either left or right subtree, attach subtree to a parent
  else if( r->right == NULL )
  {
    *p = r->left;    // reattach left subtree
    free(r);
  }
  else if( r->left == NULL )
  {
    *p = r->right;   // reattach right subtree. *p now points to r->right.
    free(r);
  }
  // when a node has both subtrees
  else
  {
    // get to the leftmost node of the 'right' subtree. this is the same as <list-find-end-idiom> in
    // 'list'. This becomes a searching of single linked list.
    for( q = r->right; q->left; q = q->left )
      ;

    // reattach left subtree to the far left of right subtree. notice how easy to move the whole
    // subtree.
    q->left = r->left;     

    *p = r->right;         // reattach right subtree

    free(r);
  }
}

For many cases, not given a pointer to a node to delete but instead given a key for which the
corresponding node must be deleted. So combine 'search' and delete function. Compare TreeSearch
which do not have EQ comarison.Why does this have? Since this time it has to delete when found.

void DeleteKeyTree( TreeNode** root, TreeNode** keyposition, KeyType target )
{
  // not found
  if(*root == NULL)
    Error("attempt to delete a nonexistent node from binary search tree");
  else if ( EQ( target, (*root)->entry.key ) )
  {
    // <Q> why need keyposition? since root will be deleted?
    *keyposition = *root;
    DeleteNodeTree(root);
  } 
  else if( LT( target, (*root)->entry.key ))
    DeleteKeyTree( &root->left, keyposition, target);
  else
    DeleteKeyTree( &root->right, keyposition, target);
}


{random-binary-search-tree-template-version}

#include <iostream>

typedef enum { success, overflow, underflow, duplicate_error, not_present} Error_code;

template <typename Entry>
struct Binary_node
{
  Entry data;
  Binary_node<Entry> *left;
  Binary_node<Entry> *right;

  Binary_node() { left = right = NULL; };
  Binary_node( const Entry &x ) { left = right = NULL; data = x;};
};

// Binary_tree {{
//
template <typename Entry>
class Binary_tree 
{
  public:
    Binary_tree() { root = NULL; }
    Binary_tree(const Binary_tree<Entry> &original);
    Binary_tree & operator=(const Binary_tree<Entry> &original);
    // ~Binary_tree();

    bool empty() const { return root == NULL; }
    int size() const;
    void clear();
    int height() const;

    void insert( const Entry & );
    void inorder( void (*visit)(Entry &));

  protected:
    void recursive_inorder( Binary_node<Entry> *sub_root, void (*visit)(Entry &));
    Binary_node<Entry> *root;
};

template <typename Entry>
void Binary_tree<Entry>::inorder( void (*visit)(Entry &))
{
  recursive_inorder(root, visit);
}

template <class Entry>
void Binary_tree<Entry>::recursive_inorder(Binary_node<Entry> *sub_root, void (*visit)(Entry &))
{
  if (sub_root != NULL) 
  {
    recursive_inorder(sub_root->left, visit);
    (*visit)(sub_root->data);
    recursive_inorder(sub_root->right, visit);
  }
}
//
// Binary_tree }}


// Search_tree {{
//
template <typename Record>
class Search_tree: public Binary_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    Error_code remove( const Record &old_data );

    // If there is an entry in the tree whose key matches that in target, the parameter target is
    // replaced by the corresponding record from the tree and a code of success is returned.
    // Otherwise a code of not_present is returned.
    // <note> it seems unuseful to replace target parameter when found since that's the same value.
    // May be useful to return some other value?
    Error_code tree_search( Record &target ) const;

  private:
    Error_code search_and_insert( Binary_node<Record> *&sub_root, const Record &new_data ); 
    Binary_node<Record> *search_for_node( Binary_node<Record> *sub_root, 
        const Record &target) const;

    // to support removal with record.
    Error_code search_and_destroy( Binary_node<Record>* &sub_root, const Record &target);

    // If sub_root is NULL, a code of not_present is returned. Otherwise, the root of the subtree is
    // removed in such a way that the properties of a binary search tree are preserved. The
    // parameter sub_root is reset as the root of the modified subtree, and success is returned.
    Error_code remove_root( Binary_node<Record> *&sub_root );
};

// If the key of target is not in the subtree, a result of NULL is returned. Otherwise, a pointer
// to the subtree node containing the target is returned.

// template <typename Record>
// Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
//     const Record &target) const
// {
//   if( sub_root == NULL || sub_root->data == target )
//     return sub_root;
//   else if( target > sub_root->data )
//     return search_for_node( sub_root->right, target );
//   else
//     return search_for_node( sub_root->left, target );
// }

// recursion removal version
template <typename Record>
Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
    const Record &target) const
{
  while( sub_root && sub_root->data != target )
  {
    if( target > sub_root->data )
      sub_root = sub_root->right;
    else
      sub_root = sub_root->left;
  }

  return sub_root;
}

template <typename Record>
Error_code Search_tree<Record>::tree_search( Record &target ) const
{
  Error_code result = success;

  Binary_node<Record> *found = search_for_node( this->root, target );
  if( found == NULL )
    return not_present;
  else
    target = found->data;

  return result;
}

template <typename Record>
Error_code Search_tree<Record>::insert( const Record &new_data )
{
  return search_and_insert( this->root, new_data );
}

// <key> <call-by-value-problem> notice the use of "*&" here or else this is an bug as the same of
// TreeInsert() since sub_root is a local copy and the same wrong output.
// Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *sub_root, const Record
// &new_data); 
template <typename Record>
Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *&sub_root, 
    const Record &new_data ) 
{
  if( sub_root == NULL )
  {
    sub_root = new Binary_node<Record>(new_data);
    return success;
  }
  else if( new_data < sub_root->data )
    return search_and_insert( sub_root->left, new_data );
  else if( new_data > sub_root->data )
    return search_and_insert( sub_root->right, new_data );
  else 
    return duplicate_error;
}

// the parameter is one of links of the tree, and not just a copy.
// remove_root(x->left);
//
// <note> that the argument type.
//
// <note> this it different approach from DeleteNodeTree( TreeNode** p ): 
//
// First, move to to-delete node's left subtree and find the immediate predecessor of to-delete node
// when do inorder traversal at the node's left subtree. How? This is the node as far right as
// possible and it has no right child since we went as far right as possible. So it can be removed
// from its current position without difficulty. 
//
// Second, swap this node with the to-delete node that was supposed to be removed.
//
// The key is that the properties of a binary search tree will still be satisfied, since there were
// no keys in the original tree whose ordering comes between the removed key and its immediate
// predecessor.
//
template <typename Record>
Error_code Search_tree<Record>::remove_root( Binary_node<Record> *&sub_root )
{
  if( sub_root == NULL ) return not_present;

  Binary_node<Record> *to_delete = sub_root;

  if( sub_root->right == NULL )
    sub_root = sub_root->left;
  else if ( sub_root->left == NULL )
    sub_root = sub_root->right;
  else  // neither subtree is empty
  {
    to_delete = sub_root->left;   // move left

    Binary_node<Record> *parent = sub_root;

    while( to_delete->right != NULL )
    {
      parent = to_delete;
      to_delete = to_delete->right;
    }

    // move from to_delete(predecessor) to root(node to delete)
    sub_root->data = to_delete->data;   

    // <note> this is interesting and cases for when predecessor does have left subtree but right
    // null.
    //          ...               or              ...           
    //        [ ] sub_root                      [ ] sub_root
    //                                        ...                 
    //     [ ]    to_delete                  [ ]    parent
    //                                        
    //  [ ]  N                            [ ]  [ ]  to_delete             
    // ...                                   ...  N                
    //
    if(parent == sub_root)  // this is when didn't run while loop
      sub_root->left = to_delete->left;
    else
      parent->right = to_delete->left;
  }

  // remove it from the tree 
  delete to_delete;
  return success;
}

template <typename Record>
Error_code Search_tree<Record>::search_and_destroy( Binary_node<Record>* &sub_root, const Record &target)
{
  // remove_root handles sub_root is NULL
  if( sub_root == NULL || sub_root->data == target )
    return remove_root( sub_root );
  else if( target < sub_root->data )
    return search_and_destroy( sub_root->left, target );
  else
    return search_and_destroy( sub_root->right, target );
}

template <typename Record>
Error_code Search_tree<Record>::remove( const Record &target )
{
  return search_and_destroy( this->root, target ); 
}
//
// Search_tree }}


void PrintTreeNode( int &entry )
{
  std::cout << " " << entry << ",";
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  Search_tree<int> bst;
  Error_code result;

  // insert
  for(int idx = 0; idx < size; idx++)
  {
    result = bst.insert( arr[idx] );
    if( result != success )
    {
      std::cout << "insert failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  bst.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 

  // remove
  for(int idx = 0; idx < size; idx++)
  {
    result = bst.remove( arr[idx] );
    if( result != success )
    {
      std::cout << "remove failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  bst.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 
}

kt@kt-ub-vb:~/work$ ./a.out 
{ 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33,}
{}
kt@kt-ub-vb:~/work$ 


{balanced-binary-search-tree}
<tree-balance> <balancing>
This delete approach is 'far' from optimal as it could greatly increase the height of the tree. For
example:

     (r)                       (x)    
   (b) (x)    delete r       (b) (y)  
 (a)     (y)               (a)      (z) 
           (z)                       

       (r)    delete r          (z)
    (c)  (z)                  (y)
  (b)  (y)                  (x)
(a)  (x)                  (c)
                        (b)
                      (a)

The second example increases its height. Thus the time required for a later search can substantially
increase, even though the total size of the tree has decreased. Hence to optimise the use of binary
search tree, 'need' methods to make the left and right subtree more nearly 'balanced' meaning reduced
height.

<more-cost-to-balance>
Is it worthwhile, on average, to keep a binary search tree balanced or rebalance it for a random
input order? The average cost of not balancing a binary search tree is approximately 39% more
comparisons because not balanced tree becomes random binary search tree. See 9.3.6 in {ref-001}

<build-balanced-bst>
For example, when receives inputs 'numbered' 1...31 in the order, build them into a tree that will be
as 'bushy' as possible. This is inorder sequence.

                                       (16)                                               2^4 (level4)
                  (8)                                          (24)                       2^3
      (4)                  (12)                    (20)                    (28)           2^2
  (2)      (6)      (10)         (14)        (18)        (22)        (26)        (30)     2^1
(1) (3)  (5) (7)  (9) (11)    (13) (15)   (17) (19)   (21) (23)   (25) (27)   (29) (31)   2^0

Two things to draw algorithm:

1. The observation from the above diagram. 2, 6, 10, 14, 18, 22, 26, 30 are 'divisible' by 2 and so
on. "each node is exactly as many 'levels' above the 'leaves' as the highest power of 2 that divides
its label(number)"

2. The assumption that do not know in advnace how many nodes will be built into the tree. So
determine how to tidy up the tree when all the nodes have been received but there is a dangling
subtree. <tidy-up>

The sequences to build a tree are:
When node number 1 arrives, is a leaf and therefore its left and right pointers should both be NULL.
When node number 2 arrives, goes above node 1 and should remember where node 1 is. 
When node number 3 arrives, is a leaf but is in the right of node 2 and remember node 2. 

                                 (4)*        (4)*        level 2
         (2)*     (2)*        (2)         (2)            level 1
(1)*  (1)      (1)   (3)   (1)   (3)   (1)   (3)   (5)*  level 0
n=1   n=2      n=3         n=4         n=5

where * is a node that must be remembered to build future links as the tree grows

Must keep a list of all nodes previously processed? No and need 'only' to remember one node on each
level, the last node processed on that level from one level above('parent' level). Pointers in
lastnode array that will quite small. For example, 20 levels can have 2^20-1 > 1,000,000 nodes.

<handle-leaf>
As each new node arrives, can set its right pointer to NULL (at least temporarily). The left pointer
is NULL if it's a leaf; that is to be on level 0, index of 'lastnode' array. Otherwise, it is the
entry in 'lastnode' array one level lower than the new node. lastnode[0] is always NULL and by doing
this can treat the leaves in the 'same' way as other nodes.

<left-right-child>
For some nodes, the right link should not permanently NULL since the node to insert may be the right
child of some previous node. For some, it may be left child, in which case its parent node has not
yet arrived. Can tell which case occurs by looking at lastnode. 

1. If level is the level of new node then parent level is level+1. Look at lastnode[level+1] and if
the right is still null, its right must be the new node. E.g., 3, 6, 14, ...

2. Look at lastnode[level+1] and if the right is not null then the right is aleady arrived. The new
node must be the left of some future node. E.g., 5 when parent is 2

<code>
// This can be used to build the fresh tree from inputs or to 'reorganize' the unbalanced tree?
TreeNode *BuildTree(void)
{
  TreeNode *newnode;
  int count = 0;
  int level;

  TreeNode* lastnode[ MAXHEIGHT ];

  for( level = 0; level < MAXHEIGHT; level++ )
    lastnode[level] = NULL;

  while((newnode = GetNode()) != NULL )
    Insert( newnode, ++count, lastnode );

  // after all the nodes have been inserted into the new tree, find the root of the tree and then
  // connect any right subtrees that may be dangling. For example, n=5 and 21 node.
  newnode = FindRoot(lastnode);

  ConnectSubtree( lastnode );

  // return root of the tree
  return newnode;
}

// If there is information available, GetNode creates a TreeNode, copies the information into the
// node, and returns a pointer to this TreeNode. Otherwise, returns NULL. This is to obtain each new
// node.
TreeNode *GetNode();

<insert> which assumes the ordered input. counts is [1, n]
// level n
// ...
// level 3        lastnode[3], points to a node on level 2
// level 2        lastnode[2], points to a node on level 1
// level 1        lastnode[1], points to a node on level 0
// level 0        lastnode[0], points to a node on level -1 (imaginary)
//
void Insert( TreeNode *newnode, int count, TreeNode *lastnode[] )
{
  // make a level+1 as in <handle-left>
  int level = Power2(count)+1;

  newnode->right = NULL;
  newnode->left = lastnode[level-1];   // leaf or left of one level lower

  lastnode[level] = newnode;           // set current level

  // for example, when n=6
  if(lastnode[level+1] && !lastnode[level+1]->right ) // parent level
    lastnode[level+1]->right = newnode;
}

<power> this is interesting to know
// find the 'highest' power of 2 that divides count. requires input x != 0. 
// returns level = 0,1,2,3,4,5...
// count:   4        12       20
// level, x 0  4     0  12    0  20
//          1  2     1  6     1  10
//          2* 1     2* 3     2* 5

// true when x is odd number
#define ODD(x)    ((x)/2*2 != (x))

int Power2(int x)
{
  int level;

  // run when x is even
  for(level=0; !ODD(x); level++)
    x/=2;

  return level;
}

<find-root>
// the root is the highest node in the tree; hence its pointer is the highest entry 'not' equal to
// NULL in the lastnode array. lastnode[level] points to the root which is on level-1 level.
TreeNode *FindRoot(TreeNode *lastnode[])
{
  int level;

  // skip NULL entries
  for( level = MAXHEIGHT-1; level > 0 && !lastnode[level]; level--)
    ;

  if( level <= 0 )   // notice that not consider level 0
    return NULL;
  else
    return lastnode[level];
}

<tidy-up>
// How to tie in any subtrees that may not yet be connected properly after all the nodes have been
// received? The difficulty is that some nodes in the upper part of tree may still have their right
// links set to null, even though further nodes have come in that belong in their right subtrees.
// Any node for which the right child is 'still' null will be one of the nodes in lastnode. Its right
// child should be set to the highest node in lastnode that is not already in its left subtree.
//
// See when n==5.

void ConnectSubtree( TreeNode *lastnode[] )
{
  TreeNode *p;
  int level, templevel;

  // find the root but don't care level 0 and 1 since it is alerady a complete tree when n==3.
  for( level = MAXHEIGHT-1; level > 2 && !lastnode[level]; level--)
    ;

  // scan a node in lastnode which has its right node NULL.
  while( level > 2 ) // level 1 and 2 are already okay
  {
    if( lastnode[level]->right )
      level--; // search for highest dangling node
    else // right subtree is undefined
    {
      // a child and level which a child is on
      p = lastnode[level]->left;
      templevel = level-1;

      // find highest entry not in left subtree. on one level below. when exit loop,
      // lastnode[tempnode] is a node which is not in left.
      do {     
        p = p->right;
      } while( p && p == lastnode[--templevel]);

      // set right
      lastnode[level]->right = lastnode[templevel];

      // to exit the while
      level = templevel;
    }
  } // while end
}


This algorithm produces a binary tree that is not always completed balanced. For n=32, it will
become the root of the tree and all 31 node will be in its left. 5 steps from the root to leaf.
Hence one comparison more than necessary will usually be done and it is not really a high price.

This algorithm is never more than one level away from optimality. There are sophisticated methods
for building a binary tree that is as balanced as possible but recommend a simpler method, one that
does not need to know in advance how many nodes are in the tree. For many practical purposes, this
should prove sufficient.


={============================================================================
*kt_dev_algo_012* avl tree

{avl-tree}
In many application, insertions and deletions occur continually with no predictable order. AVL tree
is a method to keep the tree very nearly balanced at all times for all search, insertion and
deletions to optimise search times even in the worst case. In almost all cases, AVL tree closely
approximates that of ideal, completely balanced binary search tree. O(logN).

<definition> height difference between left and right never be more than 1
An AVL tree is a binary search tree in which the heights of the left and right subtrees of the root
differ by at 'most' 1 and in which the left and right subtrees are 'again' AVL trees. This means
that this most 1 rule applies to all but not just to root. 

With each node of an AVL tree is associated a <balance-factor> that is left-higher, equal-height, or
right-higher according, respectively, as the left subtree has height greater than, equal to, or less
than that of the right subtree.

            [-]            where "-" equal, "/" left high, and "\" right high

      [-]         [\]

   [-]   [-]         [-]

<insert> see avl_insert()
The insertions of AVL tree proceed in exactly the same way as insertions example into an ordinary
binary search tree, except that the balance factors must be 'adjusted'.

Note, however, that the balance factors can only be determined 'after' the insertion is made.

The only case that can cause difficulty occurs when the new node is added to a subtree of the root
and make height difference 2.

The basic structure of our algorithm will thus be the same as the ordinary recursive binary tree
insertion algorithm, but with significant additions to accommodate the processing of balance factors
and other structure of AVL trees.

e ->     [-] k  

      [-] e    [-] t

v ->     [\] k             // blance of k changes 

      [-] e    [\] t

                  [-] v

p ->     [\] k             // blance of k not changes 

      [-] e    [-] t

            [-]p  [-] v


<rebalance> <rotations>
Now consider the case when a new node has been inserted into the taller subtree of a root node and
its height has increased, so that now one subtree has height 2 more than the other, and the tree no
longer satisfies the AVL requirements. We must now rebuild part of the tree to restore its balance.

Let's consider that have inserted the new node into the right subtree, its height has increased, and
the original tree(sub_root) was right higher. There are three cases to consider, 'depending' on the
balance factor of right_tree; cases covered by the function right_balance.

<case-one> <right-higher> <left-rotation>
When the balance factor of right_tree is right higher 'after' insertion. The action needed in this
case is called a left rotation; we have rotated the node right_tree upward to the root, dropping
root down into the left subtree of right_tree; the subtree T2 of nodes with keys between those of
root and right_tree now becomes the right subtree of root rather than the left subtree of
right_tree.

      [\\] sub_root           : h+1+1+1   -- becomes -->                 [-] right_tree

            <- rotate left

   T1(h)       [\] right_tree : (h+1)+1                          [-] root       T3(h+1)

         T2(h)    T3(h)+1                                   T1(h)    T2(h)

<case-two> <left-higher> <double-rotation-left>
The second case, when the balance factor of right_tree is left higher, is slightly more complicated.
It is necessary to move two levels, to the node sub_tree that roots the left subtree of right_tree,
to find the new root. called double rotation.

<note> 
double rotation left = firstly, rotation right on right sub tree + secondly, rotation left
double rotation right = firstly, rotation left on left sub tree + secondly, rotation right

One of T2 or T2 has height h; Take case when T2(h-1) and T3(h)

        [\\] root               =>      [ ] root               =>                [-] sub_root 
                                                                            /           \
                                            <- rotate left               [/] root        [-] right_tree
 /             \                      /     \                           /   \           /   \
T1(h)          [/] right_tree   =>  T1(h)   [ ] sub_root       =>   T1(h)   T2(h-1)  T3(h)  T4(h)
                                          /     \
            -> rotate right             T2(h-1) [-] right_tree
          /            \                       /   \
        [ ] sub_tree   T4(h)                T3(h)  T4(h)
       /   \
   T2(h-1)  T3(h)                                     

In this second case, the new balance factors for root and right_tree depend on the previous balance
factor for sub_tree. (The new balance factor for sub_tree will always be equal_height.) The
resulting balance factors are:

old sub_tree      new root    new right_tree       new sub_tree
   -                 -              -                 -
   /                 -              \                 -
   \                 /              -                 -


<case-three> <equal-height>
This is the case when right_tree has the equal height after insertion but this case, in fact, can
'never' happen. To see why, let us recall that we have just inserted a new node into the subtree
rooted at right_tree, and this subtree now has height 2 more than the left subtree of the root.
(this is why right_balance is called in the first place). 

If these subtrees had equal heights after the insertion, the full tree has 1 difference and meets
AVL property. That is, the height of the full subtree rooted at right_tree was not changed by the
insertion, contrary to what we already know. In other words, contrary to why this function was
called.


<example>
Do run avl_insert on input k, m, u, t, v, p. This has one rotation left and double rotation left.
The final tree is:

        [-] t
     /      \ 
   [-] m     [-] u
 /    \        \
[-] k  [-] p    [-] v


<key>
This avl_insert add new entry at the leaf, update balance factors while goes up the recursive chain
and if necessary, balance sub tree. When do balance, uses the 'previous' balance value to decide which
action it requires but after all, these are actiona 'after' insertion.

<performance>
At first glance it may appear that each one of these calls might induce either a single or double
rotation of the appropriate subtree, but, in fact, at most 'only' one (single or double) rotation
will ever be done. 

To see this, let us recall that rotations are done only in functions right_balance and left_balance
and that these functions are called only when the height of a subtree has increased. When these
functions return, however, the rotations have removed the increase in height, so, for the remaining
(outer) recursive calls, the height has not increased, so no further rotations or changes of balance
factors are done.

Most of the insertions into an AVL tree will induce no rotations. Even when rotations are needed,
they will usually occur near the leaf that has just been inserted.

Later we shall see that we can expect the height of AVL trees to be much 'less' than that of random
search trees, and therefore both insertion and retrieval will be significantly more efficient in AVL
trees than in random binary search trees.

<code> TODO: needs more functions to make it run

#include <iostream>

enum Error_code { success, overflow, underflow, duplicate_error, not_present};
enum Balance_factor { left_higher, equal_height, right_higher };

template <typename Entry>
struct Binary_node
{
  Entry data;
  Binary_node<Entry> *left;
  Binary_node<Entry> *right;

  Binary_node() { left = right = NULL; };
  Binary_node( const Entry &x ) { left = right = NULL; data = x;};

  // <note> why these virtuals? two points:
  //
  // One slightly tricky point about this specification is that the left and right pointers of a
  // Binary_node have type Binary_node *. The apparent pointer type incompatibility is not a serious
  // problem, because a pointer to an object from a base class can also point to an object of a
  // derived class.
  //
  // The benefit that we get in return for implementing AVL nodes with a derived structure is the
  // reuse of all of our functions for processing nodes of binary trees and search trees.
  //
  virtual void set_balance( Balance_factor b ) { };
  virtual Balance_factor get_balance() const { };
};

// Binary_tree {{
//
template <typename Entry>
class Binary_tree 
{
  public:
    Binary_tree() { root = NULL; }
    Binary_tree(const Binary_tree<Entry> &original);
    Binary_tree & operator=(const Binary_tree<Entry> &original);
    // ~Binary_tree();

    bool empty() const { return root == NULL; }
    int size() const;
    void clear();
    int height() const;

    void insert( const Entry & );
    void inorder( void (*visit)(Entry &));

  protected:
    void recursive_inorder( Binary_node<Entry> *sub_root, void (*visit)(Entry &));
    Binary_node<Entry> *root;
};

template <typename Entry>
void Binary_tree<Entry>::inorder( void (*visit)(Entry &))
{
  recursive_inorder(root, visit);
}

template <class Entry>
void Binary_tree<Entry>::recursive_inorder(Binary_node<Entry> *sub_root, void (*visit)(Entry &))
{
  if (sub_root != NULL) 
  {
    recursive_inorder(sub_root->left, visit);
    (*visit)(sub_root->data);
    recursive_inorder(sub_root->right, visit);
  }
}
//
// Binary_tree }}


// Search_tree {{
//
template <typename Record>
class Search_tree: public Binary_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    Error_code remove( const Record &old_data );
    // If there is an entry in the tree whose key matches that in target, the parameter target is
    // replaced by the corresponding record from the tree and a code of success is returned.
    // Otherwise a code of not_present is returned.
    // <note> it seems unuseful to replace target parameter when found since that's the same value.
    // May be useful to return some other value?
    Error_code tree_search( Record &target ) const;

  private:
    Error_code search_and_insert( Binary_node<Record> *&sub_root, const Record &new_data ); 
    Binary_node<Record> *search_for_node( Binary_node<Record> *sub_root, 
        const Record &target) const;

    // to support removal with record.
    Error_code search_and_destroy( Binary_node<Record>* &sub_root, const Record &target);

    // If sub_root is NULL, a code of not_present is returned. Otherwise, the root of the subtree is
    // removed in such a way that the properties of a binary search tree are preserved. The
    // parameter sub_root is reset as the root of the modified subtree, and success is returned.
    Error_code remove_root( Binary_node<Record> *&sub_root );
};

// If the key of target is not in the subtree, a result of NULL is returned. Otherwise, a pointer
// to the subtree node containing the target is returned.

// template <typename Record>
// Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
//     const Record &target) const
// {
//   if( sub_root == NULL || sub_root->data == target )
//     return sub_root;
//   else if( target > sub_root->data )
//     return search_for_node( sub_root->right, target );
//   else
//     return search_for_node( sub_root->left, target );
// }

// recursion removal version
template <typename Record>
Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
    const Record &target) const
{
  while( sub_root && sub_root->data != target )
  {
    if( target > sub_root->data )
      sub_root = sub_root->right;
    else
      sub_root = sub_root->left;
  }

  return sub_root;
}

template <typename Record>
Error_code Search_tree<Record>::tree_search( Record &target ) const
{
  Error_code result = success;

  Binary_node<Record> *found = search_for_node( this->root, target );
  if( found == NULL )
    return not_present;
  else
    target = found->data;

  return result;
}

template <typename Record>
Error_code Search_tree<Record>::insert( const Record &new_data )
{
  return search_and_insert( this->root, new_data );
}

// <key> <call-by-value-problem> notice the use of "*&" here or else this is an bug as the same of
// TreeInsert() since sub_root is a local copy and the same wrong output.
// Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *sub_root, const Record
// &new_data); 
template <typename Record>
Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *&sub_root, 
    const Record &new_data ) 
{
  if( sub_root == NULL )
  {
    sub_root = new Binary_node<Record>(new_data);
    return success;
  }
  else if( new_data < sub_root->data )
    return search_and_insert( sub_root->left, new_data );
  else if( new_data > sub_root->data )
    return search_and_insert( sub_root->right, new_data );
  else 
    return duplicate_error;
}

// the parameter is one of links of the tree, and not just a copy.
// remove_root(x->left);
//
// <note> that the argument type.
//
// <note> this it different approach from DeleteNodeTree( TreeNode** p ): 
// First, move to to-delete node's left subtree and find the immediate predecessor when do inorder
// traversal. This finds the node as far right as possible and it has no right child since we went
// as far right as possible.  So it can be removed from its current position without difficulty. 
//
// Second, swap this node with the node that was supposed to be removed.
//
// The key is that the properties of a binary search tree will still be satisfied, since there were
// no keys in the original tree whose ordering comes between the removed key and its immediate
// predecessor.
template <typename Record>
Error_code Search_tree<Record>::remove_root( Binary_node<Record> *&sub_root )
{
  if( sub_root == NULL ) return not_present;

  Binary_node<Record> *to_delete = sub_root;

  if( sub_root->right == NULL )
    sub_root = sub_root->left;
  else if ( sub_root->left == NULL )
    sub_root = sub_root->right;
  else  // neither subtree is empty
  {
    to_delete = sub_root->left;   // move left

    Binary_node<Record> *parent = sub_root;

    while( to_delete->right != NULL )
    {
      parent = to_delete;
      to_delete = to_delete->right;
    }

    // move from to_delete(predecessor) to root(node to delete)
    sub_root->data = to_delete->data;   

    // <note> this is interesting and cases for when predecessor does have left subtree but right
    // null.
    //          ...               or              ...           
    //        [ ] sub_root                      [ ] sub_root
    //                                        ...                 
    //     [ ]    to_delete                  [ ]    parent
    //                                        
    //  [ ]  N                            [ ]  [ ]  to_delete             
    // ...                                   ...  N                
    //
    if(parent == sub_root)  // this when don't have while loop run  
      sub_root->left = to_delete->left;
    else  
      parent->right = to_delete->left;
  }

  // remove it from the tree 
  delete to_delete;
  return success;
}

template <typename Record>
Error_code Search_tree<Record>::search_and_destroy( Binary_node<Record>* &sub_root, const Record &target)
{
  // remove_root handles sub_root is NULL
  if( sub_root == NULL || sub_root->data == target )
    return remove_root( sub_root );
  else if( target < sub_root->data )
    return search_and_destroy( sub_root->left, target );
  else
    return search_and_destroy( sub_root->right, target );
}

template <typename Record>
Error_code Search_tree<Record>::remove( const Record &target )
{
  return search_and_destroy( this->root, target ); 
}
//
// Search_tree }}

// AVL_node {{
//
template <typename Record>
struct AVL_node: public Binary_node<Record>
{
  Balance_factor balance;

  AVL_node();
  AVL_node( const Record &x );

  void set_balance( Balance_factor b ) { balance = b; };
  Balance_factor get_balance() const { return balance; };
};

template <typename Record>
AVL_node<Record>::AVL_node()
{
  Binary_node<Record>::Binary_node();
  balance = equal_height;
}

template <typename Record>
AVL_node<Record>::AVL_node( const Record &x )
{
  Binary_node<Record>::Binary_node(x);
  balance = equal_height;
}
//
// AVL_node }}


// AVL_tree {{
//
template <typename Record>
class AVL_tree: public Search_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    Error_code remove( const Record &old_data );

  private:
    Error_code avl_insert( Binary_node<Record> *&sub_root, const Record &new_data,
        bool &taller );

    void right_balance( Binary_node<Record> *&sub_root );
    void rotate_left( Binary_node<Record> *&sub_root );
};

template <typename Record>
Error_code AVL_tree<Record>::insert( const Record &new_data )
{
  bool taller;
  return avl_insert( this->root, new_data, taller );
}

template <typename Record>
Error_code AVL_tree<Record>::avl_insert( Binary_node<Record> *&sub_root, const Record &new_data,
    bool &taller )
{
  Error_code result = success;

  if( sub_root == NULL )
  {
    sub_root = new AVL_node<Record>(new_data);
    taller = true;
  }
  else if( new_data < sub_root->data )  // insert in left subtree
  {
    result = avl_insert( sub_root->left, new_data, taller );
    if( taller == true )  // new node made
      switch( sub_root->get_balance())
      {
        // <note> parent balance was left and added one more in left. so difference > 1 and needs rebalancing
        case left_higher:         
          left_balance(sub_root); // rebalancing
          taller = false;         // rebalancing always shorten the tree
          break;

        case equal_height:        // parent balance
          sub_root->set_balance(left_higher);
          break;

        case right_higher:        // parent balance
          sub_root->set_balance(equal_height);
          taller = false;
          break;
      }
  }
  else if( new_data > sub_root->data )  // insert in right subtree
  {
    result = avl_insert( sub_root->right, new_data, taller );
    if( taller == true )  // new node made
      switch( sub_root->get_balance())  // get parent balance
      {
        case left_higher:         
          sub_root->set_balance(equal_height);
          taller = false;
          break;

        case equal_height:     
          sub_root->set_balance(right_higher);
          break;

        case right_higher:        
          right_balance(sub_root);
          taller = false;       
          break;
      }
  }
  else
  {
    result = duplicate_error;
    taller = false;
  }

  return result;
}

// Pre: sub_root points to a subtree of the AVL_tree. This subtree has a nonempty right subtree.
// Post: sub_root is reset to point to its former right child, and the former sub_root node is the
// left child of the new sub_root node.
// <note> rotate right child but argument is its parent
template <typename Record>
void AVL_tree<Record>::rotate_left( Binary_node<Record> *&sub_root )
{
  // impossible case
  if( sub_root == NULL || sub_root->right == NULL )
    std::cout << "warning: program error detected in rotate_left" << std::endl;
  else
  {
    Binary_node<Record> *right_tree = sub_root->right;

    sub_root->right = right_tree->left;
    right_tree->left = sub_root;
    sub_root = right_tree;
  }
}

template <typename Record>
void AVL_tree<Record>::right_balance( Binary_node<Record> *&sub_root )
{
  // <note> see how to take reference from a pointer and to use in rotate_right
  Binary_node<Record> *&right_tree = sub_root->right;

  switch( right_tree->get_balance() )   // get right tree balance 'after' insertion
  {
    // <case-one> single rotation left
    case right_higher:
      // set balance before rotation since rotation moves pointers
      sub_root->set_balance(equal_height);
      right_tree->set_balance(equal_height);
      rotate_left(sub_root);
      break;

    // <case-three> impossible case
    case equal_height:
      std::cout << "warning: program error detected in right_balance" << std::endl;
      break;

    // <case-two> double rotation left
    case left_higher:
      Binary_node<Record> *sub_tree = right_tree->left;

      switch( sub_tree->get_balance() )
      {
        case equal_height:
          sub_root->set_balance(equal_height);
          right_tree->set_balance(equal_height);
          break;
        case left_higher:
          sub_root->set_balance(equal_height);
          right_tree->set_balance(right_higher);
          break;
        case right_higher:
          sub_root->set_balance(left_higher);
          right_tree->set_balance(equal_height);
          break;
      }

      sub_tree->set_balance(equal_height);
      rotate_right(right_tree);   // see the argument
      rotate_left(sub_root);

      break;
  }
}
//
// AVL_tree }}

void PrintTreeNode( int &entry )
{
  std::cout << " " << entry << ",";
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  Search_tree<int> bst;
  Error_code result;

  // insert
  for(int idx = 0; idx < size; idx++)
  {
    result = bst.insert( arr[idx] );
    if( result != success )
    {
      std::cout << "insert failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  bst.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 

  // remove
  for(int idx = 0; idx < size; idx++)
  {
    result = bst.remove( arr[idx] );
    if( result != success )
    {
      std::cout << "remove failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  bst.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 
}


{splay-tree}

Like hospital example, want to keep records that are newly inserted or frequently accessed very
close to the root, while records that are inactive may be placed far off, near or in the leaves.

Also cannot shut down the hospital for an hour to rebuild the tree into the desired shape, so do
self-adjusting data that automatically changes its shape to meet the above.


={============================================================================
*kt_dev_algo_013* multiway trees

Binary trees, as we have seen, are a powerful and elegant form of data structure. Even so, the
'restriction' to no more than two children at each node is severe, and there are many possible
applications for trees as data structures where the number of children of a node can be 'arbitrary'.

<ordered-tree> which is different from a binary tree.
Hence we define an ordered tree to be a rooted tree in which the children of each vertex are
assigned an order.

Note that ordered trees for which no vertex has more than two children are still not the same class
as binary trees. If a vertex in a binary tree has only one child, then it could be either on the
left side or on the right side, and the two resulting binary trees are different, but both would be
the same as ordered trees.

<computer-implementation>
To use an ordered tree as a data structure, the obvious way to implement it in computer memory would
be to extend the standard way to implement a binary tree, keeping as many link members in each node
as there may be subtrees, in place of the two links needed for binary trees. 

Clearly this method of representing ordered trees is very wasteful of space. So linked list. To keep
the children of each node in a linked list, we shall need two kinds of links. first_child and
next_sibling. By using these two links we now have the structure of a binary tree; that is, the
linked implementation of an ordered tree is a linked 'binary' tree. why binary? since each node has
two links; first_child(left) and next_sibling(right).

    ()      first_child: / , next_sibling: ->
   /
  () -----------------> () ------------------> ()
  /                     /                      /
 ()-> () -> () -> ()   ()                     () -> ()
      /                /                            /
     ()               () -> () -> () -> ()         ()


{b-tree} balanced multiway tree. external searching
Given disk access is slow(expensive) how can we minimize the number of disk access? With each
access, however, we obtain a block that may have room for several records. Using these records we
may be able to make a 'multiway' decision concerning which block/page to access next. Hence multiway
trees are especially appropriate for external searching.

The devised is a multiway search tree to make the 'height' of the tree as small as possible. The
definition is:

<definition>
A B-tree of order 'm' is an m-way search tree in which

1. All leaves are on the same level.

2. All internal nodes except the root have at most m 'nonempty' children, and at least [m/2]
nonempty children.

3. The number of keys in each internal node is 'one' less than the number of its nonempty children,
  and these keys partition the keys in the children in the fashion of a search tree.

4. The root has at most m children, but may have as few as 2 if it is not a leaf, or none if the
tree consists of the root alone.

<insertion>
The condition that all leaves be on the same level forces a characteristic behavior of B-trees: In
contrast to binary search trees, B-trees are not allowed to grow at their leaves; instead, they are
forced to 'grow' at the 'root'.

When a search is later made through the tree, therefore, a comparison with the median key will serve
to direct the search into the proper subtree.

When a key is added to a full root, then the root splits in two and the median key sent upward
becomes a new root. This is the only time when the B-tree grows in height.

<example>
input: a g f b,k,d h m,j,e s i r,x,c l n t u,p

1. a g f b     ->    [a b f g]    // [a] -> [a g] -> [a f g] -> [a b f g ]

2. k           ->         [f]
                         /   \
                     [a b]    [g k]

3. d h m       ->         [f]
                         /   \
                   [a b d]    [g h k m]

4. j           ->         [f       j]
                         /   \    /  \
                   [a b d]    [g h]  [k m]

5. e s i r     ->         [f         j]
                         /   \      /  \
                   [a b d e]  [g h i]  [k m r s]

6. x           ->         [f         j      r]
                         /   \      /  \   /  \
                   [a b d e]  [g h i]  [k m]  [s x]

7. c i n t u   ->      [c      f        j          r]
                       /  \  /   \     /  \       /  \
                   [a b]  [d e]  [g h i]  [k l m n]  [s t u x]

8. p           ->                [     j    ]
                                /            \
                       [c      f]             [m     r]
                       /  \  /   \           /  \   /  \
                   [a b]  [d e]  [g h i]  [k l]  [n p]  [s t u x]

From 7 to 8:
inset, push_down, split     [c      f        j          r]
                            /  \  /   \     /  \       /  \
push_down, split        [a b]  [d e]  [g h i]  [k l m n]  [s t u x]

push_down(hit null)

<code> TODO: how to traverse?

#include <iostream>

// Since these list are short, for simplicity, use contiguous array and count
//
// The relationship between count, data, and branch when order is 5, m == 5.
//
// count : 0 for emptiness and [1, m]
//
// position : [0, m-1]
//
// data       [0]     [1]     [2]     [3]     : target ==
//          /    \   /   \   /   \   /  \
// branch [0]     [1]     [2]     [3]   [4]   : target < or target >
//        left    right
//
// '/' means < and '\' menas <
//
// branch[0] points to the subtree containing all records with keys less than the key in data[0];
// branch[1] points to the subtree with keys between data[pos-1] and data[pos]
// ...
// branch[4] points to the subtree containing all records with keys greater than the key in data[3];
// 
// So it seems one large constuct which has four binary search trees.
//

typedef enum { success, overflow, underflow, duplicate_error, not_present} Error_code;

template <typename Record, int order>
struct B_node
{
  // # of records in the tree, [1,m]. count-1 is # of keys
  int count;
  // list of entries(keys or records), m-1
  Record data[order-1];
  // list of pointers to the children(branches), m
  B_node<Record, order> *branch[order];

  B_node() { count = 0; };
};

// For simplicity, construct B tree in high-speed memory. These pointers would be replaced by the
// address of various blocks or pages on disk, and taking a pointer reference would become making a
// disk access.
template <typename Record, int order>
class B_tree 
{
  public:
    Error_code search_tree( Record &target );
    Error_code insert( const Record &entry );
    B_tree() { root = NULL; }

    void inorder( void (*visit)(Record &));

    // aux functions
  private:
    void recursive_inorder( B_node<Record, order> *sub_root, void (*visit)(Record &));

    Error_code recursive_search_tree( B_node<Record, order> *current, Record &target );
    Error_code search_node( B_node<Record, order> *current, const Record &target, int &position );
    Error_code push_down( B_node<Record, order> *current, const Record &new_entry, 
        Record &median, B_node<Record, order>* &right_branch );
    Error_code push_in( B_node<Record, order> *current, const Record &new_entry, 
        B_node<Record, order> *right_branch, int position );
    void split_node( B_node<Record, order> *current, const Record extra_entry, 
        B_node<Record, order> *extra_branch, int position, B_node<Record, order> *right_branch, Record &median );

  private:
    B_node<Record, order> *root;
};

// <traverse> do not work.
//
template <typename Record, int order>
void B_tree<Record, order>::inorder( void (*visit)(Record &))
{
  recursive_inorder(root, visit);
}

template <typename Record, int order>
void B_tree<Record, order>::recursive_inorder(B_node<Record, order> *sub_root, void (*visit)(Record &))
{
  if (sub_root != NULL) 
  {
    recursive_inorder(sub_root->left, visit);
    (*visit)(sub_root->data);
    recursive_inorder(sub_root->right, visit);
  }
}

// <search>
//

// The assumption is that records can be compared with standard operators.
//
// Post: If there is an entry in the B-tree whose key matches that in target, the parameter target
// is replaced by the corresponding Record from the B-tree and a code of success is returned.
// Otherwise a code of not_present is returned.
template <typename Record, int order>
Error_code B_tree<Record, order>::search_tree( Record &target )
{
  return recursive_search_tree( root, target );
}

// <note> In multiway tree, however, we must examine each node more 'extensively' to find which branch to
// take at the next step. use search_node().
//
// <note> This is tail recursion so can be replaced by iteration.
//
// Pre: current is either NULL or points to a subtree of the B_tree.  
// Post: If the Key of target is not in the subtree, a code of not_present is returned. Otherwise,
// a code of success is returned and target is set to the corresponding Record of the subtree.
//
template <typename Record, int order>
Error_code B_tree<Record, order>::recursive_search_tree( B_node<Record, order> *current, Record &target )
{
  Error_code result = not_present;

  int position;

  if( current != NULL )
  {
    // The function search_node uses an output parameter 'position', which is the index of the target
    // if found within the current node and otherwise is the index of the branch on which to
    // continue the search.
    result = search_node( current, target, position );

    if( result == not_present )
      result = recursive_search_tree( current->branch[position], target );
    else
      target = current->data[position];
  }

  return result;
}

// determine the position where target should be in; data position when the target is found or the
// branch position to be searched/inserted when not found.
//
// if found, return success and the position in data
// if not found, return the position in branch to be searched/inserted.
//
// <note> the same position used for data or for branch.
// <note> for branch position, 'else' case can return either the last branch(greater-than) or the
// less-than branch.
// <note> this is effectively 'sort' function.
//
template <typename Record, int order>
Error_code B_tree<Record, order>::search_node( B_node<Record, order> *current, const Record &target, 
    int &position )     // @out, position
{
  position = 0;

  // perform a sequential search
  // For B-trees of large order, this function should be modified to use binary search instead of
  // sequential search. In some applications, a significant amount of information is stored with
  // each record of the B-tree, so that the order of the B-tree will be relatively small, and
  // sequential search within a node is appropriate. In many applications, only keys are kept in the
  // nodes, so the order is much larger, and binary search should be used to locate the position of
  // a key within a node.
  //
  // Yet another possibility is to use a linked binary search tree instead of a sequential array of
  // entries for each node; this possibility will be investigated at length later in this chapter.
  //
  while( position < current->count && target > current->data[position] )
    position++;

  // check position again since position == current->count when while ends
  if( position < current->count && target == current->data[position] )
    return success;
  else // <key> ( position == count or target < current->data[position] )
    return not_present;
}

// <insert>
// Insertion into a B-tree can be most naturally formulated as a recursive function
// For the push_down recursion, however, we need three additional output parameters; current,
// median, and right_branch.
// 
// <note> we shall require that the key being inserted is 'not' already present in the tree.


// insert splits current node by push_down() recursive function to maintain B tree property.
//
//                                              [median]
//                                            /         \
// new entry -> [ *current(node) ]  =>  [ node ]      [ node ]
//
//              (a) (b) (c) (d)         (a) (b)       (c) (d)
// 
template <typename Record, int order>
Error_code B_tree<Record, order>::insert( const Record &new_entry )
{
  Record median;

  B_node<Record, order> *right_branch, *new_root;

  Error_code result = push_down( root, new_entry, median, right_branch ); 
  if( result == overflow )
  {
    new_root = new B_node<Record, order>;
    new_root->count = 1;
    new_root->data[0] = median;         // median from a split
    new_root->branch[0] = root;         // the previous which is now left
    new_root->branch[1] = right_branch; // the right from a split
    root = new_root;
    result = success;
  }

  return result;
}

// Otherwise, new_entry is inserted into the subtree: If this causes the height of the subtree to
// grow, a code of overflow is returned, and the Record median is extracted to be reinserted higher
// in the B-tree, together with the subtree right_branch on its right. If the height does not grow,
// a code of success is returned.
template <typename Record, int order>
Error_code B_tree<Record, order>::push_down( B_node<Record, order> *current, const Record &new_entry, 
    Record &median, 
    B_node<Record, order>* &right_branch )
{
  Error_code result;
  int position;

  // stopping rule
  // In a B-tree, a new record is first inserted into a leaf. Shall thus use the condition current
  // == NULL to terminate the recursion; that is, we shall continue to move down the tree searching
  // for new_entry until we hit an empty subtree.
  //
  // Since the B-tree does not grow by adding new leaves, we do not then immediately insert
  // new_entry, but instead we return a code of overflow (since an empty subtree cannot have a
  // record inserted) and send the record back up (now called median) for later insertion.
  // This handles the first insertion when the tree is empty.
  if( current == NULL )
  {
    median = new_entry;
    right_branch = NULL;
    result = overflow;    // this passes up to insert call
  }
  else
  {
    if( search_node( current, new_entry, position ) == success )
      result = duplicate_error;
    // not found and insert entry into the tree
    else
    {
      Record extra_entry;
      B_node<Record, order> *extra_branch;

      // result = push_down( current->branch[position], new_entry, median, right_branch );
      result = push_down( current->branch[position], new_entry, extra_entry, extra_branch );
      // hit the leaf subtree
      if( result == overflow )
      {
        // the leaf has a room to insert
        if( current->count < order -1 )
        {
          result = success;
          // here position means branch position to insert
          push_in( current, extra_entry, extra_branch, position ); 
        }
        else
          split_node( current, extra_entry, extra_branch, position, right_branch, median );
      }
    } // search_node else
  } // else

  return result;
}

// inserts the Record entry and its 'right-hand' pointer right_branch into the node *current,
// provided there is room for the insertion.
template <typename Record, int order>
Error_code B_tree<Record, order>::push_in( B_node<Record, order> *current, const Record &new_entry, 
    B_node<Record, order> *right_branch, int position )
{
  // <note> count(# of children) and position(array index) has 1 difference. see loop and indexing.
  // <note> see move difference in data and branch. this is why said 'right-hand' pointer.
  //
  //           0   1   2   3   4       0   1   2   3   4   5
  //  data    [0] [1] [2] '\0'        [0] [1] [N] [2] '\0' 
  //  branch  [0] [1] [2] [3] '\0'    [0] [1] [2] [3] [N] '\0'
  //                                              <Q>

  // shift all later from position to right
  for( int i = current->count; i > position; i-- )
  {
    current->data[i] = current->data[i-1];
    current->branch[i+1] = current->branch[i];
  }

  // <Q> this set branch[pos+1] = NULL. Given branch[pos] was a less-than subtree before insertion,
  // when insert new entry, should there be 'rearrange' [pos] and [pos+1] subtree? If not now, then
  // later somepoint? NO. since insertion always happens at leaf level, all branch pointers are
  // actually null. It is just for the sake of simpliticy.
  // 
  current->data[position] = new_entry;
  current->branch[position+1] = right_branch;
  current->count++;
}

template <typename Record, int order>
void B_tree<Record, order>::split_node( 
    B_node<Record, order> *current,       // @in, node to be split 
    const Record extra_entry,             // @in, new entry to insert
    B_node<Record, order> *extra_branch,  // @in, right-hand subtree of new entry
    int position,                         // @in, index in node where new entry goes
    B_node<Record, order> *right_branch,  // @out, right-hand subtree after a split
    Record &median )                      // @out, median after a split (in neither half)
{
  right_branch = new B_node<Record, order>;

  int mid = order/2;    // same as arrary size/2

  // first case: new entry belongs in left branch
  if( position <= mid )
  {
    // move right half of current to right branch
    for( int i = mid; i < order-1; i++ )
    {
      right_branch->data[i-mid] = current->data[i];
      right_branch->branch[i+1-mid] = current->branch[i+1];
    }

    // set count for left and right branch
    current->count = mid;
    right_branch->count = order-1-mid;

    // push into the left(current)
    push_in( current, extra_entry, extra_branch, position );
  }
  // second case: new entry belongs in right branch
  else
  {
    mid++; // temporarily leave the median in left

    // move right half of current to right branch. <note> same as first case
    for( int i = mid; i < order-1; i++ )
    {
      right_branch->data[i-mid] = current->data[i];
      right_branch->branch[i+1-mid] = current->branch[i+1];
    }

    // set count for left and right branch. <note> same as first case
    current->count = mid;
    right_branch->count = order-1-mid;

    // push into the right. <note> pos-mid
    push_in( right_branch, extra_entry, extra_branch, position-mid );
  }

  // <Q> This seems to be working only for second case.
  median = current->data[current->count-1];
  current->count--;

  right_branch->branch[0] = current->branch[current->count];
}

void PrintTreeNode( char &entry )
{
  std::cout << " " << entry << ",";
}

int main()
{
  char arr[] = "abcdefghijklmnopqrstuvwxyz";
  int size = ( sizeof(arr)/sizeof(arr[0]));

  B_tree<char, 5> btree;
  Error_code result;

  // insert
  for(int idx = 0; idx < size; idx++)
  {
    result = btree.insert( arr[idx] );
    if( result != success )
    {
      std::cout << "insert failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  btree.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 
}


{red-black-tree}
In the last section, we used a contiguous list to store the entries within a single node of a
B-tree. Doing so was appropriate because the number of entries in one node is usually relatively
'small' and because we were emulating methods that might be used in external files on a disk, where
dynamic memory may not be available, and records may be stored contiguously on the disk.

<key> notice that this says about 'node' itself.

In general, however, we may use <any-ordered-structure> we wish for storing the entries in each
B-tree node. <small-binary-search-trees> turn out to be an excellent choice. We need only be careful
to distinguish between the links 'within' a single B-tree node and the links from one B-tree node to
another. Let us therefore draw the links within one B-tree node as curly colored lines(red) and the
links between B-tree nodes as straight black lines(black).

This shows a B-tree of order 4 constructed this way and each node construction contains one, two, or
three entries.

      [ a b c ]           =>           [b]
      /  / \  \                       // \\     : red 
     T1 T2 T3 T4                     a     c
                                    / \   / \   : black
                                   T1 T2 T3 T4

A red-black tree is a binary search tree, with links colored red or black, obtained from a B-tree of
order 4 in the way just described. After we have converted a B-tree into a red-black tree, we can
use it like 'any' other binary search tree. In particular, searching and traversal of a red-black
tree are 'exactly' the same as for an ordinary binary search tree; 

How? we simply ignore the color of the links. Insertion and deletion, however, require more care to
maintain the underlying B-tree structure.

<convention>
1. each node colored nodes of a red-black tree as colored with the same color as the link
immediately 'above' it. 

2. the convention that the root is colored black since the root has no link above it. Similarly, we
shall consider that all the empty subtrees (corresponding to NULL links) are colored black.


<definition>
A red-black tree is a binary search tree in which each node has either the color red or black and
that satisfies the following conditions:

The first condition defining a B-tree, that all its empty subtrees are on the same level, means that
every simple path from the root to an empty subtree (NULL) goes through the same number of B-tree
nodes. The corresponding red-black tree has one black node (and perhaps one or two red nodes) for
each B-tree node. Hence black condition we obtain the black condition:

black condition. Every simple path from the root to an empty subtree (a NULL link) goes through the
same 'number' of black nodes.

We need a condition on red-black trees that will guarantee that no more than three nodes are
identified together (by red links) as one B-tree node, and that nodes with three entries are in red
condition the balanced form we are using. This guarantee comes from the red condition:

red condition. If a node is red, then its parent exists and is black.

<performance>
The height of a red-black tree containing n nodes is no more than 2 lg n.

Hence the time for searching a red-black tree with n nodes is O(log N) in every case. We shall find
that the time for insertion is also O(log N)

<insert>
we can 'reuse' all of our earlier methods and functions for manipulating binary search trees and their
nodes. In particular, searching and traversal are identical for red-black trees and for binary
search trees.

<the-new-node-is-red>
The recursive insertion process terminates when we hit an empty subtree, whereupon we create a new
node and attach it to the tree in place of the empty subtree. Should this new node be red or black?
Were we to make it black, we would new node increase the number of black nodes on one path (and only
one path), thereby violating the black condition. Hence the new node 'must' be 'red'.

<when-the-parent-is-red>
If the parent of the new red node is black, then the insertion is finished, but if the parent is
red, then we have introduced a violation of the red condition into the tree. The major work of the
insertion algorithm is to remove such a violation of the red condition

<postpone-work>
Our algorithm is considerably simplified, however, if we do not consider these cases immediately,
but instead postpone the work as long as we can.

the node inserted:
Hence, when we make a node red, we do not immediately try to repair the tree, but instead simply
return from the recursive call with a status indicator set to indicate that the node just processed
is 'red'.

the parent node:
After this return, we are again processing the 'parent' node. If it is black, then conditions for a
red-black tree are satisfied and the process terminates. If it is red, then again we do not
immediately attempt to repair the tree, but instead we set the status variable to indicate that we
have 'two' 'red' 'nodes' together, and then simply return from the recursive call.

whether the inserted is right or left:
It turns out, in this case, to be helpful to use the status variable also to indicate if the two red
nodes are related as left child or right child.

the grandparent:
After returning from the second recursive call, we are processing the grandparent node. Here is
where our convention that the root will always be black is helpful: Since the parent node is red, it
cannot be the root, and hence the grandparent exists.  This grandparent, moreover, is guaranteed to
be black, since its child (the parent node) is red, and the only violation of the red condition is
farther down the tree.

<key> At the grandparent, need to restore the tree only when the parent is red.

restore:
We shall examine 'only' the cases where the parent is the 'left' child of the grandparent; those
where it is the right child are 'symmetric'. We need to distinguish two cases according to the 'color'
of the other (the 'right') child of the grandparent, that is, the 'aunt' or "uncle" of the original
node.

<aunt-is-black> First suppose this aunt node is black. This case also covers the possibility
that the aunt node does not exist. (Recall that an empty subtree is considered black.) Then the
red-black properties are restored by a single or double 'rotation' to the right. In both these
diagrams, verify that the rotation (and associated color changes) removes the 'violation' of the
'red' condition and preserves the black condition by 'not' changing the number of black nodes on any
path down the tree.

Here "// or \\" for 'red' and "/ or \" for black.

1. notice that parent and child are in the same side(left)
             /                                              /
grandparent []             => rotate right          parent []
           //  \                                         //  \\
   parent []   aunt T4                            child []    [] grandparent
         //  \                                         /  \  /  \
  child []   T3                                       T1  T2 T3 T4 aunt
       /  \
     T1    T2

>
2. notice that parent and child are in the different side. child is on right.
             /                double                        /
grandparent []             => rotate right          parent []
           //  \                                         //  \\
   parent []   aunt T4                            child []    [] grandparent
         / \\                                          /  \  /  \
       T1   [] child                                  T1  T2 T3 T4 aunt
           /  \
          T2  T3


<aunt-is-red>
No rotation occurs, but the colors are changed. The parent and aunt nodes become black, and the
grandparent node becomes red. Should verify that the number of black nodes on any path down the tree
remains the same.

Since the grandparent node has become red, however, it is quite possible that the red condition is
'still' violated: The great-grandparent node may also be red. Hence the process may 'not' terminate.
We need to set the status indicator to show that we have a newly red node, and then we can continue
to work out of the recursion. Any violation of the red condition, however, moves two levels up the
tree, and, since the root is black, the process will 'eventually' terminate.

<make-root-black>
It is also possible that this process will change the root from black to red; hence, in the
outermost call, we need to make sure that the root is changed 'back' to 'black' if necessary.


               /                                          //             
  grandparent []             => color flip    grandparent []             
           //    \\                                     /    \           
   parent []      []aunt T4                    parent []      []aunt T4  
         // \    /  \                                // \    /  \        
  child []   T1  T2 T3                        child []   T1  T2 T3       

               /                                          //             
  grandparent []             => color flip    grandparent []             
           //    \\                                     /    \           
   parent []      []aunt T4                    parent []      []aunt T4  
         /  \\   /  \                                /  \\   /  \        
        T1  []   T2 T3                              T1   []  T2 T3       
            child                                        child


It is in this function, modify_left that our decision to postpone the restoration of the red-black
properties pays off. When modify_left is invoked, we know that the insertion was made in the left
subtree of the current node; we know its color; and, by using the RB_code status variable, we know
the condition of the subtree into which the insertion went. By using all this information, we can
now 'determine' exactly what 'actions', if any, are needed to 'restore' the red-black properties.

<code>
#include <iostream>

// RB TREE
// We might go back to our original motivation and implement red-black trees as B-trees whose nodes
// store search trees rather than contiguous lists. This approach would force us to recode most of
// the methods and auxiliary functions of a B-tree, because the original versions relied heavily on
// the contiguous representation of node entries. We shall therefore investigate an alternative
// implementation, where we construct a red-black tree class that inherits the properties of our
// search-tree class

enum Error_code { success, overflow, underflow, duplicate_error, not_present, internal_error };
enum Color { red, black };

// These outcomes from a call to the recursive insertion function describe the following results:
//
// okay: The color of the current root (of the subtree) has not changed; the tree now satisfies the
// conditions for a red-black tree.
//
// red_node: The current root has changed from black to red; modification may or may not be needed
// to restore the red-black properties.
//
// right_red: The current root and its right child are now both red; a color flip or rotation is
// needed.
//
// left_red: The current root and its left child are now both red; a color flip or rotation is
// needed.
//
// duplicate: The entry being inserted duplicates another entry; this is an error.
// 
enum RB_code { okay, red_node, left_red, right_red, duplicate };

// Binary_node {{
//
template <typename Entry>
struct Binary_node
{
  Entry data;
  Binary_node<Entry> *left;
  Binary_node<Entry> *right;

  Binary_node() { left = right = NULL; };
  Binary_node( const Entry &x ) { left = right = NULL; data = x;};

  virtual void set_color( Color c ) { };
  virtual Color get_color() const { return red; };
};
// Binary_node }}

// Binary_tree {{
//
template <typename Entry>
class Binary_tree 
{
  public:
    Binary_tree() { root = NULL; }
    Binary_tree(const Binary_tree<Entry> &original);
    Binary_tree & operator=(const Binary_tree<Entry> &original);
    // ~Binary_tree();

    bool empty() const { return root == NULL; }
    int size() const;
    void clear();
    int height() const;

    void insert( const Entry & );
    void inorder( void (*visit)(Entry &));

  protected:
    void recursive_inorder( Binary_node<Entry> *sub_root, void (*visit)(Entry &));
    Binary_node<Entry> *root;
};

template <typename Entry>
void Binary_tree<Entry>::inorder( void (*visit)(Entry &))
{
  recursive_inorder(root, visit);
}

template <class Entry>
void Binary_tree<Entry>::recursive_inorder(Binary_node<Entry> *sub_root, void (*visit)(Entry &))
{
  if (sub_root != NULL) 
  {
    recursive_inorder(sub_root->left, visit);
    (*visit)(sub_root->data);
    recursive_inorder(sub_root->right, visit);
  }
}
// Binary_tree }}


// Search_tree {{
//
template <typename Record>
class Search_tree: public Binary_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    Error_code remove( const Record &old_data );
    // If there is an entry in the tree whose key matches that in target, the parameter target is
    // replaced by the corresponding record from the tree and a code of success is returned.
    // Otherwise a code of not_present is returned.
    // <note> it seems unuseful to replace target parameter when found since that's the same value.
    // May be useful to return some other value?
    Error_code tree_search( Record &target ) const;

  private:
    Error_code search_and_insert( Binary_node<Record> *&sub_root, const Record &new_data ); 
    Binary_node<Record> *search_for_node( Binary_node<Record> *sub_root, 
        const Record &target) const;

    // to support removal with record.
    Error_code search_and_destroy( Binary_node<Record>* &sub_root, const Record &target);

    // If sub_root is NULL, a code of not_present is returned. Otherwise, the root of the subtree is
    // removed in such a way that the properties of a binary search tree are preserved. The
    // parameter sub_root is reset as the root of the modified subtree, and success is returned.
    Error_code remove_root( Binary_node<Record> *&sub_root );
};

// If the key of target is not in the subtree, a result of NULL is returned. Otherwise, a pointer
// to the subtree node containing the target is returned.

// template <typename Record>
// Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
//     const Record &target) const
// {
//   if( sub_root == NULL || sub_root->data == target )
//     return sub_root;
//   else if( target > sub_root->data )
//     return search_for_node( sub_root->right, target );
//   else
//     return search_for_node( sub_root->left, target );
// }

// recursion removal version
template <typename Record>
Binary_node<Record> *Search_tree<Record>::search_for_node( Binary_node<Record> *sub_root, 
    const Record &target) const
{
  while( sub_root && sub_root->data != target )
  {
    if( target > sub_root->data )
      sub_root = sub_root->right;
    else
      sub_root = sub_root->left;
  }

  return sub_root;
}

template <typename Record>
Error_code Search_tree<Record>::tree_search( Record &target ) const
{
  Error_code result = success;

  Binary_node<Record> *found = search_for_node( this->root, target );
  if( found == NULL )
    return not_present;
  else
    target = found->data;

  return result;
}

template <typename Record>
Error_code Search_tree<Record>::insert( const Record &new_data )
{
  return search_and_insert( this->root, new_data );
}

// <key> <call-by-value-problem> notice the use of "*&" here or else this is an bug as the same of
// TreeInsert() since sub_root is a local copy and the same wrong output.
// Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *sub_root, const Record
// &new_data); 
template <typename Record>
Error_code Search_tree<Record>::search_and_insert( Binary_node<Record> *&sub_root, 
    const Record &new_data ) 
{
  if( sub_root == NULL )
  {
    sub_root = new Binary_node<Record>(new_data);
    return success;
  }
  else if( new_data < sub_root->data )
    return search_and_insert( sub_root->left, new_data );
  else if( new_data > sub_root->data )
    return search_and_insert( sub_root->right, new_data );
  else 
    return duplicate_error;
}

// the parameter is one of links of the tree, and not just a copy.
// remove_root(x->left);
//
// <note> that the argument type.
//
// <note> this it different approach from DeleteNodeTree( TreeNode** p ): 
// First, move to to-delete node's left subtree and find the immediate predecessor when do inorder
// traversal. This finds the node as far right as possible and it has no right child since we went
// as far right as possible.  So it can be removed from its current position without difficulty. 
//
// Second, swap this node with the node that was supposed to be removed.
//
// The key is that the properties of a binary search tree will still be satisfied, since there were
// no keys in the original tree whose ordering comes between the removed key and its immediate
// predecessor.
template <typename Record>
Error_code Search_tree<Record>::remove_root( Binary_node<Record> *&sub_root )
{
  if( sub_root == NULL ) return not_present;

  Binary_node<Record> *to_delete = sub_root;

  if( sub_root->right == NULL )
    sub_root = sub_root->left;
  else if ( sub_root->left == NULL )
    sub_root = sub_root->right;
  else  // neither subtree is empty
  {
    to_delete = sub_root->left;   // move left

    Binary_node<Record> *parent = sub_root;

    while( to_delete->right != NULL )
    {
      parent = to_delete;
      to_delete = to_delete->right;
    }

    // move from to_delete(predecessor) to root(node to delete)
    sub_root->data = to_delete->data;   

    // <note> this is interesting and cases for when predecessor does have left subtree but right
    // null.
    //          ...               or              ...           
    //        [ ] sub_root                      [ ] sub_root
    //                                        ...                 
    //     [ ]    to_delete                  [ ]    parent
    //                                        
    //  [ ]  N                            [ ]  [ ]  to_delete             
    // ...                                   ...  N                
    //
    if(parent == sub_root)  // this when don't have while loop run  
      sub_root->left = to_delete->left;
    else  
      parent->right = to_delete->left;
  }

  // remove it from the tree 
  delete to_delete;
  return success;
}

template <typename Record>
Error_code Search_tree<Record>::search_and_destroy( Binary_node<Record>* &sub_root, const Record &target)
{
  // remove_root handles sub_root is NULL
  if( sub_root == NULL || sub_root->data == target )
    return remove_root( sub_root );
  else if( target < sub_root->data )
    return search_and_destroy( sub_root->left, target );
  else
    return search_and_destroy( sub_root->right, target );
}

template <typename Record>
Error_code Search_tree<Record>::remove( const Record &target )
{
  return search_and_destroy( this->root, target ); 
}
// Search_tree }}

// RB_node {{
//
template <typename Record>
struct RB_node: public Binary_node<Record>
{
  Color color;

  RB_node();
  RB_node( const Record &x );

  // RB_node() { Binary_node<Record>::Binary_node(); color = red; };
  // RB_node( const Record &x ) { Binary_node<Record>::Binary_node(x); color = red; };

  void set_color( Color c ) { color = c; };
  Color get_color() const { return color; };
};

template <typename Record>
RB_node<Record>::RB_node()
{
  Binary_node<Record>::Binary_node(); 
  color = red;
}

template <typename Record>
RB_node<Record>::RB_node( const Record &x)
{
  // Binary_node<Record>::Binary_node(x); 
  this->data = x;
  this->left = this->right = NULL;
  color = red;
}
// RB_node }}


// RB_tree {{
//
template <typename Record>
class RB_tree: public Search_tree<Record>
{
  public:
    Error_code insert( const Record &new_data );
    // Error_code remove( const Record &old_data );

  private:
    RB_code rb_insert( Binary_node<Record> *&current, const Record &new_data );
    RB_code modify_left( Binary_node<Record> *&current, RB_code &child_status );
    RB_code modify_right( Binary_node<Record> *&current, RB_code &child_status );
    RB_code rotate_right( Binary_node<Record> *&current );
    RB_code rotate_left( Binary_node<Record> *&current );
    RB_code flip_color( Binary_node<Record> *&current );
};

template <typename Record>
Error_code RB_tree<Record>::insert( const Record &new_data )
{
  RB_code status = rb_insert( this->root, new_data );

  // convert private RB_code to public Error_code
  switch( status )
  {
    // see <make-root-black>
    case red_node:
      this->root->set_color(black);
    case okay:
      return success;

    case duplicate:
      return duplicate_error;

    case right_red:
    case left_red:
      std::cout << "warning: program error detected in RB_tree::insert" << std::endl;
      return internal_error;
  }
}

// Pre: current is either NULL or points to the first node of a subtree of an RB_tree
//
// Post: If the key of new_entry is already in the subtree, a code of duplicate is returned.
// Otherwise, the Record new_entry is inserted into the subtree pointed to by current. The
// properties of a red-black tree have been restored, except possibly at the root current and one of
// its children, whose status is given by the output RB_code.
template <typename Record>
RB_code RB_tree<Record>::rb_insert( Binary_node<Record> *&current, const Record &new_data )
{
  RB_code status, child_status;

  if( current == NULL )
  {
    current = new RB_node<Record>(new_data);
    status = red_node;
  }
  else if( new_data < current->data )  // insert in left subtree
  {
    child_status = rb_insert( current->left, new_data );
    status = modify_left( current, child_status );
  }
  else if( new_data > current->data )  // insert in right subtree
  {
    child_status = rb_insert( current->right, new_data );
    status = modify_right( current, child_status );
  }
  else
  {
    status = duplicate;
  }

  return status;
}

// Pre: An insertion has been made in the left subtree of *current that has returned the value of
// child_status for this subtree.
//
// Post: Any color change or rotation needed for the tree rooted at current has been made, and a
// status code is returned.
template <typename Record>
RB_code RB_tree<Record>::modify_left( Binary_node<Record> *&current, RB_code &child_status )
{
  RB_code status = okay;

  Binary_node<Record> *aunt = current->right;
  Color aunt_color = black;

  if( aunt != NULL )
    aunt_color = aunt->get_color();

  switch( child_status )
  {
    // no action needed as tree is already okay
    case okay: 
      break;

    case red_node:
      if( current->get_color() == red )   // red inserted at current-1 and current is red. need to restore at the current+1.
        status = left_red;                // <note> left_red
      else                                // red inserted and current black. so okay.
        status = okay;
      break;

    case left_red:
      if( aunt_color == black )
        status = rotate_right(current);
      else
        status = flip_color(current);
      break;

    case right_red:
      if( aunt_color == black )
      {
        // status = double_rotate_right(current);
        Binary_node<Record> *&left_tree = current->left;
        status = rotate_left(left_tree);
        status = rotate_right(current);
      }
      else
        status = flip_color(current);
      break;
  }
  return status;
}

// Pre: An insertion has been made in the 'right' subtree of *current that has returned the value of
// child_status for this subtree.
//
// Post: Any color change or rotation needed for the tree rooted at current has been made, and a
// status code is returned.
template <typename Record>
RB_code RB_tree<Record>::modify_right( Binary_node<Record> *&current, RB_code &child_status )
{
  RB_code status = okay;

  Binary_node<Record> *aunt = current->left;
  Color aunt_color = black;

  if( aunt != NULL )
    aunt_color = aunt->get_color();

  switch( child_status )
  {
    // no action needed as tree is already okay
    case okay: 
      break;

    case red_node:
      if( current->get_color() == red )   // red inserted at current-1 and current is red. need to restore at the current+1.
        status = right_red;               // <note> right_red
      else                                // red inserted and current black. so okay.
        status = okay;
      break;

    case left_red:
      if( aunt_color == black )
      {
        // status = double_rotate_left(current);
        Binary_node<Record> *&right_tree = current->right;
        status = rotate_right(right_tree);
        status = rotate_left(current);
      }
      else
        status = flip_color(current);
      break;

    case right_red:
      if( aunt_color == black )
        status = rotate_left(current);
      else
        status = flip_color(current);
      break;
  }
  return status;
}

// From AVL tree codes:
// Pre: current points to a subtree of the RB_tree. This subtree has a nonempty 'left' subtree.
// Post: current is updated to point to its former 'left' child, and the former current node is the
// 'right' child of the new current node.
//
// <note> rotate left child but argument is its parent
//
// <Q> what's the return for error case
template <typename Record>
RB_code RB_tree<Record>::rotate_right( Binary_node<Record> *&current )
{
  // impossible case
  if( current == NULL || current->left == NULL )
    std::cout << "warning: program error detected in rotate_right" << std::endl;
  else
  {
    Binary_node<Record> *left_tree = current->left;

    current->left = left_tree->right;
    left_tree->right = current;
    current = left_tree;
  }

  return okay;
}


// From AVL tree codes:
// Pre: current points to a subtree of the RB_tree. This subtree has a nonempty 'right' subtree.
// Post: current is updated to point to its former 'right' child, and the former current node is the
// 'left' child of the new current node.
//
// <note> rotate right child but argument is its parent
//
template <typename Record>
RB_code RB_tree<Record>::rotate_left( Binary_node<Record> *&current )
{
  // impossible case
  if( current == NULL || current->right == NULL )
    std::cout << "warning: program error detected in rotate_left" << std::endl;
  else
  {
    Binary_node<Record> *right_tree = current->right;

    current->right = right_tree->left;
    right_tree->left = current;
    current = right_tree;
  }

  return okay;
}

template <typename Record>
RB_code RB_tree<Record>::flip_color( Binary_node<Record> *&current )
{
  // impossible case
  if( current == NULL || current->right == NULL || current->left == NULL )
    std::cout << "warning: program error detected in flip_color" << std::endl;
  else
  {
    current->set_color(red);
    current->right->set_color(black);
    current->left->set_color(black);
  }

  return okay;
}
// RB_tree }}

void PrintTreeNode( int &entry )
{
  std::cout << " " << entry << ",";
}

int main()
{
  // int arr[] = { 2, 3, 5, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33 };
  int arr[] = { 33, 2, 31, 5, 30, 6, 12, 10, 13, 15, 17, 29, 3 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  RB_tree<int> rbt;
  Error_code result;

  // insert
  for(int idx = 0; idx < size; idx++)
  {
    result = rbt.insert( arr[idx] );
    if( result != success )
    {
      std::cout << "insert failed: " << arr[idx] << " into a tree" << std::endl; 
    }
  }

  // print
  std::cout << "{"; 
  rbt.inorder( PrintTreeNode );
  std::cout << "}" << std::endl; 

  // remove
  //for(int idx = 0; idx < size; idx++)
  //{
  //  result = bst.remove( arr[idx] );
  //  if( result != success )
  //  {
  //    std::cout << "remove failed: " << arr[idx] << " into a tree" << std::endl; 
  //  }
  //}

  // print
  // std::cout << "{"; 
  // bst.inorder( PrintTreeNode );
  // std::cout << "}" << std::endl; 
}


={============================================================================
*kt_dev_algo_050* comparison of methods

Three(five) imporant efficiency criteria when choosing algorithms: p330 in {ref-001}

1) use of space
2) computer time
3) programming effort

4) statistical analysis. to see difference between worst and best case.
5) empirical testing


# ============================================================================
#{ CASES
={============================================================================
*kt_dev_algo_100*	double linked list

// size of hash table.
#define MHV_HASH_SIZE 3

// hash function for handles.
#define HASH(handle) (((uint32_t)(handle)) % MHV_HASH_SIZE)

typedef struct SPfmListHead_
{
  struct SPfmListHead_ *nxt, *prv;
} SPfmListHead;

static SPfmListHead m_apstStreamHashTable[MHV_HASH_SIZE];

<DN-one>
This double linked list has an entry which has also a double linked list.

m_apstStreamHashTable

     prev           prev          prev
      |               |             |
    [0]             [1]           [2]   : headers
    |               |             |
   next            next          next 

     prev           prev          prev
      |               |             |
    [E]             [E]           [E]   : entries
    <- prev
       next ->
    |               |             |
   next            next          next 

<DN-two>
The hash table is simple mod operation. % HASH_SIZE and handles is an counter whcih increase by one.
So all handles will belongs one of {0,1,2} when HASH_SIZE is 3.

<DN-three>
This is implemented as circular but no use of it.

<DN-four>
Typical list structure has following structures and can define the entry as we want. However, how
can we use this List for different entry structure?

typedef struct listnode {
     ListEntry entry;
     struct listnode* next;
     struct listnode* prev;
} ListNode;

typedef struct list {
     ListNode*  current;
   ...
} List;


{generic-support} 
Here, trick is to have ListNode as the first member for <any> entry structure and to have a link to
that member. This build a linked list on that. In this example, it uses is as the first member, uses
its offset, and use type cast to what want to have. Why the first member? Because need to get the
start address of the object. This is C way since it assumes that memory layout or internal representation.  

typedef struct listnode {     <DN> no entry in a node
     struct listnode* next;
     struct listnode* prev;
} ListNode;

typedef struct list {
     ListNode*  current;
   ...
} List;

typedef struct {
  ListNode node;
  ...
} A_type_entry;

typedef struct {
  ListNode node;
  ...
} B_type_entry;

<init>

for( ii=0; ii < MHV_HASH_SIZE; ii++ )
{
  PFM_INIT_LIST_HEAD(m_apstStreamHashTable + ii);
}

void PFM_INIT_LIST_HEAD(SPfmListHead *ptr)
{
  ptr->nxt = ptr;
  ptr->prv = ptr;
}

<add>

typedef struct _SMhvStream
{
    SPfmListHead list;  // [DN] this is the first member of a structure
    ...
    SPfmListHead subs;
    SPfmListHead triggers;
    ...
} SMhvStream;

p = (SMhvStream *)blkAlloc(&m_StreamHashBlockCtrl);

PFM_INIT_LIST_HEAD(&p->subs);
PFM_INIT_LIST_HEAD(&p->triggers);

pfmListAddTail(m_apstStreamHashTable + HASH(p->handle), &(p->list));
/* add to stream. */
pfmListAddTail(&p->subs, &ev->strlist);

// Add an item to the tail of a list.
// @param   list    The list to modify
// @param   entry   The entry to add at the tail of list.
void pfmListAddTail(SPfmListHead * list, SPfmListHead * entry)
{
  entry->nxt = list;
  entry->prv = (list)->prv;
  list->prv->nxt = entry;
  (list)->prv = entry;
}

// Add an item to the head of a list.
// @param   list    The list to modify
// @param   entry   The entry to add at the start of list.
void pfmListAddHead(SPfmListHead * list, SPfmListHead * entry)
{
  entry->nxt = list->nxt;
  entry->prv = list;
  list->nxt->prv = entry;
  list->nxt = entry;
}

// Remove an item from its list.
// @param   item    The item to remove.
void pfmListRemove(SPfmListHead * item)
{
  item->nxt->prv = item->prv;
  item->prv->nxt = (item)->nxt;
}

<search> simple sequential search from each head

SPfmListHead *item;

for( int ii=0; ii < MHV_HASH_SIZE; ii++ )
{
  pfmForEach(item, m_apstStreamHashTable + HASH(h))
  {
    SMhvStream *p;
    p = pfmListEntry(item, SMhvStream, list);
    if (p != NULL) // should p ever be NULL?
    {
      use p;
    }
  }
}

#define pfmForEach(item, head) \
    for (item = (head)->nxt; item != (head); item = item->nxt)

#define pfmListEntry(item, type, member) \
    ((type *)((void*)((uint8_t *)(item)-(size_t)(&((type *)0)->member))))
                     |                                                |     : get memeber offset
             |                                                         |    : type cast to void*
                                                                            : type cast to type*


# ============================================================================
#{ DISCUSSION
={============================================================================
*kt_dev_algo_300* C++ map insertion and lookup performance and storage overhead

http://stackoverflow.com/questions/1822114/c-map-insertion-and-lookup-performance-and-storage-overhead

The question is:

I would like to store a mapping of an integer key to a float value in-memory. I have roughly 130
million keys (and, accordingly, 130 million values). My focus is on lookup performance. I have to do
many, many millions of lookups. The C++ STL library has a map class for associative arrays of this
sort. I have several questions about map. What is the storage overhead of map for a dataset of the
size mentioned above? How does storage overhead scale, in general, with map? It looks like the
underlying data structure for map is a red-black, balanced binary tree. It sounds like the
real-world performance for this is O(log n) for insertion and retrieval. It mentions O(1) for a
hinted insertion. My input is pre-sorted, so I believe I should be able to provide a hint for
insertion events. How would I provide this hint, using the methods listed here? Is there an STL
container that provides better lookup performance?  Are there other publicly-available, open-source
frameworks with an associate array class that uses an underlying data structure that would perform
better than STL map? If writing my own container class would provide better lookup performance, what
data structures might I research? I am using GCC 4 for this task, running under either Linux or Mac
OS X. I apologize in advance if these are dumb questions. Thank you for your advice.

Given what you've said, I'd think very hard about using an std::vector<pair<int, float> >, and using
std::lower_bound, std::upper_bound, and/or std::equal_range to look up values.

While the exact overhead of std::map can (and does) vary, there's little or no room for question
that it will normally consume extra memory and look up values more slowly than a binary search in a
vector. As you've noted, it's normally (and almost unavoidably) implemented as some sort of balanced
tree, which imposes overhead for the pointers and the balancing information, and typically means
each node is allocated separately as well. Since your nodes are pretty small (typically 8 bytes)
that extra data is likely to be at least as much as what you're actually storing (i.e. at least 100%
overhead). Separate allocations often mean poor locality of reference, which leads to poor cache
usage.

Edit: Looking just at implementations of std::map, it's probably worth noting that most use a
red-black tree. If you were going to use an std::map, an implementation that uses an AVL tree would
probably suit your purposes better -- an AVL tree has slightly tighter constraints on balancing.
This gives slightly faster lookup at the expense of slightly slower insertion and deletion (since it
has to re-balance more often to maintain its stricter interpretation of "balanced"). As long as
your data remains constant during use, however, an std::vector is still almost certainly better.

One other possibility worth noting: if your keys are at least fairly even distributed, you might
want to try looking up using interpolation instead of bisection. i.e. instead of always starting at
the middle of the vector, you do a linear interpolation to guess at the most likely starting point
for the lookup. Of course, if your keys follow some known non-linear distribution, you can use a
matching interpolation instead.

Edit 2: Assuming the keys are reasonably even distributed, the interpolation search has a complexity
of O(log log N). For 130 million keys, that works out to around 4 probes to find an item. To do
significantly better than that with (normal/non-perfect) hashing, you need a good algorithm, and you
need to keep the load factor in the table around 75% or so -- i.e. you need to allow for something
like 32 million extra (empty) spots in your table to improve the expected complexity from four
probes to three. I may just be old fashioned, but that strikes me as a lot of extra storage to use
for such a small speed improvement.

OTOH, it's true that this is nearly the ideal situation for perfect hashing -- the set is known
	ahead of time, and the key is quite small (important, since hashing is normally linear on the key
			size). Even so, unless the keys are distributed pretty unevenly, I wouldn't expect any huge
	improvement -- a perfect hash function is often (usually?) fairly complex.  share|improve this
	answer
	
definitely just use a binary search in the vector. Least memory, fastest too. –  Will Nov 30 '09 at
20:33
	
What about insertions? To use binary search, you'll have to keep the array sorted. Random
insertions in a vector are not particularly efficient. –  Raphaël Saint-Pierre Nov 30 '09 at 20:36
	
@RaphealSP: yes, if the data were dynamic (i.e. you need to support insertions/deletions during
		use), a sorted vector isn't a good choice. He notes, however, that the data starts out sorted,
	which I took as indicating that he's just reading in data, but not modifying it afterwards. –
		Jerry Coffin Nov 30 '09 at 20:41
	 
I am only inserting once. I do not need to modify my input set afterwards. –  Alex Reynolds Nov 30
'09 at 20:45 


# ============================================================================
#{ GLIBC
==============================================================================
*kt_dev_glib_000* glib sites

http://www.gnu.org/software/libc/libc.html
https://sourceware.org/glibc/wiki/GlibcGit

git clone git://sourceware.org/git/glibc.git

o use tabstop=6 for better view.


={============================================================================
*kt_dev_glib_001* atoi, htoi

{man-page}
<atoi>
NAME
       atoi, atol, atoll, atoq - convert a string to an integer

SYNOPSIS
       #include <stdlib.h>

       int atoi(const char *nptr);
       long atol(const char *nptr);
       long long atoll(const char *nptr);
       long long atoq(const char *nptr);

DESCRIPTION
       The atoi() function converts the initial portion of the string  pointed
       to by nptr to int.  The behavior is the same as
       
           strtol(nptr, (char **) NULL, 10);

       note: except that atoi() does not detect errors.

//< from comments in tail excercise
   1.  atoi() has a normally annoying property of not being able to
       tell the caller conclusively whether the input was bad ("abc")
       or it was really zero ("0"), because it returns 0 for both    
       cases.  Here, we exploit that property, because we only want
       to accept options in the form of "-n".                      
//>
       The atol() and atoll() functions behave the same as atoi(), except that
       they convert the initial portion of the string to their return type  of
       long or long long.  atoq() is an obsolete name for atoll().

RETURN VALUE
       The converted value.

<strtol>
NAME
       strtol, strtoll, strtoq - convert a string to a long integer

SYNOPSIS
       #include <stdlib.h>

       long int strtol(const char *nptr, char **endptr, int base);
       long long int strtoll(const char *nptr, char **endptr, int base);

DESCRIPTION
       The strtol() function converts the initial part of the string  in  nptr
       to  a  long  integer  value  according to the given 'base', which must be
       between 2 and 36 inclusive, or be the special value 0.

       // note. handle leading white space, 0x, and sign
       The string may begin with an arbitrary amount of white space (as deter‐
       mined by isspace(3)) followed by a single optional '+' or '-' sign.  If
       base is zero or 16, the string may then include a "0x" prefix, and  the
       number  will  be read in base 16; otherwise, a zero base is taken as 10
       (decimal) unless the next character is '0', in which case it  is  taken
       as 8 (octal).

       // note: zero base is 10 base

       The  remainder  of  the  string is converted to a long int value in the
       obvious manner, stopping at the first character which is  not  a  valid
       digit  in the given base.  (In bases above 10, the letter 'A' in either
       upper or lower case represents 10, 'B' represents  11,  and  so  forth,
       with 'Z' representing 35.)

       // note see how return and error are handled.
       If endptr is not NULL, strtol() stores the address of the first [invalid]
       character in *endptr.  If there were no digits at all, strtol()  stores
       the  original value of nptr in *endptr (and returns 0).  In particular,
       if *nptr is not '\0' but **endptr is '\0' on return, the entire  string
       is valid.

       The  strtoll()  function  works  just  like  the  strtol() function but
       returns a long long integer value.

RETURN VALUE
       The strtol() function returns the result of the conversion, unless  the
       value  would  underflow  or overflow.  If an underflow occurs, strtol()
       returns LONG_MIN.  If an overflow occurs,  strtol()  returns  LONG_MAX.
       In  both  cases,  errno is set to ERANGE.  Precisely the same holds for
       strtoll()  (with  LLONG_MIN  and  LLONG_MAX  instead  of  LONG_MIN  and
       LONG_MAX).

ERRORS
       EINVAL (not in C99) The given base contains an unsupported value.

       ERANGE The resulting value was out of range.

       The  implementation  may also set errno to EINVAL in case no conversion
       was performed (no digits seen, and 0 returned).

EXAMPLE
       The  program  shown  below demonstrates the use of strtol().  The first
       command-line argument specifies a string  from  which  strtol()  should
       parse  a  number.  The second (optional) argument specifies the base to
       be used for the conversion.  (This argument  is  converted  to  numeric
       form  using atoi(3), a function that performs no error checking and has
       a simpler interface than strtol().)  Some examples of the results  pro‐
       duced by this program are the following:

           $ ./a.out 123
           strtol() returned 123

           $ ./a.out '    123'
           strtol() returned 123

           $ ./a.out 123abc
           strtol() returned 123
           Further characters after number: abc

           $ ./a.out 123abc 55
           strtol: Invalid argument

           $ ./a.out ''
           No digits were found

           $ ./a.out 4000000000
           strtol: Numerical result out of range

   Program source

       #include <stdlib.h>
       #include <limits.h>
       #include <stdio.h>
       #include <errno.h>

       int
       main(int argc, char *argv[])
       {
           int base;
           char *endptr, *str;
           long val;

           if (argc < 2) {
               fprintf(stderr, "Usage: %s str [base]\n", argv[0]);
               exit(EXIT_FAILURE);
           }

           str = argv[1];
           base = (argc > 2) ? atoi(argv[2]) : 10;

           errno = 0;    /* To distinguish success/failure after call */
           val = strtol(str, &endptr, base);

           /* Check for various possible errors */
           if ((errno == ERANGE && (val == LONG_MAX || val == LONG_MIN))
                   || (errno != 0 && val == 0)) {
               perror("strtol");
               exit(EXIT_FAILURE);
           }

           if (endptr == str) {
               fprintf(stderr, "No digits were found\n");
               exit(EXIT_FAILURE);
           }

           /* If we got here, strtol() successfully parsed a number */
           printf("strtol() returned %ld\n", val);

           if (*endptr != '\0')        /* Not necessarily an error... */
               printf("Further characters after number: %s\n", endptr);

           exit(EXIT_SUCCESS);
       }


<example> from ansic, p43.
// This is 'naive' implementation since no error handlings and return 0 when failed to convert.
// Compare to strtol

int atoi(char s[])
{
  int n, i;

  // Why there is no check on the end of string input? '0' is not the same as 0(NULL) and when see
  // any other than numbers, for loops ends.
  for(n = 0, i = 0; s[i] >= '0' && s[i] <= '9'; i++)
    n = n*10 + (s[i]-'0');

  return n;
}

// atoi second version <ansic-example> p61
#include <ctype.h>

int atoi(char s[])
{
  int i, n, sign;

  // skip white spaces
  for(i = 0; isspace( s[i] ); i++)
    ;

  sign = (s[i] == '-') ? -1 : 1;

  // skip sign
  if( s[i] == '+' || s[i] == '-' )
    i++;

  for(n = 0; isdigit( s[i] ); i++)
    n = n*10 + (s[i]-'0');

  return sign*n;
}

// returns EOF for end of file, zero if the next input is not a number, and a
// positive value if the input contains a valid number. ansic p97.
int getint(int *pn)
{
  int c, sign;

  // skip white spaces
  while( isspace(c = getc() ))
      ;

  // not a number
  if( !isdigit(c) && c != EOF && c != '+' && c != '-' )
  {
    ungetc(c);
    return 0;
  }

  sign = (c == '-') ? -1 : 1;

  if( c == '+' || c == '-' )
    c = getc();

  for( *pn = 0; isdigit(c); c = getc() )
    *pn = *pn * 10 + (c - '0');

  *pn *= sign;

  if( c != EOF )
    ungetc(c);

  return c;
} 

To make it compile in gcc:

int getint(int *pn)
{
  int c, sign;

  // skip white spaces
  while( isspace(c = getchar() ))
      ;

  // not a number
  if( !isdigit(c) && c != EOF && c != '+' && c != '-' )
  {
    ungetc(c, stdin);
    return 0;
  }

  sign = (c == '-') ? -1 : 1;

  if( c == '+' || c == '-' )
    c = getchar();

  for( *pn = 0; isdigit(c); c = getchar() )
    *pn = *pn * 10 + (c - '0');

  *pn *= sign;

  if( c != EOF )
    ungetc(c, stdin);

  return c;
} 

<exercise> 
From ansic, exercise 5-1. As written, getint treats a + or - not followed by a digit as a valid
representation of zero. Fix it to push such a character back on the input.


<getchar-and-eof>
From ansic 1.5.1, "we can't use char since c must be big enough to hold EOF in addition to any
possible char. Therefore we use int"

GETS(3)                    Linux Programmer's Manual
int getchar(void);

int main(int argc, char* argv[])
{
  // int c;
  char c;

  printf("EOF (0x%x)\n", EOF);

  c = getchar();

  while( c != EOF )
  {
    putchar(c);
    c = getchar();
  }
}

kt@kt-ub-vb:~/work$ ./a.out 
EOF (0xffffffff)
a b v <1>
a b v <2>
(waiting input)

For <1>, a b v (ENTER) then <2> comes. This means that when press ENTER, input stream ends and is
ready to process. The getchar and putchar runs on this stream and only runs when press ENTER.

EOF is an integer defined in stdio.h but the specific numeric value doesn't matter as long as it is
not the same as any char value. This is why use symbolic constant.

<code-online>
// A utility function to check whether x is numeric
bool isNumericChar(char x)
{
  return (x >= '0' && x <= '9')? true: false;
}

// A simple atoi() function. If the given string contains any invalid character, then this function
// returns 0
int myAtoi(char *str)
{
  if (*str == NULL)
    return 0;

  int res = 0;  // Initialize result
  int sign = 1;  // Initialize sign as positive
  int i = 0;  // Initialize index of first digit

  // If number is negative, then update sign
  if (str[0] == '-')
  {
    sign = -1;
    i++;  // Also update index of first digit
  }

  // Iterate through all digits of input string and update result
  for (; str[i] != '\0'; ++i)
  {
    if (isNumericChar(str[i]) == false)
      return 0; // You may add some lines to write error message to error stream
    res = res*10 + str[i] - '0';
  }

  // Return result with sign
  return sign*res;
}

<code-glibc>
Here only consider usual char type which is not wide char and 10 base. So disregard followings:

#ifdef USE_NUMBER_GROUPING
# ifdef USE_WIDE_CHAR

// stdlib/atio.c
int
atoi (const char *nptr)
{
  return (int) strtol (nptr, (char **) NULL, 10);
}

// stdlib/strtol.c
INT
strtol (nptr, endptr, base)
     const STRING_TYPE *nptr;
     STRING_TYPE **endptr;
     int base;
{
  return INTERNAL (__strtol_l) (nptr, endptr, base, 0, _NL_CURRENT_LOCALE);
}

// stdlib/strtol_l.c
// The interesting bit are: base handling, overflow handling,
//
INT
INTERNAL (__strtol_l) (nptr, endptr, base, group, loc)
     const STRING_TYPE *nptr;
     STRING_TYPE **endptr;
     int base;
     int group;
     __locale_t loc;
{
  const STRING_TYPE *s;
  UCHAR_TYPE c;
  const STRING_TYPE *save, *end;

  unsigned LONG int i;
  int overflow;

  save = s = nptr;

  /* Skip white space.  */
  while (ISSPACE (*s))
    ++s;

  /* Check for a sign.  */
  negative = 0;
  if (*s == L_('-'))
  {
    negative = 1;
    ++s;
  }
  else if (*s == L_('+'))
    ++s;

  /* Recognize number prefix and if BASE is zero, figure it out ourselves.  */
  // skip
  
  /* Save the pointer so we can check later if anything happened.  */
  // so handled the sign from s
  save = s;

  end = NULL;

  /* Avoid runtime division; lookup cutoff and limit.  */
  cutoff = cutoff_tab[base - 2];
  cutlim = cutlim_tab[base - 2];

  overflow = 0;
  i = 0;
  c = *s;

  // this is for QUAD
  if (sizeof (long int) != sizeof (LONG int))
  {
    unsigned long int j = 0;
    // same as cutoff_tab
    unsigned long int jmax = jmax_tab[base - 2];

    // scan through each char
    for (;c != L_('\0'); c = *++s)
    {
      // is it possible case?
      if (s == end)
        break;

      // convert to digit
      if (c >= L_('0') && c <= L_('9'))
        c -= L_('0');
      else if (ISALPHA (c))
        c = TOUPPER (c) - L_('A') + 10;
      else
        break;

      // cannot bigger than base
      if ((int) c >= base)
        break;
      /* Note that we never can have an overflow.  */
      else if (j >= jmax)
      {
        /* We have an overflow.  Now use the long representation.  */
        i = (unsigned LONG int) j;
        goto use_long;
      }
      // make a digit in corresponding unit
      else
        j = j * (unsigned long int) base + c;
    } // for end

    i = (unsigned LONG int) j;
  }
  // this is usual case
  else
    for (;c != L_('\0'); c = *++s)
    {
      if (s == end)
        break;

      if (c >= L_('0') && c <= L_('9'))
        c -= L_('0');
      else if (ISALPHA (c))
        c = TOUPPER (c) - L_('A') + 10;
      else
        break;

      // when c is alphabet
      if ((int) c >= base)
        break;

      /* Check for overflow.  */
      if (i > cutoff || (i == cutoff && c > cutlim))
        overflow = 1;
      else
      {
use_long:
        i *= (unsigned LONG int) base;
        i += c;
      }
    }

  /* Check if anything actually happened.  */
  // nothing converted
  if (s == save)
    goto noconv;

  /* Store in ENDPTR the address of one character
     past the last character we converted.  */
  if (endptr != NULL)
    *endptr = (STRING_TYPE *) s;

  /* Return the result of the appropriate sign.  */
  return negative ? -i : i;
}

// the bellow is the pre-calculated table for each base and the value are the
// max value for division and remainder. for example, cutoff = cutoff_tab[base
// - 2]; get the value for base 10.

/* Define tables of maximum values and remainders in order to detect
   overflow.  Do this at compile-time in order to avoid the runtime
   overhead of the division.  */
extern const unsigned long __strtol_ul_max_tab[] attribute_hidden;
extern const unsigned char __strtol_ul_rem_tab[] attribute_hidden;

#define DEF(TYPE, NAME)							   \
  const TYPE NAME[] attribute_hidden =					   \
  {									   \
    F(2), F(3), F(4), F(5), F(6), F(7), F(8), F(9), F(10), 		   \
    F(11), F(12), F(13), F(14), F(15), F(16), F(17), F(18), F(19), F(20),  \
    F(21), F(22), F(23), F(24), F(25), F(26), F(27), F(28), F(29), F(30),  \
    F(31), F(32), F(33), F(34), F(35), F(36)				   \
  }

#if !UNSIGNED && !defined (USE_WIDE_CHAR) && !defined (QUAD)
# define F(X)	ULONG_MAX / X
  DEF (unsigned long, __strtol_ul_max_tab);
# undef F
# define F(X)	ULONG_MAX % X
  DEF (unsigned char, __strtol_ul_rem_tab);
# undef F
#endif

/* Define some more readable aliases for these arrays which correspond
   to how they'll be used in the function below.  */
#define jmax_tab	__strtol_ul_max_tab
#if defined(QUAD) && __WORDSIZE == 32
# define cutoff_tab	__strtol_ull_max_tab
# define cutlim_tab	__strtol_ull_rem_tab
#else
# define cutoff_tab	__strtol_ul_max_tab
# define cutlim_tab	__strtol_ul_rem_tab
#endif

#ifdef QUAD
...
#else
# define LONG long


{htoi}

From ansic, exercise 2-3. 
Write the function htoi(s), which converts a string of hexadecimal digits (including an 'optional'
0x or 0X) into its equivalent integer value. The allowable digits are 0 through 9, a through f,
and A through F.

<mine>
int mhtoi(char s[])
{
  int n, i = 0, v = 0;

  // optional 0x or 0X
  if(s[0] == '0' && ( s[1] == 'x' || s[1] == 'X' ))
    i = 2;

  // isxdigit()
  // checks for a hexadecimal digits, that is, one of 
  // 0 1 2 3 4 5 6 7 8 9 a b c d e f A B C D E F.
   
  for(n = 0; isxdigit(s[i]); i++)
  {
    if( s[i] >= '0' && s[i] <= '9' )
      v = s[i] - '0';
    else if( s[i] >= 'a' && s[i] <= 'f' )
      v = s[i] - 'a' + 10;
    else 
      v = s[i] - 'A' + 10;

    n = n*16 + v;
  }

  return n;
}

int main(int argc, char* argv[])
{	
  printf("0x4A is %d\n", mhtoi("0x4A"));
  printf("0x4a is %d\n", mhtoi("0x4a"));
  printf("4a is %d\n", mhtoi("4a"));
  printf("0x157DCE is %d\n", mhtoi("0x157DCE"));
} 

<online>
http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_2:Exercise_3
<1>
/*
 * I've tried hard to restrict the solution code to use only what
 * has been presented in the book at this point (page 46). As a
 * result, the implementation may seem a little naive. Error
 * handling is a problem. I chose to adopt atoi's approach, and
 * return 0 on error. Not ideal, but the interface doesn't leave
 * Richard Heathfield much choice.
 *
 * I've used unsigned int to keep the behaviour well-defined even
 * if overflow occurs. After all, the exercise calls for conversion
 * to 'an integer', and unsigned ints are integers!
 */

/* These two header files are only needed for the test driver */
#include <stdio.h>
#include <stdlib.h>

/* Here's a helper function to get Richard Heathfield around the problem of not
 * having strchr
 */
// note this is interesting to get decimal value of hex char
int hexalpha_to_int(int c)
{
  char hexalpha[] = "aAbBcCdDeEfF";
  int i;
  int answer = 0;

  for(i = 0; answer == 0 && hexalpha[i] != '\0'; i++)
  {
    if(hexalpha[i] == c)
    {
      answer = 10 + (i / 2);
    }
  }

  return answer;
}

unsigned int htoi(const char s[])
{
  unsigned int answer = 0;
  int i = 0;
  int valid = 1;
  int hexit;

  if(s[i] == '0')
  {
    ++i;
    if(s[i] == 'x' || s[i] == 'X')
    {
      ++i;
    }
  }

  while(valid && s[i] != '\0')
  {
    answer = answer * 16;
    if(s[i] >= '0' && s[i] <= '9')
    {
      answer = answer + (s[i] - '0');
    }
    else
    {
      hexit = hexalpha_to_int(s[i]);
      if(hexit == 0)
      {
        valid = 0;
      }
      else
      {
        answer = answer + hexit;
      }
    }

    ++i;
  }

  if(!valid)
  {
    answer = 0;
  }

  return answer;
}

/* Solution finished. This bit's just a test driver, so
 * I've relaxed the rules on what's allowed.
 */

int main(void)
{
  char *endp = NULL;
  char *test[] =
  {
    "F00",
    "bar",
    "0100",
    "0x1",
    "0XA",
    "0X0C0BE",
    "abcdef",
    "123456",
    "0x123456",
    "deadbeef",
    "zog_c"
  };

  unsigned int result;
  unsigned int check;

  size_t numtests = sizeof test / sizeof test[0];

  size_t thistest;

  for(thistest = 0; thistest < numtests; thistest++)
  {
    result = htoi(test[thistest]);
    check = (unsigned int)strtoul(test[thistest], &endp, 16);

    if((*endp != '\0' && result == 0) || result == check)
    {
      printf("Testing %s. Correct. %u\n", test[thistest], result);
    }
    else
    {
      printf("Testing %s. Incorrect. %u\n", test[thistest], result);
    }
  }

  return 0;
}


Testing F00. Correct. 3840
Testing bar. Correct. 0             // this is wrong since strtol do for "ba" as mine.
Testing 0100. Correct. 256
Testing 0x1. Correct. 1
Testing 0XA. Correct. 10
Testing 0X0C0BE. Correct. 49342
Testing abcdef. Correct. 11259375
Testing 123456. Correct. 1193046
Testing 0x123456. Correct. 1193046
Testing deadbeef. Correct. 3735928559
Testing zog_c. Correct. 0

<2>
#include <stdio.h>
#define HEX_LO(N) ((N) >= 'a' && (N) <= 'f')
#define HEX_HI(N) ((N) >= 'A' && (N) <= 'F')
#define HEX_NU(N) ((N) >= '0' && (N) <= '9')
#define IS_HEX(N) (HEX_LO(N) || HEX_HI(N) || HEX_NU(N))

unsigned long htoi(char []);
int main(void)
{
  int i;

  char *test[11] = {
    "F00",
    "bar",
    "0100",
    "0x1",
    "0XA",
    "0X0C0BE",
    "abcdef",
    "123456",
    "0x123456",
    "deadbeef",
    "zog_c"
  };

  for(i =0; i < 11; ++i) {
    printf("%10s %10lu\n",test[i], htoi(test[i]));
  }
  return 0;
}

unsigned long htoi(char hexstr[])
{
  int i;
  long num;
  num = 0;
  i = 0;
  char j;
  if(hexstr[0] == '0' && (hexstr[1] == 'x' || hexstr[1] =='X')) i = 2;

  while(hexstr[i] != '\0') {
    j = hexstr[i];
    if(! IS_HEX(j)) return 0;
    if(HEX_LO(j)) num = num * 16 + 10 + j - 'a';
    else if(HEX_HI(j)) num = num * 16 + 10 + j - 'A';
    else num = num * 16 + j - '0';
    i++;
  }
  return num;
}

kt@kt-ub-vb:~/work$ ./a.out 
       F00       3840
       bar          0      // here again
      0100        256
       0x1          1
       0XA         10
   0X0C0BE      49342
    abcdef   11259375
    123456    1193046
  0x123456    1193046
  deadbeef 3735928559
     zog_c          0


={============================================================================
*kt_dev_glib_002* atof

{man-page}
<atof>
NAME
       atof - convert a string to a double

SYNOPSIS
       #include <stdlib.h>

       double atof(const char *nptr);

DESCRIPTION
       The  atof() function converts the initial portion of the string pointed
       to by nptr to double.  The behavior is the same as

           strtod(nptr, (char **) NULL);

       except that atof() does not detect errors.

RETURN VALUE
       The converted value.

<strtod>       
NAME
       strtod, strtof, strtold - convert ASCII string to floating-point number

SYNOPSIS
       #include <stdlib.h>

       double strtod(const char *nptr, char **endptr);
       float strtof(const char *nptr, char **endptr);
       long double strtold(const char *nptr, char **endptr);

DESCRIPTION
       The strtod(), strtof(), and strtold() functions convert the initial
       portion of the string pointed to by nptr to double, float, and long
       double representation, respectively.

{code-glibc}
Here only consider usual char type which is not wide char and 10 base. So disregard followings:

// stdlib/atof.c
/* Convert a string to a double.  */
double
atof (const char *nptr)
{
  return strtod (nptr, (char **) NULL);
}

// stdlib/strtod.c
FLOAT
STRTOF (nptr, endptr)
     const STRING_TYPE *nptr;
     STRING_TYPE **endptr;
{
  return INTERNAL(STRTOF_L) (nptr, endptr, 0, _NL_CURRENT_LOCALE);
}

# ifdef USE_WIDE_CHAR
#  define STRTOF wcstod
#  define STRTOF_L __wcstod_l
# else
#  define STRTOF strtod
#  define STRTOF_L __strtod_l <use>
# endif

// stdlib/strtod_l.c

/* Return a floating point number with the value of the given string NPTR.
   Set *ENDPTR to the character after the last used one.  If the number is
   smaller than the smallest representable number, set `errno' to ERANGE and
   return 0.0.  If the number is too big to be represented, set `errno' to
   ERANGE and return HUGE_VAL with the appropriate sign.  */
FLOAT
____STRTOF_INTERNAL (nptr, endptr, group, loc)
     const STRING_TYPE *nptr;
     STRING_TYPE **endptr;
     int group;
     __locale_t loc;
{
  // more than 1000 lines
}

<example> ansic, p71.

int atoi(char s[])
{
  int i, n, sign;

  // skip white spaces
  for(i = 0; isspace( s[i] ); i++)
    ;

  sign = (s[i] == '-') ? -1 : 1;

  // skip sign
  if( s[i] == '+' || s[i] == '-' )
    i++;

  for(n = 0; isdigit( s[i] ); i++)
    n = n*10 + (s[i]-'0');

  return sign*n;
}

The atof extends atoi and the point is that do it as a normal decimal and devide it later by the
width of decimal point. For example, 3.14 means 314/100

double atof(char s[])
{
  int i, sign;
  double val, power;

  for(i = 0; isspace( s[i] ); i++)     // skip white spaces
    ;

  sign = (s[i] == '-') ? -1 : 1;

  if( s[i] == '+' || s[i] == '-' )     // skip sign
    i++;

  for(val = 0.0; isdigit( s[i] ); i++)
    val = val*10 + (s[i]-'0');

  if( s[i] == '.' )                    // skip decimal point
    i++;

  // do integer or fractional part
  for(power = 1.0; isdigit( s[i] ); i++)
  {
    val = val*10 + (s[i]-'0');
    power *= 10.0;
  }

  return sign*val/power;
}

Given atof, properly declared, we could write atoi in terms of it:

int atoi( char s[] )
{
  double atof( char s[] );

  return (int) atof(s);          // discard information but intended
}

<exercise>
The ansic, page 73, exercise 4-2. Extend atof to handle scientific notation of the form 123.45e-6
where a floating-point number may be followed by e or E and an optionally signed exponent.


={============================================================================
*kt_dev_glib_003* itoa

{man-page}
<itoa>
NONE since it is not part of glibc and should use sprintf instead.

{1}
// * supports 10 base
// * not use reverse()
// * supports the sign
// * return the allocated string
//
// char* itoa(int n);
//
// Key points:
//
// * % and / operation
// * do-while which is necessary since at least one char must be installed in
//   the array even if n is zero.

<code>
char* itoa(int n)
{
  char* ret = NULL;
  int nchar = 0;
  bool negative = false;

  if( n < 0 )
  {
    n = -n;
    negative = true;
    nchar++;
  }

  // how many spaces are needed?
  int temp = n;
  do {
    nchar++;
    temp /= 10;
  } while(temp);

  ret = new char[nchar+1];
  ret[nchar] = 0;

  // convert number to string
  if(negative)
    ret[0] = '-';

  int i = nchar-1;

  do {
    ret[i--] = n%10 + '0';
    n /= 10;
  } while(n);

  return ret;
}


<mine>
#include <iostream>
#include <string>
#include <memory>

using namespace std;

char* itoa_one(int n)
{
  unsigned int num_chars = 0;
  bool sign = false;
  char* buffer = NULL;

  // check sign and make it positive
  if( n < 0 )
  {
    sign = true;
    n = -n;
  }

  // needs a space for the sign?
  if(sign)
    num_chars++;

  // works out num_chars
  int temp = n;
  do {
    temp /= 10;
    num_chars++;
  } while(temp);

  // allocate string and null
  buffer = new char[num_chars+1];

  // note: missed
  buffer[num_chars] = 0;

  // needs the sign?
  if(sign)
    buffer[0] = '-';

  // converts integer from the end

  // note: missed
  num_chars--;

  do {
    buffer[num_chars--] = '0' + n % 10;
  } while(n/=10);

  return buffer;
}

int main()
{
  char *str = itoa_one(-256);
  cout << "converted string: " << str << endl;
}

// <2> From internet.
// https://android.googlesource.com/kernel/lk/+/qcom-dima-8x74-fixes/lib/libc
// /* Copyright (c) 2012, The Linux Foundation. All rights reserved.
//  */
// 
// #include <stdlib.h>
// #include <string.h>
// #include <ctype.h>
// 
// int itoa(int num, unsigned char* str, int len, int base)
// {
//   int sum = num;
//   int i = 0;
//   int digit;
// 
//   if (len == 0)
//     return -1;
// 
//   do
//   {
//     // sign will remain after %
//     digit = sum % base;
// 
//     if (digit < 0xA)
//       str[i++] = '0' + digit;
//     else
//       str[i++] = 'A' + digit - 0xA; // what is it?
// 
//     sum /= base;
// 
//   }while (sum && (i < (len - 1)));
// 
//   if (i == (len - 1) && sum)
//     return -1;
// 
//   str[i] = '\0';
//   strrev(str); // reverse a string. note this is not part of standard c
// 
//   return 0;
// }


{2} ansic, p64

<code>
void itoa( int n, char s[] )
{
  int i, sign;

  if( (sign = n) < 0 )     // record sign
    n = -n;                // make n positive

  i = 0;

  do {                        // generate digits in reverse order
    s[i++] = '0' + n % 10;    // get next digit
  } while( (n /= 10) > 0 );   // delete it

  if(sign < 0)
    s[i++] = '-';

  s[i] = '\0';

  reverse(s);
}


<mine>
#include <iostream>
#include <string>
#include <cstring>

using namespace std;

void reverse(char *s)
{
  int start, end, temp;

  // note: strlen(s)-1 ?
  for(start = 0, end = strlen(s)-1; start < end; start++, end--)
  {
    temp = s[start];
    s[start] = s[end];
    s[end] = temp;
  }
}

void itoa_two( int n, char s[] )
{
  int num_chars = 0, sign = 0;

  // note: can be shorten as code
  if( n < 0 )
  {
    sign = 1;
    n = -n;
  }

  do {
    s[num_chars++] = '0' + n % 10;
  } while( n/=10 );

  if( sign )
    s[num_chars++] = '-';

  s[num_chars] = 0;

  reverse(s);
}

int main()
{
  char text[100] = {0};
  itoa_two( -256, text );
  cout << "converted string: " << text << endl;
}


<ex>
The ansic, page 64, exercise 3-5. Write the function itob(n,s,b) that converts
the integer n into a base b character representation in the string s. In
particular, itob(n,s,16) formats n as a hexadecimal integer in s. 

#include <stdio.h>
#include <string.h>

void reverse(char s[])
{
  int c, i, j;

  for( i = 0, j = strlen(s)-1; i < j; i++, j-- )
    c = s[i], s[i] = s[j], s[j] = c;
}

// The point is that bit representation is the same regardless of base and so do
// the mod operation. The problem is that char set from 0 to Z used is not
// contiguous in ASCII and the below is handy.
// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_3:Exercise_5 Of course,
// this version do not support XXX_MIN handling.

void itob_one(int n, char s[], int b) 
{
  static char digits[] = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ";
  int i, sign;

  if ( b < 2 || b > 36 ) {
    fprintf(stderr, "EX3_5: Cannot support base %d\n", b);
    return;
  }

  if ((sign = n) < 0)
    n = -n;

  i = 0;

  do {
    s[i++] = digits[n % b];
  } while ((n /= b) > 0);

  if (sign < 0)
    s[i++] = '-';

  s[i] = '\0';

  reverse(s);
}

// this do not use char array but not works for singed case. 
int itob_two(int num, char* str, int base)
{
  int sum = num;
  int i = 0;
  int digit;

  //if (len == 0)
  //  return -1;

  do
  {
    // sign will remain after %
    digit = sum % base;

    if (digit < 0xA)
      str[i++] = '0' + digit;
    else
      str[i++] = 'A' + digit - 0xA; // what is it?

    sum /= base;

  // }while (sum && (i < (len - 1)));
  }while (sum );

  // if (i == (len - 1) && sum)
  //   return -1;

  str[i] = '\0';
  reverse(str);
  // strrev(str); // reverse a string. note this is not part of standard c

  return 0;
}

int main(int argc, char* argv[])
{
  char text1[100] = {0};

  {
    printf("-------------------\n");

    itob_one( 256, text1, 10 );
    printf("itoa'ed string:%s\n", text1);

    itob_one( -256, text1, 10 );
    printf("itoa'ed string:%s\n", text1);

    itob_one( 256, text1, 8 );
    printf("itoa'ed string:%s\n", text1);

    itob_one( 256, text1, 16 );
    printf("itoa'ed string:%s\n", text1);
  }

  {
    printf("-------------------\n");

    itob_two( 256, text1, 10 );
    printf("itoa'ed string:%s\n", text1);

    itob_two( -256, text1, 10 );
    printf("itoa'ed string:%s\n", text1);

    itob_two( 256, text1, 8 );
    printf("itoa'ed string:%s\n", text1);

    itob_two( 256, text1, 16 );
    printf("itoa'ed string:%s\n", text1);
  }
} 

-------------------
itoa'ed string:256
itoa'ed string:-256
itoa'ed string:400
itoa'ed string:100
-------------------
itoa'ed string:256
itoa'ed string:.+*
itoa'ed string:400
itoa'ed string:100


<exercise>
The ansic, page 64, exercise 3-6. Write a version of itoa that accepts three
arguments instead of two. The third argument is a minimum field width; the
converted number must be padded with blanks on the left if necessary to make it
wide enough.

void itoa_w(int n, char s[], int w)
{
  int sign;

  if( (sign = n ) < 0 )
    n = -n;

  int i = 0;

  do {
    s[i++] = n % 10 + '0';
  } while( ( n /= 10 ) );

  if(sign < 0)
    s[i++] = '-';

  // here, the value of i is both the number of characters in number
  // representation and the index of array for a next char.
  // '2' '5' '6' '\0'
  //  0   1   2   3 

  int fill;
  for( fill = i; fill < w; fill++ )
    s[fill] = '0';

  s[fill] = '\0'; 

  reverse(s);
}

int main(int argc, char* argv[])
{
  int tests[5] = {256, INT_MAX, -300, 172, 38478235};
  char st[101] = "";
  int i;

  for (i = 0; i < 5; i++) {
    mitoa_width(tests[i], st, 9);
    printf("%12d in string form is %12s\n", tests[i], st);
  }

  return 0;
} 

The simpler is:

void itoa_w(int n, char s[], int w)
{
  int sign;

  if( (sign = n ) < 0 )
    n = -n;

  int i = 0;

  do {
    s[i++] = n % 10 + '0';
  } while( ( n /= 10 ) );

  if(sign < 0)
    s[i++] = '-';

  while( i < w )
    s[i++] = '0';

  s[i] = '\0'; 

  reverse(s);
}


<example> ansic, p87
This is recursive version that do not need reverse function.

void printd(int n)
{
  if( n < 0 )
  {
    putchar('-');
    n = -n;
  }

  if(n/10)
    printd(n/10);

  putchar( n%10 + '0');
}


<exercise>
The ansic, page 88, exercise 4-12. Adapt the ideas of printd to write a recursive version of itoa ;
that is, convert an integer into a string by calling a recursive routine.

// when use printd directly. got idea from mitoa_rec_two

char *mitoa_rec(int n, char s[])
{
  if( n < 0 )
  {
    // putchar('-');
    *s++ = '-';
    n = -n;
  }

  if(n/10)
    s = mitoa_rec(n/10, s );

  // putchar( n%10 + '0');
  *s++ = (n%10 + '0');
  *s = '\0';

  return s;
}

// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_4:Exercise_12
// Here is the first solution by Flash Gordon, which uses pointers which have not been introduced by
// this point. It relies on the C99 behaviour of dividing a negative number rounding towards zero. 

char *mitoa_rec_two(int n, char s[], int base)
{
  int d = n % base;
  int r = n / base;
  if (n < 0) {
    *s++ = '-';
    d = -d;
    r = -r;
  }
  if (r)
    s = itoa_rec(r, s, base);
  *s++ = "0123456789abcdefghijklmnopqrstuvwxyz"[d]; // note how to use
  *s = 0;
  return s;
}


int main(int argc, char* argv[])
{
  int tests[5] = {256, INT_MAX, -300, 172, 38478235};
  char st[101] = "";
  int i;

  printf("---------------------\n");

  for (i = 0; i < 5; i++) {
    mitoa_rec_two(tests[i], st, 10);
    printf("%12d in string form is %12s\n", tests[i], st);
  }

  printf("---------------------\n");

  for (i = 0; i < 5; i++) {
    mitoa_rec(tests[i], st);
    printf("%12d in string form is %12s\n", tests[i], st);
  }

  return 0;
}


={============================================================================
*kt_dev_glib_004* printf

// stdio-common/printf.c
/* Write formatted output to stdout from the format string FORMAT.  */
/* VARARGS1 */
int
__printf (const char *format, ...)
{
  va_list arg;
  int done;

  va_start (arg, format);
  done = vfprintf (stdout, format, arg);
  va_end (arg);

  return done;
}

#undef _IO_printf
ldbl_strong_alias (__printf, printf);


={============================================================================
*kt_dev_glib_005* qsort

The ansic said that the standard qsort can sort 'any' object type. Wondered how?

NAME
       qsort - sorts an array

SYNOPSIS
       #include <stdlib.h>

       void qsort(void *base, size_t nmemb, size_t size,
                  int(*compar)(const void *, const void *));

DESCRIPTION
       The  qsort()  function sorts an array with nmemb elements of size size.
       The base argument points to the start of the array.

The example in the man page.

static int
cmpstringp(const void *p1, const void *p2)
{
  /* The actual arguments to this function are "pointers to
     pointers to char", but strcmp(3) arguments are "pointers
     to char", hence the following cast plus dereference */

  return strcmp(* (char * const *) p1, * (char * const *) p2);
}

int main(int argc, char *argv[])
{
  int j;

  if (argc < 2) {
    fprintf(stderr, "Usage: %s <string>...\n", argv[0]);
    exit(EXIT_FAILURE);
  }

  qsort(&argv[1], argc - 1, sizeof(argv[1]), cmpstringp);

  for (j = 1; j < argc; j++)
    puts(argv[j]);
  exit(EXIT_SUCCESS);
}

$ ./a.out h e l l o w o r l d
d
e
h
l
l
l
o
o
r
w


<code>
int compint(const void *p1, const void *p2)
{
  return *(const int *)p1 - *(const int *)p2;
}

int main()
{
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  qsort( arr, size, sizeof(int), compint );

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}

kt@kt-ub-vb:~/work$ ./a.out 
{ 2, 5, 6, 6, 10, 12, 13, 15, 17, 29, 30, 31, 33, }


<ansic-version>

// ansic, p110 which is pointer array version
void qsort( char *v[], int left, int right )
{
  int i, last;

  // do nothing if array contains fewer than two elements
  if( left >= right )
    return;

  // move partition elem
  swap( v, left, (left+right)/2 );

  last = left;  // to v[0]

  // partition
  for(i = left+1; i <= right; i++)
    if( strcmp(v[i], v[left]) < 0 )
      swap( v, ++last, i );

  // restore partition elem
  swap(v, left, last);

  qsort( v, left, last-1 );
  qsort( v, last+1, right );
}

How can make this to support 'any' data type and 'independent' of comparison and exchange
operations? ansic, p119.

char *lineptr[MAXLINES];

void qsort( void *v[], int, int, int (*)(void*, void*) );
int numcmp( char *, char *);

int main()
{
  int numeric = 0;

  // set numeric from argv

  qsort( (void*) lineptr, 0, nlines-1, 
      (int(*)(void*, void*))( numeric ? numcmp : strcmp ));
}

void qsort( void *v[], int left, int right, int (*comp)(void*, void*) )
{
  int i, last;

  if( left >= right )
    return;

  swap( v, left, (left+right)/2 );
  
  last = left;

  for( i = left+1; i <= right; i++ )
    if( (*comp)( v[i], v[left] ) < 0 )    // or comp(...)
      swap( v, i, ++last );

  swap( v, left, last );

  qsort( v, left, last-1 );
  qsort( v, last+1, right );
}

// not sure how it's supposed to sort 'numerically' since atof("abc") returns 0.0 as atoi does
int numcmp( char *s1, char *s2 )
{
  double v1, v2;

  v1 = atof(s1);
  v2 = atof(s2);

  if( v1 < v2 )
    return -1;
  else if ( v1 > v2 )
    return 1;
  else
    return 0;
}

void swap( void *v[], int i, int j )
{
  void *temp;     // <diff>

  temp = v[i];
  v[i] = v[j];
  v[j] = temp;
}

The first is to use (void) pointer since can cast to void * and back again without loss of
information. The second is to use function pointers.


<exercise>
ansic, exercise 5-14. Modify the sort program to handle a -r flag, which indicates sorting in
reverse (decreasing) order.  Be sure that -r works with -n.

void cqsort( int v[], int left, int right )
{
  int i, last;

  // do nothing if array contains fewer than two elements
  if( left >= right )
    return;

  // move partition elem
  swap( v, left, (left+right)/2 );

  last = left;  // to v[0]

  // partition
  for(i = left+1; i <= right; i++)
    //if( v[i] < v[left] )
    if( v[i] > v[left] )         // to reverse
      swap( v, ++last, i );

  // restore partition elem
  swap(v, left, last);

  cqsort( v, left, last-1 );
  cqsort( v, last+1, right );
}


int compint(const void *p1, const void *p2)
{
  //return *(const int *)p1 - *(const int *)p2;
  return *(const int *)p2 - *(const int *)p1;      // to reverse
}

int main()
{
  int arr[] = { 30, 2, 31, 5, 33, 6, 12, 10, 13, 15, 17, 29, 6 };
  int size = ( sizeof(arr)/sizeof(arr[0]));

  cqsort( arr, 0, size-1 );
  // qsort( arr, size, sizeof(int), compint );

  std::cout << "{ "; 

  for(int idx = 0; idx < size; idx++)
    std::cout << arr[idx] << ", "; 

  std::cout << "}" << std::endl; 
}


<exercise>
ansic, exercise 5-15. Add the option -f to fold upper and lower case together, so that case
distinctions are not made during sorting; for example, a and A compare equal.

http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_15

The key is to use strcmp which support no case.

/* strcmp_f */
int strcmp_f(char *s, char *t)
{
  for ( ; toupper(*s) == toupper(*t); s++, t++)
    if (*s == '\0')
      return 0;

  return toupper(*s) - toupper(*t);
}


={============================================================================
*kt_dev_glib_006* tail-program

<ex> *ex-tail* *ex-interview*
A question of google first phone screening.

The ansic, page 118, exercise 5-13. Write the program tail, which prints the
last n lines of its input. By default, n is 10, say, but it can be changed by an
optional argument, so that

tail -n

prints the last n lines. The program should behave rationally no matter how unreasonable the input
or the value of n. Write the program so it makes the best use of available storage; lines should be
stored as in the sorting program of Section 5.6, not in a two-dimensional array of fixed size.

<outline>
handle -n option; get and set n variable, allocate n pointer array.

read all lines of input, readlines()
- read until EOF and return #read lines.
- use %n to fill pointer array in circular fashion.

write at most n lines, writelines()
- if the return value from readlines is smaller than n, then print #return lines from 0.
- if the return value from readlines is greater than n, then print n lines from /n.

<code>
<1> mine based on sort example in p108.

#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define MAXLINES 100
char *lineptr[MAXLINES];

#define MAXLEN  1000

// <one> notice that it includes '\n'
int mygetline(char line[], int maxlen )
{
  int c, i;

  // <Q1> also notice that ' < maxlen-1' leave one space for a null
  for(i = 0; i < maxlen-1 && ((c = getchar()) != EOF) && c != '\n'; i++)
    line[i] = c;

  // <Q2>
  if( c == '\n')
  {
    line[i] = c;
    ++i;
  }

  line[i] = '\0';
  return i;
}

// returns n line when [0, n-1]
int readlines( char *v[], int max )
{
  char *p, line[MAXLEN];
  int len, cline, rlines = 0;

  while((len = mygetline(line, MAXLEN)) > 0 )
  {
    // get current line
    cline = rlines++%max;

    // if v[] is used before
    if( v[cline] != NULL )
      free( v[cline] );
   
    if( (p = (char *)malloc(len)) == NULL )
    {
      printf("readline: error: p is null\n");
      return -1;
    }

    //line[len-1] = '\0';     // this depends on how it will be printed out in writelines. use
    //"%s\n" or "%s"
    strcpy( p, line );
    v[cline] = p;
  }

  return rlines;
}

// first try
//void writelines( char *v[], int lines, int max )
//{
//  int wlines = 0;
//
//  if( lines <= max )
//  {
//    // print from 0 for lines
//    int n;
//    for(n = 0; n < lines; n++)
//      printf("%s", lineptr[n] );
//  }
//  else
//  {
//    // print from lines%max for max
//    int n;
//    int cline;
//
//    for( n = 0, cline = lines%max; n < max; n++, cline++ )
//      printf("%s", lineptr[cline%max] );
//  }
//}

// second try based on the <2>
void writelines( char *v[], int lines, int max )
{
  // print from lines%max for max
  int n;
  int cline;

  for( n = 0; n < max; n++ )
  {
    cline = (lines+n)%max;
    if( lineptr[cline] )
    {
      printf("%s", lineptr[cline] );
      free( lineptr[cline] );
    }
  }
}

// do not handle error of handling argvs.
// do not use malloc on lineptr.
//
int main( int argc, char *argv[] )
{
  int max_line = 10;

  if( --argc > 0 && (*++argv)[0] == '-' )
  {
    max_line = atoi( ++argv[0] ); 
    printf("set max line is %d\n", max_line );
  }

  printf("max line is %d\n", max_line );

  int nlines;

  if(( nlines = readlines( lineptr, max_line )) >= 0 )
  {
    writelines( lineptr, nlines, max_line );
    return 0;
  }
  else
  {
    printf("error: input too big to tail\n");
    return 1;
  }
}


<2> Steven Huang's solution, http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_13
/* K&R Exercise 5-13 */
/* Steven Huang */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define DEFAULT_NUM_LINES      10
#define MAX_LINE_LEN           1000

// Points of interest for a novice:
//
// 1. atoi() has a normally annoying property of not being able to tell the caller conclusively
// whether the input was bad ("abc") or it was really zero ("0"), because it returns 0 for both
// cases. Here, we exploit that property, because we only want to accept options in the form of
// "-n".                      
//
// note: this is to print outputs and is taken in the second try.
// 2. Try to understand how this program deals with input that doesn't even have as many lines as
// the line_ptrs[] array. That is, how does this program degenerate into just displaying everything
// it read?  (Hint:  what does it mean when line_ptrs[x] is NULL?)
//
// 3. Using modulo arithmetic on an index to a 'circular' array is a common and useful technique.
//
// Try to understand the range of values that current_line (and j, later) will take. In
// particular, why shouldn't we just do this:
//
//     for (i = 0; i < num_lines; i++)
//       if (line_ptrs[i])    
//         printf("%s", line_ptrs[i]);
//
// 4. Why do we still use a "%s" to display what's inside line_ptrs, rather than just:
//
//     printf(line_ptrs[i]);
// 
// 5.  There is a bug in this program, where you see:
//
//     numlines = -numlines;
//
//     When will this break? note: this means when it is the largest negative number

/* K&R2 p29 */
int mgetline(char s[], int lim)
{
  int c, i;

  for (i = 0; i < lim - 1 && (c = getchar()) != EOF && c != '\n'; i++)
    s[i] = c;
  if (c == '\n')
    s[i++] = c;
  s[i] = '\0';
  return i;
}

/* duplicates a string */
char *dupstr(const char *s)
{
  char *p = malloc(strlen(s) + 1); 

  if (p)
    strcpy(p, s);
  return p;
}

int main(int argc, char *argv[])
{
  int num_lines = DEFAULT_NUM_LINES;
  char **line_ptrs;
  char buffer[MAX_LINE_LEN];
  int i;
  unsigned j, current_line;

  if (argc > 1) {
    // We use a little trick here. The command line parameter should be in the form of "-n", where n
    // is the number of lines. We don't check for the "-", but just pass it to atoi() anyway, and
    // then check if atoi() returned us a negative number.
    // note: the trick is to expect -10 from atoi("-10");

    num_lines = atoi(argv[1]);

    if (num_lines >= 0) {
      fprintf(stderr, "Expected -n, where n is the number of lines\n");
      return EXIT_FAILURE;                                           
    }

    // Now make num_lines the positive number it's supposed to be.
    num_lines = -num_lines;
  } 

  // First, let's get enough storage for a list of n pointers...
  line_ptrs = malloc(sizeof *line_ptrs * num_lines);
  if (!line_ptrs) {
    fprintf(stderr, "Out of memory.  Sorry.\n");
    return EXIT_FAILURE;
  }

  // and make them all point to NULL
  for (i = 0; i < num_lines; i++)
    line_ptrs[i] = NULL;

  // Now start reading
  current_line = 0;
  do {
    mgetline(buffer, sizeof buffer);
    if (!feof(stdin)) {
      if (line_ptrs[current_line]) {
        // there's already something here
        free(line_ptrs[current_line]);
      }

      line_ptrs[current_line] = dupstr(buffer);
      if (!line_ptrs[current_line]) {
        fprintf(stderr, "Out of memory.  Sorry.\n");
        return EXIT_FAILURE;
      }

      current_line = (current_line + 1) % num_lines;
    }

  } while (!feof(stdin));

  // Finished reading the file, so we are ready to print the lines
  for (i = 0; i < num_lines; i++) {
    j = (current_line + i) % num_lines;
    if (line_ptrs[j]) {
      printf("%s", line_ptrs[j]);
      free(line_ptrs[j]);
    }
  }

  return EXIT_SUCCESS;
}

<3> C++ version
#include <iostream>
#include <string>
#include <fstream>   // for ifstream
#include <vector>

using namespace std;

const int MAXLINE=10;

// tail filename
int main(int argc, char* argv[] )
{
  vector<string> file;

  if( argc != 2 )
  {
    cerr << "usuage: tail filename" << endl;
    exit(1);
  }

  std::ifstream ifs( argv[1], std::ifstream::in );

  for( int i = 0; i < MAXLINE; i++ )
    file.push_back( string() );

  string line;
  int lines = 0, totalLines = 0;

  // read lines
  while( getline(ifs, line) )
  {
    cout << "read:" << lines << ":" << line << endl;
    file[lines] = std::move(line);
    totalLines++;
    lines++;
    lines = lines % MAXLINE;
    // lines = lines++ % MAXLINE;   // note: cause seg fault <TODO> needs to find out more
  }

  // write lines
  // note: this do not work when more than MAX
  for( int i = 0; i < MAXLINE; i++ )
  {
    if( (totalLines < MAXLINE) && !file[lines].empty() )
      cout << "write:" << lines << ":" << file[lines] << endl;

    lines++;
    lines = lines % MAXLINE;
  }

  ifs.close();
}

<4> corrected version
note: Can use argv for vector creation and uses the fixed value for simplicity.
note: Used read line count only and the key is that write loop is used only to use the number of
loop. Not use loop index value.
note: See how C++ code is simpler than C.

#include <iostream>
#include <string>
#include <fstream>
#include <vector>

using namespace std;

const int MAXLINE=10;

int main(int argc, char* argv[])
{
  vector<string> ifile;

  if( argc != 2 )
  {
    cerr << "usage: tail filename" << endl;
    exit(1);
  }

  std::ifstream ifs( argv[1], std::ifstream::in );

  for( int i = 0; i < MAXLINE; i++ )
    ifile.push_back( string() );

  string line;
  int rlines = 0;

  // read lines
  while( getline(ifs, line) )
  {
    // cout << "read:" << rlines << ":" << line << endl;
    ifile[rlines++] = std::move(line);
    rlines %= MAXLINE;
  }

  // write lines
  for(int i = 0; i < MAXLINE; i++)
  {
    if(!ifile[rlines].empty())
      cout << "write: " << rlines << ":" << ifile[rlines] << endl;

    rlines = (rlines+1) % MAXLINE;
  }

  ifs.close();
}


kt@kt-ub-vb:~/work$ cat inputless.txt 
1: this is one
2: this is two
3: this is three
4: this is four
5: this is five
6: this is six
7: this is seven
8: this is eight

kt@kt-ub-vb:~/work$ cat inputmore.txt 
1: this is one
2: this is two
3: this is three
4: this is four
5: this is five
6: this is six
7: this is seven
8: this is eight
9: this is nine
10: this is ten
11: this is ten+1
12: this is ten+2


={============================================================================
*kt_dev_glib_007* fopen

fopen works for all:

char fname1[] = "./input.txt";
char fname2[] = ".//input.txt";
char fname3[] = ".///input.txt";
char fname4[] = "./if/comp.sh";
char fname5[] = "./if//comp.sh";
char fname6[] = "./if///comp.sh";


={============================================================================
*kt_dev_glib_008* isdigit


include/ctype.h

/* The spec says that isdigit must only match the decimal digits.  We
   can check this without a memory access.  */
#  undef isdigit
#  define isdigit(c) ({ int __c = (c); __c >= '0' && __c <= '9'; })

note that if there is no second part, x && y, then emits compile error.

if(({ int __c = (c); __c >= '0' && __c <= '9'; }))


<isspace>
This includes '\n'


={============================================================================
*kt_dev_glib_010* abs

stblib/abs.c

/* Return the absolute value of I.  */
int
abs (int i)
{
  return i < 0 ? -i : i;
}


={============================================================================
*kt_dev_glib_101* general tips

o use tabstop=6 to view
o each function has a single c file so search file than using a tag since tag search do not work for
some.

<def-wide>
#ifdef USE_WIDE_CHAR
# include <wctype.h>
# define L_(Ch) L##Ch
# define UCHAR_TYPE wint_t
# define STRING_TYPE wchar_t
# define ISSPACE(Ch) __iswspace_l ((Ch), loc)
# define ISALPHA(Ch) __iswalpha_l ((Ch), loc)
# define TOUPPER(Ch) __towupper_l ((Ch), loc)
#else
# if defined _LIBC \
   || defined STDC_HEADERS || (!defined isascii && !defined HAVE_ISASCII)
#  define IN_CTYPE_DOMAIN(c) 1
# else
#  define IN_CTYPE_DOMAIN(c) isascii(c)
# endif
# define L_(Ch) Ch   <use>
# define UCHAR_TYPE unsigned char
# define STRING_TYPE char
# define ISSPACE(Ch) __isspace_l ((Ch), loc)
# define ISALPHA(Ch) __isalpha_l ((Ch), loc)
# define TOUPPER(Ch) __toupper_l ((Ch), loc)
#endif


={============================================================================
*kt_dev_glib_200* strcpy and strncpy

{reference-code}
/* strcpy: copy t to s; pointer version 
 * lib: The strcpy() and strncpy() functions return a pointer to the destination string dest
 */
void strcpy( char *s, char *t )
{
  while( *s++ = *t++ ) 
    ;
}

{man-page}
#include <string.h>

char *strcpy(char *dest, const char *src);
char *strncpy(char *dest, const char *src, size_t n);

DESCRIPTION
The strcpy() function copies the string pointed to by src, 'including' the terminating null byte
('\0'), to the buffer pointed to by dest. The strings may not overlap, and the destination string
dest must be large enough to receive the copy.

The  strncpy()  function  is similar, except that at most n bytes of src are copied.

Warning: If there is no null byte among the first n bytes of src, the string  placed in dest will
'not' be null-terminated.

If the length of src is less than n, strncpy() 'pads' the remainder of dest with null bytes.

       A simple implementation of strncpy() might be:

           char *
           strncpy(char *dest, const char *src, size_t n)
           {
               size_t i;

               for (i = 0; i < n && src[i] != '\0'; i++)
                   dest[i] = src[i];
               for ( ; i < n; i++)
                   dest[i] = '\0';

               return dest;
           }

NOTES
       Some  programmers consider strncpy() to be inefficient and error prone.  If the pro‐
       grammer knows (i.e., includes code to test!)  that the size of dest is greater  than
       the length of src, then strcpy() can be used.

       If  there  is  no  terminating null byte in the first n characters of src, strncpy()
       produces an unterminated string in dest.  Programmers often prevent this mistake  by
       forcing termination as follows:

           strncpy(buf, str, n);
           if (n > 0)
               buf[n - 1]= '\0';

BUGS
       If  the  destination  string  of a strcpy() is not large enough, then anything might
       happen.  Overflowing fixed-length string buffers is a favorite cracker technique for
       taking  complete  control  of  the machine.  Any time a program reads or copies data
       into a buffer, the program first needs to check that there's enough space.  This may
       be unnecessary if you can show that overflow is impossible, but be careful: programs
       can get changed over time, in ways that may make the impossible possible.

<KT> 
strcpy can be a problem in two points:
1) there is no null in src. do not know when stop copying.
2) dest is not large enough.

strncpy can be a problem.
1) there is no null in n bytes of src then dest is not null terminated. 


{glibc}
// string/strcpy.c
/* Copy SRC to DEST.  */
char *
strcpy (dest, src)
     char *dest;
     const char *src;
{
  char c;
  char *s = (char *) src;

  // this is offset between src and dest. then why -1? because used in do-loop below and increase s
  // anyway so need to -1.
  //
  // src
  // [ ] [ ] [ ] [ ]
  //                     by off
  //     [ ] [ ] [ ] [ ]
  //     dst
  //
  const ptrdiff_t off = dest - s - 1;

  do
  {
    c = *s++;
    s[off] = c;
  }
  while (c != '\0');

  return dest;
}


// string/strncpy.c
char *
STRNCPY (char *s1, const char *s2, size_t n)
{
  char c;
  char *s = s1;

  --s1;

  if (n >= 4)
  {
    size_t n4 = n >> 2;

    for (;;)
    {
      c = *s2++;
      *++s1 = c;
      if (c == '\0')
        break;
      c = *s2++;
      *++s1 = c;
      if (c == '\0')
        break;
      c = *s2++;
      *++s1 = c;
      if (c == '\0')
        break;
      c = *s2++;
      *++s1 = c;
      if (c == '\0')
        break;
      if (--n4 == 0)
        goto last_chars;
    }
    n = n - (s1 - s) - 1;
    if (n == 0)
      return s;
    goto zero_fill;
  }

last_chars:
  n &= 3;
  if (n == 0)
    return s;

  do
  {
    c = *s2++;
    *++s1 = c;
    if (--n == 0)
      return s;
  }
  while (c != '\0');

zero_fill:
  do
    *++s1 = '\0';
  while (--n > 0);

  return s;
}


<exercise> 
From ansic, p107, exercise 5-5. Write versions of the library functions strncpy, strncat, and
strncmp, which operate on at most the first n characters of their argument strings. For example,
strncpy(s,t,n) copies at most n characters of t to s. Full descriptions are in Appendix B.


={============================================================================
*kt_dev_glib_201* strlen

{man-page}
NAME
       strlen - calculate the length of a string

SYNOPSIS
       #include <string.h>
       size_t strlen(const char *s);

DESCRIPTION
       The  strlen()  function  calculates the length of the string s,
       'excluding' the terminating null byte ('\0').

RETURN VALUE
       The strlen() function returns the number of characters in s.

CONFORMING TO
       SVr4, 4.3BSD, C89, C99.

SEE ALSO
       string(3), strnlen(3), wcslen(3), wcsnlen(3)

{glibc}
string/strlen.c

/* Return the length of the null-terminated string STR. Scan for
   the null terminator <DN> quickly by testing four bytes at a time.  */

size_t
strlen (str) const char *str;
{
  const char *char_ptr;
  const unsigned long int *longword_ptr;
  unsigned long int longword, himagic, lomagic;

  /* Handle the first few characters by reading one character at a time.
     Do this until CHAR_PTR is aligned on a longword boundary.  */
  // [KT] this moves a pointer until found the alignment boundary and return if found null before
  // the boundary.
  for (char_ptr = str; ((unsigned long int) char_ptr & (sizeof (longword) - 1)) != 0; ++char_ptr)
    if (*char_ptr == '\0')
      return char_ptr - str;

  /* All these elucidatory comments refer to 4-byte longwords,
     but the theory applies equally well to 8-byte longwords.  */
  longword_ptr = (unsigned long int *) char_ptr;

  /* Bits 31, 24, 16, and 8 of this number are zero. Call these bits
     the "holes." Note that there is a hole just to the left of
     each byte, with an extra at the end:

    bits:  01111110 11111110 11111110 11111111
    bytes: AAAAAAAA BBBBBBBB CCCCCCCC DDDDDDDD

    The 1-bits make sure that carries propagate to the next 0-bit.
    The 0-bits provide holes for carries to fall into.  */

  himagic = 0x80808080L; 
  lomagic = 0x01010101L;

  // [KT]
  // if (sizeof (longword) > 4)
  // {
  //   /* 64-bit version of the magic.  */
  //   /* Do the shift in two steps to avoid a warning if long has 32 bits.  */
  //   himagic = ((himagic << 16) << 16) | himagic;
  //   lomagic = ((lomagic << 16) << 16) | lomagic;
  // }
  // if (sizeof (longword) > 8)
  //   abort ();

  /* Instead of the traditional loop which tests each character,
     we will test a longword at a time. The tricky part is testing
     if *any of the four* bytes in the longword in question are zero.  */
  for (;;)
  {
    longword = *longword_ptr++;
    // [KT] '&' is left-to-right and '~' is higher.
   
    /* Which of the bytes was the zero?  If none of them were, it was
       a misfire; continue the search.  */
    if (((longword - lomagic) & ~longword & himagic) != 0)
    {
      const char *cp = (const char *) (longword_ptr - 1);

      if (cp[0] == 0)
        return cp - str;
      if (cp[1] == 0)
        return cp - str + 1;
      if (cp[2] == 0)
        return cp - str + 2;
      if (cp[3] == 0)
        return cp - str + 3;
    }
    // [KT] removed the checks for sizeof(longword) > 4
  }
}

<case-one> char arr[] = {"abcdefghijkl"};

skipped a(0x61) and read four bytes as little endian.
                                       .         .         .         .
0x65646362; longword         "0110 0101 0110 0100 0110 0011 0110 0010
0x01010101; lomagic          "        1 0000 0001 0000 0001 0000 0001
0x64636261; longword-lomagic "0110 0100 0110 0011 0110 0010 0110 0001 
0x9A9B9C9D; ~logword         "1001 1010 1001 1011 1001 1100 1001 1101
0x80808080; himagic          "1000 0000 1000 0000 1000 0000 1000 0000
0x0       ; & result

<case-two> char arr[] = {"abcde"};

skipped first two and read three chars and null.

0x656463; longword       
0x00656463;                " <0000-0000> 110 0101 0110 0100 0110 0011
0x01010101; lomagic          "        1 0000 0001 0000 0001 0000 0001
0xFF646362; longword-lomagic:"1111 1111 0110 0100 0110 0011 0110 0010
0xFF9A9B9C; ~logword        :"1111 1111 1001 1010 1001 1011 1001 1100
0x80808080; himagic         :"1000 0000 1000 0000 1000 0000 1000 0000
0x80000000;                  "1000 0000 0000 0000 0000 0000 0000 0000

So if there is a null byte in the sequence then this byte will become 0x80 and if not, the end
result will be 0x0. So if the result is null, keep scanning.

<DN> There is no NULL pointer check on the input string. Of course, one can also argue that not
checking for NULL is fine as well. There is an asumption that there is an NULL in the input.


<ansic-example>
return length of s

int strlen( char s[] )
{
  int i = 0;

  while( s[i] != '\0' )
    ++i;

  return i;
}

// ansic, p103. excluding NULL.
int strlen( char *s )
{
  char *p = s;

  while( *p != '\0' )
    p++;

  return p-s;
}


={============================================================================
*kt_dev_glib_202* strcat

<ansic-example>
/* strcat: concatenate t to end of s; s must be big enough. note lib version returns a pointer of
 * resulting string
 */
void strcat( char s[], char t[] ) 
{
  int i, j;

  i = j = 0;
  while( s[i] != '\0' )                // find end of s
    i++;

  while( (s[i++] = t[j++]) != '\0' )   // copy t
    ;
}

<exercise> 
From ansic, exercise 5-3. Write a pointer version of the function strcat that we showed in Chapter
2: strcat(s,t) copies the string t to the end of s.

#include <stdio.h>

#define STR_BUFFER 10000

void mstrcat_one(char *, char *);
void mstrcat_two(char *s, char *t);
void mstrcat_three(char *s, char *t);
void mstrcat_four(char *s, char *t);

int main(int argc, char *argv[])
{
  //char string1[STR_BUFFER] = "What A ";
  char string1[STR_BUFFER] = "";
  char string2[STR_BUFFER] = "Wonderful World!";

  printf ("String 1:%s\n", string1);

  //mstrcat_one(string1, string2);
  //mstrcat_two(string1, string2);
  mstrcat_three(string1, string2);

  printf ("String 2:%s\n", string2);
  printf ("Cat Result:%s\n", string1);

  return 0;
}

// NOT OK.
// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_3
/* Concatenate t to s. */
void mstrcat_one(char *s, char *t)
{
  /*
   * '*++s' is used to reference the pointer before incremmenting it so
   * that the check for falsehood ('\0') is done with the next character
   * instead of '*s++' which would check, then increment. Using '*s++'
   * would increment the pointer to the base string past the null
   * termination character. When outputting the string, this made it
   * appear that no concatenation occurred because the base string is
   * cut off by the null termination character ('\0') that was never
   * copied over.
   */
  while(*++s); /* Get to the end of the string */
  while((*s++ = *t++));
}

// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_3
void mstrcat_two(char *s, char *t)
{
  /* run through the destination string until we point at the terminating '\0' */ 
  while('\0' != *s)
  {
    ++s;
  }

  /* now copy until we run out of string to copy */
  while('\0' != (*s = *t))
  {
    ++s;
    ++t;
  }
}

// NOT OK as mstrcat_one.
void mstrcat_three(char *s, char *t)
{
  while(*s++)
    ;

  while(*s++ = *t++)
    ;
}

void mstrcat_four(char *s, char *t)
{
  while(*s)
    s++;

  while(*s++ = *t++)
    ;
}


={============================================================================
*kt_dev_glib_203* strstr, strindex

From ansic p68, simple grep example. The strstr is similar to strindex, except that it returns a
pointer instead of an index.

// my outline
int strindex( char s[], char t[] )
{
  // scan trhough s
  for(int si = 0; s[si]; si++)
  {
    // scan through s and t as long as both matches and t[] or s[] is not null
    // when t[] ends first, loops ends and do not need consider.
    // when s[] ends first, loops ends and do not need consider.
    // when both ends at the same time, to prevent overrun, have a check one of them if it's null.
    for( int ti = 0, int tsi = si; t[ti] && s[tsi] == t[ti]; tsi++, ti++ )
      ;

    // if t[ti] is null, that means t is found.
    if( !t[ti] )
      return si;
  }

  return -1;
}

// reference code
int strindex( char s[], char t[] )
{
  int i, j, k;

  for( i = 0; s[i] != '\0'; i++ )
  {
    for( j=i, k=0; t[k] != '\0' && s[j]==t[k]; j++, k++ )
      ;

    // why k>0 ? when t is null string input, t[] = ""; 
    if( k > 0 && t[k] == '\0' )
      return i;

  return -1;
}

However, the reference code do +1 on s[] regardless of how many matched in t. For example, think
cases:

s: a b a b c d e ...   a a a b c d e ...
t: a b c d e

If know how many char mached in the inner search then the outer search could to that to skip and
could run a bit faster.

// strindex: return index of t in s, -1 if none
int strindex( char s[], char t[] )
{
  int sidx, tidx, start;

  start = -1;

  // loop through s
  for( sidx = 0, tidx = 0; s[sidx]; )
  {
    if( s[sidx] == t[tidx] )
    {
      start = sidx;

      // if s matches to the second of t
      while( s[++sidx] == t[++tidx] )
        ;

      // seen mismatch and exited while. exited since t reches the end?
      if( t[tidx] == '\0' )
        return start;
      // seem mismatch and exited while since different chars.
      else
      {
        start = -1;
        tidx = 0;
      }
    }
    else
      sidx++;
  }

  return start;
}


<exercise>
The ansic, page 71, exercise 4-1. Write the function strindex(s,t) , which returns the position of
the rightmost occurrence of t in s , or -1 if there is none. 

# idea 01
# Have the same approach as the original but keep going on the outer loop while updating the match
# rather than stop at the first match. That is to return the last match.

# idea 02
# Have the same structure as the original but starts from end of both. To do this, need to know the
# length of both which means loop through both.

# idea 03
# If can change input, reverse both array and run the original.

It seems that idea 01 may be the best since has less performance penalty but hae a bit more code.

int strindex_one( const char s[], const char t[] )
{
  // scan trhough s
  for(int si = 0; s[si]; si++)
  {
    int ti, tsi;
    // scan through s and t as long as both matches and t[] or s[] is not null
    for( ti = 0, tsi = si; t[ti] && s[tsi] == t[ti]; tsi++, ti++ )
      ;

    // if t[ti] is null, that means t is found.
    if( ti > 0 && t[ti] == '\0' )
      return si;
  }

  return -1;
}

// this is idea 01
int strindex_two( const char s[], const char t[] )
{
  int lsi = -1;

  // scan trhough s
  for(int si = 0; s[si]; si++)
  {
    int ti, tsi;
    // scan through s and t as long as both matches and t[] or s[] is not null
    for( ti = 0, tsi = si; t[ti] && s[tsi] == t[ti]; tsi++, ti++ )
      ;

    // if t[ti] is null, that means t is found.
    if( ti > 0 && t[ti] == '\0' )
      lsi = si;
  }

  return lsi;
}

int main(int argc, char* argv[])
{
  char line[MAXLINE];
  int found = 0;

  //                     012345678901
  found = strindex_one( " this is a long ago story, long really", "long" );
  printf("found %d\n", found );

  found = strindex_one( " this is a long ago story, long really", "longg" );
  printf("found %d\n", found );

  //                     012345678901234567890123456789
  found = strindex_two( " this is a long ago story, long really", "long" );
  printf("found %d\n", found );

  found = strindex_two( " this is a long ago story, long really", "longg" );
  printf("found %d\n", found );

  return found;
} 

$ ./a.out 
found 11
found -1
found 27
found -1


<exercise> strrstr?
From ansic, exercise 5-4. Write the function strend(s,t) , which returns 1 if the string t occurs at
the end of the string s, and zero otherwise.

Is the same approach as the above exercise 4-1? Not necessarily.

// http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_5:Exercise_4
int strend(char *s, char *t)
{
  s += (strlen(s) - strlen(t));     //increments to the point of comparison
  while (*s++ == *t++)              //tests for equality
    if (*s == '\0')                 //checks for null character while lines are equal
      return 1;
  return 0;
}

If has a check on.

int strend(char *s, char *t)
{
  int slen = strlen(s);
  int tlen = strlen(t);

  if( slen >= tlen )
  {
    s += (slen - tlen);     //increments to the point of comparison

    while (*s++ == *t++)              //tests for equality
      if (*s == '\0')                 //checks for null character while lines are equal
        return 1;

    return 0;
  }

  return -1;
}


={============================================================================
*kt_dev_glib_204* strcmp

From ansic p106. return <0 if s < t, 0 if s == t, > 0 if s > t.

int strcmp( char *s, char *t )
{
  for( int i = 0; s[i] == t[i]; i++ )
    if( s[i] == '\0' )
      return 0;

  return s[i] - t[i];
}

int strcmp( char *s, char *t )
{
  for( ; *s == *t; s++, t++ )
    if( *s == '\0' )
      return 0;

  return *s - *t;
}


={============================================================================
*kt_dev_glib_205* strpbrk, strtok

<exercise> <strpbrk>
From ansic, exercise 2-5. Write the function any(s1,s2), which returns the first location in the
string s1 where 'any' character from the string s2 occurs, or -1 if s1 contains no characters from
s2. (The standard library function strpbrk does the same job but returns a pointer to the location.)

STRPBRK(3)                 Linux Programmer's Manual                STRPBRK(3)

NAME
strpbrk - search a string for any of a set of characters

SYNOPSIS
#include <string.h>
char *strpbrk(const char *s, const char *accept);

DESCRIPTION
The  strpbrk() function locates the first occurrence in the string s of
any of the characters in the string accept.

RETURN VALUE
The strpbrk() function returns a pointer to the  character  in  s  that
matches  one  of the characters in accept, or NULL if no such character
is found.

// one
// not good since based on the "squeeze" approach which means more work to find the first time since
// key chars can happen any order and did not stop on "first" match
int any_mine( char s[], char t[] )
{
  int ret = -1;
  int i;

  // run through t[]
  for(; *t; t++)
  {
    // run through s[]
    for( i = 0; s[i]; i++ )
    {
      // found a match
      if( s[i] == *t )
      {
        // update found index when either it's the first time or found the less than the previous
        if( ret < 0 || i < ret )
        {
          ret = i;
          break;
        }
      }
    }
  }

  return ret;
}

// two
http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_2:Exercise_5

// The pedestrian solution is Richard Heathfield's
// Here is my solution, which is very simple but quite naive and inefficient. It has a worst-case
// time complexity of O(nm) where n and m are the lengths of the two strings.

int any_online_one(char s1[], char s2[])
{
  int i;
  int j;
  int pos;

  pos = -1;

  // by having "pos == -1" checks, two for loops stops as soon as found a match and means the
  // "first" location as the problem states. But the worst still O(nm).
  //
  // <Q> is this check on pos really needed? not really here since it returns when found. However,
  // if want to exit loop and continue doing, then pos is useful to exit loop as soon as found
  // rather than looping to the end. Like <goto-alternative> in dev_01.
  for(i = 0; pos == -1 && s1[i] != '\0'; i++)
  {
    for(j = 0; pos == -1 && s2[j] != '\0'; j++)
    {
      if(s2[j] == s1[i])
      {
        return pos = i;
      }
    }
  }

  return pos;
}

// three
// Could anything be simpler? Pilcrow 22:46, 24 August 2011 (UTC)
int any_online_two(char s1[], char s2[])
{
  int i;
  int j;

  // no need for further code when found a match
  for(i = 0; s1[i] != '\0'; i++)
  {
    for(j = 0; s2[j] != '\0'; j++)
    {
      if(s2[j] == s1[i])
      {
        return i;
      }
    }
  }

  return -1;
}

// four
http://clc-wiki.net/wiki/K%26R2_solutions:Chapter_2:Exercise_5

Here's a much better solution, by Partha Seetala. This solution has a worst- case time complexity of
only O(n + m) which is considerably better.

It works in a very interesting way. He first defines an array with one element for each possible
character in the character set, and then takes the second string and 'ticks' the array at each
position where the second string contains the character corresponding to that position. It's then a
simple matter to loop through the first string, quitting as soon as he hits a 'ticked' position in
the array.

#include <stdio.h> /* for NULL */

int any(char *s1, char *s2)
{
  char array[256]; /* rjh comments
                    * (a) by making this char array[256] = {0}; the first loop becomes unnecessary.
                    * (b) for full ANSIness, #include <limits.h>, make the array unsigned char,
                    *     cast as required, and specify an array size of UCHAR_MAX(255) + 1.
                    * (c) the return statements' (parentheses) are not required.
                    */
  int  i;
  if (s1 == NULL) {
    if (s2 == NULL) {
      return(0);
    } else {
      return(-1);
    }
  }

  for(i = 0; i < 256; i++) {
    array[i] = 0;
  }

  while(*s2 != '\0') {
    array[*s2] = 1;
    s2++;
  }

  i = 0;
  while(s1[i] != '\0') {
    if (array[s1[i]] == 1) {
      return(i);
    }
    i++;
  }
  return(-1);
}


<getword> <getop>

#include <stdio.h>
#include <ctype.h>
#include <string.h>

// This is to emulate getchar and not need. However shows the overrun issue.
// there shall be ' ' at the end to end the getop while loop since there is no ungetch. If there is
// no space at the end, get the last token and getop will get NULL since no ungetch and '\n' is
// already used. So get op return null but not '\n'. Hence run until core dumped. This is the result
// of overrun. 
static char input[] = "10.2 30 .2 101010.202020 \n";

static char words[] = "this is a string to tokenize \n\n";

int getch()
{
  static int i = 0;
  return input[i++];
}

int getchw()
{
  static int i = 0;
  return words[i++];
}

// ansic, p78. see <reverse-polish-calculator> for full example.
//
// int type;
// char s[MAXOP];
//
// while(( type = getop(s)) != EOF )
// {...}
int getop( char s[] )
{
  int i, c;

  // skip spaces. save the first when exits
  while( (s[0] = c = getch()) == ' ' || c == '\t' )
    ;

  // not a number such as EOF/NL but string is not used when get EOF. 
  // make a string for a caller to print.
  if( !isdigit(c) && c != '.' ) 
  {
    s[1] = '\0'; return c;
  }

  i = 0;

  // collect integer part
  if( isdigit(c) )
    while( isdigit( s[++i] = c = getch()) )
      ;

  // collect fraction part
  if( c == '.' )
    while( isdigit( s[++i] = c = getch()) )
      ;

  s[i] = '\0';

  //if( c != EOF )
  //  ungetch(c);

  return 1;     // to signal it's got the number
  // return NUMBER;     // '0' to signal it's got the number
}

// ansic, p136. get next word or character from input.
// char word[MAXWORD];
//
// while( getword( word, MAXWORD ) != EOF )
//  if( isalpha( word[0] ))
//  {...}
int getword( char *word, int lim )
{
  int c;
  char *w = word;

  // skip spaces.
  while(isspace(c = getchw()))
      ;

  if( c != EOF )
    *w++ = c;

  // not a alphabet such as EOF and make the output null sting. isspace includes '\n'.
  if( !isalpha(c) )
  {
    *w = '\0'; return c;
  }

  for(; --lim > 0; w++ )
    if( !isalpha(*w = getchw()) )
    {
      // ungetch(*w);
      break;
    }

  *w = '\0';

  return word[0];
}

int main( int argc, char *argv[] )
{
  char line[100];

  {
    while( getop(line) != '\n' )
      printf("%s\n", line ); 
  }

  {
    while( getword(line, 100) )
      printf("%s\n", line ); 
  }

  {
    char *token = NULL;
    token = strtok(input, " \n" );
    while( token )
    {
      printf("tok: %s\n", token );
      token = strtok(NULL, " \n" );
    }
  }
}

<getop-vs-getword>
1. getop handles only numeric values and for non-numeric, save it as a string for a caller to print.
This makes difference in handling not supported chars.

2. getop may have overrun when there are inputs more than buffer size since no check on that.

3. getwords prevents overrun and do not use return value as char (getop uses return value as a
operator to use). Also, uses word[0] to check

4. getop and getword assumes stdin which uses EOF to signal the end. May change to use on string to
get token.

<strtok>
The strtok() function parses a string into a sequence of tokens. On the first call to strtok() the
string to be parsed should be specified in str. In each subsequent call that should parse the same
string, str should be NULL.

strtok modify input string since replace delimiter with null so that user can have string operation
or print out. This means that can use strpbrk instead of using strtok.


={============================================================================
*kt_dev_glib_206* strdup

From ansic, p143.

char *strdup( char *s )
{
  char *p;

  p = (char *) malloc( strlen(s) + 1 ); // +1 for '\0'
  if( p != NULL )
    strcpy( p, s );

  return p;
}

This leaves error-handling to its caller when malloc returns NULL.


={============================================================================
*kt_dev_glib_207* strchr and basename

#include <string.h>

char *strchr(const char *s, int c);
char *strrchr(const char *s, int c);

The strchr() function returns a pointer to the first occurrence of the character c in the string s.

The strrchr() function returns a pointer to the last occurrence of  the character c in the string s.

<example> to get filename
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

int main(int argc, char** argv)
{
  char *argVec[5];

  argVec[0] = strrchr( argv[1], '/' );
  if( argVec[0] != NULL )
    argVec[0]++;
  else
    argVec[0] = argv[1];

  printf( "Usage: %s: %s cmd [args]\n\n"
          "Run `cmd` passing it `args` and run nexus-inspect"
          " when that completes\n"
          , argVec[0], basename(argv[1]));

  exit(EXIT_SUCCESS);
}


$ ./a.out /home/keitee/work/home/keitee/work
Usage: work: work cmd [args]

Run `cmd` passing it `args` and run nexus-inspect when that completes
$ 

note: man 3 basename which is glibc version.


={============================================================================
*kt_dev_glib_208* getopt

#include <unistd.h>

int getopt(int argc, char * const argv[], const char *optstring);

extern char *optarg;
extern int optind, opterr, optopt;

The getopt() function parses the command-line arguments. An element of argv that starts with '-'
    (and is not exactly "-" or "--") is an option element. The characters of this element (aside
            from the initial '-') are "option characters". If getopt() is called repeatedly, it
    'returns' successively each of the option characters from each of the option elements.

// note: return option characters whenever gets called successfully

The  variable  optind  is the index of the next element to be processed in argv.  The system
initializes this value to 1.  The caller can reset it to 1 to restart scanning of the same argv, or
when scanning a new argument vector.

// note: optind is index of argv[]

If getopt() finds another option character, it returns that character, updating the external
variable optind and a static variable nextchar so that the next call to getopt()  can resume the
scan with the following option character or argv-element.

// note: updates global optind

The  variable  optind  is the index of the next element to be processed in argv.  The system
initializes this value to 1.  The caller can reset it to 1 to restart scanning of the same argv, or
when scanning a new argument vector.

If there are no more option characters, getopt() returns -1.  Then optind is the index in argv of
the first argv-element that is not an option.

If  getopt()  does  not recognize an option character, it prints an error message to stderr, stores
the character in optopt, and returns '?'.  The calling program may prevent the error message by
setting opterr to 0.

#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>

int main( int argc, char* argv[])
{
  int opt, nsecs;

  while(( opt = getopt( argc, argv, "nt:")) != -1 )
  {
    switch(opt)
    {
      case 'n':
        fprintf( stderr, "got option n\n");
        break;

      case 't':
        nsecs = atoi( optarg );
        fprintf( stderr, "got option t, nsecs(%d)\n", nsecs );
        break;

        // note: this is for when fails to parse options but not there is 'no' options given.
      default:
        fprintf( stderr, "usuage: %s [-t nsecs] [-n] name \n", argv[0] );
        exit(EXIT_FAILURE);
    }
  }

  printf("opt=%d, optind=%d\n", opt, optind );

  if( optind >= argc )
  {
    fprintf( stderr, "expected arg after options\n");
    exit(EXIT_FAILURE);
  }

  exit(EXIT_SUCCESS);
}


$ ./a.out 
opt=-1, optind=1
expected arg after options

$ ./a.out -n
got option n
opt=-1, optind=2                                   // note: opt is -1 always outside of a loop
expected arg after options

$ ./a.out -t
./a.out: option requires an argument -- 't'        // note: message from getopt
usuage: ./a.out [-t nsecs] [-n] name 

So there should be a handing of case when there is no arguments given.

  if( argc == 1 ) 
  {
    usage( argv[0] );
    return EXIT_FAILURE;
  }


={============================================================================
*kt_dev_glib_300* malloc

From ansic 8.7, stroage allocator, p185

//**
// <arena>
// Since other activities in the program/system may also request space without calling 'this'
// allocator, malloc, the space that malloc manages may not be 'contiguous'. Its free storage is
// kept as a list of free blocks and it is a single circular linked list since the last points to
// the first.
//
// The blocks are kept in order of increasing address.
//
// ..| XXXX | in use | free | free | in use | free | XXXX | in use | free | in use | free | XXXX
//
// in use and free, owned by malloc. XXXX not owned by malloc.
//
// In sum, areana means the address space consisting of 'in use' and 'free' blocks and managed by
// malloc/free. Note that it is both 'use' and 'free' block.
//

typedef long Align;   // for alignment to long boundary

union header {  // block header
  struct {
    union header *ptr;  // next block if on free list. <Q> why union?
    unsigned size;
  } s;

  Align x;
};

typedef union header Header;

//
//   points to next free block
//   ^
// +---+------+-----------------------+
// |   | size |                       |
// +---+------+-----------------------+
//            ^
//            address returned to user

static Header base;           // empty list to get started
static Header *freep = NULL;  // start of free list


//**
// free: put block ap in free list
//
// <key> assumption to a caller. that pointers to different blocks returned by sbrk can be
// 'meaningfully' compared. This is not guranteeded by the standard, which permits pointer
// comparisons 'only' within an array. Thus this version is 'portable' only for machines which
// general pointer comparison is meaningful.
//
// <Q> what will happen when 'double-free' happens? In this implemenatation, seems to be causing
// infinite loop to find a place to insert.
//
void free( void *ap )
{
  Header *bp, *p;

  bp = (Header *)ap -1; // point to block header since ap is block+1

  // Scans the free list starting at freep and look for the place to insert <the-free-block>. To
  // free means that it will insert that block into the free list. The free block is either between
  // two existing free blocks or at the end of the list. (when either it is the first time or is to
  // have more new memory from the system, or to free block.)
  //
  // for( starts from freep and scan the list to find a [p, nextp] which p < block < nextp )
  //   if( p is greater then nextp in address and block is out of <arena> )
  //     break;
  //
  // So end the loop in two cases:
  // 1. when found [p, nextp] which is p < block < nextp.
  // 2. when p hits the last of the free list meaning not in the arena, do check if block is out of
  // arena and then break. this is the case when add new space into the areana including when
  // malloc/free starts
  //
  // freep                                                 points to the first
  // [ ]      [ ]         [ ]       [ ]     ...            [ ] 
  // p        nextp
  //                      p         nextp
  //                                        ...
  // nextp                                                 p
  //
  // or
  // ( when ininted, there is only one node in the free list )
  //
  // [ ] which is base; base->nextp = freep = prevp = &base;
  //
  // <key> In other words, two cases to insert; when free a block which is in use before and when
  // add new space from operating system into the list. 
  //
  // <key> Having a base pointing to self makes 'search' generic for all cases.
  //
  for( p = freep; !(bp > p && bp < p->s.ptr); p = p->s.ptr )
    if( p >= p->s.ptr && (bp > p || bp < p->s.ptr ))
      break;

  // In any case, if the block being freed is adjacent to 'either' neighbor, the blocks are
  // 'combined'.
  //
  // ----------------------------------------------------------> increasing address
  //        lower            upper
  // p                       nextp 
  // [ free ]                [ free ]                   [ free ]
  //        |           bp   |
  //        |        <------>| CASE01 (combined to upper)
  //        |                |
  //        |    <------>    | CASE02
  //        |                |
  //        |<------>        | CASE03 (combined to lower)
  //        |                |
  //        |<-------------->| CASE04 (conbined to both)
  //
  // <key> The troubles are keeping the pointers pointing to the right things and the size correct.
  // See how the combination of four cases are used.

  // handle 'right' side of the list
  if( bp + bp->s.size == p->s.ptr ) // join to upper nbr(neighbor)
  {
    bp->s.size += p->s.ptr->s.size;
    bp->s.ptr = p->s.ptr->s.ptr;
  }
  else
    bp->s.ptr = p->s.ptr;

  // handle 'left' side of the list
  if( p + p->s.size == bp )         // join to lower nbr
  {
    p->s.size += bp->s.size;
    p->s.ptr = bp->s.ptr;
  }
  else
    p->s.ptr = bp;

  // <update-freep>, returns 'previous'
  freep = p;
}

#define NALLOC 1024 // minimum #units to request

//**
// morecore: ask system for more memory in unit
//
static Header *morecore(unsigned nu)
{
  char *cp;
  Header *up;

  // <key> since asking the system for memory is expensive operation, don't want to do that on every
  // call to malloc, so morecore requests at least NALLOC units.
  //
  // <Q> It said "this larger block will be chopped up as needed" but cannot see how in this
  // implementation. See malloc.
  //
  if( nu < NALLOC ) 
    nu = NALLOC;

  // Header is a unit and return Header array[n]
  //
  // sbrk(n) system call returns a pointer to n more bytes and returns -1 of there was no space.
  // void *sbrk(intptr_t increment);
  //
  cp = sbrk( nu*sizeof(Header) );
  if( cp == (char *) -1) // no space at all
    return NULL;

  up = (Header *)cp;
  up->s.size = nu;

  free((void*)(up+1));

  return freep;
}


//** 
// malloc: general purpose storage allocator
//
void *malloc( unsigned nbytes )
{
  Header *p, *prevp;
  unsigned nunits;

  // 1. to get #units for requested nbytes. why is this? If Header size is 10 then
  //
  // < blk#1 > < blk#2    > < blk #3 > when use nbytes/sizeof(Header)+1
  // 1 2 ... 9 10 11 ... 19 20 ...     : nbytes
  // < blk#1    > < blk #2   > <       when use (nbytes-1)/sizeof(Header)+1
  //
  // the first approach uses 'two' units when nbytes 10 although one unit is enough so waste memory.
  //
  // 2. add one more unit for every requst
  nunits = ( nbytes + sizeof(Header) -1 )/sizeof(Header) + 1;

  // 1. This is single linked list. Move [prev, p] window along the list and start from p. If found
  // a exact block(node) from the free list then remove that node by chaning prev->next. If not, get
  // the tail end which effectively chops up to the smaller blocks.
  //
  // That's why need to have prev and this is to remove a node from a linked list(unlink from the
  // list). The freep is updated with the prev of the found(removed) node which is where the last
  // block found and is the starting point for next call.
  //
  //         [ ]      [ ]      [ ]       [ ]       [ ]       [ ]       [ ]      
  // loop 0: freep
  //         prevp     p
  // loop 1:           prev     p
  //                                      X (if this is the found)
  // loop n:                    prev      p
  //                            freep       (update node link and freep)
  //
  // In any case, the free list is then searched and the search begins at the point, freep, where
  // the last block was found. This strategy helps keep the list homogeneous.
  //
  if(( prevp = freep ) == NULL )  // no free list yet
  {
    base.s.ptr = freep = prevp = &base;
    base.s.size = 0;
  }

  for( p = prevp->s.ptr; ; prevp = p, p = p->s.ptr )   // walk along list and see 'no' condition
  {
    // found a free node and 'first-fit'
    if( p->s.size >= nunits )  // big enough
    {
      if( p->s.size == nunits )   // exactly
        prevp->s.ptr = p->s.ptr;
      else
      { // node is biggger and only uses the tail(bottom) end.
        p->s.size -= nunits;  // reduce the size of the origin block(becomes previous)
        p += p->s.size;       // moves p to the tail end and set header of the new block
        p->s.size = nunits;   // set the size of new block
        // <key> This effectively chops up the block and make it out of the free list or arena.
      }

      // <update-freep>, set 'previous'
      freep = prevp;
      // return address after the header of a block
      return (void *)(p+1);
    }

    if( p == freep ) // wrapped around free list (including the first time)
      if(( p = morecore( nunits )) == NULL)
        return NULL;  // none left
  }
}


# ============================================================================
#{ test framework
={============================================================================
*kt_dev_test_001* gtest

https://code.google.com/p/googletest/

<build>
Download the source, run ./configure and try sample files. The thing is that is to inlcude
'gtest-all.o' to use it in your project. That's it.

  g++ -isystem ${GTEST_DIR}/include -I${GTEST_DIR} \
      -pthread -c ${GTEST_DIR}/src/gtest-all.cc
  ar -rv libgtest.a gtest-all.o

<sample-output>
From README in the download:
  cd ${GTEST_DIR}/make
  make
  ./sample1_unittest

note: the result has ok(green) and failed(red) colors on terminal.

$ ./sample1_unittest 
Running main() from gtest_main.cc
[==========] Running 6 tests from 2 test cases.
[----------] Global test environment set-up.
[----------] 3 tests from FactorialTest
[ RUN      ] FactorialTest.Negative
[       OK ] FactorialTest.Negative (0 ms)
[ RUN      ] FactorialTest.Zero
[       OK ] FactorialTest.Zero (0 ms)
[ RUN      ] FactorialTest.Positive
[       OK ] FactorialTest.Positive (0 ms)
[----------] 3 tests from FactorialTest (0 ms total)

[----------] 3 tests from IsPrimeTest
[ RUN      ] IsPrimeTest.Negative
[       OK ] IsPrimeTest.Negative (0 ms)
[ RUN      ] IsPrimeTest.Trivial
[       OK ] IsPrimeTest.Trivial (0 ms)
[ RUN      ] IsPrimeTest.Positive
[       OK ] IsPrimeTest.Positive (0 ms)
[----------] 3 tests from IsPrimeTest (0 ms total)

[----------] Global test environment tear-down
[==========] 6 tests from 2 test cases ran. (0 ms total)
[  PASSED  ] 6 tests.


={============================================================================
*kt_dev_test_002* gtest: intro

https://code.google.com/p/googletest/wiki/Primer

Introduction: Why Google C++ Testing Framework?

Google C++ Testing Framework helps you write better C++ tests.

No matter whether you work on Linux, Windows, or a Mac, if you write C++ code, Google Test can help
you.

So what makes a good test, and how does Google C++ Testing Framework fit in? We believe:

1. Tests should be 'independent' and repeatable. It's a pain to debug a test that succeeds or fails as
a result of other tests. Google C++ Testing Framework isolates the tests by running each of them on
a different object. When a test fails, Google C++ Testing Framework allows you to run it in
isolation for quick debugging.

    Tests should be well organized and reflect the structure of the tested code. Google C++ Testing Framework groups related tests into test cases that can share data and subroutines. This common pattern is easy to recognize and makes tests easy to maintain. Such consistency is especially helpful when people switch projects and start to work on a new code base.
    Tests should be portable and reusable. The open-source community has a lot of code that is platform-neutral, its tests should also be platform-neutral. Google C++ Testing Framework works on different OSes, with different compilers (gcc, MSVC, and others), with or without exceptions, so Google C++ Testing Framework tests can easily work with a variety of configurations. (Note that the current release only contains build scripts for Linux - we are actively working on scripts for other platforms.)
    When tests fail, they should provide as much information about the problem as possible. Google C++ Testing Framework doesn't stop at the first test failure. Instead, it only stops the current test and continues with the next. You can also set up tests that report non-fatal failures after which the current test continues. Thus, you can detect and fix multiple bugs in a single run-edit-compile cycle.
    The testing framework should liberate test writers from housekeeping chores and let them focus on the test content. Google C++ Testing Framework automatically keeps track of all tests defined, and doesn't require the user to enumerate them in order to run them.
    Tests should be fast. With Google C++ Testing Framework, you can reuse shared resources across tests and pay for the set-up/tear-down only once, without making tests depend on each other. 

Since Google C++ Testing Framework is based on the popular xUnit architecture, you'll feel right at home if you've used JUnit or PyUnit before. If not, it will take you about 10 minutes to learn the basics and get started. So let's go!

Note: We sometimes refer to Google C++ Testing Framework informally as Google Test.
Setting up a New Test Project

To write a test program using Google Test, you need to compile Google Test into a library and link your test with it. We provide build files for some popular build systems: msvc/ for Visual Studio, xcode/ for Mac Xcode, make/ for GNU make, codegear/ for Borland C++ Builder, and the autotools script (deprecated) and CMakeLists.txt for CMake (recommended) in the Google Test root directory. If your build system is not on this list, you can take a look at make/Makefile to learn how Google Test should be compiled (basically you want to compile src/gtest-all.cc with GTEST_ROOT and GTEST_ROOT/include in the header search path, where GTEST_ROOT is the Google Test root directory).

Once you are able to compile the Google Test library, you should create a project or build target for your test program. Make sure you have GTEST_ROOT/include in the header search path so that the compiler can find "gtest/gtest.h" when compiling your test. Set up your test project to link with the Google Test library (for example, in Visual Studio, this is done by adding a dependency on gtest.vcproj).

If you still have questions, take a look at how Google Test's own tests are built and use them as examples.
Basic Concepts

When using Google Test, you start by writing assertions, which are statements that check whether a condition is true. An assertion's result can be success, nonfatal failure, or fatal failure. If a fatal failure occurs, it aborts the current function; otherwise the program continues normally.

Tests use assertions to verify the tested code's behavior. If a test crashes or has a failed assertion, then it fails; otherwise it succeeds.

A test case contains one or many tests. You should group your tests into test cases that reflect the structure of the tested code. When multiple tests in a test case need to share common objects and subroutines, you can put them into a test fixture class.

A test program can contain multiple test cases.

We'll now explain how to write a test program, starting at the individual assertion level and building up to tests and test cases.
Assertions

Google Test assertions are macros that resemble function calls. You test a class or function by making assertions about its behavior. When an assertion fails, Google Test prints the assertion's source file and line number location, along with a failure message. You may also supply a custom failure message which will be appended to Google Test's message.

The assertions come in pairs that test the same thing but have different effects on the current function. ASSERT_* versions generate fatal failures when they fail, and abort the current function. EXPECT_* versions generate nonfatal failures, which don't abort the current function. Usually EXPECT_* are preferred, as they allow more than one failures to be reported in a test. However, you should use ASSERT_* if it doesn't make sense to continue when the assertion in question fails.

Since a failed ASSERT_* returns from the current function immediately, possibly skipping clean-up code that comes after it, it may cause a space leak. Depending on the nature of the leak, it may or may not be worth fixing - so keep this in mind if you get a heap checker error in addition to assertion errors.

To provide a custom failure message, simply stream it into the macro using the << operator, or a sequence of such operators. An example:

ASSERT_EQ(x.size(), y.size()) << "Vectors x and y are of unequal length";

for (int i = 0; i < x.size(); ++i) {
  EXPECT_EQ(x[i], y[i]) << "Vectors x and y differ at index " << i;
}

Anything that can be streamed to an ostream can be streamed to an assertion macro--in particular, C strings and string objects. If a wide string (wchar_t*, TCHAR* in UNICODE mode on Windows, or std::wstring) is streamed to an assertion, it will be translated to UTF-8 when printed.
Basic Assertions

These assertions do basic true/false condition testing.
Fatal assertion 	Nonfatal assertion 	Verifies
ASSERT_TRUE(condition); 	EXPECT_TRUE(condition); 	condition is true
ASSERT_FALSE(condition); 	EXPECT_FALSE(condition); 	condition is false

Remember, when they fail, ASSERT_* yields a fatal failure and returns from the current function, while EXPECT_* yields a nonfatal failure, allowing the function to continue running. In either case, an assertion failure means its containing test fails.

Availability: Linux, Windows, Mac.
Binary Comparison

This section describes assertions that compare two values.

Fatal assertion 	Nonfatal assertion 	Verifies
ASSERT_EQ(expected, actual);	EXPECT_EQ(expected, actual);	expected == actual
ASSERT_NE(val1, val2); 	EXPECT_NE(val1, val2); 	val1 != val2
ASSERT_LT(val1, val2); 	EXPECT_LT(val1, val2); 	val1 < val2
ASSERT_LE(val1, val2); 	EXPECT_LE(val1, val2); 	val1 <= val2
ASSERT_GT(val1, val2); 	EXPECT_GT(val1, val2); 	val1 > val2
ASSERT_GE(val1, val2); 	EXPECT_GE(val1, val2); 	val1 >= val2

In the event of a failure, Google Test prints both val1 and val2 . In ASSERT_EQ* and EXPECT_EQ* (and all other equality assertions we'll introduce later), you should put the expression you want to test in the position of actual, and put its expected value in expected, as Google Test's failure messages are optimized for this convention.

Value arguments must be comparable by the assertion's comparison operator or you'll get a compiler error. We used to require the arguments to support the << operator for streaming to an ostream, but it's no longer necessary since v1.6.0 (if << is supported, it will be called to print the arguments when the assertion fails; otherwise Google Test will attempt to print them in the best way it can. For more details and how to customize the printing of the arguments, see this Google Mock recipe.).

These assertions can work with a user-defined type, but only if you define the corresponding comparison operator (e.g. ==, <, etc). If the corresponding operator is defined, prefer using the ASSERT_*() macros because they will print out not only the result of the comparison, but the two operands as well.

Arguments are always evaluated exactly once. Therefore, it's OK for the arguments to have side effects. However, as with any ordinary C/C++ function, the arguments' evaluation order is undefined (i.e. the compiler is free to choose any order) and your code should not depend on any particular argument evaluation order.

ASSERT_EQ() does pointer equality on pointers. If used on two C strings, it tests if they are in the same memory location, not if they have the same value. Therefore, if you want to compare C strings (e.g. const char*) by value, use ASSERT_STREQ() , which will be described later on. In particular, to assert that a C string is NULL, use ASSERT_STREQ(NULL, c_string) . However, to compare two string objects, you should use ASSERT_EQ.

Macros in this section work with both narrow and wide string objects (string and wstring).

Availability: Linux, Windows, Mac.
String Comparison

The assertions in this group compare two C strings. If you want to compare two string objects, use EXPECT_EQ, EXPECT_NE, and etc instead.

Fatal assertion 	Nonfatal assertion 	Verifies
ASSERT_STREQ(expected_str, actual_str); 	EXPECT_STREQ(expected_str, actual_str); 	the two C strings have the same content
ASSERT_STRNE(str1, str2); 	EXPECT_STRNE(str1, str2); 	the two C strings have different content
ASSERT_STRCASEEQ(expected_str, actual_str);	EXPECT_STRCASEEQ(expected_str, actual_str); 	the two C strings have the same content, ignoring case
ASSERT_STRCASENE(str1, str2);	EXPECT_STRCASENE(str1, str2); 	the two C strings have different content, ignoring case

Note that "CASE" in an assertion name means that case is ignored.

*STREQ* and *STRNE* also accept wide C strings (wchar_t*). If a comparison of two wide strings fails, their values will be printed as UTF-8 narrow strings.

A NULL pointer and an empty string are considered different.

Availability: Linux, Windows, Mac.

See also: For more string comparison tricks (substring, prefix, suffix, and regular expression matching, for example), see the Advanced Google Test Guide.
Simple Tests

To create a test:

    Use the TEST() macro to define and name a test function, These are ordinary C++ functions that don't return a value.
    In this function, along with any valid C++ statements you want to include, use the various Google Test assertions to check values.
    The test's result is determined by the assertions; if any assertion in the test fails (either fatally or non-fatally), or if the test crashes, the entire test fails. Otherwise, it succeeds. 

TEST(test_case_name, test_name) {
 ... test body ...
}

TEST() arguments go from general to specific. The first argument is the name of the test case, and the second argument is the test's name within the test case. Both names must be valid C++ identifiers, and they should not contain underscore (_). A test's full name consists of its containing test case and its individual name. Tests from different test cases can have the same individual name.

For example, let's take a simple integer function:

int Factorial(int n); // Returns the factorial of n

A test case for this function might look like:

// Tests factorial of 0.
TEST(FactorialTest, HandlesZeroInput) {
  EXPECT_EQ(1, Factorial(0));
}

// Tests factorial of positive numbers.
TEST(FactorialTest, HandlesPositiveInput) {
  EXPECT_EQ(1, Factorial(1));
  EXPECT_EQ(2, Factorial(2));
  EXPECT_EQ(6, Factorial(3));
  EXPECT_EQ(40320, Factorial(8));
}

Google Test groups the test results by test cases, so logically-related tests should be in the same test case; in other words, the first argument to their TEST() should be the same. In the above example, we have two tests, HandlesZeroInput and HandlesPositiveInput, that belong to the same test case FactorialTest.

Availability: Linux, Windows, Mac.
Test Fixtures: Using the Same Data Configuration for Multiple Tests

If you find yourself writing two or more tests that operate on similar data, you can use a test fixture. It allows you to reuse the same configuration of objects for several different tests.

To create a fixture, just:

    Derive a class from ::testing::Test . Start its body with protected: or public: as we'll want to access fixture members from sub-classes.
    Inside the class, declare any objects you plan to use.
    If necessary, write a default constructor or SetUp() function to prepare the objects for each test. A common mistake is to spell SetUp() as Setup() with a small u - don't let that happen to you.
    If necessary, write a destructor or TearDown() function to release any resources you allocated in SetUp() . To learn when you should use the constructor/destructor and when you should use SetUp()/TearDown(), read this FAQ entry.
    If needed, define subroutines for your tests to share. 

When using a fixture, use TEST_F() instead of TEST() as it allows you to access objects and subroutines in the test fixture:

TEST_F(test_case_name, test_name) {
 ... test body ...
}

Like TEST(), the first argument is the test case name, but for TEST_F() this must be the name of the test fixture class. You've probably guessed: _F is for fixture.

Unfortunately, the C++ macro system does not allow us to create a single macro that can handle both types of tests. Using the wrong macro causes a compiler error.

Also, you must first define a test fixture class before using it in a TEST_F(), or you'll get the compiler error "`virtual outside class declaration`".

For each test defined with TEST_F(), Google Test will:

    Create a fresh test fixture at runtime
    Immediately initialize it via SetUp() ,
    Run the test
    Clean up by calling TearDown()
    Delete the test fixture. Note that different tests in the same test case have different test fixture objects, and Google Test always deletes a test fixture before it creates the next one. Google Test does not reuse the same test fixture for multiple tests. Any changes one test makes to the fixture do not affect other tests. 

As an example, let's write tests for a FIFO queue class named Queue, which has the following interface:

template <typename E> // E is the element type.
class Queue {
 public:
  Queue();
  void Enqueue(const E& element);
  E* Dequeue(); // Returns NULL if the queue is empty.
  size_t size() const;
  ...
};

First, define a fixture class. By convention, you should give it the name FooTest where Foo is the class being tested.

class QueueTest : public ::testing::Test {
 protected:
  virtual void SetUp() {
    q1_.Enqueue(1);
    q2_.Enqueue(2);
    q2_.Enqueue(3);
  }

  // virtual void TearDown() {}

  Queue<int> q0_;
  Queue<int> q1_;
  Queue<int> q2_;
};

In this case, TearDown() is not needed since we don't have to clean up after each test, other than what's already done by the destructor.

Now we'll write tests using TEST_F() and this fixture.

TEST_F(QueueTest, IsEmptyInitially) {
  EXPECT_EQ(0, q0_.size());
}

TEST_F(QueueTest, DequeueWorks) {
  int* n = q0_.Dequeue();
  EXPECT_EQ(NULL, n);

  n = q1_.Dequeue();
  ASSERT_TRUE(n != NULL);
  EXPECT_EQ(1, *n);
  EXPECT_EQ(0, q1_.size());
  delete n;

  n = q2_.Dequeue();
  ASSERT_TRUE(n != NULL);
  EXPECT_EQ(2, *n);
  EXPECT_EQ(1, q2_.size());
  delete n;
}

The above uses both ASSERT_* and EXPECT_* assertions. The rule of thumb is to use EXPECT_* when you want the test to continue to reveal more errors after the assertion failure, and use ASSERT_* when continuing after failure doesn't make sense. For example, the second assertion in the Dequeue test is ASSERT_TRUE(n != NULL), as we need to dereference the pointer n later, which would lead to a segfault when n is NULL.

When these tests run, the following happens:

    Google Test constructs a QueueTest object (let's call it t1 ).
    t1.SetUp() initializes t1 .
    The first test ( IsEmptyInitially ) runs on t1 .
    t1.TearDown() cleans up after the test finishes.
    t1 is destructed.
    The above steps are repeated on another QueueTest object, this time running the DequeueWorks test. 

Availability: Linux, Windows, Mac.

Note: Google Test automatically saves all Google Test flags when a test object is constructed, and restores them when it is destructed.
Invoking the Tests

TEST() and TEST_F() implicitly register their tests with Google Test. So, unlike with many other C++ testing frameworks, you don't have to re-list all your defined tests in order to run them.

After defining your tests, you can run them with RUN_ALL_TESTS() , which returns 0 if all the tests are successful, or 1 otherwise. Note that RUN_ALL_TESTS() runs all tests in your link unit -- they can be from different test cases, or even different source files.

When invoked, the RUN_ALL_TESTS() macro:

    Saves the state of all Google Test flags.
    Creates a test fixture object for the first test.
    Initializes it via SetUp().
    Runs the test on the fixture object.
    Cleans up the fixture via TearDown().
    Deletes the fixture.
    Restores the state of all Google Test flags.
    Repeats the above steps for the next test, until all tests have run. 

In addition, if the text fixture's constructor generates a fatal failure in step 2, there is no point for step 3 - 5 and they are thus skipped. Similarly, if step 3 generates a fatal failure, step 4 will be skipped.

Important: You must not ignore the return value of RUN_ALL_TESTS(), or gcc will give you a compiler error. The rationale for this design is that the automated testing service determines whether a test has passed based on its exit code, not on its stdout/stderr output; thus your main() function must return the value of RUN_ALL_TESTS().

Also, you should call RUN_ALL_TESTS() only once. Calling it more than once conflicts with some advanced Google Test features (e.g. thread-safe death tests) and thus is not supported.

Availability: Linux, Windows, Mac.
Writing the main() Function

You can start from this boilerplate:

#include "this/package/foo.h"
#include "gtest/gtest.h"

namespace {

// The fixture for testing class Foo.
class FooTest : public ::testing::Test {
 protected:
  // You can remove any or all of the following functions if its body
  // is empty.

  FooTest() {
    // You can do set-up work for each test here.
  }

  virtual ~FooTest() {
    // You can do clean-up work that doesn't throw exceptions here.
  }

  // If the constructor and destructor are not enough for setting up
  // and cleaning up each test, you can define the following methods:

  virtual void SetUp() {
    // Code here will be called immediately after the constructor (right
    // before each test).
  }

  virtual void TearDown() {
    // Code here will be called immediately after each test (right
    // before the destructor).
  }

  // Objects declared here can be used by all tests in the test case for Foo.
};

// Tests that the Foo::Bar() method does Abc.
TEST_F(FooTest, MethodBarDoesAbc) {
  const string input_filepath = "this/package/testdata/myinputfile.dat";
  const string output_filepath = "this/package/testdata/myoutputfile.dat";
  Foo f;
  EXPECT_EQ(0, f.Bar(input_filepath, output_filepath));
}

// Tests that Foo does Xyz.
TEST_F(FooTest, DoesXyz) {
  // Exercises the Xyz feature of Foo.
}

}  // namespace

int main(int argc, char **argv) {
  ::testing::InitGoogleTest(&argc, argv);
  return RUN_ALL_TESTS();
}

The ::testing::InitGoogleTest() function parses the command line for Google Test flags, and removes all recognized flags. This allows the user to control a test program's behavior via various flags, which we'll cover in AdvancedGuide. You must call this function before calling RUN_ALL_TESTS(), or the flags won't be properly initialized.

On Windows, InitGoogleTest() also works with wide strings, so it can be used in programs compiled in UNICODE mode as well.

But maybe you think that writing all those main() functions is too much work? We agree with you completely and that's why Google Test provides a basic implementation of main(). If it fits your needs, then just link your test with gtest_main library and you are good to go.
Important note for Visual C++ users

If you put your tests into a library and your main() function is in a different library or in your .exe file, those tests will not run. The reason is a bug in Visual C++. When you define your tests, Google Test creates certain static objects to register them. These objects are not referenced from elsewhere but their constructors are still supposed to run. When Visual C++ linker sees that nothing in the library is referenced from other places it throws the library out. You have to reference your library with tests from your main program to keep the linker from discarding it. Here is how to do it. Somewhere in your library code declare a function:

__declspec(dllexport) int PullInMyLibrary() { return 0; }

If you put your tests in a static library (not DLL) then __declspec(dllexport) is not required. Now, in your main program, write a code that invokes that function:

int PullInMyLibrary();
static int dummy = PullInMyLibrary();

This will keep your tests referenced and will make them register themselves at startup.

In addition, if you define your tests in a static library, add /OPT:NOREF to your main program linker options. If you use MSVC++ IDE, go to your .exe project properties/Configuration Properties/Linker/Optimization and set References setting to Keep Unreferenced Data (/OPT:NOREF). This will keep Visual C++ linker from discarding individual symbols generated by your tests from the final executable.

There is one more pitfall, though. If you use Google Test as a static library (that's how it is defined in gtest.vcproj) your tests must also reside in a static library. If you have to have them in a DLL, you must change Google Test to build into a DLL as well. Otherwise your tests will not run correctly or will not run at all. The general conclusion here is: make your life easier - do not write your tests in libraries!
Where to Go from Here

Congratulations! You've learned the Google Test basics. You can start writing and running Google Test tests, read some samples, or continue with AdvancedGuide, which describes many more useful Google Test features.
Known Limitations

Google Test is designed to be thread-safe. The implementation is thread-safe on systems where the pthreads library is available. It is currently unsafe to use Google Test assertions from two threads concurrently on other systems (e.g. Windows). In most tests this is not an issue as usually the assertions are done in the main thread. If you want to help, you can volunteer to implement the necessary synchronization primitives in gtest-port.h for your platform. 

={============================================================================
*kt_dev_test_003* gtest: own example

{code-to-test}
#include <iostream>
#include <cstdlib>

#include "gtest/gtest.h"

typedef int EntryType;

typedef struct node
{
  EntryType entry;
  node*     pnext;
} Node;

typedef struct {
  int    count;
  Node*  header;
} List;

Node* MakeNode( EntryType entry )
{
  Node* pnode = NULL;

  if( (pnode = (Node*) malloc( sizeof(Node))) == NULL )
  {
    std::cout << "no more memory" << std::endl;
    return NULL;
  }

  pnode->entry = entry;
  pnode->pnext = NULL;

  return pnode;
}

void CreatList( List* list )
{ 
  list->count = 0;
  list->header = NULL; 
}

bool ListEmpty( List* list )
{ return ( list->header == NULL ); }

// add only at the end. see there are approaches to find end; one is to use pnext and the other is
// to use count. 
bool AddList( List* list, EntryType entry )
{
  Node* pnode, *pend;

  if( (pnode = MakeNode(entry)) == NULL )
  {
    std::cout << "add: mem is full" << std::endl;
    return false;
  }

  if( ListEmpty( list ) )
  {
    list->header = pnode;
  }
  else
  {
#ifdef USE_PNEXT
    // search the end using pnext
    for( pend = list->header; pend->pnext; pend = pend->pnext )
      ;
#else
    // search the end using count
    pend = list->header;
    for( int current = 1; current < list->count; current++) // note that less than
      pend = pend->pnext;
#endif

    pend->pnext = pnode;
  }

  list->count++;

  return true;
}

typedef void(*TRAVERSEFUNC)(EntryType);

void TraverseList( List* list, TRAVERSEFUNC func)
{
  Node* pnode;

  if( ListEmpty(list) )
  {
    std::cout << "list is empty" << std::endl;
    return;
  }

  pnode = list->header;

  while(pnode)
  {
    func(pnode->entry);
    pnode = pnode->pnext;
  }
}

void EntryPrint(EntryType item)
{
  std::cout << "item is: " << item << std::endl;
}

TEST(Sample, EmptyCheck) {
  List list;
  CreatList(&list);

  EXPECT_EQ( 1, ListEmpty(&list) );
  EXPECT_EQ( 0, ListEmpty(&list) );    note: line #112 
}

int main(int argc, char **argv)
{
  int item = 0;

  testing::InitGoogleTest(&argc, argv);

//  List list;
//  CreatList(&list);
//
//  std::cout << "type in 5 numbers." << std::endl;
//
//  for(int i=0; i < 5; i++)
//  {
//    std::cin >> item;
//    AddList(&list, item );
//  }
//
//  TraverseList(&list, EntryPrint);
  return RUN_ALL_TESTS();
}


<makefile>
# A sample Makefile for building Google Test and using it in user
# tests.  Please tweak it to suit your environment and project.  You
# may want to move it to your project's root directory.
#
# SYNOPSIS:
#
#   make [all]  - makes everything.
#   make TARGET - makes the given target.
#   make clean  - removes all files generated by make.

# Please tweak the following variable definitions as needed by your
# project, except GTEST_HEADERS, which you can use in your own targets
# but shouldn't modify.

# Points to the root of Google Test, relative to where this file is.
# Remember to tweak this if you move this file.
GTEST_DIR = ..

# Where to find user code.
USER_DIR = ../samples

# Flags passed to the preprocessor.
# Set Google Test's header directory as a system directory, such that
# the compiler doesn't generate warnings in Google Test headers.
CPPFLAGS += -isystem $(GTEST_DIR)/include

# Flags passed to the C++ compiler.
CXXFLAGS += -g -Wall -Wextra -pthread

# All tests produced by this Makefile.  Remember to add new tests you
# created to the list.
TESTS = sample1_unittest

# All Google Test headers.  Usually you shouldn't change this
# definition.
GTEST_HEADERS = $(GTEST_DIR)/include/gtest/*.h \
                $(GTEST_DIR)/include/gtest/internal/*.h

# House-keeping build targets.

all : $(TESTS)

clean :
	rm -f $(TESTS) gtest.a gtest_main.a *.o

# Builds gtest.a and gtest_main.a.

# Usually you shouldn't tweak such internal variables, indicated by a
# trailing _.
GTEST_SRCS_ = $(GTEST_DIR)/src/*.cc $(GTEST_DIR)/src/*.h $(GTEST_HEADERS)

# For simplicity and to avoid depending on Google Test's
# implementation details, the dependencies specified below are
# conservative and not optimized.  This is fine as Google Test
# compiles fast and for ordinary users its source rarely changes.
gtest-all.o : $(GTEST_SRCS_)
	$(CXX) $(CPPFLAGS) -I$(GTEST_DIR) $(CXXFLAGS) -c \
            $(GTEST_DIR)/src/gtest-all.cc

gtest.a : gtest-all.o
	$(AR) $(ARFLAGS) $@ $^

sample1.o : llist.cc $(GTEST_HEADERS)
	$(CXX) $(CPPFLAGS) $(CXXFLAGS) -c llist.cc -o sample1.o

# KT
# sample1_unittest.o : $(USER_DIR)/sample1_unittest.cc \
#                      $(USER_DIR)/sample1.h $(GTEST_HEADERS)
# 	$(CXX) $(CPPFLAGS) $(CXXFLAGS) -c $(USER_DIR)/sample1_unittest.cc

# sample1_unittest : sample1.o sample1_unittest.o gtest_main.a
sample1_unittest : sample1.o gtest.a
	$(CXX) $(CPPFLAGS) $(CXXFLAGS) -lpthread $^ -o $@

<output>
$ ./sample1_unittest 
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from Sample
[ RUN      ] Sample.EmptyCheck
[       OK ] Sample.EmptyCheck (0 ms)
[----------] 1 test from Sample (0 ms total)

[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (0 ms total)
[  PASSED  ] 1 test.


$ ./sample1_unittest 
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from Sample
[ RUN      ] Sample.EmptyCheck
llist.cc:112: Failure
Value of: ListEmpty(&list)
  Actual: true
Expected: 0
[  FAILED  ] Sample.EmptyCheck (0 ms)
[----------] 1 test from Sample (0 ms total)

[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (1 ms total)
[  PASSED  ] 0 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] Sample.EmptyCheck

 1 FAILED TEST


={============================================================================
*kt_dev_test_100* cppunit

<1>
http://cppunit.sourceforge.net/doc/1.8.0/index.html

This has the cookbook as below and source. However, this source is cvs
repository and cannot use it directly.

<2>
http://freedesktop.org/wiki/Software/cppunit/#index1h1

CppUnit is the C++ port of the famous JUnit framework for unit testing. Test
output is in XML for automatic testing and GUI based for supervised tests.

CppUnit is the unit test framework used by LibreOffice and now maintained at
FreeDesktop. This is a continuation of the original cppunit project. note: this
is <1>

Getting the sources

cppunit sources are stored in git. To get them, you can use:

git clone git://anongit.freedesktop.org/git/libreoffice/cppunit/

Release Versions

Cppunit 1.13.2 MD5: d1c6bdd5a76c66d2c38331e2d287bc01

Building it

Once the source has been checked out, cppunit can be built in usual manner:

cd cppunit
./autogen.sh
./configure
make
make check # optional
make install


={============================================================================
*kt_dev_test_101* cppunit: cookbook

http://cppunit.sourceforge.net/doc/1.8.0/cppunit_cookbook.html#cppunit_cookbook

<simple-test-case>
You want to know whether your code is working.

How do you do it?

There are many ways. Stepping through a debugger or littering your code with
stream output calls are two of the simpler ways, but they both have drawbacks. 

Stepping through your code is a good idea, but it is 'not' automatic. You have
to do it every time you make changes. Streaming out text is also fine, but it
makes code 'ugly' and it generates far more information than you need most of
the time.

Tests in CppUnit can be run automatically. They are easy to set up and once you
have written them, they are always there to help you keep confidence in the
quality of your code.

To make a simple test, here is what you do:

Subclass the TestCase class. Override the method runTest(). When you want to
check a value, call CPPUNIT_ASSERT(bool) and pass in an expression that is true
if the test succeeds.

For example, to test the equality comparison for a Complex number class, write:

class ComplexNumberTest : public CppUnit::TestCase { 
  public: 
    ComplexNumberTest( std::string name ) : CppUnit::TestCase( name ) {}

    // note: Complex is a class to test

    void runTest() {
      CPPUNIT_ASSERT( Complex (10, 1) == Complex (10, 1) );
      CPPUNIT_ASSERT( !(Complex (1, 1) == Complex (2, 2)) );
    }
};


{fixture}
That was a very simple test. Ordinarily, you'll have many little test cases that
you'll want to run on the same set of objects. To do this, use a fixture.

A fixture is a 'known' 'set' of objects that serves as a base for a set of test
cases. Fixtures come in very handy when you are testing as you develop.

Let's try out this style of development and learn about fixtures along the away.
Suppose that we are really developing a complex number class. Let's start by
defining a empty class named Complex.

class Complex {};

Now create an instance of ComplexNumberTest above, compile the code and see what
happens. The first thing we notice is a few compiler errors. The test uses
operator==, but it is not defined. Let's fix that.

bool operator==( const Complex &a, const Complex &b) 
{ 
  return true; 
}

Now compile the test, and run it. This time it compiles but the test fails.
note: since it always returns true and fails on the second assert. We need a bit
more to get an operator==() working correctly, so we revisit the code.

class Complex { 
  friend bool operator ==(const Complex& a, const Complex& b);
  double real, imaginary;
  public:
  Complex( double r, double i = 0 ) 
    : real(r), imaginary(i) 
  {
  }
};

bool operator ==( const Complex &a, const Complex &b )
{ 
  return eq( a.real, b.real )  &&  eq( a.imaginary, b.imaginary ); 
}

If we compile now and run our test it will pass.

Now we are ready to add new operations and new tests. At this point a fixture
would be handy. We would probably be better off when doing our tests if we
decided to instantiate three or four complex numbers and reuse them across our
tests.

<how-to-use-fixture>
Here is how we do it:

o Add member variables for each part of the fixture
o 'override' setUp() to initialize the variables
o 'override' tearDown() to release any permanent resources you allocated in
setUp()

note: requires to inherit from "TestFixture"

#include <cppunit/TestFixture.h>

class ComplexNumberTest : public CppUnit::TestFixture 
{
  private:
    Complex *m_10_1, *m_1_1, *m_11_2;

  protected:
    void setUp()
    {
      m_10_1 = new Complex( 10, 1 );
      m_1_1 = new Complex( 1, 1 );
      m_11_2 = new Complex( 11, 2 );  
    }

    void tearDown() 
    {
      delete m_10_1;
      delete m_1_1;
      delete m_11_2;
    }
};

Once we have this fixture, we can add the complex addition test case that we
need over the course of our development.


{fixture-add-test}
How do you write and invoke individual tests using a fixture?

There are two steps to this process:

o Write the test case 'as' a 'method' in the fixture class
o Create a TestCaller which runs that particular method

Here is our test case class with a few extra case methods:

class ComplexNumberTest : public CppUnit::TestFixture  
{
  private:
    Complex *m_10_1, *m_1_1, *m_11_2;
  protected:
    void setUp()
    {
      m_10_1 = new Complex( 10, 1 );
      m_1_1 = new Complex( 1, 1 );
      m_11_2 = new Complex( 11, 2 );  
    }

    void tearDown() 
    {
      delete m_10_1;
      delete m_1_1;
      delete m_11_2;
    }

    void testEquality()
    {
      CPPUNIT_ASSERT( *m_10_1 == *m_10_1 );
      CPPUNIT_ASSERT( !(*m_10_1 == *m_11_2) );
    }

    void testAddition()
    {
      CPPUNIT_ASSERT( *m_10_1 + *m_1_1 == *m_11_2 );
    }
};


{fixture-run-test}
<test-caller> 
One may create and run instances for 'each' test case like this:

CppUnit::TestCaller<ComplexNumberTest> 
   test( "testEquality", &ComplexNumberTest::testEquality );
CppUnit::TestResult result;
test.run( &result );

The second argument to the test caller constructor is the address of a method on
ComplexNumberTest. When the test caller is run, that specific method will be
run. This is 'not' a 'useful' thing to do since:

o as no diagnostics will be displayed. 
o run a single test case.


<test-suite>
How do you set up your tests so that you can run them 'all' at once? CppUnit
provides a TestSuite class that runs any number of TestCases together.

To create a suite of two or more tests, you do the following:

CppUnit::TestSuite suite;
CppUnit::TestResult result;

suite.addTest( new CppUnit::TestCaller<ComplexNumberTest>( "testEquality", 
                       &ComplexNumberTest::testEquality ) );

suite.addTest( new CppUnit::TestCaller<ComplexNumberTest>( "testAddition", 
                       &ComplexNumberTest::testAddition ) );

suite.run( &result );

TestSuites don't only have to contain callers for TestCases. They can contain
any object that implements the Test interface. For example, you can create a
TestSuite in your code and I can create one in mine, and we can run them
together by creating a TestSuite that contains both:

CppUnit::TestSuite suite;
CppUnit::TestResult result;
suite.addTest( ComplexNumberTest::suite() );
suite.addTest( SurrealNumberTest::suite() );
suite.run( &result );

note: this uses testRunner below and suite can be nested. That is to run
multiple 'suite' together.


{test-runner} note: this is test 'case' file
How do you run your tests and collect their results?

Once you have a test suite, you'll want to run it. CppUnit provides tools to
define the suite to be run and to display its results. You 'make' your suite
'accessible' to a "TestRunner" program with a static method suite that returns a
test suite.

For example, to make a ComplexNumberTest suite available to a TestRunner, add
the following code to ComplexNumberTest:

note: 'static' function.

{
  public: 
    static CppUnit::Test *suite()
    {
      CppUnit::TestSuite *suiteOfTests = 
          new CppUnit::TestSuite( "ComplexNumberTest" );

      suiteOfTests->addTest( 
              new CppUnit::TestCaller<ComplexNumberTest>( "testEquality", 
            &ComplexNumberTest::testEquality ) );

      suiteOfTests->addTest( 
              new CppUnit::TestCaller<ComplexNumberTest>( "testAddition",
            &ComplexNumberTest::testAddition ) );

      return suiteOfTests;
    }
}


<text-version> note: this is main file to 'run' test files.
To use the text version, include the header files for the tests in Main.cpp:

#include <cppunit/ui/text/TestRunner.h>
#include "ExampleTestCase.h"
#include "ComplexNumberTest.h"

And add a call to addTest(CppUnit::Test *) in the main() function:

int main( int argc, char **argv)
{
  CppUnit::TextUi::TestRunner runner;
  runner.addTest( ExampleTestCase::suite() );
  runner.addTest( ComplexNumberTest::suite() );
  runner.run();
  return 0;
}

The TestRunner will run the tests. If all the tests pass, you'll get an
informative message. If any fail, you'll get the following information:

o The name of the test case that failed
o The name of the source file that contains the test
o The line number where the failure occurred
o All of the text inside the call to CPPUNIT_ASSERT() which detected the failure


<failure-and-error>
CppUnit distinguishes between failures and errors. A failure is anticipated and
checked for with assertions. Errors are 'unanticipated' problems like division
by zero and other exceptions thrown by the C++ runtime or your code.

note: nested or hiarachical structure and this can be even simpler when use
factory below.

main                          Test file(feature/group) 01            Test file(feature/group) 02 
                  
{                             class A : public CppUnit::TestFixture  class B : ...
   runner.addTest(A.suite);   {
   runner.addTest(B.suite);      suite:
   runner.run();                    caller(test01);
}                                   caller(test02);
                                    ...
                              };


{helper-macros}
As you might have noticed, implementing the fixture static suite() method is a
repetitive and error prone task. A set of macros have been created to
automatically implements the static suite() method.

note: see Writing test fixture 
http://cppunit.sourceforge.net/doc/1.8.0/group___writing_test_fixture.html

The following code is a rewrite of ComplexNumberTest using those macros:

{{ ComplexNumberTest.cpp  

#include <cppunit/extensions/HelperMacros.h>

class ComplexNumberTest : public CppUnit::TestFixture  
{
  protected:
    // First, we declare the suite, passing the class name to the macro:
    CPPUNIT_TEST_SUITE( ComplexNumberTest );

    // The suite created by the static suite() method is named after the class
    // name. Then, we declare each test case of the fixture:
    CPPUNIT_TEST( testEquality ); 
    CPPUNIT_TEST( testAddition );

    // Finally, we end the suite declaration:
    CPPUNIT_TEST_SUITE_END();

    // At this point, a method with the following signature has been implemented:
    static CppUnit::TestSuite *suite();

    // note: So the above three macros is to implement "suite()" and the rest of
    // the fixture is left as it was. So 'unchanged'.

  private:
    Complex *m_10_1, *m_1_1, *m_11_2;
  protected:
    void setUp()
    {
      m_10_1 = new Complex( 10, 1 );
      m_1_1 = new Complex( 1, 1 );
      m_11_2 = new Complex( 11, 2 );  
    }

    void tearDown() 
    {
      delete m_10_1;
      delete m_1_1;
      delete m_11_2;
    }

    void testEquality()
    {
      CPPUNIT_ASSERT( *m_10_1 == *m_10_1 );
      CPPUNIT_ASSERT( !(*m_10_1 == *m_11_2) );
    }

    void testAddition()
    {
      CPPUNIT_ASSERT( *m_10_1 + *m_1_1 == *m_11_2 );
    }
};

CPPUNIT_TEST_SUITE_REGISTRATION(ComplexNumberTest);

}} ComplexNumberTest.cpp  

The name of the TestCaller added to the suite are a composition of the fixture
name and the method name.

In the present case, the names would be: "ComplexNumberTest.testEquality" and
"ComplexNumberTest.testAddition".

<handle-exception>
The helper macros help you write comon assertion. For example, to check that
ComplexNumber throws a MathException when dividing a number by 0:

o add the test to the suite using CPPUNIT_TEST_EXCEPTION, specifying the
expected exception type.

o write the test case method

CPPUNIT_TEST_SUITE( ComplexNumberTest );
// [...]
CPPUNIT_TEST_EXCEPTION( testDivideByZeroThrows, MathException );
CPPUNIT_TEST_SUITE_END();

// [...]

  void testDivideByZeroThrows()
  {
    // The following line should throw a MathException.
    *m_10_1 / ComplexNumber(0);
  }

If the expected exception is not thrown, then a assertion failure is reported.


{factory-registry}
The TestFactoryRegistry was created to solve two pitfalls:

o forgetting to add your fixture suite to the test runner since it is in another
file, it is easy to forget. note: In main file, must call "addTest()" for each
test case.

o compilation bottleneck caused by the inclusion of all test case headers (see
        previous example) note: Assume that each test case has own header file
and implementation file.

The TestFactoryRegistry is a place where suites can be registered at
initialization time.

To register the ComplexNumber suite, in the .cpp file, you add: see above.

#include <cppunit/extensions/HelperMacros.h>

CPPUNIT_TEST_SUITE_REGISTRATION( ComplexNumber );

Behind the scene, a static variable type of AutoRegisterSuite is declared. On
construction, it will register a TestSuiteFactory into the TestFactoryRegistry.
The TestSuiteFactory returns the TestSuite returned by ComplexNumber::suite().

To run the tests, using the text test runner, we don't need to include the
fixture anymore:

#include <cppunit/extensions/TestFactoryRegistry.h>
#include <cppunit/ui/text/TestRunner.h>

int main( int argc, char **argv)
{
  CppUnit::TextUi::TestRunner runner;

  // First, we retreive the instance of the TestFactoryRegistry:

  CppUnit::TestFactoryRegistry &registry = CppUnit::TestFactoryRegistry::getRegistry();

  // Then, we obtain and add a new TestSuite created by the TestFactoryRegistry
  // that contains 'all' the test suite registered using
  // CPPUNIT_TEST_SUITE_REGISTRATION().

  runner.addTest( registry.makeTest() );
  runner.run();
  return 0;
}

note: make it possible to add all tests by calling a single addTest.


<Q>
Post-build check

Well, now that we have our unit tests running, how about integrating unit
testing to our build process?

To do that, the application must returns a value different than 0 to indicate
that there was an error.

TestRunner::run() returns a boolean indicating if the run was successful.

Updating our main programm, we obtains:

#include <cppunit/extensions/TestFactoryRegistry.h>
#include <cppunit/ui/text/TestRunner.h>

int main( int argc, char **argv)
{
  CppUnit::TextUi::TestRunner runner;
  CppUnit::TestFactoryRegistry &registry = CppUnit::TestFactoryRegistry::getRegistry();
  runner.addTest( registry.makeTest() );
  bool wasSucessful = runner.run( "", false );
  return wasSucessful;
}

Now, you need to 'run' your application after compilation.


={============================================================================
*kt_dev_test_102* cppunit: simple

http://freedesktop.org/wiki/Software/cppunit/#index1h1

From cppunit/examples/simple

<test-case-header>
#ifndef CPP_UNIT_EXAMPLETESTCASE_H
#define CPP_UNIT_EXAMPLETESTCASE_H

#include <cppunit/extensions/HelperMacros.h>

/* 
 * A test case that is designed to produce
 * example errors and failures
 *
 */

class ExampleTestCase : public CPPUNIT_NS::TestFixture
{
  CPPUNIT_TEST_SUITE( ExampleTestCase );
  CPPUNIT_TEST( example );
  CPPUNIT_TEST( anotherExample );
  CPPUNIT_TEST( testAdd );
  CPPUNIT_TEST( testEquals );
  CPPUNIT_TEST_SUITE_END();

protected:
  double m_value1;
  double m_value2;

public:
  void setUp();

protected:
  void example();
  void anotherExample();
  void testAdd();
  void testEquals();
};

#endif

<test-case-source>
#include <cppunit/config/SourcePrefix.h>
#include "ExampleTestCase.h"

CPPUNIT_TEST_SUITE_REGISTRATION( ExampleTestCase );

void ExampleTestCase::example()
{
  CPPUNIT_ASSERT_DOUBLES_EQUAL( 1.0, 1.1, 0.05 );
  CPPUNIT_ASSERT( 1 == 0 );
  CPPUNIT_ASSERT( 1 == 1 );
}


void ExampleTestCase::anotherExample()
{
  CPPUNIT_ASSERT (1 == 2);
}

void ExampleTestCase::setUp()
{
  m_value1 = 2.0;
  m_value2 = 3.0;
}

void ExampleTestCase::testAdd()
{
  double result = m_value1 + m_value2;
  CPPUNIT_ASSERT( result == 6.0 );
}


void ExampleTestCase::testEquals()
{
  long* l1 = new long(12);
  long* l2 = new long(12);

  CPPUNIT_ASSERT_EQUAL( 12, 12 );
  CPPUNIT_ASSERT_EQUAL( 12L, 12L );
  CPPUNIT_ASSERT_EQUAL( *l1, *l2 );

  delete l1;
  delete l2;

  CPPUNIT_ASSERT( 12L == 12L );
  CPPUNIT_ASSERT_EQUAL( 12, 13 );
  CPPUNIT_ASSERT_DOUBLES_EQUAL( 12.0, 11.99, 0.5 );
}


<main-source>
#include <cppunit/BriefTestProgressListener.h>
#include <cppunit/CompilerOutputter.h>
#include <cppunit/extensions/TestFactoryRegistry.h>
#include <cppunit/TestResult.h>
#include <cppunit/TestResultCollector.h>
#include <cppunit/TestRunner.h>


int
main()
{
  printf("--- { main\n");

  // Create the event manager and test controller
  CPPUNIT_NS::TestResult controller;

  // Add a listener that colllects test result
  CPPUNIT_NS::TestResultCollector result;
  controller.addListener( &result );        

  // Add a listener that print dots as test run.
  CPPUNIT_NS::BriefTestProgressListener progress;
  controller.addListener( &progress );      

  // Add the top suite to the test runner
  CPPUNIT_NS::TestRunner runner;
  runner.addTest( CPPUNIT_NS::TestFactoryRegistry::getRegistry().makeTest() );
  runner.run( controller );

  // Print test in a compiler compatible format.
  CPPUNIT_NS::CompilerOutputter outputter( &result, CPPUNIT_NS::stdCOut() );
  outputter.write(); 

  printf("--- } main\n");

  return result.wasSuccessful() ? 0 : 1;
}

<result-output>
--- { main
ExampleTestCase::example : assertion                  { summary
ExampleTestCase::anotherExample : assertion
ExampleTestCase::testAdd : assertion
ExampleTestCase::testEquals : assertion               }
ExampleTestCase.cpp:8:Assertion                       { details of each failure
Test name: ExampleTestCase::example
double equality assertion failed
- Expected: 1
- Actual  : 1.1
- Delta   : 0.05
                                                      }
ExampleTestCase.cpp:16:Assertion
Test name: ExampleTestCase::anotherExample
assertion failed
- Expression: 1 == 2

ExampleTestCase.cpp:28:Assertion
Test name: ExampleTestCase::testAdd
assertion failed
- Expression: result == 6.0

ExampleTestCase.cpp:45:Assertion
Test name: ExampleTestCase::testEquals
equality assertion failed
- Expected: 12
- Actual  : 13

Failures !!!
Run: 4   Failure total: 4   Failures: 4   Errors: 0
--- } main

note: failure is different from errors.


={============================================================================
*kt_dev_test_103* cppunit-macros

* Making assertions
http://cppunit.sourceforge.net/doc/1.8.0/group___assertions.html

Assers that "..." means that expect "..." true. That is assert("...").

include/cppunit/TestAssert.h

<1> #define CPPUNIT_ASSERT_EQUAL(expected, actual)

/** Asserts that two values are equals.
 * \ingroup Assertions
 *
 * Equality and string representation can be defined with
 * an appropriate CppUnit::assertion_traits class.
 *
 * A diagnostic is printed if actual and expected values disagree.
 *
 * Requirement for \a expected and \a actual parameters:
 * - They are exactly of the same type
 * - They are serializable into a std::strstream using operator <<.
 * - They can be compared using operator ==. 
 *
 * The last two requirements (serialization and comparison) can be
 * removed by specializing the CppUnit::assertion_traits.
 */

Asserts that two values are equals. That is fail if actual and expected values
disagree. 


{2} not in the 1.8.0 doc and but in the latest.

/** Asserts that the given expression throws an exception of the specified type. 
 * \ingroup Assertions
 * Example of usage:
 * \code
 *   std::vector<int> v;
 *  CPPUNIT_ASSERT_THROW( v.at( 50 ), std::out_of_range );
 * \endcode
 */
# define CPPUNIT_ASSERT_THROW( expression, ExceptionType )              \
   CPPUNIT_ASSERT_THROW_MESSAGE( CPPUNIT_NS::AdditionalMessage(),       \
                                 expression,                            \
                                 ExceptionType )

<ex> if the expression does not raise exception, then fail

    CPPUNIT_ASSERT_THROW(mr->setSink("invalid://0").get(),
                         InvalidLocatorException);


/** Asserts that the given expression throws an exception of the specified type, 
 * setting a user supplied message in case of failure. 
 * \ingroup Assertions
 * Example of usage:
 * \code
 *   std::vector<int> v;
 *  CPPUNIT_ASSERT_THROW_MESSAGE( "- std::vector<int> v;", v.at( 50 ), std::out_of_range );
 * \endcode
 */

<3>
/** Asserts that the given expression does not throw any exceptions.
 * \ingroup Assertions
 * Example of usage:
 * \code
 *   std::vector<int> v;
 *   v.push_back( 10 );
 *  CPPUNIT_ASSERT_NO_THROW( v.at( 0 ) );
 * \endcode
 */

<4>
/** Assertion with a user specified message.
 * \ingroup Assertions
 * \param message Message reported in diagnostic if \a condition evaluates
 *                to \c false.
 * \param condition If this condition evaluates to \c false then the
 *                  test failed.
 */
#define CPPUNIT_ASSERT_MESSAGE(message,condition)                          \


={============================================================================
*kt_dev_test_104* cppunit: example

void testGetEventFromSummary()
{
    // 1
    SystemClientSummary summary = make_sample_summary();

    // 2
    CPPUNIT_ASSERT_EQUAL(ENTITY_SCHEDULE_EVENT, summary.getSummaryType());
    CPPUNIT_ASSERT_NO_THROW(summary.getEvent());
    CPPUNIT_ASSERT(summary.getEvent());
    CPPUNIT_ASSERT_EQUAL(string("Eastenders"), summary.getEvent()->getTitle());
    CPPUNIT_ASSERT_EQUAL(string("mediumSynopsis"), summary.getEvent()->getSynopsis());
    CPPUNIT_ASSERT(summary.getEvent()->getService());
    CPPUNIT_ASSERT_EQUAL(string("dvb://233a..1044"), 
        summary.getEvent()->getService()->getIdentifier("locator"));
    CPPUNIT_ASSERT_EQUAL(string("dvb://233a..1044;1"), 
        summary.getEvent()->getIdentifier("locator"));
    CPPUNIT_ASSERT_EQUAL(false, summary.getEvent()->isPresent());
    CPPUNIT_ASSERT_EQUAL(false, summary.getEvent()->getReminderBookingStatus());
    CPPUNIT_ASSERT_EQUAL(METADATA_CLIENT::COMPLETED, summary.getEvent()->getRecordingStatus());
    CPPUNIT_ASSERT_EQUAL(0U, summary.getEvent()->getContainingServiceListIndex());
}

#1: Create an object to test. In this case, makes up summary object made up with
data structure.

#2: Run tests on this object.

Essentially, this mocks up an object, and excersize tests to see if returns
matches data from the mock and to see if has expected initialize value and
state.


={============================================================================
*kt_dev_test_105* cppunit: with gmock example

#1: See how to create mock object and use it for the rest using pointer.
#2: Use setUp overloads

// called by cppunit
void setUp()
{
    // this is a mock object
    mockEventRepo = boost::make_shared<NS_IRON_SYSTEM::MockEventRepositoryAsync>();
}

// each test calls this
void setUp(MetadataSource source, bool useDTTHistory = true, bool skipPFCallsSetup = false, 
        bool enableEventCache = false, bool useBrokerMock = false)
{
    ...
}

void testGetPresentEvent()
{
    // setup the mocks
    EXPECT_CALL(*mockEventRepo, getPresentFollowing(getDefaultUnifiedServices()[0].serviceLocator)).
            WillOnce(returnNewCompletedFuture(vector<NS_IRON_SYSTEM::Event>(1, getBBC1Events()[0])));

    EXPECT_CALL(*mockEventRepo, getPresentFollowing(getDefaultUnifiedServices()[1].serviceLocator)).
            WillOnce(returnNewCompletedFuture(vector<NS_IRON_SYSTEM::Event>(1, getCafeTVEvents()[0])));

    // 
    setUp(DTT_ONLY, true, true);

    // object under test
    boost::shared_ptr<NS_CLIENT::Event> e = eventRepo->getPresentEvent(0);
    
    CPPUNIT_ASSERT_MESSAGE("There should be an event returned", e);
    
    CPPUNIT_ASSERT_EQUAL(getBBC1Events()[0].eventLocator, e->getIdentifier("locator"));
    CPPUNIT_ASSERT_EQUAL(getBBC1Events()[0].shortTitle["eng"], e->getTitle());
    CPPUNIT_ASSERT_EQUAL(getBBC1Events()[0].start, (uint32_t)to_time_t(e->getStart()));
    CPPUNIT_ASSERT_EQUAL(getBBC1Events()[0].publishedDuration, (uint32_t)e->getDuration());
}


={============================================================================
*kt_dev_test_106* cppunit: display test name when run

void testEventAccessors_When_ConstructedFromAnIronEvent()
{
    cout << "\033[01;31m { " << __PRETTY_FUNCTION__ << "\033[m" << endl;

    CPPUNIT_ASSERT_EQUAL(string("The latest national and international"
        "news stories from the BBC News team, followed by weather."), 
        event.getSynopsis());

    cout << "} " << endl;
}


={============================================================================
*kt_dev_test_107* cppunit: inject dependency to object under test

This shows the way of how injecting real resources(dependencies) directly
through the constructor by using more args than using mock.

createGstMediaRouter(dispatcher);
  boost::bind(gst_pipeline_new, "pipeline"))) :

createGstMediaRouter(dispatcher,
  boost::bind(gst_pipeline_new, "pipeline")); 


={============================================================================
*kt_dev_test_108* cppunit: test runner command line options

test$ ./gstmediaroutertest --help
Allowed options:

Test runner options:
  --cases arg            Specify which test cases to run.  This is a whitespace
                         seperated list of test cases
  --list-cases           List the cases that would be run rather than 
                         runningthem
  --help                 Print this help message


CPPUNIT_TEST_SUITE(GstMediaRouterTest);
This leads to the test binary name

CPPUNIT_TEST(test_thatCallingSetSinkTwiceThrowsIllegalConfigurationException);
This leads to the each test case name

note:
When run a single test which do not have any calls to setUp() and tearDown() to
run a test, it's done by cppunit automatically.


={============================================================================
*kt_dev_test_200* gmock:

googlemock
This project has been absorbed into the GoogleTest project. All open googlemock
issues have been moved there. https://github.com/google/googletest


={============================================================================
*kt_dev_test_201* gmock-for-dummies

https://github.com/google/googletest/blob/master/googlemock/docs/ForDummies.md

* What Is Google C++ Mocking Framework?

When you write a prototype or test, often it's not feasible or wise to rely on
real objects 'entirely'. A mock object implements the same interface as a real
object so it can be used as one, but lets you 'specify' at *run-time* how it
will be used and what it should do; which methods will be called? in which
order? how many times? with what arguments? what will they return? etc.

Note: It is easy to confuse the term fake objects with mock objects. Fakes and
mocks actually mean very different things in the Test-Driven Development (TDD)
community:

<fake-and-mock>
Fake objects have working implementations, but usually take some shortcut;
perhaps to make the operations less expensive, which makes them not suitable for
    production. An in-memory file system would be an example of a fake.

Mocks are objects pre-programmed with expectations, which form a specification
of the calls they are expected to receive. 

note: not sure about difference

If all this seems too abstract for you, don't worry - the most important thing
to remember is that a mock allows you to check the 'interaction' between
'itself' and 'code' that uses it. The difference between fakes and mocks will
become much clearer once you start to use mocks.

Google C++ Mocking Framework (or Google Mock for short) is a library (sometimes
        we also call it a "framework" to make it sound cool) for creating mock
classes and using them. It does to C++ what jMock and EasyMock do to Java.


Using Google Mock involves three basic steps:

1. Use some simple macros to describe the interface you want to mock, and they
   will expand to the implementation of your mock class.

2. Create some mock objects and specify its expectations and behavior using an
   intuitive syntax.

3. Exercise code that uses the mock objects. Google Mock will catch any
   violation of the expectations as soon as it arises. 


* Why Google Mock?

While mock objects help you 'remove' unnecessary 'dependencies' in tests and make
them fast and reliable, using mocks manually in C++ is hard:

o Someone has to implement the mocks. The job is usually tedious and
error-prone. No wonder people go great distance to avoid it.

o The quality of those manually written mocks is a bit, uh, unpredictable. You
may see some really polished ones, but you may also see some that were hacked up
in a hurry and have all sorts of ad hoc restrictions.

o The knowledge you gained from using one mock doesn't transfer to the next. 

In contrast, Java and Python programmers have some fine mock frameworks, which
automate the creation of mocks. As a result, mocking is a proven effective
technique and widely adopted practice in those communities. Having the right
tool absolutely makes the difference.

Google Mock was built to help C++ programmers. It was inspired by jMock and
EasyMock, but designed with C++'s specifics in mind. It is your friend if any of
the following problems is bothering you:

note: prototying
o You are stuck with a sub-optimal design and wish you had done more prototyping
before it was too late, but prototyping in C++ is by no means "rapid".

o Your tests are slow as they depend on too many libraries or use expensive
resources e.g. a database.

o Your tests are brittle as some resources they use are unreliable e.g. the
network.

note: testing
o You want to test how your code handles a failure (e.g. a file checksum error),
  but it's not easy to cause one.

o You need to make sure that your module interacts with other modules in the
right way, but it's hard to observe the interaction; therefore you resort to
observing the side effects at the end of the action, which is awkward at best.

note: mock-out
o You want to "mock out" your dependencies, except that they don't have mock
implementations yet; and, frankly, you aren't thrilled by some of those
hand-written mocks. 


We encourage you to use Google Mock as:

o a design tool, for it lets you experiment with your interface design early and
often. More iterations lead to better designs!

o a testing tool to cut your tests' outbound dependencies and probe the
interaction between your module and its collaborators. 


* Getting Started

Using Google Mock is easy! Inside your C++ source file, just #include
"gtest/gtest.h" and "gmock/gmock.h", and you are ready to go. 


* A Case for Mock Turtles

Let's look at an example. Suppose you are developing a graphics program that
relies on a LOGO-like API for drawing. How would you test that it does the right
thing? Well, you can run it and compare the screen with a golden screen
snapshot, but let's admit it: tests like this are expensive to run and fragile. 

What if you just upgraded to a shiny new graphics card that has better
anti-aliasing? Suddenly you have to update all your golden images. It would be
too painful if all your tests are like this. Fortunately, you learned about
Dependency Injection and know the right thing to do: instead of having your
application talk to the drawing API directly, wrap the API in an interface (say,
        Turtle) and code to that interface:

note: dependency injection?

class Turtle {
  ...
  virtual ~Turtle() {}
  virtual void PenUp() = 0;
  virtual void PenDown() = 0;
  virtual void Forward(int distance) = 0;
  virtual void Turn(int degrees) = 0;
  virtual void GoTo(int x, int y) = 0;
  virtual int GetX() const = 0;
  virtual int GetY() const = 0;
};

Note that the destructor of Turtle must be virtual, as is the case for all
classes you intend to inherit from - otherwise the destructor of the derived
class will not be called when you delete an object through a base pointer, and
you'll get corrupted program states like memory leaks.

You can control whether the turtle's movement will leave a trace using PenUp()
and PenDown(), and control its movement using Forward(), Turn(), and GoTo().
Finally, GetX() and GetY() tell you the current position of the turtle.

Your program will normally use a real implementation of this interface. In
tests, you can use a *mock-implementation* instead. This allows you to easily
check what drawing primitives your program is calling, with what arguments, and
in which order. 

Tests written this way are much more robust, they won't break because your new
machine does anti-aliasing differently, easier to read and maintain; the intent
of a test is expressed in the code, not in some binary images, and run much,
   much faster. 


* Writing the Mock Class

If you are lucky, the mocks you need to use have already been implemented by
some nice people. If, however, you find yourself in the position to write a mock
class, relax - Google Mock turns this task into a fun game! Well, almost. 
  

** How to Define It

Using the Turtle interface as example, here are the simple steps you need to
follow:

1. 'derive' a class MockTurtle from Turtle.

2. Take a virtual function of Turtle while it's possible to mock non-virtual
methods using templates, it's much more involved. Count how many arguments it
has.

3. In the 'public' section of the child class, write MOCK_METHODn(); or
MOCK_CONST_METHODn(); if you are mocking a const method, where n is the 'number'
of the arguments; if you counted wrong, shame on you, and a compiler error will
tell you so.

4. Now comes the fun part: you take the function signature, cut-and-paste the
function name as the first argument to the macro, and leave what's left as the
second argument. in case you're curious, this is the type of the function.

5. Repeat until all virtual functions you want to mock are done. 

After the process, you should have something like:

// class Turtle {
//   ...
//   virtual ~Turtle() {}
//   virtual void PenUp() = 0;
//   virtual void PenDown() = 0;
//   virtual void Forward(int distance) = 0;
//   virtual void Turn(int degrees) = 0;
//   virtual void GoTo(int x, int y) = 0;
//   virtual int GetX() const = 0;
//   virtual int GetY() const = 0;
// };

#include "gmock/gmock.h"  // Brings in Google Mock.

class MockTurtle : public Turtle {
 public:
  ...
  MOCK_METHOD0(PenUp, void());
  MOCK_METHOD0(PenDown, void());
  MOCK_METHOD1(Forward, void(int distance));
  MOCK_METHOD1(Turn, void(int degrees));
  MOCK_METHOD2(GoTo, void(int x, int y));
  MOCK_CONST_METHOD0(GetX, int());
  MOCK_CONST_METHOD0(GetY, int());
};

note: do not need to define

You don't need to 'define' these mock methods somewhere else - the MOCK_METHOD*
macros will 'generate' the 'definitions' for you. It's that simple! Once you get
the hang of it, you can pump out mock classes faster than your source-control
system can handle your check-ins.

Tip: If even this is too much work for you, you'll find the gmock_gen.py tool in
Google Mock's scripts/generator/ directory (courtesy of the cppclean project)
useful. This command-line tool requires that you have Python 2.4 installed. You
give it a C++ file and the name of an abstract class defined in it, and it will
print the definition of the mock class for you. Due to the complexity of the C++
language, this script may not always work, but it can be quite handy when it
does. For more details, read the user documentation. 

http://code.google.com/p/googlemock/source/browse/trunk/scripts/generator/README


** Where to Put It

When you define a mock class, you need to decide where to put its definition.
Some people put it in a *_test.cc. This is fine when the interface being mocked
(say, Foo) is owned by the same person or team. Otherwise, when the owner of Foo
changes it, your test could break. You can't really expect Foo's maintainer to
fix every test that uses Foo, can you?

The rule of thumb is: if you need to mock Foo and it's owned by others, define
the mock class in Foo's package. Better, in a testing sub-package such that you
can clearly separate production code and testing utilities, and put it in a
mock_foo.h. Then everyone can reference mock_foo.h from their tests. If Foo ever
changes, there is only one copy of MockFoo to change, and only tests that depend
on the changed methods need to be fixed.

note: use a header and put it in testing sub package.

Another way to do it: you can introduce a thin layer FooAdaptor on top of Foo
and code to this new interface. Since you own FooAdaptor, you can absorb changes
in Foo much more easily. While this is more work initially, carefully choosing
the adaptor interface can make your code easier to write and more readable (a
        net win in the long run), as you can choose FooAdaptor to fit your
specific domain much better than Foo does. 


* Using Mocks in Tests

Once you have a mock class, using it is easy. The typical work flow is:

1. Import the Google Mock names from the "testing" namespace such that you can
use them unqualified (You only have to do it once per file. Remember that
        namespaces are a good idea and good for your health.).

2. 'create' some mock objects.

3. Specify your 'expectations' on them. How many times will a method be called?
With what arguments?  What should it do? etc.

4. 'exercise' some code that 'uses' the mocks; optionally, check the result
using Google Test assertions. If a mock method is called more than expected or
with wrong arguments, you'll get an error immediately.

5. When a mock is destructed, Google Mock will automatically check whether all
expectations on it have been satisfied. note: this causes a test failure. 

Here's an example: 

#include "path/to/mock-turtle.h"              // 0
#include "gmock/gmock.h"
#include "gtest/gtest.h"

using ::testing::AtLeast;                     // 1

TEST(PainterTest, CanDrawSomething) {
  MockTurtle turtle;                          // 2
  EXPECT_CALL(turtle, PenDown())              // 3
      .Times(AtLeast(1));

  Painter painter(&turtle);                   // 4

  EXPECT_TRUE(painter.DrawCircle(0, 0, 10));
}                                             // 5

int main(int argc, char** argv) 
{
  // The following line must be executed to initialize Google Mock
  // (and Google Test) before running the tests.
  //
  // note: does it mean that no need to call InitGoogleTest()?

  ::testing::InitGoogleMock(&argc, argv);
  return RUN_ALL_TESTS();
}

As you might have guessed, this test checks that PenDown() is called at least
once. If the painter object didn't call this method, your test will 'fail' with
a message like this:

path/to/my_test.cc:119: Failure
Actual function call count doesn't match this expectation:
Actually: never called;
Expected: called at least once.

note: the painter object is one under test that uses a turtle. so here is
mocking up "turtle" to test painter object.

// Tip 1: If you run the test from an Emacs buffer, you can hit <Enter> on the
// line number displayed in the error message to jump right to the failed
// expectation.

Tip 2: If your mock objects are never 'deleted', the final verification won't
happen. Therefore it's a good idea to use a heap leak checker in your tests when
you allocate mocks on the heap.


Important note: 
Google Mock requires expectations to be set 'before' the mock functions are
called, otherwise the behavior is 'undefined'. In particular, you mustn't
interleave EXPECT_CALL()s and calls to the mock functions.

This means EXPECT_CALL() should be read as expecting that a call will occur in
the future, not that a call has occurred. Why does Google Mock work like that?
Well, specifying the expectation beforehand allows Google Mock to report a
violation as soon as it arises, when the context such as stack trace, etc is
still available. This makes debugging much easier.

Admittedly, this test is contrived and doesn't do much. You can easily achieve
the same effect without using Google Mock. However, as we shall reveal soon,
    Google Mock allows you to do much more with the mocks. 


* Using Google Mock with Any Testing Framework

If you want to use something other than Google Test (e.g. CppUnit or CxxTest) as
your testing framework, just change the main() function in the previous section
to:

int main(int argc, char** argv) {
  // The following line causes Google Mock to throw an exception on failure,
  // which will be interpreted by your testing framework as a test failure.
  ::testing::GTEST_FLAG(throw_on_failure) = true;
  ::testing::InitGoogleMock(&argc, argv);
  ... whatever your testing framework requires ...
}

This approach has a catch: it makes Google Mock throw an exception from a mock
object's destructor sometimes. With some compilers, this sometimes causes the
test program to crash. You'll still be able to notice that the test has failed,
     but it's not a graceful failure.

A better solution is to use Google Test's event listener API to report a test
failure to your testing framework properly. You'll need to implement the
OnTestPartResult() method of the event listener interface, but it should be
straightforward.

If this turns out to be too much work, we suggest that you stick with Google
Test, which works with Google Mock seamlessly (in fact, it is technically part
        of Google Mock.). If there is a reason that you cannot use Google Test,
    please let us know. 


* Setting Expectations

<right-expectation>
The key to using a mock object successfully is to set the right expectations on
it. If you set the expectations too 'strict', your test will fail as the result
of unrelated changes. If you set them too 'loose', bugs can slip through. You
want to do it just right such that your test can catch exactly the kind of bugs
you intend it to catch. Google Mock provides the necessary means for you to do
it "just right." 

** General Syntax

In Google Mock we use the EXPECT_CALL() macro to set an expectation on a mock
method. The general 'syntax' is:

EXPECT_CALL(mock_object, method(matchers))
    .Times(cardinality)
    .WillOnce(action)
    .WillRepeatedly(action);

The macro has two arguments: first the mock object, and then the method and its
arguments. Note that the two are separated by a comma (,), not a period (.). Why
using a comma? The answer is that it was necessary for technical reasons.

<optional-clause>
The macro can be followed by some optional clauses that provide more information
about the expectation. We'll discuss how each clause works in the coming
sections.

This syntax is designed to make an expectation read like English. For example,
     you can probably guess that

using ::testing::Return;...

EXPECT_CALL(turtle, GetX())
    .Times(5)
    .WillOnce(Return(100))
    .WillOnce(Return(150))
    .WillRepeatedly(Return(200));

says that the turtle object's GetX() method will be called five times, it will
return 100 the first time, 150 the second time, and then 200 every time. Some
people like to call this style of syntax a Domain-Specific Language (DSL).

Note: Why do we use a macro to do this? It serves two purposes: first it makes
expectations easily identifiable (either by grep or by a human reader), and
second it allows Google Mock to include the source file location of a failed
expectation in messages, making debugging easier. 

note: how does this macro expands?

** Matchers: What Arguments Do We Expect?

When a mock function takes arguments, we 'must' specify what arguments we are
expecting; for example:

// Expects the turtle to move forward by 100 units.
EXPECT_CALL(turtle, Forward(100));

<do-not-care-args>
Sometimes you may not want to be too specific. Remember that talk about tests
being too rigid? Over specification leads to brittle tests and obscures the
intent of tests. Therefore we encourage you to specify only what's necessary -
no more, no less. 

<_>
If you care to check that Forward() will be called but aren't interested in its
actual argument, write _ as the argument, which means "anything goes":

using ::testing::_;
...
// Expects the turtle to move forward.
EXPECT_CALL(turtle, Forward(_));

_ is an instance of what we call 'matchers'. A matcher is like a predicate and
can test whether an argument is what we'd expect. You can use a matcher inside
EXPECT_CALL() wherever a function argument is expected.

A list of built-in matchers can be found in the CheatSheet. For example, here's
the Ge; greater than or equal matcher:
https://code.google.com/p/googlemock/wiki/CheatSheet

using ::testing::Ge;...
EXPECT_CALL(turtle, Forward(Ge(100)));

This checks that the turtle will be told to go forward by at least 100 units. 


** Cardinalities: How Many Times Will It Be Called? <cardinality-clause>

The first clause we can specify following an EXPECT_CALL() is Times(). We call
its argument a cardinality as it tells how many times the call should occur. It
allows us to repeat an expectation many times without actually writing it as
many times. More importantly, a cardinality can be "fuzzy", just like a matcher
can be. This allows a user to express the intent of a test exactly.

An interesting special case is when we say Times(0). You may have guessed - it
means that the function shouldn't be called with the 'given' arguments at all,
      and Google Mock will report a Google Test failure whenever the function is
      (wrongfully) called.

We've seen AtLeast(n) as an example of fuzzy cardinalities earlier. For the list
of built-in cardinalities you can use, see the CheatSheet.
https://code.google.com/p/googlemock/wiki/CheatSheet

The Times() clause can be omitted. If you omit Times(), Google Mock will 'infer'
the cardinality for you. The rules are easy to remember:

o If neither WillOnce() nor WillRepeatedly() is in the EXPECT_CALL(), the
inferred cardinality is Times(1).

o If there are n WillOnce()'s but no WillRepeatedly(), where n >= 1, the
cardinality is Times(n).

o If there are n WillOnce()'s and one WillRepeatedly(), where n >= 0, the
cardinality is Times(AtLeast(n)). 

note: means that n number of WillOnce() clauses

Quick quiz: what do you think will happen if a function is expected to be called
twice but actually called four times? 


** Actions: What Should It Do? <action-clause>

Remember that a mock object doesn't really have a working implementation? We as
users have to 'tell' it "what to do when a method is invoked." This is easy in
Google Mock.

First, if the return type of a mock function is a built-in type or a pointer,
    the function has a default action; a void function will just return, a bool
    function will return false, and other functions will return 0. 

In addition, in C++ 11 and above, a mock function whose return type is
default-constructible (i.e. has a default constructor) has a default action of
returning a default-constructed value. If you don't say anything, this behavior
will be used.

Second, if a mock function doesn't have a default action, or the default action
doesn't suit you, you can specify the action to be taken each time the
expectation matches using a series of WillOnce() clauses followed by an optional
WillRepeatedly(). For example,

using ::testing::Return;...
EXPECT_CALL(turtle, GetX())
    .WillOnce(Return(100))
    .WillOnce(Return(200))
    .WillOnce(Return(300));

This says that turtle.GetX() will be called exactly three times. Google Mock
inferred this from how many WillOnce() clauses we've written, since we didn't
explicitly write Times(), and will 'return' 100, 200, and 300 respectively.

using ::testing::Return;...
EXPECT_CALL(turtle, GetY())
    .WillOnce(Return(100))
    .WillOnce(Return(200))
    .WillRepeatedly(Return(300));

says that turtle.GetY() will be called at least twice (Google Mock knows this as
        we've written two WillOnce() clauses and a WillRepeatedly() while having
        no explicit Times()), will return 100 the first time, 200 the second
time, and 300 from the third time on.

Of course, if you explicitly write a Times(), Google Mock will not try to infer
the cardinality itself. What if the number you specified is larger than there
are WillOnce() clauses? Well, after all WillOnce()s are used up, Google Mock
will do the default action for the function every time (unless, of course, you
        have a WillRepeatedly().).

<can-call-function>
What can we do inside WillOnce() besides Return()? You can return a reference
using ReturnRef(variable), or invoke a pre-defined function, among others.

*important* The EXPECT_CALL() statement evaluates the action clause only 'once',
  even though the action may be performed many times. Therefore you must be
  careful about side effects. The following may not do what you want:

int n = 100;
EXPECT_CALL(turtle, GetX())
.Times(4)
.WillRepeatedly(Return(n++));

Instead of returning 100, 101, 102, ..., consecutively, this mock function will
'always' return 100 as n++ is only evaluated once. Similarly, Return(new Foo)
will create a new Foo object when the EXPECT_CALL() is executed, and will return
the same pointer every time. 

<custom-action>
If you want the side effect to happen every time, you need to define a custom
action, which we'll teach in the CookBook.

Time for another quiz! What do you think the following means?

using ::testing::Return;...
EXPECT_CALL(turtle, GetY())
.Times(4)
.WillOnce(Return(100));

Obviously turtle.GetY() is expected to be called four times. But if you think it
will return 100 every time, think twice! Remember that one WillOnce() clause
will be consumed each time the function is invoked and the 'default' action will
be taken afterwards. So the right answer is that turtle.GetY() will return 100
the first time, but return 0 from the second time on, as returning 0 is the
default action for int functions. 

// MOCK_CONST_METHOD0(GetX, int());
// MOCK_CONST_METHOD0(GetY, int());


** Using Multiple Expectations

So far we've only shown examples where you have a single expectation. More
realistically, you're going to specify expectations on multiple mock methods,
    which may be from 'multiple' mock objects.

By default, when a mock method is invoked, Google Mock will 'search' the
expectations in the 'reverse' order they are defined, and stop when an active
expectation that 'matches' the arguments is found. You can think of it as "newer
rules override older ones.". If the matching expectation cannot take any more
calls, you will get an upper-bound-violated failure. Here's an example:

using ::testing::_;...
EXPECT_CALL(turtle, Forward(_));  // #1
EXPECT_CALL(turtle, Forward(10))  // #2
    .Times(2);

If Forward(10) is called three times in a row, the third time it will be an
error, as the last matching expectation (#2) has been 'saturated'. 

If, however, the third Forward(10) call is replaced by Forward(20), then it
would be 'okay', as now #1 will be the matching expectation.

Side note: Why does Google Mock search for a match in the reverse order of the
expectations? The reason is that this allows a user to set up the 'default'
expectations in a mock object's constructor or the test fixture's set-up phase
and then customize the mock by writing more specific expectations in the test
body. So, if you have two expectations on the same method, you want to put the
one with more 'specific' matchers after the other, or the more specific rule
would be shadowed by the more general one that comes after it. 


={============================================================================
*kt_dev_test_201* gmock-for-sequence

** Ordered vs Unordered Calls

By default, an expectation can match a call even though an earlier expectation
hasn't been satisfied. In other words, the calls don't have to occur in the
order the expectations are specified.

Sometimes, you may want all the expected calls to occur in a 'strict' order. To
say this in Google Mock is easy:

using ::testing::InSequence;...
TEST(FooTest, DrawsLineSegment) {
  ...
  {
    InSequence dummy;

    EXPECT_CALL(turtle, PenDown());
    EXPECT_CALL(turtle, Forward(100));
    EXPECT_CALL(turtle, PenUp());
  }
  Foo();
}

By creating an object of type InSequence, all expectations in its 'scope' are
put into a sequence and have to occur sequentially. Since we are just relying on
the constructor and destructor of this object to do the actual work, its name is
really irrelevant.

In this example, we test that Foo() calls the three expected functions in the
order as written. If a call is made out-of-order, it will be an error.

What if you care about the relative order of some of the calls, but not all of
them? Can you specify an arbitrary partial order? The answer is ... yes! If you
are impatient, the details can be found in the CookBook. 


https://github.com/google/googletest/blob/master/googlemock/docs/CookBook.md
Expecting Partially Ordered Calls

Sometimes requiring everything to occur in a predetermined order can lead to
brittle tests. For example, we may care about A occurring before both B and C,
        but aren't interested in the relative order of B and C. In this case,
        the test should reflect our real intent, instead of being overly
        constraining.

Google Mock allows you to impose an arbitrary DAG (directed acyclic graph) on
the calls. One way to express the DAG is to use the After clause of EXPECT_CALL.

Another way is via the InSequence() clause (not the same as the InSequence
        class), which we borrowed from jMock 2. It's less flexible than After(),
        but more convenient when you have long chains of sequential calls, as it
        doesn't require you to come up with different names for the expectations
        in the chains. Here's how it works:

If we view EXPECT_CALL() statements as nodes in a graph, and add an edge from
node A to node B wherever A must occur before B, we can get a DAG. We use the
term "sequence" to mean a directed path in this DAG. Now, if we decompose the
DAG into sequences, we just need to know which sequences each EXPECT_CALL()
    belongs to in order to be able to reconstruct the orginal DAG.

So, to specify the partial order on the expectations we need to do two things:
first to define some Sequence objects, and then for each EXPECT_CALL() say which
Sequence objects it is part of. Expectations in the same sequence must occur in
the order they are written. For example,

  using ::testing::Sequence;

  Sequence s1, s2;

  EXPECT_CALL(foo, A())
      .InSequence(s1, s2);
  EXPECT_CALL(bar, B())
      .InSequence(s1);
  EXPECT_CALL(bar, C())
      .InSequence(s2);
  EXPECT_CALL(foo, D())
      .InSequence(s2);

specifies the following DAG (where s1 is A -> B, and s2 is A -> C -> D):

       +---> B
       |
  A ---|
       |
       +---> C ---> D

This means that A must occur before B and C, and C must occur before D. There's
no restriction about the order other than these.


={============================================================================
*kt_dev_test_201* gmock-for-sequence

** All Expectations Are Sticky (Unless Said Otherwise)

Now let's do a quick quiz to see how well you can use this mock stuff already.
How would you test that the turtle is asked to go to the origin exactly twice.
you want to ignore any other instructions it receives?

After you've come up with your answer, take a look at ours and compare notes.
solve it yourself first - don't cheat!:

using ::testing::_;...
EXPECT_CALL(turtle, GoTo(_, _))  // #1
    .Times(AnyNumber());
EXPECT_CALL(turtle, GoTo(0, 0))  // #2
    .Times(2);

Suppose turtle.GoTo(0, 0) is called three times. In the third time, Google Mock
will see that the arguments match expectation #2. Remember that we always pick
the last matching expectation. 

Now, since we said that there should be only two such calls, Google Mock will
report an error immediately. This is basically what we've told you in the "Using
Multiple Expectations" section above.

This example shows that expectations in Google Mock are *sticky* by default, in
the sense that they 'remain' active even 'after' we have reached their
invocation upper bounds. This is an important rule to remember, as it affects
the meaning of the spec, and is different to how it's done in many other mocking
frameworks (Why'd we do that? Because we think our rule makes the common cases
    easier to express and understand.).

Simple? Let's see if you've really understood it: what does the following code
say?

using ::testing::Return;
...
for (int i = n; i > 0; i--) {
  EXPECT_CALL(turtle, GetX())
      .WillOnce(Return(10*i));
}

If you think it says that turtle.GetX() will be called n times and will return
10, 20, 30, ..., consecutively, think twice! The problem is that, as we said,
    expectations are sticky. So, the second time turtle.GetX() is called, the
    last (latest) EXPECT_CALL() statement will match, and will immediately lead
    to an "upper bound exceeded" error - this piece of code is not very useful!

One correct way of saying that turtle.GetX() will return 10, 20, 30, ..., is to
explicitly say that the expectations are not sticky. In other words, they should
retire as soon as they are saturated:

using ::testing::Return;
...
for (int i = n; i > 0; i--) {
  EXPECT_CALL(turtle, GetX())
    .WillOnce(Return(10*i))
    .RetiresOnSaturation();
}

And, there's a better way to do it: in this case, we expect the calls to occur
in a specific order, and we line up the actions to match the order. Since the
order is important here, we should make it explicit using a sequence:

using ::testing::InSequence;
using ::testing::Return;
...
{
  InSequence s;

  for (int i = 1; i <= n; i++) {
    EXPECT_CALL(turtle, GetX())
        .WillOnce(Return(10*i))
        .RetiresOnSaturation();
  }
}

By the way, the other situation where an expectation may not be sticky is when
it's in a sequence - as soon as another expectation that comes after it in the
sequence has been used, it automatically retires (and will never be used to
        match any call). 


** Uninteresting Calls

A mock object may have many methods, and not all of them are that interesting.
For example, in some tests we may not care about how many times GetX() and
GetY() get called.

In Google Mock, if you are not interested in a method, just do 'not' say
anything about it. If a call to this method occurs, you'll see a warning in the
test output, but it won't be a failure.  

* What Now?

Congratulations! You've learned enough about Google Mock to start using it. Now,
    you might want to join the googlemock discussion group and actually write
    some tests using Google Mock - it will be fun. Hey, it may even be addictive
    - you've been warned.

Then, if you feel like increasing your mock quotient, you should move on to the
CookBook. You can learn many advanced features of Google Mock there -- and
advance your level of enjoyment and testing bliss. 


={============================================================================
*kt_dev_test_202* gmock: example

<1> use gmock and cppunit

class X {

class RepositoryTest : public CppUnit::TestFixture 
{

    void setUp()
    {
        // note: 
        // Create a mock object once and use it throughout tests
        mockMB = boost::make_shared<NS_IRON_SYSTEM::MockEventRepositoryAsync>();
    }

    void testGetScheduleEventFull()
    {
        NS_X_SYSTEM::Result result;
        result.recordIdentifier = "id12";

        // note: <custom-action>
        EXPECT_CALL(*mockMB, getEvent("abc"))
            .WillOnce(returnNewCompletedFuture(result));

        // note: Broker is from setUp()
        NS_Z::Future<FullEventPtr> f = Broker->getFullEvent("abc");
        boost::shared_ptr<FullEvent> fe(f.get());

        CPPUNIT_ASSERT(fe);
        CPPUNIT_ASSERT_EQUAL(result.recordIdentifier, fe->getRecordIdentifier());
    }
};


={============================================================================
*kt_dev_test_203* gmock: cook: write action

https://code.google.com/p/googlemock/wiki/CookBook#Writing_New_Actions_Quickly

* Writing New Actions Quickly

If the built-in actions don't work for you, and you find it inconvenient to use
Invoke(), you can use a macro from the ACTION* family to quickly define a new
action that can be used in your code as if it's a built-in action.

By writing

ACTION(name) { statements; }

In a namespace scope (i.e. not inside a class or function), you will define an
    action with the given name that executes the statements. The value returned
    by statements will be used as the return value of the action. Inside the
    statements, you can refer to the K-th (0-based) argument of the mock
    function as argK. For example:

ACTION(IncrementArg1) { return ++(*arg1); }

allows you to write

... WillOnce(IncrementArg1());

Note that you don't need to specify the types of the mock function arguments.
    Rest assured that your code is type-safe though: you'll get a compiler error
    if *arg1 doesn't support the ++ operator, or if the type of ++(*arg1) isn't
        compatible with the mock function's return type.

Another example:

ACTION(Foo) {
  (*arg2)(5);
  Blah();
  *arg1 = 0;
  return arg0;
}

defines an action Foo() that invokes argument #2 (a function pointer) with 5,
        calls function Blah(), sets the value pointed to by argument #1 to 0,
        and returns argument #0.

For more convenience and flexibility, you can also use the following pre-defined
symbols in the body of ACTION: 


* Writing New Parameterized Actions Quickly

Sometimes you'll want to 'parameterize' an action you define. For that we have
another macro

ACTION_P(name, param) { statements; }

For example,

ACTION_P(Add, n) { return arg0 + n; }

will allow you to write

// Returns argument #0 + 5.
... WillOnce(Add(5));

For convenience, we use the term 'arguments' for the values used to invoke the
mock function, and the term 'parameters' for the values used to instantiate an
action.

Note that you don't need to provide the type of the parameter either. Suppose
the parameter is named param, you can also use the Google-Mock-defined symbol
param_type to refer to the type of the parameter as inferred by the compiler.
For example, in the body of ACTION_P(Add, n) above, you can write n_type for the
type of n.

Google Mock also provides ACTION_P2, ACTION_P3, and etc to support
multi-parameter actions. For example,

ACTION_P2(ReturnDistanceTo, x, y) {
  double dx = arg0 - x;
  double dy = arg1 - y;
  return sqrt(dx*dx + dy*dy);
}

lets you write

... WillOnce(ReturnDistanceTo(5.0, 26.5));

You can view ACTION as a degenerated parameterized action where the number of
parameters is 0.

You can also easily define actions overloaded on the number of parameters:

ACTION_P(Plus, a) { ... }
ACTION_P2(Plus, a, b) { ... }


<ex>
/**
 * These helper actions are for use with Google Mock objects.
 *
 * When returning a future from a mock object expectation, care is needed to
 * make sure a new future is created each time the expectation is matched.
 * This shows up as a problem when setCallback is called on the returned future.
 *
 * The problem is that when using something like:
 *
 * EXPECT_CALL( ... ).WillRepeatedly(Return(FunctionThatReturnsAFuture()));
 *
 * Google Mock will copy the future returned from `FunctionThatReturnsAFuture()`
 * and always return the same future. This doesn't work for instance if you ever
 * call setCallback() on that future, which will throw a
 * DuplicateFutureCallback error on subsequent calls.
 *
 * Even this doesn't work, surprisingly:
 *
 * EXPECT_CALL( ... ).WillOnce(Return(FunctionThatReturnsAFuture()))
 *                   .WillOnce(Return(FunctionThatReturnsAFuture()));
 *
 * Again, the same promise is returned. I'm not quite sure how that happens
 * though.
 *
 * This can be used like this:
 *
 * EXPECT_CALL( ... ).WillOnce(returnNewCompletedFuture(someValue))
 *
 */

// copied again:
// Important note: The EXPECT_CALL() statement evaluates the action clause only
// 'once', even though the action may be performed many times. Therefore you
// must be careful about side effects. The following may not do what you want:

ACTION(returnNewCompletedFuture) {
    return completedFuture();
}

ACTION_P(returnNewCompletedFuture, value) {
    return completedFuture<typename return_type::value_type>(value);
}

ACTION_P(returnNewExceptionalFuture, exception) {
    return exceptionalFuture<typename return_type::value_type>(exception);
}


={============================================================================
*kt_dev_test_204* gmock: cheat: cardinality

https://code.google.com/p/googlemock/wiki/CheatSheet

Cardinalities
These are used in Times() to specify how many times a mock function will be
called:

AnyNumber()
The function can be called any number of times.

AtLeast(n)
The call is expected at least n times.

AtMost(n)
The call is expected at most n times.

Between(m, n)
The call is expected between m and n (inclusive) times.

Exactly(n) or n 
The call is expected exactly n times. In particular, the call should never
happen when n is 0.


={============================================================================
*kt_dev_test_205* gmock: cheat: using a function as action

Using a Function or a Functor as an Action

Invoke(f)
Invoke f with the arguments passed to the mock function, where f can be a
global/static function or a functor.

Invoke(object_pointer, &class::method)
Invoke the method on the object with the arguments passed to the mock function.

InvokeWithoutArgs(f)
Invoke f, which can be a global/static function or a functor. f must take no
arguments.

InvokeWithoutArgs(object_pointer, &class::method)
Invoke the method on the object, which takes no arguments.

InvokeArgument<N>(arg1, arg2, ..., argk)
Invoke the mock function's N-th (0-based) argument, which must be a function or
a functor, with the k arguments.

The 'return' value of the invoked function is used as the return value of the
action.

When defining a function or functor to be used with Invoke*(), you can declare
any unused parameters as Unused:

double Distance(Unused, double x, double y) { return sqrt(x*x + y*y); }
...
EXPECT_CALL(mock, Foo("Hi", _, _)).WillOnce(Invoke(Distance));

In InvokeArgument<N>(...), if an argument needs to be passed by reference, wrap
  it inside ByRef(). For example,

InvokeArgument<2>(5, string("Hi"), ByRef(foo))

calls the mock function's #2 argument, passing to it 5 and string("Hi") by
value, and foo by reference. 


={============================================================================
*kt_dev_test_206* gmock: cheat: combine actions

Combining Actions

Want to do more than one thing when a function is called? That's fine. DoAll()
allow you to do 'sequence' of actions every time. Only the return value of the
'last' action in the sequence will be used.

using ::testing::DoAll;

class MockFoo : public Foo {
 public:
  MOCK_METHOD1(Bar, bool(int n));
};
...

  EXPECT_CALL(foo, Bar(_))
      .WillOnce(DoAll(action_1,
                      action_2,
                      ...
                      action_n));


={============================================================================
*kt_dev_test_207* gmock: cook: nice and strict mock

Some of the mocks are called quite often and are expected to have some default
reaction which is expressed with WillByDefault() statement in setUp(). This
still results is "Uninteresting mock call" warning generated pointing at the
default value defined in setUp().

To make output less verbose and avoid warning for mocks which are know to
return some default, NiceMock template can be used. This commit wraps to of
the mock objects known to have default value returned with NiceMock. This
reduces the noise in the output while running the test. 

https://code.google.com/p/googlemock/wiki/CookBook

The Nice, the Strict, and the Naggy

If a mock method has no EXPECT_CALL spec but is called, Google Mock will print
a warning about the "uninteresting call". The 'rationale' is:

New methods may be added to an interface after a test is written. We shouldn't
fail a test just because a method it doesn't know about is called. However,
this may also mean there's a bug in the test, so Google Mock shouldn't be
  silent either. If the user believes these calls are harmless, he can add an
  EXPECT_CALL() to suppress the warning. 

However, sometimes you may want to suppress all "uninteresting call" warnings,
while sometimes you may want the opposite, i.e. to treat all of them as
  errors. Google Mock lets you make the decision on a per-mock-object basis.

Suppose your test uses a mock class MockFoo:

TEST(...) {
  MockFoo mock_foo;
  EXPECT_CALL(mock_foo, DoThis());
  ... code that uses mock_foo ...
}

<nice-mock>
If a method of mock_foo other than DoThis() is called, it will be reported by
Google Mock as a warning. However, if you rewrite your test to use
NiceMock<MockFoo> instead, the warning will be 'gone', resulting in a cleaner
test output:

using ::testing::NiceMock;

TEST(...) {
  NiceMock<MockFoo> mock_foo;
  EXPECT_CALL(mock_foo, DoThis());
  ... code that uses mock_foo ...
}

NiceMock<MockFoo> is a subclass of MockFoo, so it can be used wherever MockFoo
is accepted.

It also works if MockFoo's constructor takes some arguments, as
NiceMock<MockFoo> "inherits" MockFoo's constructors:

using ::testing::NiceMock;

TEST(...) {
  NiceMock<MockFoo> mock_foo(5, "hi");  // Calls MockFoo(5, "hi").
  EXPECT_CALL(mock_foo, DoThis());
  ... code that uses mock_foo ...
}


<strict-mock>
The usage of StrictMock is similar, 'except' that it makes all uninteresting
calls failures:

using ::testing::StrictMock;

TEST(...) {
  StrictMock<MockFoo> mock_foo;
  EXPECT_CALL(mock_foo, DoThis());
  ... code that uses mock_foo ...

  // The test will fail if a method of mock_foo other than DoThis()
  // is called.
}

There are some caveats though (I don't like them just as much as the next guy,
    but sadly they are side effects of C++'s limitations):

NiceMock<MockFoo> and StrictMock<MockFoo> only work for mock methods defined
using the MOCK_METHOD* family of macros directly in the MockFoo class. If a
mock method is defined in a base class of MockFoo, the "nice" or "strict"
modifier may not affect it, depending on the compiler. In particular, nesting
NiceMock and StrictMock (e.g. NiceMock<StrictMock<MockFoo> >) is not
supported.

The constructors of the base mock (MockFoo) cannot have arguments passed by
non-const reference, which happens to be banned by the Google C++ style guide.

During the constructor or destructor of MockFoo, the mock object is not nice
or strict. This may cause surprises if the constructor or destructor calls a
mock method on this object. 

This behavior, however, is consistent with C++'s general rule: if a
constructor or destructor calls a virtual method of this object, that method
is treated as non-virtual. In other words, to the base class's constructor or
destructor, this object behaves like an instance of the base class, not the
derived class. This rule is required for safety. Otherwise a base constructor
may use members of a derived class before they are initialized, or a base
destructor may use members of a derived class after they have been destroyed. 

Finally, you should be very cautious about when to use naggy or strict mocks,
  as they tend to make tests more brittle and harder to maintain. When you
  refactor your code without changing its externally visible behavior, ideally
  you should't need to update any tests. If your code interacts with a naggy
  mock, however, you may start to get spammed with warnings as the result of
  your change. Worse, if your code interacts with a strict mock, your tests
  may start to fail and you'll be forced to fix them. 
  
Our general recommendation is to use nice mocks (not yet the default) most of
the time, use naggy mocks (the current default) when developing or debugging
tests, and use strict mocks only as the last resort. 


={============================================================================
*kt_dev_test_208* gmock-errors when misses expectation

This fails the test.

<ex>
Do not have expectaion of a call but there is.

terminate called after throwing an instance of 'std::runtime_error'
  what():  Uninteresting mock function call - returning default value.
    Function call: setSource(@0x7ffd3f3eda50 "http://bbc.co.uk/xx.mpd", 1)
    The mock function has no default action set, and its return type 
    has no default value set.
Aborted
FAIL: test/js/testplay


<ex>
Do have expectation but uses return value. Expected ErrorValue::locator but
returned ErrorValue::data and regarded as 'not' called.

Actual function call count doesn't match 
  EXPECT_CALL(*listener, ErrorEvent(ErrorValue::locator,
  ErrorEventContext::source,_))...
         Expected: to be called once
           Actual: never called - unsatisfied and active
F..unknown file: Failure


<ex>
This is when EXPECT_CALL( *listener, ErrorEvent( 6, 0, _)) but object returns
ErrorEvent(6, 1). See arg# starts 0.

Unexpected mock function call - returning directly.
    Function call: ErrorEvent(6, 1, @0x18da938 "\nGStreamer error domain: gst-resource-error-quark\nAdditional debug:\n(no debug)")
Google Mock tried the following 1 expectation, but it didn't match:

/home/kpark/builds/_virtual_/pc/DEVARCH/Nickel/Nickel.System.GStreamer/test/GstMediaRouterTest.cpp:1341: EXPECT_CALL(*listener, ErrorEvent(errorVal, context, _))...
  Expected arg #1: is equal to 0
           Actual: 1
         Expected: to be called once
           Actual: never called - unsatisfied and active

Actual function call count doesn't match EXPECT_CALL(*listener, ErrorEvent(errorVal, context, _))...
         Expected: to be called once
           Actual: never called - unsatisfied and active
F

GstMediaRouterTest.cpp:1348:Assertion
Test name: nickel::system::GstMediaRouterTest::test_that404OnResourceError
assertion failed
- Expression: success
- done.get() did not happen within DEFAULT_TIMEOUTms

VerifyAndClearMock.h:36:Assertion
Test name: nickel::system::GstMediaRouterTest::test_that404OnResourceError
tearDown() failed
- forced failure
- Mock::VerifyAndClear( listener ) failed at line: 479

Failures !!!
Run: 1   Failure total: 2   Failures: 2   Errors: 0


={============================================================================
*kt_dev_test_208* gmock: case example

void GstMediaRouterTest::test_thatGetPositionReturnsStableValues()
{
    NS_ZINC::AtomicBool done;

    EXPECT_CALL(
            *listener, SourceEvent(_, _))
        .Times(AnyNumber());

    EXPECT_CALL(
            *listener, BufferStatusEvent(_))
        .Times(AnyNumber());

    // note:
    // Each time when it gets called, that is gets an event, invoke the function
    // which set done to true.

    EXPECT_CALL(*listener, StatusEvent(StatusEventValue::started))
        .Times(3)
        .WillRepeatedly(InvokeWithoutArgs(boost::function<void(void)>(
                        boost::bind(&NS_ZINC::AtomicBool::set,
                            boost::ref(done), true))));

    EXPECT_CALL(*listener, StatusEvent(StatusEventValue::seek_started))
        .Times(2)
        .WillRepeatedly(InvokeWithoutArgs(boost::function<void(void)>(
                        boost::bind(&NS_ZINC::AtomicBool::set,
                            boost::ref(done), false))));

    mr->setSource(server.getManifestUrl(), SetSourceReason::unspecified).get();
    mr->setSink("decoder://headless").get();
    mr->start().get();

    // note:
    // This waits for some time and do assert on if there is no the first event
    // fired. Not all three events. 

    ZINC_ASSERT_WITHIN_TIMEOUT(done.get(), DEFAULT_TIMEOUT);

    mr->setPlaySpeed(0.0).get();
    mr->seekPosition(SeekReference::end, 0, SeekMode::prioritise_speed).get();

    ZINC_ASSERT_WITHIN_TIMEOUT(done.get(), DEFAULT_TIMEOUT);

    const int32_t seek_amount = 10000;
    const int32_t position_slack = 200;

    mr->seekPosition(SeekReference::end, seek_amount, SeekMode::prioritise_speed).get();

    while (!done.get()) {
        // The assertion below needs to take into account the fact that when MR is
        // paused current position will be changing because seekable range as seen
        // by DashDemux will be tied to wall clock hence it will keep moving.
        Position p = mr->getPosition().get();
        CPPUNIT_ASSERT(p.current > -seek_amount - position_slack &&
                p.current < -seek_amount + position_slack);
    }

    mr->stop().get();
}


# ============================================================================
#{
={============================================================================
*kt_dev_ref*	references

{ref-001} data structure and program design in C/C++, 2nd Ed, Robert Kruse, Prentice Hall.
ftp://ftp.prenhall.com/pub/esm/computer_science.s-041/kruse/cpp/

{ref-002} thinking in C++. 
http://www.mindviewinc.com/Books/

{ref-003} design patterns, Erich Gamma and et el. Addison Wesley

{ref-004} cracking the coding interview, 5th Ed.

{ref-005} C++ primer, 5th Ed.

==============================================================================
Copyright: see |ktkb|  vim:tw=100:ts=3:ft=help:norl:
